Python 2.7.18
Python 3.8.5
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 1, 'noise_multiplier': 1e-05, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
resampled train counts:  tensor([ 532,  497,  521,  486,  510, 3034, 2938, 3079, 2965, 2998])
resampled test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
training set size:  (17560, 3, 32, 32)
test set size:  (17495, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.658197 Acc@1: 0.031206 (ε = 5500000079.72, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.430546 Acc@1: 0.182616 (ε = 60499999725.65, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.448098 Acc@1: 0.191002 (ε = 115499999371.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.004933 Acc@1: 0.199154 
Base private model test accuracy:  0.1988568162332095
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.00      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.00      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.00      0.00      0.00      2972
         6.0       0.63      0.07      0.12      3080
         7.0       0.30      0.00      0.00      2961
         8.0       0.25      0.98      0.39      3024
         9.0       0.06      0.11      0.08      3003

    accuracy                           0.20     17495
   macro avg       0.12      0.11      0.06     17495
weighted avg       0.21      0.20      0.10     17495

Base private model train accuracy:  0.1938496583143508
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       532
         1.0       0.00      0.00      0.00       497
         2.0       0.00      0.00      0.00       521
         3.0       0.00      0.00      0.00       486
         4.0       0.00      0.00      0.00       510
         5.0       0.00      0.00      0.00      3034
         6.0       0.54      0.06      0.11      2938
         7.0       0.14      0.00      0.00      3079
         8.0       0.24      0.98      0.39      2965
         9.0       0.06      0.10      0.08      2998

    accuracy                           0.19     17560
   macro avg       0.10      0.11      0.06     17560
weighted avg       0.17      0.19      0.10     17560

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5345102505694761
test acc: 0.4821081513661827
min train acc: 0.7279179810725552
maj train acc: 0.5014020563493123
min test acc: 0.3057784911717496
maj test acc: 0.5113833044867528
total acc: 0.5083585325497804
total min acc: 0.5186953062848051
total maj acc: 0.5064
precision, recall: (0.5088366041418194, 0.5345102505694761)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['none', 0.5, 137499999229.9384, 0.1988568162332095, 0.1938496583143508, 0.5083585325497804, 0.5186953062848051, 0.5064, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.00      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.00      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.00      0.00      0.00      2972\n         6.0       0.63      0.07      0.12      3080\n         7.0       0.30      0.00      0.00      2961\n         8.0       0.25      0.98      0.39      3024\n         9.0       0.06      0.11      0.08      3003\n\n    accuracy                           0.20     17495\n   macro avg       0.12      0.11      0.06     17495\nweighted avg       0.21      0.20      0.10     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       532\n         1.0       0.00      0.00      0.00       497\n         2.0       0.00      0.00      0.00       521\n         3.0       0.00      0.00      0.00       486\n         4.0       0.00      0.00      0.00       510\n         5.0       0.00      0.00      0.00      3034\n         6.0       0.54      0.06      0.11      2938\n         7.0       0.14      0.00      0.00      3079\n         8.0       0.24      0.98      0.39      2965\n         9.0       0.06      0.10      0.08      2998\n\n    accuracy                           0.19     17560\n   macro avg       0.10      0.11      0.06     17560\nweighted avg       0.17      0.19      0.10     17560\n']
experiment_number: 177
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-177.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 3.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3066, 2949, 3108, 3070, 2941, 3077, 3034, 2994, 3017, 3014])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30270, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.944095 Acc@1: 0.102244 (ε = 0.21, δ = 1e-05) for α = 57.0
	Train Epoch: 1 	Loss: 3.032997 Acc@1: 0.124632 (ε = 0.29, δ = 1e-05) for α = 56.0
	Train Epoch: 1 	Loss: 2.900253 Acc@1: 0.118390 (ε = 0.36, δ = 1e-05) for α = 54.0
	Test set:Loss: 2.304094 Acc@1: 0.158469 
	Train Epoch: 2 	Loss: 2.306770 Acc@1: 0.097561 (ε = 0.40, δ = 1e-05) for α = 51.0
	Train Epoch: 2 	Loss: 2.300278 Acc@1: 0.123128 (ε = 0.46, δ = 1e-05) for α = 45.0
	Train Epoch: 2 	Loss: 2.351852 Acc@1: 0.132376 (ε = 0.51, δ = 1e-05) for α = 42.0
	Test set:Loss: 2.500672 Acc@1: 0.087324 
	Train Epoch: 3 	Loss: 2.351738 Acc@1: 0.139724 (ε = 0.53, δ = 1e-05) for α = 40.0
	Train Epoch: 3 	Loss: 2.322033 Acc@1: 0.156330 (ε = 0.58, δ = 1e-05) for α = 37.0
	Train Epoch: 3 	Loss: 2.349610 Acc@1: 0.165761 (ε = 0.62, δ = 1e-05) for α = 35.0
	Test set:Loss: 2.274723 Acc@1: 0.123546 
	Train Epoch: 4 	Loss: 2.347143 Acc@1: 0.169576 (ε = 0.64, δ = 1e-05) for α = 34.0
	Train Epoch: 4 	Loss: 2.253562 Acc@1: 0.160845 (ε = 0.68, δ = 1e-05) for α = 33.0
	Train Epoch: 4 	Loss: 2.292999 Acc@1: 0.164996 (ε = 0.71, δ = 1e-05) for α = 31.0
	Test set:Loss: 2.178046 Acc@1: 0.275970 
	Train Epoch: 5 	Loss: 2.313402 Acc@1: 0.174831 (ε = 0.73, δ = 1e-05) for α = 31.0
	Train Epoch: 5 	Loss: 2.310088 Acc@1: 0.173475 (ε = 0.76, δ = 1e-05) for α = 29.0
	Train Epoch: 5 	Loss: 2.282437 Acc@1: 0.171562 (ε = 0.79, δ = 1e-05) for α = 28.0
	Test set:Loss: 2.338951 Acc@1: 0.166618 
	Train Epoch: 6 	Loss: 2.314947 Acc@1: 0.188860 (ε = 0.81, δ = 1e-05) for α = 28.0
	Train Epoch: 6 	Loss: 2.294715 Acc@1: 0.186661 (ε = 0.84, δ = 1e-05) for α = 27.0
	Train Epoch: 6 	Loss: 2.311526 Acc@1: 0.185165 (ε = 0.86, δ = 1e-05) for α = 26.0
	Test set:Loss: 2.362647 Acc@1: 0.177151 
	Train Epoch: 7 	Loss: 2.261214 Acc@1: 0.213771 (ε = 0.88, δ = 1e-05) for α = 26.0
	Train Epoch: 7 	Loss: 2.380866 Acc@1: 0.192923 (ε = 0.91, δ = 1e-05) for α = 25.0
	Train Epoch: 7 	Loss: 2.423636 Acc@1: 0.195281 (ε = 0.93, δ = 1e-05) for α = 25.0
	Test set:Loss: 2.364659 Acc@1: 0.154899 
	Train Epoch: 8 	Loss: 2.414460 Acc@1: 0.196277 (ε = 0.95, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.528197 Acc@1: 0.198687 (ε = 0.97, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.427272 Acc@1: 0.199631 (ε = 1.00, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.392363 Acc@1: 0.153581 
	Train Epoch: 9 	Loss: 2.464207 Acc@1: 0.192653 (ε = 1.01, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.439158 Acc@1: 0.203873 (ε = 1.03, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.430361 Acc@1: 0.195426 (ε = 1.05, δ = 1e-05) for α = 22.0
	Test set:Loss: 2.376822 Acc@1: 0.085685 
	Train Epoch: 10 	Loss: 2.438458 Acc@1: 0.180508 (ε = 1.07, δ = 1e-05) for α = 22.0
	Train Epoch: 10 	Loss: 2.410448 Acc@1: 0.192963 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 10 	Loss: 2.384889 Acc@1: 0.188827 (ε = 1.11, δ = 1e-05) for α = 21.0
	Test set:Loss: 2.287460 Acc@1: 0.210649 
	Train Epoch: 11 	Loss: 2.491336 Acc@1: 0.163636 (ε = 1.12, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.341232 Acc@1: 0.186075 (ε = 1.14, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.347417 Acc@1: 0.180188 (ε = 1.16, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.405655 Acc@1: 0.143810 
	Train Epoch: 12 	Loss: 2.338570 Acc@1: 0.207237 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.471285 Acc@1: 0.193722 (ε = 1.19, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.476681 Acc@1: 0.191763 (ε = 1.22, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.292256 Acc@1: 0.191118 
	Train Epoch: 13 	Loss: 2.280705 Acc@1: 0.189573 (ε = 1.23, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.464694 Acc@1: 0.184760 (ε = 1.24, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.383454 Acc@1: 0.181585 (ε = 1.26, δ = 1e-05) for α = 19.0
	Test set:Loss: 2.246897 Acc@1: 0.210090 
	Train Epoch: 14 	Loss: 2.344288 Acc@1: 0.183690 (ε = 1.27, δ = 1e-05) for α = 19.0
	Train Epoch: 14 	Loss: 2.314715 Acc@1: 0.195250 (ε = 1.29, δ = 1e-05) for α = 18.0
	Train Epoch: 14 	Loss: 2.308467 Acc@1: 0.195089 (ε = 1.31, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.279922 Acc@1: 0.171600 
	Train Epoch: 15 	Loss: 2.382737 Acc@1: 0.215798 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.351416 Acc@1: 0.205587 (ε = 1.34, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.356090 Acc@1: 0.203061 (ε = 1.36, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.323360 Acc@1: 0.182487 
	Train Epoch: 16 	Loss: 3.626113 Acc@1: 0.211232 (ε = 1.37, δ = 1e-05) for α = 18.0
	Train Epoch: 16 	Loss: 2.408108 Acc@1: 0.211753 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 16 	Loss: 2.341445 Acc@1: 0.210994 (ε = 1.40, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.206657 Acc@1: 0.260622 
	Train Epoch: 17 	Loss: 2.307086 Acc@1: 0.209976 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.405861 Acc@1: 0.212598 (ε = 1.43, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.474394 Acc@1: 0.216796 (ε = 1.44, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.168447 Acc@1: 0.283213 
	Train Epoch: 18 	Loss: 2.305226 Acc@1: 0.231385 (ε = 1.45, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.265295 Acc@1: 0.224778 (ε = 1.47, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.325584 Acc@1: 0.228412 (ε = 1.49, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.246837 Acc@1: 0.280506 
	Train Epoch: 19 	Loss: 2.174482 Acc@1: 0.241519 (ε = 1.49, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.266529 Acc@1: 0.233510 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.267182 Acc@1: 0.232988 (ε = 1.53, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.177832 Acc@1: 0.238433 
	Train Epoch: 20 	Loss: 2.237127 Acc@1: 0.225884 (ε = 1.53, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.246399 Acc@1: 0.220824 (ε = 1.55, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.268036 Acc@1: 0.224864 (ε = 1.57, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.213497 Acc@1: 0.265563 
	Train Epoch: 21 	Loss: 2.236704 Acc@1: 0.213169 (ε = 1.58, δ = 1e-05) for α = 16.0
	Train Epoch: 21 	Loss: 2.295857 Acc@1: 0.228059 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 21 	Loss: 2.348427 Acc@1: 0.227282 (ε = 1.61, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.247841 Acc@1: 0.233664 
	Train Epoch: 22 	Loss: 2.201833 Acc@1: 0.236615 (ε = 1.61, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.221427 Acc@1: 0.234228 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.217667 Acc@1: 0.235321 (ε = 1.64, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.238276 Acc@1: 0.242612 
	Train Epoch: 23 	Loss: 2.274534 Acc@1: 0.255795 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.215810 Acc@1: 0.244588 (ε = 1.67, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.209521 Acc@1: 0.243757 (ε = 1.68, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.175679 Acc@1: 0.284716 
	Train Epoch: 24 	Loss: 2.244765 Acc@1: 0.247954 (ε = 1.69, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.251133 Acc@1: 0.238179 (ε = 1.70, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.259366 Acc@1: 0.236732 (ε = 1.72, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.210064 Acc@1: 0.263685 
	Train Epoch: 25 	Loss: 2.109059 Acc@1: 0.251036 (ε = 1.72, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.321357 Acc@1: 0.241113 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.283320 Acc@1: 0.240759 (ε = 1.75, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.230210 Acc@1: 0.253029 
	Train Epoch: 26 	Loss: 2.220743 Acc@1: 0.235577 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.213884 Acc@1: 0.242042 (ε = 1.77, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.293597 Acc@1: 0.243179 (ε = 1.79, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.199763 Acc@1: 0.283053 
	Train Epoch: 27 	Loss: 2.204681 Acc@1: 0.256601 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.512899 Acc@1: 0.236962 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.524169 Acc@1: 0.241311 (ε = 1.82, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.204692 Acc@1: 0.265540 
	Train Epoch: 28 	Loss: 2.303202 Acc@1: 0.233100 (ε = 1.83, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.358068 Acc@1: 0.246740 (ε = 1.84, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.284919 Acc@1: 0.246926 (ε = 1.86, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.202478 Acc@1: 0.266786 
	Train Epoch: 29 	Loss: 2.158451 Acc@1: 0.249807 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.211255 Acc@1: 0.243022 (ε = 1.88, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.221366 Acc@1: 0.241387 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.204583 Acc@1: 0.265777 
	Train Epoch: 30 	Loss: 2.202689 Acc@1: 0.253344 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.214497 Acc@1: 0.243222 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.211707 Acc@1: 0.242740 (ε = 1.92, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.202474 Acc@1: 0.266403 
Base private model test accuracy:  0.26653329522720776
              precision    recall  f1-score   support

         0.0       0.08      0.18      0.11       508
         1.0       0.08      0.13      0.10       482
         2.0       0.05      0.04      0.04       510
         3.0       0.06      0.15      0.08       489
         4.0       0.06      0.46      0.11       466
         5.0       0.30      0.10      0.14      2972
         6.0       0.39      0.31      0.34      3080
         7.0       0.29      0.22      0.25      2961
         8.0       0.52      0.48      0.50      3024
         9.0       0.44      0.30      0.35      3003

    accuracy                           0.27     17495
   macro avg       0.23      0.23      0.20     17495
weighted avg       0.34      0.27      0.29     17495

Base private model train accuracy:  0.24331020812685827
              precision    recall  f1-score   support

         0.0       0.30      0.19      0.23      3066
         1.0       0.32      0.16      0.22      2949
         2.0       0.13      0.03      0.05      3108
         3.0       0.22      0.16      0.18      3070
         4.0       0.20      0.45      0.28      2941
         5.0       0.19      0.10      0.13      3077
         6.0       0.23      0.33      0.27      3034
         7.0       0.19      0.23      0.21      2994
         8.0       0.31      0.48      0.38      3017
         9.0       0.31      0.31      0.31      3014

    accuracy                           0.24     30270
   macro avg       0.24      0.24      0.23     30270
weighted avg       0.24      0.24      0.23     30270

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5729765444334325
test acc: 0.5653246753246753
min train acc: 0.6813375627808618
maj train acc: 0.4725905150433452
min test acc: 0.586436691493532
maj test acc: 0.5445404151089339
total acc: 0.5691174062551171
total min acc: 0.6336158748932256
total maj acc: 0.5083648484071533
precision, recall: (0.5643628790836913, 0.5729765444334325)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 1.9265688443804843, 0.26653329522720776, 0.24331020812685827, 0.5691174062551171, 0.6336158748932256, 0.5083648484071533, '              precision    recall  f1-score   support\n\n         0.0       0.08      0.18      0.11       508\n         1.0       0.08      0.13      0.10       482\n         2.0       0.05      0.04      0.04       510\n         3.0       0.06      0.15      0.08       489\n         4.0       0.06      0.46      0.11       466\n         5.0       0.30      0.10      0.14      2972\n         6.0       0.39      0.31      0.34      3080\n         7.0       0.29      0.22      0.25      2961\n         8.0       0.52      0.48      0.50      3024\n         9.0       0.44      0.30      0.35      3003\n\n    accuracy                           0.27     17495\n   macro avg       0.23      0.23      0.20     17495\nweighted avg       0.34      0.27      0.29     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.30      0.19      0.23      3066\n         1.0       0.32      0.16      0.22      2949\n         2.0       0.13      0.03      0.05      3108\n         3.0       0.22      0.16      0.18      3070\n         4.0       0.20      0.45      0.28      2941\n         5.0       0.19      0.10      0.13      3077\n         6.0       0.23      0.33      0.27      3034\n         7.0       0.19      0.23      0.21      2994\n         8.0       0.31      0.48      0.38      3017\n         9.0       0.31      0.31      0.31      3014\n\n    accuracy                           0.24     30270\n   macro avg       0.24      0.24      0.23     30270\nweighted avg       0.24      0.24      0.23     30270\n']
experiment_number: 19
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-19.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 3.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([472, 512, 536, 516, 512, 467, 519, 476, 470, 483])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4963, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.379563 Acc@1: 0.060440 (ε = 0.21, δ = 1e-05) for α = 57.0
	Train Epoch: 1 	Loss: 15.762129 Acc@1: 0.091546 (ε = 0.29, δ = 1e-05) for α = 56.0
	Train Epoch: 1 	Loss: 15.173714 Acc@1: 0.103887 (ε = 0.36, δ = 1e-05) for α = 54.0
	Test set:Loss: 58.623942 Acc@1: 0.058864 
	Train Epoch: 2 	Loss: 52.261387 Acc@1: 0.120773 (ε = 0.40, δ = 1e-05) for α = 51.0
	Train Epoch: 2 	Loss: 83.437138 Acc@1: 0.111098 (ε = 0.46, δ = 1e-05) for α = 45.0
	Train Epoch: 2 	Loss: 93.435099 Acc@1: 0.105922 (ε = 0.51, δ = 1e-05) for α = 42.0
	Test set:Loss: 143.667975 Acc@1: 0.147742 
	Train Epoch: 3 	Loss: 111.595146 Acc@1: 0.091892 (ε = 0.53, δ = 1e-05) for α = 40.0
	Train Epoch: 3 	Loss: 101.066585 Acc@1: 0.101042 (ε = 0.58, δ = 1e-05) for α = 37.0
	Train Epoch: 3 	Loss: 154.918565 Acc@1: 0.100586 (ε = 0.62, δ = 1e-05) for α = 35.0
	Test set:Loss: 158.375421 Acc@1: 0.161536 
	Train Epoch: 4 	Loss: 73.668091 Acc@1: 0.126374 (ε = 0.64, δ = 1e-05) for α = 34.0
	Train Epoch: 4 	Loss: 261.565130 Acc@1: 0.096697 (ε = 0.68, δ = 1e-05) for α = 33.0
	Train Epoch: 4 	Loss: 234.263304 Acc@1: 0.098525 (ε = 0.71, δ = 1e-05) for α = 31.0
	Test set:Loss: 142.472525 Acc@1: 0.031234 
	Train Epoch: 5 	Loss: 134.656052 Acc@1: 0.131707 (ε = 0.73, δ = 1e-05) for α = 31.0
	Train Epoch: 5 	Loss: 177.304786 Acc@1: 0.102427 (ε = 0.76, δ = 1e-05) for α = 29.0
	Train Epoch: 5 	Loss: 246.593775 Acc@1: 0.098861 (ε = 0.79, δ = 1e-05) for α = 28.0
	Test set:Loss: 341.236481 Acc@1: 0.039323 
	Train Epoch: 6 	Loss: 233.762268 Acc@1: 0.142045 (ε = 0.81, δ = 1e-05) for α = 28.0
	Train Epoch: 6 	Loss: 493.386391 Acc@1: 0.104112 (ε = 0.84, δ = 1e-05) for α = 27.0
	Train Epoch: 6 	Loss: 456.600030 Acc@1: 0.100874 (ε = 0.86, δ = 1e-05) for α = 26.0
	Test set:Loss: 340.651257 Acc@1: 0.035313 
	Train Epoch: 7 	Loss: 286.321899 Acc@1: 0.111702 (ε = 0.88, δ = 1e-05) for α = 26.0
	Train Epoch: 7 	Loss: 433.594248 Acc@1: 0.099784 (ε = 0.91, δ = 1e-05) for α = 25.0
	Train Epoch: 7 	Loss: 711.181848 Acc@1: 0.096627 (ε = 0.93, δ = 1e-05) for α = 25.0
	Test set:Loss: 491.049352 Acc@1: 0.166961 
	Train Epoch: 8 	Loss: 258.825439 Acc@1: 0.088106 (ε = 0.95, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 465.982359 Acc@1: 0.091449 (ε = 0.97, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 495.816380 Acc@1: 0.096081 (ε = 1.00, δ = 1e-05) for α = 23.0
	Test set:Loss: 700.857373 Acc@1: 0.031929 
	Train Epoch: 9 	Loss: 405.124786 Acc@1: 0.073298 (ε = 1.01, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2059.284524 Acc@1: 0.094861 (ε = 1.03, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 1646.955556 Acc@1: 0.100279 (ε = 1.05, δ = 1e-05) for α = 22.0
	Test set:Loss: 641.518555 Acc@1: 0.030001 
	Train Epoch: 10 	Loss: 2415.459473 Acc@1: 0.061611 (ε = 1.07, δ = 1e-05) for α = 22.0
	Train Epoch: 10 	Loss: 2700.884852 Acc@1: 0.089860 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 10 	Loss: 1826.564206 Acc@1: 0.094901 (ε = 1.11, δ = 1e-05) for α = 21.0
	Test set:Loss: 688.313803 Acc@1: 0.168836 
	Train Epoch: 11 	Loss: 575.206238 Acc@1: 0.094118 (ε = 1.12, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 578.655989 Acc@1: 0.109920 (ε = 1.14, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 848.885727 Acc@1: 0.108930 (ε = 1.16, δ = 1e-05) for α = 20.0
	Test set:Loss: 422.464651 Acc@1: 0.031530 
	Train Epoch: 12 	Loss: 571.268799 Acc@1: 0.096774 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 1121.291770 Acc@1: 0.091014 (ε = 1.19, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 777.624016 Acc@1: 0.094301 (ε = 1.22, δ = 1e-05) for α = 20.0
	Test set:Loss: 625.055729 Acc@1: 0.164463 
	Train Epoch: 13 	Loss: 155.121384 Acc@1: 0.069652 (ε = 1.23, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 1007.859372 Acc@1: 0.088870 (ε = 1.24, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2934.830124 Acc@1: 0.095042 (ε = 1.26, δ = 1e-05) for α = 19.0
	Test set:Loss: 693.873790 Acc@1: 0.167977 
	Train Epoch: 14 	Loss: 550.477539 Acc@1: 0.066667 (ε = 1.27, δ = 1e-05) for α = 19.0
	Train Epoch: 14 	Loss: 1826.554710 Acc@1: 0.099911 (ε = 1.29, δ = 1e-05) for α = 18.0
	Train Epoch: 14 	Loss: 1591.320095 Acc@1: 0.105101 (ε = 1.31, δ = 1e-05) for α = 18.0
	Test set:Loss: 816.808591 Acc@1: 0.031024 
	Train Epoch: 15 	Loss: 939.632751 Acc@1: 0.050691 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 1344.941245 Acc@1: 0.097679 (ε = 1.34, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 1086.224309 Acc@1: 0.099319 (ε = 1.36, δ = 1e-05) for α = 18.0
	Test set:Loss: 735.608170 Acc@1: 0.032998 
	Train Epoch: 16 	Loss: 332.713959 Acc@1: 0.118182 (ε = 1.37, δ = 1e-05) for α = 18.0
	Train Epoch: 16 	Loss: 615.779276 Acc@1: 0.100893 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 16 	Loss: 846.835888 Acc@1: 0.098929 (ε = 1.40, δ = 1e-05) for α = 17.0
	Test set:Loss: 1023.937483 Acc@1: 0.172669 
	Train Epoch: 17 	Loss: 239.785492 Acc@1: 0.107477 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 737.967314 Acc@1: 0.097060 (ε = 1.43, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 1326.026857 Acc@1: 0.100176 (ε = 1.44, δ = 1e-05) for α = 17.0
	Test set:Loss: 913.883252 Acc@1: 0.031404 
	Train Epoch: 18 	Loss: 67.232933 Acc@1: 0.123762 (ε = 1.45, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 1527.517557 Acc@1: 0.111205 (ε = 1.47, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 1495.911334 Acc@1: 0.107799 (ε = 1.49, δ = 1e-05) for α = 16.0
	Test set:Loss: 775.173289 Acc@1: 0.166555 
	Train Epoch: 19 	Loss: 372.981049 Acc@1: 0.077348 (ε = 1.49, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 787.928929 Acc@1: 0.100994 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 636.871861 Acc@1: 0.099651 (ε = 1.53, δ = 1e-05) for α = 16.0
	Test set:Loss: 704.359620 Acc@1: 0.030618 
	Train Epoch: 20 	Loss: 1422.532959 Acc@1: 0.114679 (ε = 1.53, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 782.964983 Acc@1: 0.100875 (ε = 1.55, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 1543.769455 Acc@1: 0.103363 (ε = 1.57, δ = 1e-05) for α = 16.0
	Test set:Loss: 596.491346 Acc@1: 0.031976 
	Train Epoch: 21 	Loss: 159.788879 Acc@1: 0.119403 (ε = 1.58, δ = 1e-05) for α = 16.0
	Train Epoch: 21 	Loss: 1579.722543 Acc@1: 0.100938 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 21 	Loss: 1115.589139 Acc@1: 0.101443 (ε = 1.61, δ = 1e-05) for α = 15.0
	Test set:Loss: 628.151934 Acc@1: 0.169335 
	Train Epoch: 22 	Loss: 93.402138 Acc@1: 0.136842 (ε = 1.61, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2156.689624 Acc@1: 0.100150 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 1353.259654 Acc@1: 0.097802 (ε = 1.64, δ = 1e-05) for α = 15.0
	Test set:Loss: 664.161178 Acc@1: 0.169668 
	Train Epoch: 23 	Loss: 169.490799 Acc@1: 0.108571 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 355.213559 Acc@1: 0.109966 (ε = 1.67, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 430.610843 Acc@1: 0.108386 (ε = 1.68, δ = 1e-05) for α = 15.0
	Test set:Loss: 667.784059 Acc@1: 0.030051 
	Train Epoch: 24 	Loss: 1583.399414 Acc@1: 0.112903 (ε = 1.69, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 478.799279 Acc@1: 0.103806 (ε = 1.70, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 1118.746188 Acc@1: 0.100724 (ε = 1.72, δ = 1e-05) for α = 14.0
	Test set:Loss: 710.277572 Acc@1: 0.028982 
	Train Epoch: 25 	Loss: 358.062622 Acc@1: 0.095694 (ε = 1.72, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 1458.438582 Acc@1: 0.099122 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 1711.631239 Acc@1: 0.097833 (ε = 1.75, δ = 1e-05) for α = 14.0
	Test set:Loss: 685.626044 Acc@1: 0.030791 
	Train Epoch: 26 	Loss: 65.106140 Acc@1: 0.125000 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 226.181803 Acc@1: 0.118382 (ε = 1.77, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 946.731337 Acc@1: 0.106490 (ε = 1.79, δ = 1e-05) for α = 14.0
	Test set:Loss: 657.875356 Acc@1: 0.028796 
	Train Epoch: 27 	Loss: 1207.672363 Acc@1: 0.121951 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 1970.586907 Acc@1: 0.105438 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 1342.145973 Acc@1: 0.106751 (ε = 1.82, δ = 1e-05) for α = 14.0
	Test set:Loss: 646.382165 Acc@1: 0.167068 
	Train Epoch: 28 	Loss: 72.163811 Acc@1: 0.107843 (ε = 1.83, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2896.565878 Acc@1: 0.103719 (ε = 1.84, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2376.558342 Acc@1: 0.099653 (ε = 1.86, δ = 1e-05) for α = 13.0
	Test set:Loss: 634.939256 Acc@1: 0.030344 
	Train Epoch: 29 	Loss: 879.586243 Acc@1: 0.121827 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 473.945116 Acc@1: 0.102104 (ε = 1.88, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 1248.921644 Acc@1: 0.099469 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 631.898058 Acc@1: 0.168983 
	Train Epoch: 30 	Loss: 911.153198 Acc@1: 0.073171 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 510.600414 Acc@1: 0.100764 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 359.582620 Acc@1: 0.097107 (ε = 1.92, δ = 1e-05) for α = 13.0
	Test set:Loss: 618.710293 Acc@1: 0.167960 
Base private model test accuracy:  0.1673621034581309
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.04      0.01      0.02       482
         2.0       0.03      0.00      0.01       510
         3.0       0.04      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.16      0.00      0.01      2972
         6.0       0.17      0.94      0.29      3080
         7.0       0.11      0.00      0.01      2961
         8.0       0.19      0.00      0.00      3024
         9.0       0.06      0.00      0.00      3003

    accuracy                           0.17     17495
   macro avg       0.08      0.10      0.03     17495
weighted avg       0.12      0.17      0.06     17495

Base private model train accuracy:  0.10215595406004432
              precision    recall  f1-score   support

         0.0       0.33      0.00      0.00       472
         1.0       0.21      0.02      0.04       512
         2.0       0.00      0.00      0.00       536
         3.0       0.00      0.00      0.00       516
         4.0       0.08      0.01      0.01       512
         5.0       0.00      0.00      0.00       467
         6.0       0.10      0.93      0.18       519
         7.0       0.15      0.01      0.02       476
         8.0       0.00      0.00      0.00       470
         9.0       0.00      0.00      0.00       483

    accuracy                           0.10      4963
   macro avg       0.09      0.10      0.03      4963
weighted avg       0.09      0.10      0.03      4963

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6811769447803305
test acc: 0.296137339055794
min train acc: 0.5823909531502424
maj train acc: 0.7867513611615246
min test acc: 0.3895196506550218
maj test acc: 0.20669456066945602
total acc: 0.49469964664310956
total min acc: 0.4897188417960554
total maj acc: 0.4849804092294297
precision, recall: (0.5075075075075075, 0.6811769447803305)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 1.9265688443804843, 0.1673621034581309, 0.10215595406004432, 0.49469964664310956, 0.4897188417960554, 0.4849804092294297, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.04      0.01      0.02       482\n         2.0       0.03      0.00      0.01       510\n         3.0       0.04      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.16      0.00      0.01      2972\n         6.0       0.17      0.94      0.29      3080\n         7.0       0.11      0.00      0.01      2961\n         8.0       0.19      0.00      0.00      3024\n         9.0       0.06      0.00      0.00      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.08      0.10      0.03     17495\nweighted avg       0.12      0.17      0.06     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.33      0.00      0.00       472\n         1.0       0.21      0.02      0.04       512\n         2.0       0.00      0.00      0.00       536\n         3.0       0.00      0.00      0.00       516\n         4.0       0.08      0.01      0.01       512\n         5.0       0.00      0.00      0.00       467\n         6.0       0.10      0.93      0.18       519\n         7.0       0.15      0.01      0.02       476\n         8.0       0.00      0.00      0.00       470\n         9.0       0.00      0.00      0.00       483\n\n    accuracy                           0.10      4963\n   macro avg       0.09      0.10      0.03      4963\nweighted avg       0.09      0.10      0.03      4963\n']
experiment_number: 13
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-13.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 3.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3045, 2998, 3172, 3054, 3066, 3079, 2964, 2954, 3104, 3015])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30451, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.983411 Acc@1: 0.091443 (ε = 0.21, δ = 1e-05) for α = 57.0
	Train Epoch: 1 	Loss: 2.965242 Acc@1: 0.099702 (ε = 0.29, δ = 1e-05) for α = 56.0
	Train Epoch: 1 	Loss: 2.633591 Acc@1: 0.104007 (ε = 0.36, δ = 1e-05) for α = 54.0
	Test set:Loss: 2.254325 Acc@1: 0.158412 
	Train Epoch: 2 	Loss: 2.173339 Acc@1: 0.155766 (ε = 0.40, δ = 1e-05) for α = 51.0
	Train Epoch: 2 	Loss: 2.231821 Acc@1: 0.179831 (ε = 0.46, δ = 1e-05) for α = 45.0
	Train Epoch: 2 	Loss: 2.252109 Acc@1: 0.190217 (ε = 0.51, δ = 1e-05) for α = 42.0
	Test set:Loss: 2.061921 Acc@1: 0.241823 
	Train Epoch: 3 	Loss: 2.324706 Acc@1: 0.222404 (ε = 0.53, δ = 1e-05) for α = 40.0
	Train Epoch: 3 	Loss: 2.469714 Acc@1: 0.239800 (ε = 0.58, δ = 1e-05) for α = 37.0
	Train Epoch: 3 	Loss: 2.430492 Acc@1: 0.223891 (ε = 0.62, δ = 1e-05) for α = 35.0
	Test set:Loss: 2.098805 Acc@1: 0.234463 
	Train Epoch: 4 	Loss: 2.306227 Acc@1: 0.200622 (ε = 0.64, δ = 1e-05) for α = 34.0
	Train Epoch: 4 	Loss: 2.457402 Acc@1: 0.234952 (ε = 0.68, δ = 1e-05) for α = 33.0
	Train Epoch: 4 	Loss: 2.517827 Acc@1: 0.240998 (ε = 0.71, δ = 1e-05) for α = 31.0
	Test set:Loss: 2.120816 Acc@1: 0.263109 
	Train Epoch: 5 	Loss: 2.623414 Acc@1: 0.230954 (ε = 0.73, δ = 1e-05) for α = 31.0
	Train Epoch: 5 	Loss: 2.500618 Acc@1: 0.252033 (ε = 0.76, δ = 1e-05) for α = 29.0
	Train Epoch: 5 	Loss: 2.498072 Acc@1: 0.265000 (ε = 0.79, δ = 1e-05) for α = 28.0
	Test set:Loss: 2.211520 Acc@1: 0.310943 
	Train Epoch: 6 	Loss: 2.390826 Acc@1: 0.274062 (ε = 0.81, δ = 1e-05) for α = 28.0
	Train Epoch: 6 	Loss: 2.663230 Acc@1: 0.230267 (ε = 0.84, δ = 1e-05) for α = 27.0
	Train Epoch: 6 	Loss: 2.543657 Acc@1: 0.221157 (ε = 0.86, δ = 1e-05) for α = 26.0
	Test set:Loss: 2.084838 Acc@1: 0.271525 
	Train Epoch: 7 	Loss: 2.494626 Acc@1: 0.230835 (ε = 0.88, δ = 1e-05) for α = 26.0
	Train Epoch: 7 	Loss: 2.395608 Acc@1: 0.254412 (ε = 0.91, δ = 1e-05) for α = 25.0
	Train Epoch: 7 	Loss: 2.410926 Acc@1: 0.258789 (ε = 0.93, δ = 1e-05) for α = 25.0
	Test set:Loss: 2.073681 Acc@1: 0.316205 
	Train Epoch: 8 	Loss: 2.486690 Acc@1: 0.257075 (ε = 0.95, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.477890 Acc@1: 0.264734 (ε = 0.97, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.537236 Acc@1: 0.253428 (ε = 1.00, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.006754 Acc@1: 0.284582 
	Train Epoch: 9 	Loss: 2.537322 Acc@1: 0.236715 (ε = 1.01, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.482351 Acc@1: 0.225891 (ε = 1.03, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.463156 Acc@1: 0.240792 (ε = 1.05, δ = 1e-05) for α = 22.0
	Test set:Loss: 2.086449 Acc@1: 0.299634 
	Train Epoch: 10 	Loss: 2.469388 Acc@1: 0.260442 (ε = 1.07, δ = 1e-05) for α = 22.0
	Train Epoch: 10 	Loss: 2.386285 Acc@1: 0.247304 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 10 	Loss: 2.455893 Acc@1: 0.246864 (ε = 1.11, δ = 1e-05) for α = 21.0
	Test set:Loss: 2.169273 Acc@1: 0.221072 
	Train Epoch: 11 	Loss: 2.667316 Acc@1: 0.168567 (ε = 1.12, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.640963 Acc@1: 0.193960 (ε = 1.14, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.622977 Acc@1: 0.197255 (ε = 1.16, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.144017 Acc@1: 0.258027 
	Train Epoch: 12 	Loss: 2.582979 Acc@1: 0.213247 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.525549 Acc@1: 0.211309 (ε = 1.19, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.544974 Acc@1: 0.212208 (ε = 1.22, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.053332 Acc@1: 0.306072 
	Train Epoch: 13 	Loss: 2.529586 Acc@1: 0.232297 (ε = 1.23, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.511928 Acc@1: 0.213154 (ε = 1.24, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.512602 Acc@1: 0.216401 (ε = 1.26, δ = 1e-05) for α = 19.0
	Test set:Loss: 2.060603 Acc@1: 0.296583 
	Train Epoch: 14 	Loss: 2.562168 Acc@1: 0.219512 (ε = 1.27, δ = 1e-05) for α = 19.0
	Train Epoch: 14 	Loss: 2.551329 Acc@1: 0.233585 (ε = 1.29, δ = 1e-05) for α = 18.0
	Train Epoch: 14 	Loss: 2.549633 Acc@1: 0.232658 (ε = 1.31, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.260719 Acc@1: 0.272827 
	Train Epoch: 15 	Loss: 2.568174 Acc@1: 0.230159 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.576558 Acc@1: 0.214211 (ε = 1.34, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.550806 Acc@1: 0.221199 (ε = 1.36, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.096163 Acc@1: 0.287427 
	Train Epoch: 16 	Loss: 2.600629 Acc@1: 0.227124 (ε = 1.37, δ = 1e-05) for α = 18.0
	Train Epoch: 16 	Loss: 2.540454 Acc@1: 0.232292 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 16 	Loss: 2.547853 Acc@1: 0.236831 (ε = 1.40, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.072977 Acc@1: 0.295315 
	Train Epoch: 17 	Loss: 2.395645 Acc@1: 0.250000 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.540917 Acc@1: 0.243347 (ε = 1.43, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.561543 Acc@1: 0.236046 (ε = 1.44, δ = 1e-05) for α = 17.0
	Test set:Loss: 1.997795 Acc@1: 0.307421 
	Train Epoch: 18 	Loss: 2.565574 Acc@1: 0.236711 (ε = 1.45, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.548735 Acc@1: 0.250230 (ε = 1.47, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.594475 Acc@1: 0.242902 (ε = 1.49, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.049988 Acc@1: 0.283043 
	Train Epoch: 19 	Loss: 2.566473 Acc@1: 0.226876 (ε = 1.49, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.571196 Acc@1: 0.224089 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.568049 Acc@1: 0.226680 (ε = 1.53, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.064043 Acc@1: 0.299328 
	Train Epoch: 20 	Loss: 2.347790 Acc@1: 0.235573 (ε = 1.53, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.540434 Acc@1: 0.231693 (ε = 1.55, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.550654 Acc@1: 0.234189 (ε = 1.57, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.006892 Acc@1: 0.305222 
	Train Epoch: 21 	Loss: 2.289884 Acc@1: 0.251834 (ε = 1.58, δ = 1e-05) for α = 16.0
	Train Epoch: 21 	Loss: 2.474605 Acc@1: 0.248865 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 21 	Loss: 2.510398 Acc@1: 0.249452 (ε = 1.61, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.001871 Acc@1: 0.296202 
	Train Epoch: 22 	Loss: 2.584729 Acc@1: 0.233877 (ε = 1.61, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.520928 Acc@1: 0.233893 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.476362 Acc@1: 0.236796 (ε = 1.64, δ = 1e-05) for α = 15.0
	Test set:Loss: 1.995930 Acc@1: 0.319109 
	Train Epoch: 23 	Loss: 2.515363 Acc@1: 0.246575 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.458746 Acc@1: 0.248646 (ε = 1.67, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.492306 Acc@1: 0.247463 (ε = 1.68, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.012932 Acc@1: 0.290177 
	Train Epoch: 24 	Loss: 2.343047 Acc@1: 0.218776 (ε = 1.69, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.417574 Acc@1: 0.234189 (ε = 1.70, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.430721 Acc@1: 0.239981 (ε = 1.72, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.053255 Acc@1: 0.284106 
	Train Epoch: 25 	Loss: 2.356616 Acc@1: 0.237903 (ε = 1.72, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.459006 Acc@1: 0.253099 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.436150 Acc@1: 0.254678 (ε = 1.75, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.227506 Acc@1: 0.265843 
	Train Epoch: 26 	Loss: 2.601021 Acc@1: 0.251597 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.402805 Acc@1: 0.266411 (ε = 1.77, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.395913 Acc@1: 0.271252 (ε = 1.79, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.980767 Acc@1: 0.326423 
	Train Epoch: 27 	Loss: 2.386738 Acc@1: 0.280716 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.376424 Acc@1: 0.277968 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.343367 Acc@1: 0.275876 (ε = 1.82, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.944077 Acc@1: 0.337396 
	Train Epoch: 28 	Loss: 2.195525 Acc@1: 0.283489 (ε = 1.83, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.300983 Acc@1: 0.279877 (ε = 1.84, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.306927 Acc@1: 0.279290 (ε = 1.86, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.930399 Acc@1: 0.343243 
	Train Epoch: 29 	Loss: 2.369775 Acc@1: 0.293524 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.298108 Acc@1: 0.282071 (ε = 1.88, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.290983 Acc@1: 0.282242 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.952378 Acc@1: 0.339853 
	Train Epoch: 30 	Loss: 2.420357 Acc@1: 0.275667 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.336296 Acc@1: 0.279982 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.336637 Acc@1: 0.277774 (ε = 1.92, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.943261 Acc@1: 0.342510 
Base private model test accuracy:  0.3421549014004001
              precision    recall  f1-score   support

         0.0       0.02      0.02      0.02       508
         1.0       0.09      0.01      0.01       482
         2.0       0.03      0.02      0.02       510
         3.0       0.04      0.01      0.01       489
         4.0       0.03      0.03      0.03       466
         5.0       0.25      0.14      0.18      2972
         6.0       0.33      0.42      0.37      3080
         7.0       0.43      0.34      0.38      2961
         8.0       0.49      0.65      0.56      3024
         9.0       0.30      0.42      0.35      3003

    accuracy                           0.34     17495
   macro avg       0.20      0.21      0.19     17495
weighted avg       0.31      0.34      0.32     17495

Base private model train accuracy:  0.2837345243177564
              precision    recall  f1-score   support

         0.0       0.24      0.19      0.21      3045
         1.0       0.31      0.22      0.26      2998
         2.0       0.20      0.10      0.14      3172
         3.0       0.29      0.18      0.22      3054
         4.0       0.27      0.18      0.22      3066
         5.0       0.18      0.14      0.16      3079
         6.0       0.25      0.42      0.31      2964
         7.0       0.37      0.38      0.38      2954
         8.0       0.40      0.64      0.49      3104
         9.0       0.24      0.39      0.30      3015

    accuracy                           0.28     30451
   macro avg       0.27      0.28      0.27     30451
weighted avg       0.27      0.28      0.27     30451

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6442036124794746
test acc: 0.40974025974025974
min train acc: 0.6604571277579601
maj train acc: 0.6307868894273689
min test acc: 0.42971518571991074
maj test acc: 0.389937106918239
total acc: 0.5263020408163265
total min acc: 0.5447063471161443
total maj acc: 0.510747185261003
precision, recall: (0.5189967192295482, 0.6442036124794746)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 1.9265688443804843, 0.3421549014004001, 0.2837345243177564, 0.5263020408163265, 0.5447063471161443, 0.510747185261003, '              precision    recall  f1-score   support\n\n         0.0       0.02      0.02      0.02       508\n         1.0       0.09      0.01      0.01       482\n         2.0       0.03      0.02      0.02       510\n         3.0       0.04      0.01      0.01       489\n         4.0       0.03      0.03      0.03       466\n         5.0       0.25      0.14      0.18      2972\n         6.0       0.33      0.42      0.37      3080\n         7.0       0.43      0.34      0.38      2961\n         8.0       0.49      0.65      0.56      3024\n         9.0       0.30      0.42      0.35      3003\n\n    accuracy                           0.34     17495\n   macro avg       0.20      0.21      0.19     17495\nweighted avg       0.31      0.34      0.32     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.24      0.19      0.21      3045\n         1.0       0.31      0.22      0.26      2998\n         2.0       0.20      0.10      0.14      3172\n         3.0       0.29      0.18      0.22      3054\n         4.0       0.27      0.18      0.22      3066\n         5.0       0.18      0.14      0.16      3079\n         6.0       0.25      0.42      0.31      2964\n         7.0       0.37      0.38      0.38      2954\n         8.0       0.40      0.64      0.49      3104\n         9.0       0.24      0.39      0.30      3015\n\n    accuracy                           0.28     30451\n   macro avg       0.27      0.28      0.27     30451\nweighted avg       0.27      0.28      0.27     30451\n']
experiment_number: 9
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-9.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3037, 3102, 3060, 3193, 2970, 2991, 3026, 3069, 3009, 3128])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30585, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.879468 Acc@1: 0.092834 (ε = 0.31, δ = 1e-05) for α = 40.0
	Train Epoch: 1 	Loss: 2.448688 Acc@1: 0.111944 (ε = 0.39, δ = 1e-05) for α = 39.0
	Train Epoch: 1 	Loss: 2.397974 Acc@1: 0.117699 (ε = 0.47, δ = 1e-05) for α = 38.0
	Test set:Loss: 2.203668 Acc@1: 0.233800 
	Train Epoch: 2 	Loss: 2.257487 Acc@1: 0.196078 (ε = 0.51, δ = 1e-05) for α = 38.0
	Train Epoch: 2 	Loss: 2.333323 Acc@1: 0.169326 (ε = 0.58, δ = 1e-05) for α = 35.0
	Train Epoch: 2 	Loss: 2.455743 Acc@1: 0.157232 (ε = 0.64, δ = 1e-05) for α = 32.0
	Test set:Loss: 2.349957 Acc@1: 0.082495 
	Train Epoch: 3 	Loss: 2.353808 Acc@1: 0.133655 (ε = 0.67, δ = 1e-05) for α = 31.0
	Train Epoch: 3 	Loss: 2.329789 Acc@1: 0.159441 (ε = 0.72, δ = 1e-05) for α = 29.0
	Train Epoch: 3 	Loss: 2.353150 Acc@1: 0.185182 (ε = 0.77, δ = 1e-05) for α = 28.0
	Test set:Loss: 2.901175 Acc@1: 0.215565 
	Train Epoch: 4 	Loss: 3.443502 Acc@1: 0.195122 (ε = 0.79, δ = 1e-05) for α = 27.0
	Train Epoch: 4 	Loss: 2.460588 Acc@1: 0.200518 (ε = 0.84, δ = 1e-05) for α = 26.0
	Train Epoch: 4 	Loss: 2.485271 Acc@1: 0.208974 (ε = 0.88, δ = 1e-05) for α = 25.0
	Test set:Loss: 2.371363 Acc@1: 0.179475 
	Train Epoch: 5 	Loss: 2.282646 Acc@1: 0.217202 (ε = 0.90, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 2.284740 Acc@1: 0.231320 (ε = 0.94, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 2.350115 Acc@1: 0.238629 (ε = 0.98, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.437414 Acc@1: 0.236591 
	Train Epoch: 6 	Loss: 2.456847 Acc@1: 0.283113 (ε = 1.00, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 2.527359 Acc@1: 0.213171 (ε = 1.04, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 2.437238 Acc@1: 0.219882 (ε = 1.07, δ = 1e-05) for α = 21.0
	Test set:Loss: 2.218446 Acc@1: 0.285358 
	Train Epoch: 7 	Loss: 2.206035 Acc@1: 0.281432 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 7 	Loss: 2.340320 Acc@1: 0.259871 (ε = 1.12, δ = 1e-05) for α = 20.0
	Train Epoch: 7 	Loss: 2.364845 Acc@1: 0.259675 (ε = 1.15, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.246598 Acc@1: 0.279707 
	Train Epoch: 8 	Loss: 2.178289 Acc@1: 0.296530 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 8 	Loss: 2.287625 Acc@1: 0.296995 (ε = 1.20, δ = 1e-05) for α = 19.0
	Train Epoch: 8 	Loss: 2.294868 Acc@1: 0.285653 (ε = 1.23, δ = 1e-05) for α = 19.0
	Test set:Loss: 2.311208 Acc@1: 0.313891 
	Train Epoch: 9 	Loss: 2.480549 Acc@1: 0.262400 (ε = 1.25, δ = 1e-05) for α = 19.0
	Train Epoch: 9 	Loss: 2.298329 Acc@1: 0.283308 (ε = 1.27, δ = 1e-05) for α = 18.0
	Train Epoch: 9 	Loss: 2.318152 Acc@1: 0.286903 (ε = 1.30, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.143934 Acc@1: 0.300507 
	Train Epoch: 10 	Loss: 2.242793 Acc@1: 0.308502 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 10 	Loss: 2.218124 Acc@1: 0.300530 (ε = 1.34, δ = 1e-05) for α = 17.0
	Train Epoch: 10 	Loss: 2.230317 Acc@1: 0.305839 (ε = 1.37, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.419440 Acc@1: 0.289340 
	Train Epoch: 11 	Loss: 2.382177 Acc@1: 0.323408 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 2.205960 Acc@1: 0.324754 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 2.240892 Acc@1: 0.321968 (ε = 1.44, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.065414 Acc@1: 0.351688 
	Train Epoch: 12 	Loss: 2.248572 Acc@1: 0.334454 (ε = 1.45, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 2.230761 Acc@1: 0.320724 (ε = 1.47, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 2.210168 Acc@1: 0.311976 (ε = 1.50, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.419149 Acc@1: 0.345008 
	Train Epoch: 13 	Loss: 2.482530 Acc@1: 0.318599 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 2.224874 Acc@1: 0.317768 (ε = 1.54, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 2.214177 Acc@1: 0.322620 (ε = 1.56, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.256952 Acc@1: 0.343143 
	Train Epoch: 14 	Loss: 2.190435 Acc@1: 0.343568 (ε = 1.57, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 2.123957 Acc@1: 0.340623 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 2.158695 Acc@1: 0.339481 (ε = 1.62, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.437332 Acc@1: 0.353757 
	Train Epoch: 15 	Loss: 2.542597 Acc@1: 0.325282 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 2.260546 Acc@1: 0.335830 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 2.196098 Acc@1: 0.344258 (ε = 1.68, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.168069 Acc@1: 0.350918 
	Train Epoch: 16 	Loss: 2.327660 Acc@1: 0.342640 (ε = 1.69, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 2.267656 Acc@1: 0.347839 (ε = 1.71, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 2.216092 Acc@1: 0.346685 (ε = 1.73, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.145247 Acc@1: 0.372301 
	Train Epoch: 17 	Loss: 2.209972 Acc@1: 0.347054 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 2.143651 Acc@1: 0.347403 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 2.130036 Acc@1: 0.349187 (ε = 1.78, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.172033 Acc@1: 0.340526 
	Train Epoch: 18 	Loss: 2.073241 Acc@1: 0.362355 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 2.243308 Acc@1: 0.353502 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 2.219134 Acc@1: 0.352596 (ε = 1.83, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.077727 Acc@1: 0.362098 
	Train Epoch: 19 	Loss: 2.055916 Acc@1: 0.347471 (ε = 1.84, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 2.105989 Acc@1: 0.351959 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 2.083222 Acc@1: 0.356446 (ε = 1.88, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.037427 Acc@1: 0.370580 
	Train Epoch: 20 	Loss: 2.046739 Acc@1: 0.375742 (ε = 1.89, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 2.161337 Acc@1: 0.357448 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 2.144957 Acc@1: 0.361156 (ε = 1.93, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.213238 Acc@1: 0.368665 
	Train Epoch: 21 	Loss: 2.104176 Acc@1: 0.392555 (ε = 1.94, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 2.033922 Acc@1: 0.376047 (ε = 1.96, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 2.096779 Acc@1: 0.369764 (ε = 1.98, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.076082 Acc@1: 0.383548 
	Train Epoch: 22 	Loss: 2.057764 Acc@1: 0.377186 (ε = 1.99, δ = 1e-05) for α = 13.0
	Train Epoch: 22 	Loss: 2.038392 Acc@1: 0.377768 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 22 	Loss: 2.037988 Acc@1: 0.378676 (ε = 2.03, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.072927 Acc@1: 0.388882 
	Train Epoch: 23 	Loss: 1.996891 Acc@1: 0.396607 (ε = 2.04, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 1.981012 Acc@1: 0.393426 (ε = 2.05, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 2.002132 Acc@1: 0.390055 (ε = 2.07, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.077264 Acc@1: 0.358025 
	Train Epoch: 24 	Loss: 1.853698 Acc@1: 0.407285 (ε = 2.08, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 1.992861 Acc@1: 0.387812 (ε = 2.10, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 1.984068 Acc@1: 0.390179 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.268229 Acc@1: 0.366268 
	Train Epoch: 25 	Loss: 2.162411 Acc@1: 0.389927 (ε = 2.13, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 2.018785 Acc@1: 0.390290 (ε = 2.14, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 1.999695 Acc@1: 0.391090 (ε = 2.16, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.991204 Acc@1: 0.396889 
	Train Epoch: 26 	Loss: 1.943124 Acc@1: 0.399329 (ε = 2.17, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 1.963581 Acc@1: 0.398362 (ε = 2.19, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 1.970869 Acc@1: 0.398283 (ε = 2.21, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.105490 Acc@1: 0.378589 
	Train Epoch: 27 	Loss: 1.944993 Acc@1: 0.411382 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 1.960871 Acc@1: 0.399435 (ε = 2.23, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 1.965122 Acc@1: 0.398374 (ε = 2.25, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.108828 Acc@1: 0.385054 
	Train Epoch: 28 	Loss: 1.974911 Acc@1: 0.405201 (ε = 2.26, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 1.969622 Acc@1: 0.395742 (ε = 2.27, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 1.960374 Acc@1: 0.401305 (ε = 2.29, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.113607 Acc@1: 0.381186 
	Train Epoch: 29 	Loss: 1.941131 Acc@1: 0.401454 (ε = 2.30, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 1.952838 Acc@1: 0.397407 (ε = 2.31, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 1.948188 Acc@1: 0.397905 (ε = 2.33, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.085432 Acc@1: 0.383271 
	Train Epoch: 30 	Loss: 1.995971 Acc@1: 0.406511 (ε = 2.34, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 1.975631 Acc@1: 0.393090 (ε = 2.35, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 1.963146 Acc@1: 0.399908 (ε = 2.37, δ = 1e-05) for α = 10.8
	Test set:Loss: 2.084498 Acc@1: 0.382492 
Base private model test accuracy:  0.38296656187482137
              precision    recall  f1-score   support

         0.0       0.17      0.38      0.24       508
         1.0       0.14      0.42      0.21       482
         2.0       0.10      0.17      0.12       510
         3.0       0.06      0.19      0.10       489
         4.0       0.10      0.38      0.16       466
         5.0       0.38      0.20      0.27      2972
         6.0       0.57      0.40      0.47      3080
         7.0       0.51      0.41      0.45      2961
         8.0       0.67      0.52      0.59      3024
         9.0       0.59      0.44      0.50      3003

    accuracy                           0.38     17495
   macro avg       0.33      0.35      0.31     17495
weighted avg       0.48      0.38      0.42     17495

Base private model train accuracy:  0.40395618767369623
              precision    recall  f1-score   support

         0.0       0.49      0.45      0.47      3037
         1.0       0.53      0.55      0.54      3102
         2.0       0.40      0.28      0.33      3060
         3.0       0.34      0.30      0.32      3193
         4.0       0.31      0.39      0.35      2970
         5.0       0.26      0.24      0.25      2991
         6.0       0.37      0.41      0.39      3026
         7.0       0.40      0.42      0.41      3069
         8.0       0.49      0.54      0.51      3009
         9.0       0.45      0.47      0.46      3128

    accuracy                           0.40     30585
   macro avg       0.40      0.40      0.40     30585
weighted avg       0.40      0.40      0.40     30585

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7038320690557154
test acc: 0.7693506493506493
min train acc: 0.8755626158326715
maj train acc: 0.5407331975560081
min test acc: 0.9283963359566507
maj test acc: 0.6084345214779998
total acc: 0.7367066336504626
total min acc: 0.9023195034302516
total maj acc: 0.5741540444730906
precision, recall: (0.7518686692280824, 0.7038320690557154)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 2.3746387899695556, 0.38296656187482137, 0.40395618767369623, 0.7367066336504626, 0.9023195034302516, 0.5741540444730906, '              precision    recall  f1-score   support\n\n         0.0       0.17      0.38      0.24       508\n         1.0       0.14      0.42      0.21       482\n         2.0       0.10      0.17      0.12       510\n         3.0       0.06      0.19      0.10       489\n         4.0       0.10      0.38      0.16       466\n         5.0       0.38      0.20      0.27      2972\n         6.0       0.57      0.40      0.47      3080\n         7.0       0.51      0.41      0.45      2961\n         8.0       0.67      0.52      0.59      3024\n         9.0       0.59      0.44      0.50      3003\n\n    accuracy                           0.38     17495\n   macro avg       0.33      0.35      0.31     17495\nweighted avg       0.48      0.38      0.42     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.49      0.45      0.47      3037\n         1.0       0.53      0.55      0.54      3102\n         2.0       0.40      0.28      0.33      3060\n         3.0       0.34      0.30      0.32      3193\n         4.0       0.31      0.39      0.35      2970\n         5.0       0.26      0.24      0.25      2991\n         6.0       0.37      0.41      0.39      3026\n         7.0       0.40      0.42      0.41      3069\n         8.0       0.49      0.54      0.51      3009\n         9.0       0.45      0.47      0.46      3128\n\n    accuracy                           0.40     30585\n   macro avg       0.40      0.40      0.40     30585\nweighted avg       0.40      0.40      0.40     30585\n']
experiment_number: 20
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-20.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([485, 510, 513, 502, 500, 476, 505, 497, 482, 508])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4978, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.764904 Acc@1: 0.075269 (ε = 0.31, δ = 1e-05) for α = 40.0
	Train Epoch: 1 	Loss: 122.485477 Acc@1: 0.099222 (ε = 0.39, δ = 1e-05) for α = 39.0
	Train Epoch: 1 	Loss: 112.366803 Acc@1: 0.098040 (ε = 0.47, δ = 1e-05) for α = 38.0
	Test set:Loss: 33.908919 Acc@1: 0.162365 
	Train Epoch: 2 	Loss: 29.406925 Acc@1: 0.070093 (ε = 0.51, δ = 1e-05) for α = 38.0
	Train Epoch: 2 	Loss: 29.452807 Acc@1: 0.093804 (ε = 0.58, δ = 1e-05) for α = 35.0
	Train Epoch: 2 	Loss: 21.865278 Acc@1: 0.095554 (ε = 0.64, δ = 1e-05) for α = 32.0
	Test set:Loss: 34.715848 Acc@1: 0.028576 
	Train Epoch: 3 	Loss: 23.716946 Acc@1: 0.090476 (ε = 0.67, δ = 1e-05) for α = 31.0
	Train Epoch: 3 	Loss: 24.627182 Acc@1: 0.104610 (ε = 0.72, δ = 1e-05) for α = 29.0
	Train Epoch: 3 	Loss: 20.859359 Acc@1: 0.102065 (ε = 0.77, δ = 1e-05) for α = 28.0
	Test set:Loss: 33.560743 Acc@1: 0.037980 
	Train Epoch: 4 	Loss: 54.025936 Acc@1: 0.134615 (ε = 0.79, δ = 1e-05) for α = 27.0
	Train Epoch: 4 	Loss: 34.952255 Acc@1: 0.099706 (ε = 0.84, δ = 1e-05) for α = 26.0
	Train Epoch: 4 	Loss: 41.150619 Acc@1: 0.100537 (ε = 0.88, δ = 1e-05) for α = 25.0
	Test set:Loss: 77.211087 Acc@1: 0.159674 
	Train Epoch: 5 	Loss: 260.509491 Acc@1: 0.086705 (ε = 0.90, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 99.809292 Acc@1: 0.095173 (ε = 0.94, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 83.938049 Acc@1: 0.097776 (ε = 0.98, δ = 1e-05) for α = 23.0
	Test set:Loss: 65.725774 Acc@1: 0.158173 
	Train Epoch: 6 	Loss: 86.857826 Acc@1: 0.084112 (ε = 1.00, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 54.984290 Acc@1: 0.098355 (ε = 1.04, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 63.804016 Acc@1: 0.102279 (ε = 1.07, δ = 1e-05) for α = 21.0
	Test set:Loss: 106.705629 Acc@1: 0.167587 
	Train Epoch: 7 	Loss: 70.586006 Acc@1: 0.126214 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 7 	Loss: 165.019012 Acc@1: 0.103073 (ε = 1.12, δ = 1e-05) for α = 20.0
	Train Epoch: 7 	Loss: 182.746556 Acc@1: 0.104420 (ε = 1.15, δ = 1e-05) for α = 20.0
	Test set:Loss: 183.801636 Acc@1: 0.041417 
	Train Epoch: 8 	Loss: 185.933319 Acc@1: 0.085227 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 8 	Loss: 211.277192 Acc@1: 0.108797 (ε = 1.20, δ = 1e-05) for α = 19.0
	Train Epoch: 8 	Loss: 165.236055 Acc@1: 0.105647 (ε = 1.23, δ = 1e-05) for α = 19.0
	Test set:Loss: 197.733123 Acc@1: 0.166058 
	Train Epoch: 9 	Loss: 51.770855 Acc@1: 0.091346 (ε = 1.25, δ = 1e-05) for α = 19.0
	Train Epoch: 9 	Loss: 169.844654 Acc@1: 0.111187 (ε = 1.27, δ = 1e-05) for α = 18.0
	Train Epoch: 9 	Loss: 232.660836 Acc@1: 0.102846 (ε = 1.30, δ = 1e-05) for α = 18.0
	Test set:Loss: 168.638487 Acc@1: 0.170281 
	Train Epoch: 10 	Loss: 72.859413 Acc@1: 0.082840 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 10 	Loss: 173.773107 Acc@1: 0.106335 (ε = 1.34, δ = 1e-05) for α = 17.0
	Train Epoch: 10 	Loss: 215.135674 Acc@1: 0.100336 (ε = 1.37, δ = 1e-05) for α = 17.0
	Test set:Loss: 194.219587 Acc@1: 0.171220 
	Train Epoch: 11 	Loss: 273.368805 Acc@1: 0.117949 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 211.843845 Acc@1: 0.107252 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 257.712098 Acc@1: 0.108013 (ε = 1.44, δ = 1e-05) for α = 16.0
	Test set:Loss: 234.710367 Acc@1: 0.032542 
	Train Epoch: 12 	Loss: 500.862823 Acc@1: 0.111675 (ε = 1.45, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 270.388776 Acc@1: 0.103697 (ε = 1.47, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 250.176377 Acc@1: 0.110091 (ε = 1.50, δ = 1e-05) for α = 16.0
	Test set:Loss: 212.603480 Acc@1: 0.175906 
	Train Epoch: 13 	Loss: 583.429932 Acc@1: 0.127854 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 306.588609 Acc@1: 0.111569 (ε = 1.54, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 399.017689 Acc@1: 0.105705 (ε = 1.56, δ = 1e-05) for α = 15.0
	Test set:Loss: 278.668759 Acc@1: 0.170767 
	Train Epoch: 14 	Loss: 66.289871 Acc@1: 0.117949 (ε = 1.57, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 300.271988 Acc@1: 0.093390 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 334.996798 Acc@1: 0.095235 (ε = 1.62, δ = 1e-05) for α = 15.0
	Test set:Loss: 219.301631 Acc@1: 0.035143 
	Train Epoch: 15 	Loss: 255.812851 Acc@1: 0.062500 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 218.506403 Acc@1: 0.104894 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 259.648383 Acc@1: 0.108991 (ε = 1.68, δ = 1e-05) for α = 14.0
	Test set:Loss: 332.083260 Acc@1: 0.174663 
	Train Epoch: 16 	Loss: 97.644653 Acc@1: 0.105769 (ε = 1.69, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 528.369322 Acc@1: 0.101333 (ε = 1.71, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 418.775052 Acc@1: 0.104242 (ε = 1.73, δ = 1e-05) for α = 14.0
	Test set:Loss: 321.821583 Acc@1: 0.033395 
	Train Epoch: 17 	Loss: 227.229675 Acc@1: 0.106796 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 353.105074 Acc@1: 0.109538 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 394.671162 Acc@1: 0.108460 (ε = 1.78, δ = 1e-05) for α = 14.0
	Test set:Loss: 332.800671 Acc@1: 0.033841 
	Train Epoch: 18 	Loss: 567.668579 Acc@1: 0.119565 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 584.531054 Acc@1: 0.105646 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 560.743043 Acc@1: 0.104097 (ε = 1.83, δ = 1e-05) for α = 13.0
	Test set:Loss: 321.347126 Acc@1: 0.035256 
	Train Epoch: 19 	Loss: 95.241104 Acc@1: 0.073529 (ε = 1.84, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 266.663589 Acc@1: 0.093566 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 287.585218 Acc@1: 0.099787 (ε = 1.88, δ = 1e-05) for α = 13.0
	Test set:Loss: 220.503378 Acc@1: 0.031527 
	Train Epoch: 20 	Loss: 161.373657 Acc@1: 0.100917 (ε = 1.89, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 438.067961 Acc@1: 0.101658 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 434.664190 Acc@1: 0.099922 (ε = 1.93, δ = 1e-05) for α = 13.0
	Test set:Loss: 203.943282 Acc@1: 0.167090 
	Train Epoch: 21 	Loss: 68.848152 Acc@1: 0.061321 (ε = 1.94, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 292.033051 Acc@1: 0.086992 (ε = 1.96, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 299.380957 Acc@1: 0.091053 (ε = 1.98, δ = 1e-05) for α = 13.0
	Test set:Loss: 205.191086 Acc@1: 0.033272 
	Train Epoch: 22 	Loss: 196.635025 Acc@1: 0.115385 (ε = 1.99, δ = 1e-05) for α = 13.0
	Train Epoch: 22 	Loss: 360.032981 Acc@1: 0.088446 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 22 	Loss: 255.172246 Acc@1: 0.090511 (ε = 2.03, δ = 1e-05) for α = 12.0
	Test set:Loss: 190.259108 Acc@1: 0.164919 
	Train Epoch: 23 	Loss: 236.277924 Acc@1: 0.100000 (ε = 2.04, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 247.107562 Acc@1: 0.099590 (ε = 2.05, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 245.603971 Acc@1: 0.102627 (ε = 2.07, δ = 1e-05) for α = 12.0
	Test set:Loss: 151.310975 Acc@1: 0.173588 
	Train Epoch: 24 	Loss: 108.985641 Acc@1: 0.128440 (ε = 2.08, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 137.749473 Acc@1: 0.103902 (ε = 2.10, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 137.308958 Acc@1: 0.103762 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 148.649154 Acc@1: 0.174424 
	Train Epoch: 25 	Loss: 406.720276 Acc@1: 0.110497 (ε = 2.13, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 201.654931 Acc@1: 0.108792 (ε = 2.14, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 156.557709 Acc@1: 0.103292 (ε = 2.16, δ = 1e-05) for α = 12.0
	Test set:Loss: 144.492053 Acc@1: 0.169455 
	Train Epoch: 26 	Loss: 43.503201 Acc@1: 0.102128 (ε = 2.17, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 78.649905 Acc@1: 0.097860 (ε = 2.19, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 116.219004 Acc@1: 0.100364 (ε = 2.21, δ = 1e-05) for α = 12.0
	Test set:Loss: 152.872371 Acc@1: 0.033671 
	Train Epoch: 27 	Loss: 25.569639 Acc@1: 0.101064 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 104.248657 Acc@1: 0.115376 (ε = 2.23, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 133.600074 Acc@1: 0.104697 (ε = 2.25, δ = 1e-05) for α = 10.9
	Test set:Loss: 146.624971 Acc@1: 0.169502 
	Train Epoch: 28 	Loss: 43.759224 Acc@1: 0.084507 (ε = 2.26, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 105.109091 Acc@1: 0.095030 (ε = 2.27, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 140.859287 Acc@1: 0.093176 (ε = 2.29, δ = 1e-05) for α = 10.9
	Test set:Loss: 145.884929 Acc@1: 0.174697 
	Train Epoch: 29 	Loss: 349.398926 Acc@1: 0.127168 (ε = 2.30, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 241.222346 Acc@1: 0.114638 (ε = 2.31, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 174.418870 Acc@1: 0.109633 (ε = 2.33, δ = 1e-05) for α = 10.9
	Test set:Loss: 145.619134 Acc@1: 0.171886 
	Train Epoch: 30 	Loss: 66.775238 Acc@1: 0.046154 (ε = 2.34, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 173.642833 Acc@1: 0.104735 (ε = 2.35, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 201.847146 Acc@1: 0.102145 (ε = 2.37, δ = 1e-05) for α = 10.8
	Test set:Loss: 145.592710 Acc@1: 0.172269 
Base private model test accuracy:  0.17193483852529295
              precision    recall  f1-score   support

         0.0       0.01      0.00      0.00       508
         1.0       0.00      0.00      0.00       482
         2.0       0.02      0.00      0.00       510
         3.0       0.07      0.00      0.01       489
         4.0       0.00      0.00      0.00       466
         5.0       0.30      0.01      0.01      2972
         6.0       0.17      0.96      0.29      3080
         7.0       0.14      0.00      0.01      2961
         8.0       0.17      0.00      0.01      3024
         9.0       0.31      0.00      0.00      3003

    accuracy                           0.17     17495
   macro avg       0.12      0.10      0.03     17495
weighted avg       0.19      0.17      0.06     17495

Base private model train accuracy:  0.09863398955403777
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       485
         1.0       0.00      0.00      0.00       510
         2.0       0.18      0.00      0.01       513
         3.0       0.50      0.01      0.02       502
         4.0       0.00      0.00      0.00       500
         5.0       0.07      0.00      0.00       476
         6.0       0.10      0.95      0.18       505
         7.0       0.05      0.00      0.00       497
         8.0       0.14      0.01      0.01       482
         9.0       0.00      0.00      0.00       508

    accuracy                           0.10      4978
   macro avg       0.10      0.10      0.02      4978
weighted avg       0.10      0.10      0.02      4978

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.8846926476496585
test acc: 0.11330472103004297
min train acc: 0.9776859504132231
maj train acc: 0.7849557522123893
min test acc: 0.022746419545071617
maj test acc: 0.20815264527320032
total acc: 0.5117244241543889
total min acc: 0.5047976637463496
total maj acc: 0.49364870784056064
precision, recall: (0.5159325210871603, 0.8846926476496585)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 2.3746387899695556, 0.17193483852529295, 0.09863398955403777, 0.5117244241543889, 0.5047976637463496, 0.49364870784056064, '              precision    recall  f1-score   support\n\n         0.0       0.01      0.00      0.00       508\n         1.0       0.00      0.00      0.00       482\n         2.0       0.02      0.00      0.00       510\n         3.0       0.07      0.00      0.01       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.30      0.01      0.01      2972\n         6.0       0.17      0.96      0.29      3080\n         7.0       0.14      0.00      0.01      2961\n         8.0       0.17      0.00      0.01      3024\n         9.0       0.31      0.00      0.00      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.12      0.10      0.03     17495\nweighted avg       0.19      0.17      0.06     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       485\n         1.0       0.00      0.00      0.00       510\n         2.0       0.18      0.00      0.01       513\n         3.0       0.50      0.01      0.02       502\n         4.0       0.00      0.00      0.00       500\n         5.0       0.07      0.00      0.00       476\n         6.0       0.10      0.95      0.18       505\n         7.0       0.05      0.00      0.00       497\n         8.0       0.14      0.01      0.01       482\n         9.0       0.00      0.00      0.00       508\n\n    accuracy                           0.10      4978\n   macro avg       0.10      0.10      0.02      4978\nweighted avg       0.10      0.10      0.02      4978\n']
experiment_number: 14
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-14.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3026, 2993, 3053, 3012, 3055, 3032, 3069, 3114, 3045, 3008])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30407, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.964293 Acc@1: 0.095844 (ε = 0.31, δ = 1e-05) for α = 40.0
	Train Epoch: 1 	Loss: 2.392513 Acc@1: 0.124896 (ε = 0.39, δ = 1e-05) for α = 39.0
	Train Epoch: 1 	Loss: 2.330602 Acc@1: 0.136986 (ε = 0.47, δ = 1e-05) for α = 38.0
	Test set:Loss: 2.709778 Acc@1: 0.165385 
	Train Epoch: 2 	Loss: 3.060881 Acc@1: 0.135930 (ε = 0.51, δ = 1e-05) for α = 38.0
	Train Epoch: 2 	Loss: 2.424612 Acc@1: 0.151679 (ε = 0.58, δ = 1e-05) for α = 35.0
	Train Epoch: 2 	Loss: 2.318260 Acc@1: 0.173900 (ε = 0.64, δ = 1e-05) for α = 32.0
	Test set:Loss: 2.483762 Acc@1: 0.185111 
	Train Epoch: 3 	Loss: 2.502783 Acc@1: 0.174016 (ε = 0.67, δ = 1e-05) for α = 31.0
	Train Epoch: 3 	Loss: 2.309592 Acc@1: 0.218018 (ε = 0.72, δ = 1e-05) for α = 29.0
	Train Epoch: 3 	Loss: 2.251203 Acc@1: 0.209174 (ε = 0.77, δ = 1e-05) for α = 28.0
	Test set:Loss: 1.959206 Acc@1: 0.271821 
	Train Epoch: 4 	Loss: 2.271692 Acc@1: 0.227092 (ε = 0.79, δ = 1e-05) for α = 27.0
	Train Epoch: 4 	Loss: 2.275181 Acc@1: 0.254287 (ε = 0.84, δ = 1e-05) for α = 26.0
	Train Epoch: 4 	Loss: 2.588976 Acc@1: 0.243013 (ε = 0.88, δ = 1e-05) for α = 25.0
	Test set:Loss: 2.005538 Acc@1: 0.344225 
	Train Epoch: 5 	Loss: 2.123717 Acc@1: 0.284779 (ε = 0.90, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 2.174536 Acc@1: 0.297334 (ε = 0.94, δ = 1e-05) for α = 24.0
	Train Epoch: 5 	Loss: 2.267624 Acc@1: 0.274428 (ε = 0.98, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.162565 Acc@1: 0.218179 
	Train Epoch: 6 	Loss: 2.243138 Acc@1: 0.225101 (ε = 1.00, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 2.317406 Acc@1: 0.226948 (ε = 1.04, δ = 1e-05) for α = 22.0
	Train Epoch: 6 	Loss: 2.332208 Acc@1: 0.232954 (ε = 1.07, δ = 1e-05) for α = 21.0
	Test set:Loss: 2.043551 Acc@1: 0.292994 
	Train Epoch: 7 	Loss: 2.316217 Acc@1: 0.234424 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 7 	Loss: 2.265273 Acc@1: 0.268484 (ε = 1.12, δ = 1e-05) for α = 20.0
	Train Epoch: 7 	Loss: 2.249572 Acc@1: 0.274783 (ε = 1.15, δ = 1e-05) for α = 20.0
	Test set:Loss: 1.925104 Acc@1: 0.364067 
	Train Epoch: 8 	Loss: 2.205751 Acc@1: 0.308388 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 8 	Loss: 2.242143 Acc@1: 0.285896 (ε = 1.20, δ = 1e-05) for α = 19.0
	Train Epoch: 8 	Loss: 2.232191 Acc@1: 0.281271 (ε = 1.23, δ = 1e-05) for α = 19.0
	Test set:Loss: 2.038127 Acc@1: 0.303291 
	Train Epoch: 9 	Loss: 2.200639 Acc@1: 0.263031 (ε = 1.25, δ = 1e-05) for α = 19.0
	Train Epoch: 9 	Loss: 2.247849 Acc@1: 0.290807 (ε = 1.27, δ = 1e-05) for α = 18.0
	Train Epoch: 9 	Loss: 2.281909 Acc@1: 0.291609 (ε = 1.30, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.018515 Acc@1: 0.329792 
	Train Epoch: 10 	Loss: 2.297878 Acc@1: 0.276577 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 10 	Loss: 2.263780 Acc@1: 0.287899 (ε = 1.34, δ = 1e-05) for α = 17.0
	Train Epoch: 10 	Loss: 2.417420 Acc@1: 0.286855 (ε = 1.37, δ = 1e-05) for α = 17.0
	Test set:Loss: 1.989260 Acc@1: 0.313308 
	Train Epoch: 11 	Loss: 2.466250 Acc@1: 0.283646 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 2.498808 Acc@1: 0.242772 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 11 	Loss: 2.404435 Acc@1: 0.255716 (ε = 1.44, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.149337 Acc@1: 0.315875 
	Train Epoch: 12 	Loss: 2.300120 Acc@1: 0.258549 (ε = 1.45, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 2.263441 Acc@1: 0.268434 (ε = 1.47, δ = 1e-05) for α = 16.0
	Train Epoch: 12 	Loss: 2.273765 Acc@1: 0.278215 (ε = 1.50, δ = 1e-05) for α = 16.0
	Test set:Loss: 1.973235 Acc@1: 0.369268 
	Train Epoch: 13 	Loss: 2.258322 Acc@1: 0.329856 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 2.309300 Acc@1: 0.297241 (ε = 1.54, δ = 1e-05) for α = 16.0
	Train Epoch: 13 	Loss: 2.275390 Acc@1: 0.303538 (ε = 1.56, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.005578 Acc@1: 0.360560 
	Train Epoch: 14 	Loss: 2.258294 Acc@1: 0.310864 (ε = 1.57, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 2.262162 Acc@1: 0.291297 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 14 	Loss: 2.248205 Acc@1: 0.290443 (ε = 1.62, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.048038 Acc@1: 0.343382 
	Train Epoch: 15 	Loss: 2.177811 Acc@1: 0.315057 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 2.175123 Acc@1: 0.312713 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 15 	Loss: 2.173571 Acc@1: 0.308121 (ε = 1.68, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.965944 Acc@1: 0.362469 
	Train Epoch: 16 	Loss: 2.212958 Acc@1: 0.322848 (ε = 1.69, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 2.194282 Acc@1: 0.314639 (ε = 1.71, δ = 1e-05) for α = 14.0
	Train Epoch: 16 	Loss: 2.205815 Acc@1: 0.318279 (ε = 1.73, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.967015 Acc@1: 0.391910 
	Train Epoch: 17 	Loss: 2.240784 Acc@1: 0.316832 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 2.219199 Acc@1: 0.314116 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 17 	Loss: 2.162735 Acc@1: 0.320358 (ε = 1.78, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.931564 Acc@1: 0.383981 
	Train Epoch: 18 	Loss: 2.270098 Acc@1: 0.326342 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 2.167211 Acc@1: 0.322747 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 18 	Loss: 2.153028 Acc@1: 0.327200 (ε = 1.83, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.888848 Acc@1: 0.397387 
	Train Epoch: 19 	Loss: 2.024387 Acc@1: 0.351396 (ε = 1.84, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 2.158971 Acc@1: 0.331646 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 19 	Loss: 2.146933 Acc@1: 0.333230 (ε = 1.88, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.881365 Acc@1: 0.409803 
	Train Epoch: 20 	Loss: 2.112322 Acc@1: 0.339798 (ε = 1.89, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 2.111120 Acc@1: 0.338347 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 20 	Loss: 2.102058 Acc@1: 0.338092 (ε = 1.93, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.899488 Acc@1: 0.389655 
	Train Epoch: 21 	Loss: 2.243396 Acc@1: 0.329258 (ε = 1.94, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 2.147848 Acc@1: 0.337292 (ε = 1.96, δ = 1e-05) for α = 13.0
	Train Epoch: 21 	Loss: 2.132394 Acc@1: 0.340562 (ε = 1.98, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.852679 Acc@1: 0.386319 
	Train Epoch: 22 	Loss: 2.017863 Acc@1: 0.324561 (ε = 1.99, δ = 1e-05) for α = 13.0
	Train Epoch: 22 	Loss: 2.053250 Acc@1: 0.343003 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 22 	Loss: 2.071527 Acc@1: 0.342012 (ε = 2.03, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.962246 Acc@1: 0.390990 
	Train Epoch: 23 	Loss: 2.111385 Acc@1: 0.346535 (ε = 2.04, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 2.114793 Acc@1: 0.338321 (ε = 2.05, δ = 1e-05) for α = 12.0
	Train Epoch: 23 	Loss: 2.090297 Acc@1: 0.343281 (ε = 2.07, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.876605 Acc@1: 0.409316 
	Train Epoch: 24 	Loss: 2.003626 Acc@1: 0.360000 (ε = 2.08, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 2.024365 Acc@1: 0.349737 (ε = 2.10, δ = 1e-05) for α = 12.0
	Train Epoch: 24 	Loss: 2.032019 Acc@1: 0.351326 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.841405 Acc@1: 0.418487 
	Train Epoch: 25 	Loss: 2.010163 Acc@1: 0.348007 (ε = 2.13, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 2.033132 Acc@1: 0.355690 (ε = 2.14, δ = 1e-05) for α = 12.0
	Train Epoch: 25 	Loss: 2.020905 Acc@1: 0.354213 (ε = 2.16, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.851222 Acc@1: 0.419933 
	Train Epoch: 26 	Loss: 1.950716 Acc@1: 0.374690 (ε = 2.17, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 2.016380 Acc@1: 0.359814 (ε = 2.19, δ = 1e-05) for α = 12.0
	Train Epoch: 26 	Loss: 2.008904 Acc@1: 0.361811 (ε = 2.21, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.839694 Acc@1: 0.423949 
	Train Epoch: 27 	Loss: 2.048593 Acc@1: 0.346354 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 1.984739 Acc@1: 0.367662 (ε = 2.23, δ = 1e-05) for α = 10.9
	Train Epoch: 27 	Loss: 1.992598 Acc@1: 0.366479 (ε = 2.25, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.822523 Acc@1: 0.422337 
	Train Epoch: 28 	Loss: 1.928374 Acc@1: 0.369427 (ε = 2.26, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 2.015383 Acc@1: 0.355345 (ε = 2.27, δ = 1e-05) for α = 10.9
	Train Epoch: 28 	Loss: 2.000991 Acc@1: 0.360662 (ε = 2.29, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.820227 Acc@1: 0.425680 
	Train Epoch: 29 	Loss: 2.003457 Acc@1: 0.353708 (ε = 2.30, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 2.021552 Acc@1: 0.361937 (ε = 2.31, δ = 1e-05) for α = 10.9
	Train Epoch: 29 	Loss: 2.007133 Acc@1: 0.363770 (ε = 2.33, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.829966 Acc@1: 0.423463 
	Train Epoch: 30 	Loss: 1.960789 Acc@1: 0.361506 (ε = 2.34, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 1.972446 Acc@1: 0.360850 (ε = 2.35, δ = 1e-05) for α = 10.9
	Train Epoch: 30 	Loss: 1.985778 Acc@1: 0.363810 (ε = 2.37, δ = 1e-05) for α = 10.8
	Test set:Loss: 1.828356 Acc@1: 0.423503 
Base private model test accuracy:  0.42326378965418693
              precision    recall  f1-score   support

         0.0       0.14      0.03      0.05       508
         1.0       0.09      0.02      0.03       482
         2.0       0.01      0.00      0.00       510
         3.0       0.04      0.01      0.01       489
         4.0       0.07      0.04      0.05       466
         5.0       0.31      0.43      0.36      2972
         6.0       0.42      0.42      0.42      3080
         7.0       0.43      0.42      0.43      2961
         8.0       0.57      0.61      0.59      3024
         9.0       0.48      0.56      0.52      3003

    accuracy                           0.42     17495
   macro avg       0.26      0.25      0.25     17495
weighted avg       0.39      0.42      0.40     17495

Base private model train accuracy:  0.3626138718058342
              precision    recall  f1-score   support

         0.0       0.42      0.28      0.34      3026
         1.0       0.41      0.33      0.37      2993
         2.0       0.27      0.19      0.22      3053
         3.0       0.29      0.22      0.25      3012
         4.0       0.28      0.17      0.21      3055
         5.0       0.28      0.46      0.34      3032
         6.0       0.35      0.42      0.38      3069
         7.0       0.37      0.40      0.38      3114
         8.0       0.48      0.61      0.53      3045
         9.0       0.44      0.55      0.49      3008

    accuracy                           0.36     30407
   macro avg       0.36      0.36      0.35     30407
weighted avg       0.36      0.36      0.35     30407

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.48233901203709795
test acc: 0.6188961038961038
min train acc: 0.5137075718015666
maj train acc: 0.45625806451612905
min test acc: 0.6157323688969258
maj test acc: 0.6223265519040166
total acc: 0.5510570859066105
total min acc: 0.5649915595377224
total maj acc: 0.538850693994033
precision, recall: (0.555446144523557, 0.48233901203709795)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 2.3746387899695556, 0.42326378965418693, 0.3626138718058342, 0.5510570859066105, 0.5649915595377224, 0.538850693994033, '              precision    recall  f1-score   support\n\n         0.0       0.14      0.03      0.05       508\n         1.0       0.09      0.02      0.03       482\n         2.0       0.01      0.00      0.00       510\n         3.0       0.04      0.01      0.01       489\n         4.0       0.07      0.04      0.05       466\n         5.0       0.31      0.43      0.36      2972\n         6.0       0.42      0.42      0.42      3080\n         7.0       0.43      0.42      0.43      2961\n         8.0       0.57      0.61      0.59      3024\n         9.0       0.48      0.56      0.52      3003\n\n    accuracy                           0.42     17495\n   macro avg       0.26      0.25      0.25     17495\nweighted avg       0.39      0.42      0.40     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.42      0.28      0.34      3026\n         1.0       0.41      0.33      0.37      2993\n         2.0       0.27      0.19      0.22      3053\n         3.0       0.29      0.22      0.25      3012\n         4.0       0.28      0.17      0.21      3055\n         5.0       0.28      0.46      0.34      3032\n         6.0       0.35      0.42      0.38      3069\n         7.0       0.37      0.40      0.38      3114\n         8.0       0.48      0.61      0.53      3045\n         9.0       0.44      0.55      0.49      3008\n\n    accuracy                           0.36     30407\n   macro avg       0.36      0.36      0.35     30407\nweighted avg       0.36      0.36      0.35     30407\n']
experiment_number: 11
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-11.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3042, 2990, 2942, 3111, 3032, 2955, 3000, 3000, 3026, 2974])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30072, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.834548 Acc@1: 0.095161 (ε = 0.48, δ = 1e-05) for α = 26.0
	Train Epoch: 1 	Loss: 2.661918 Acc@1: 0.106307 (ε = 0.58, δ = 1e-05) for α = 25.0
	Train Epoch: 1 	Loss: 2.562263 Acc@1: 0.120214 (ε = 0.67, δ = 1e-05) for α = 24.0
	Test set:Loss: 2.942907 Acc@1: 0.213583 
	Train Epoch: 2 	Loss: 3.250970 Acc@1: 0.152192 (ε = 0.71, δ = 1e-05) for α = 24.0
	Train Epoch: 2 	Loss: 2.399677 Acc@1: 0.120427 (ε = 0.79, δ = 1e-05) for α = 23.0
	Train Epoch: 2 	Loss: 2.317253 Acc@1: 0.144880 (ε = 0.86, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.392515 Acc@1: 0.177431 
	Train Epoch: 3 	Loss: 2.344852 Acc@1: 0.110662 (ε = 0.90, δ = 1e-05) for α = 22.0
	Train Epoch: 3 	Loss: 2.327391 Acc@1: 0.139290 (ε = 0.97, δ = 1e-05) for α = 21.0
	Train Epoch: 3 	Loss: 2.282107 Acc@1: 0.156131 (ε = 1.03, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.784302 Acc@1: 0.139670 
	Train Epoch: 4 	Loss: 2.774144 Acc@1: 0.143775 (ε = 1.06, δ = 1e-05) for α = 20.0
	Train Epoch: 4 	Loss: 2.456062 Acc@1: 0.116320 (ε = 1.12, δ = 1e-05) for α = 19.0
	Train Epoch: 4 	Loss: 2.389738 Acc@1: 0.122729 (ε = 1.17, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.320834 Acc@1: 0.042110 
	Train Epoch: 5 	Loss: 2.329121 Acc@1: 0.116984 (ε = 1.20, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.306774 Acc@1: 0.125386 (ε = 1.25, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.278186 Acc@1: 0.151083 (ε = 1.30, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.224874 Acc@1: 0.138038 
	Train Epoch: 6 	Loss: 2.204891 Acc@1: 0.185425 (ε = 1.32, δ = 1e-05) for α = 17.0
	Train Epoch: 6 	Loss: 2.216016 Acc@1: 0.208473 (ε = 1.37, δ = 1e-05) for α = 16.0
	Train Epoch: 6 	Loss: 2.292934 Acc@1: 0.195492 (ε = 1.41, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.124707 Acc@1: 0.239335 
	Train Epoch: 7 	Loss: 2.247901 Acc@1: 0.205401 (ε = 1.44, δ = 1e-05) for α = 16.0
	Train Epoch: 7 	Loss: 2.200277 Acc@1: 0.231143 (ε = 1.48, δ = 1e-05) for α = 15.0
	Train Epoch: 7 	Loss: 2.205990 Acc@1: 0.241557 (ε = 1.52, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.098809 Acc@1: 0.261924 
	Train Epoch: 8 	Loss: 2.147027 Acc@1: 0.268949 (ε = 1.54, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.142939 Acc@1: 0.271269 (ε = 1.58, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.124323 Acc@1: 0.284934 (ε = 1.62, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.176052 Acc@1: 0.250888 
	Train Epoch: 9 	Loss: 2.116643 Acc@1: 0.274329 (ε = 1.64, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.327977 Acc@1: 0.264782 (ε = 1.68, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.218978 Acc@1: 0.281295 (ε = 1.71, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.914811 Acc@1: 0.355311 
	Train Epoch: 10 	Loss: 2.063379 Acc@1: 0.314597 (ε = 1.73, δ = 1e-05) for α = 14.0
	Train Epoch: 10 	Loss: 2.414837 Acc@1: 0.288076 (ε = 1.77, δ = 1e-05) for α = 13.0
	Train Epoch: 10 	Loss: 2.359286 Acc@1: 0.269534 (ε = 1.80, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.012684 Acc@1: 0.309505 
	Train Epoch: 11 	Loss: 2.068454 Acc@1: 0.271259 (ε = 1.82, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.096536 Acc@1: 0.298818 (ε = 1.85, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.064182 Acc@1: 0.314374 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.996715 Acc@1: 0.344599 
	Train Epoch: 12 	Loss: 1.967953 Acc@1: 0.329288 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 12 	Loss: 2.007617 Acc@1: 0.342291 (ε = 1.94, δ = 1e-05) for α = 12.0
	Train Epoch: 12 	Loss: 1.976665 Acc@1: 0.349846 (ε = 1.97, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.936666 Acc@1: 0.366111 
	Train Epoch: 13 	Loss: 1.929670 Acc@1: 0.362357 (ε = 1.98, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 1.922525 Acc@1: 0.375045 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 1.931275 Acc@1: 0.380004 (ε = 2.05, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.823720 Acc@1: 0.427599 
	Train Epoch: 14 	Loss: 1.941766 Acc@1: 0.395659 (ε = 2.06, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 1.885596 Acc@1: 0.401307 (ε = 2.09, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 1.891145 Acc@1: 0.400543 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.890733 Acc@1: 0.412687 
	Train Epoch: 15 	Loss: 1.736232 Acc@1: 0.420538 (ε = 2.14, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 1.864291 Acc@1: 0.410225 (ε = 2.17, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 1.886964 Acc@1: 0.407732 (ε = 2.20, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.908997 Acc@1: 0.401098 
	Train Epoch: 16 	Loss: 1.897304 Acc@1: 0.399845 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 1.895231 Acc@1: 0.412706 (ε = 2.24, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 1.932066 Acc@1: 0.401781 (ε = 2.26, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.916967 Acc@1: 0.377922 
	Train Epoch: 17 	Loss: 1.908615 Acc@1: 0.400974 (ε = 2.28, δ = 1e-05) for α = 10.9
	Train Epoch: 17 	Loss: 1.901662 Acc@1: 0.395443 (ε = 2.31, δ = 1e-05) for α = 10.7
	Train Epoch: 17 	Loss: 1.910826 Acc@1: 0.403489 (ε = 2.33, δ = 1e-05) for α = 10.6
	Test set:Loss: 1.859363 Acc@1: 0.422840 
	Train Epoch: 18 	Loss: 1.927157 Acc@1: 0.400986 (ε = 2.35, δ = 1e-05) for α = 10.6
	Train Epoch: 18 	Loss: 1.909508 Acc@1: 0.406758 (ε = 2.37, δ = 1e-05) for α = 10.5
	Train Epoch: 18 	Loss: 1.889807 Acc@1: 0.411124 (ε = 2.40, δ = 1e-05) for α = 10.4
	Test set:Loss: 1.951867 Acc@1: 0.423573 
	Train Epoch: 19 	Loss: 1.889179 Acc@1: 0.424460 (ε = 2.41, δ = 1e-05) for α = 10.4
	Train Epoch: 19 	Loss: 1.869128 Acc@1: 0.423294 (ε = 2.44, δ = 1e-05) for α = 10.3
	Train Epoch: 19 	Loss: 1.846334 Acc@1: 0.422863 (ε = 2.47, δ = 1e-05) for α = 10.2
	Test set:Loss: 1.859068 Acc@1: 0.414864 
	Train Epoch: 20 	Loss: 1.863458 Acc@1: 0.416804 (ε = 2.48, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 1.822080 Acc@1: 0.429994 (ε = 2.50, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 1.805615 Acc@1: 0.434512 (ε = 2.53, δ = 1e-05) for α = 10.0
	Test set:Loss: 1.994818 Acc@1: 0.397494 
	Train Epoch: 21 	Loss: 1.826308 Acc@1: 0.404023 (ε = 2.54, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.784469 Acc@1: 0.438000 (ε = 2.57, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.785159 Acc@1: 0.443615 (ε = 2.59, δ = 1e-05) for α = 9.8
	Test set:Loss: 1.962571 Acc@1: 0.428098 
	Train Epoch: 22 	Loss: 1.845717 Acc@1: 0.441224 (ε = 2.60, δ = 1e-05) for α = 9.8
	Train Epoch: 22 	Loss: 1.783834 Acc@1: 0.447750 (ε = 2.63, δ = 1e-05) for α = 9.7
	Train Epoch: 22 	Loss: 1.773712 Acc@1: 0.450131 (ε = 2.65, δ = 1e-05) for α = 9.6
	Test set:Loss: 1.809765 Acc@1: 0.449475 
	Train Epoch: 23 	Loss: 1.763044 Acc@1: 0.459302 (ε = 2.66, δ = 1e-05) for α = 9.6
	Train Epoch: 23 	Loss: 1.753454 Acc@1: 0.457334 (ε = 2.69, δ = 1e-05) for α = 9.5
	Train Epoch: 23 	Loss: 1.754710 Acc@1: 0.457193 (ε = 2.71, δ = 1e-05) for α = 9.4
	Test set:Loss: 1.875573 Acc@1: 0.442528 
	Train Epoch: 24 	Loss: 1.832055 Acc@1: 0.461214 (ε = 2.72, δ = 1e-05) for α = 9.4
	Train Epoch: 24 	Loss: 1.775578 Acc@1: 0.456350 (ε = 2.75, δ = 1e-05) for α = 9.3
	Train Epoch: 24 	Loss: 1.764824 Acc@1: 0.460312 (ε = 2.77, δ = 1e-05) for α = 9.3
	Test set:Loss: 1.876521 Acc@1: 0.439065 
	Train Epoch: 25 	Loss: 1.801799 Acc@1: 0.468725 (ε = 2.78, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.768438 Acc@1: 0.458855 (ε = 2.80, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.748134 Acc@1: 0.460002 (ε = 2.83, δ = 1e-05) for α = 9.1
	Test set:Loss: 1.842485 Acc@1: 0.446667 
	Train Epoch: 26 	Loss: 1.793242 Acc@1: 0.453734 (ε = 2.84, δ = 1e-05) for α = 9.1
	Train Epoch: 26 	Loss: 1.719398 Acc@1: 0.466586 (ε = 2.86, δ = 1e-05) for α = 9.0
	Train Epoch: 26 	Loss: 1.727927 Acc@1: 0.465726 (ε = 2.88, δ = 1e-05) for α = 9.0
	Test set:Loss: 1.852327 Acc@1: 0.446308 
	Train Epoch: 27 	Loss: 1.682886 Acc@1: 0.464286 (ε = 2.89, δ = 1e-05) for α = 9.0
	Train Epoch: 27 	Loss: 1.714214 Acc@1: 0.476115 (ε = 2.92, δ = 1e-05) for α = 8.9
	Train Epoch: 27 	Loss: 1.733829 Acc@1: 0.470782 (ε = 2.94, δ = 1e-05) for α = 8.9
	Test set:Loss: 1.846835 Acc@1: 0.449016 
	Train Epoch: 28 	Loss: 1.641979 Acc@1: 0.468927 (ε = 2.95, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.727168 Acc@1: 0.474401 (ε = 2.97, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.710330 Acc@1: 0.475252 (ε = 2.99, δ = 1e-05) for α = 8.7
	Test set:Loss: 1.889549 Acc@1: 0.440097 
	Train Epoch: 29 	Loss: 1.612377 Acc@1: 0.505272 (ε = 3.00, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.742435 Acc@1: 0.471370 (ε = 3.03, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.743081 Acc@1: 0.467295 (ε = 3.05, δ = 1e-05) for α = 8.6
	Test set:Loss: 1.884748 Acc@1: 0.441236 
	Train Epoch: 30 	Loss: 1.803926 Acc@1: 0.454545 (ε = 3.06, δ = 1e-05) for α = 8.6
	Train Epoch: 30 	Loss: 1.735990 Acc@1: 0.472306 (ε = 3.08, δ = 1e-05) for α = 8.5
	Train Epoch: 30 	Loss: 1.733091 Acc@1: 0.472619 (ε = 3.10, δ = 1e-05) for α = 8.5
	Test set:Loss: 1.870078 Acc@1: 0.446248 
Base private model test accuracy:  0.44578450985996
              precision    recall  f1-score   support

         0.0       0.21      0.44      0.28       508
         1.0       0.15      0.45      0.22       482
         2.0       0.14      0.31      0.20       510
         3.0       0.07      0.21      0.11       489
         4.0       0.12      0.36      0.18       466
         5.0       0.54      0.32      0.40      2972
         6.0       0.63      0.52      0.57      3080
         7.0       0.56      0.43      0.49      2961
         8.0       0.77      0.57      0.65      3024
         9.0       0.62      0.45      0.52      3003

    accuracy                           0.45     17495
   macro avg       0.38      0.41      0.36     17495
weighted avg       0.56      0.45      0.48     17495

Base private model train accuracy:  0.47718808193668527
              precision    recall  f1-score   support

         0.0       0.60      0.57      0.58      3042
         1.0       0.52      0.58      0.55      2990
         2.0       0.46      0.42      0.44      2942
         3.0       0.38      0.33      0.35      3111
         4.0       0.44      0.45      0.44      3032
         5.0       0.39      0.33      0.35      2955
         6.0       0.44      0.55      0.49      3000
         7.0       0.44      0.45      0.45      3000
         8.0       0.59      0.60      0.60      3026
         9.0       0.50      0.50      0.50      2974

    accuracy                           0.48     30072
   macro avg       0.48      0.48      0.48     30072
weighted avg       0.48      0.48      0.48     30072

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7740755520085129
test acc: 0.7298701298701299
min train acc: 0.9471737982039091
maj train acc: 0.615080377647359
min test acc: 0.9130658436213992
maj test acc: 0.5436206444851979
total acc: 0.7517085030884479
total min acc: 0.9298931456867344
total maj acc: 0.5798216132368149
precision, recall: (0.7366921957085891, 0.7740755520085129)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 3.107731777432171, 0.44578450985996, 0.47718808193668527, 0.7517085030884479, 0.9298931456867344, 0.5798216132368149, '              precision    recall  f1-score   support\n\n         0.0       0.21      0.44      0.28       508\n         1.0       0.15      0.45      0.22       482\n         2.0       0.14      0.31      0.20       510\n         3.0       0.07      0.21      0.11       489\n         4.0       0.12      0.36      0.18       466\n         5.0       0.54      0.32      0.40      2972\n         6.0       0.63      0.52      0.57      3080\n         7.0       0.56      0.43      0.49      2961\n         8.0       0.77      0.57      0.65      3024\n         9.0       0.62      0.45      0.52      3003\n\n    accuracy                           0.45     17495\n   macro avg       0.38      0.41      0.36     17495\nweighted avg       0.56      0.45      0.48     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.60      0.57      0.58      3042\n         1.0       0.52      0.58      0.55      2990\n         2.0       0.46      0.42      0.44      2942\n         3.0       0.38      0.33      0.35      3111\n         4.0       0.44      0.45      0.44      3032\n         5.0       0.39      0.33      0.35      2955\n         6.0       0.44      0.55      0.49      3000\n         7.0       0.44      0.45      0.45      3000\n         8.0       0.59      0.60      0.60      3026\n         9.0       0.50      0.50      0.50      2974\n\n    accuracy                           0.48     30072\n   macro avg       0.48      0.48      0.48     30072\nweighted avg       0.48      0.48      0.48     30072\n']
experiment_number: 21
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-21.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([522, 498, 509, 493, 455, 524, 465, 535, 439, 466])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4906, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.992293 Acc@1: 0.118280 (ε = 0.48, δ = 1e-05) for α = 26.0
	Train Epoch: 1 	Loss: 15.774483 Acc@1: 0.094580 (ε = 0.58, δ = 1e-05) for α = 25.0
	Train Epoch: 1 	Loss: 9.630551 Acc@1: 0.100329 (ε = 0.67, δ = 1e-05) for α = 24.0
	Test set:Loss: 4.226133 Acc@1: 0.179535 
	Train Epoch: 2 	Loss: 3.550665 Acc@1: 0.085859 (ε = 0.71, δ = 1e-05) for α = 24.0
	Train Epoch: 2 	Loss: 10.495783 Acc@1: 0.105038 (ε = 0.79, δ = 1e-05) for α = 23.0
	Train Epoch: 2 	Loss: 18.379609 Acc@1: 0.102885 (ε = 0.86, δ = 1e-05) for α = 23.0
	Test set:Loss: 8.188462 Acc@1: 0.163617 
	Train Epoch: 3 	Loss: 10.877581 Acc@1: 0.066667 (ε = 0.90, δ = 1e-05) for α = 22.0
	Train Epoch: 3 	Loss: 6.641208 Acc@1: 0.092143 (ε = 0.97, δ = 1e-05) for α = 21.0
	Train Epoch: 3 	Loss: 7.565127 Acc@1: 0.098003 (ε = 1.03, δ = 1e-05) for α = 20.0
	Test set:Loss: 18.306483 Acc@1: 0.032196 
	Train Epoch: 4 	Loss: 12.122847 Acc@1: 0.075000 (ε = 1.06, δ = 1e-05) for α = 20.0
	Train Epoch: 4 	Loss: 12.332818 Acc@1: 0.110707 (ε = 1.12, δ = 1e-05) for α = 19.0
	Train Epoch: 4 	Loss: 13.399956 Acc@1: 0.102520 (ε = 1.17, δ = 1e-05) for α = 18.0
	Test set:Loss: 24.569179 Acc@1: 0.154676 
	Train Epoch: 5 	Loss: 37.570076 Acc@1: 0.109589 (ε = 1.20, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 31.424276 Acc@1: 0.105375 (ε = 1.25, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 27.276724 Acc@1: 0.101561 (ε = 1.30, δ = 1e-05) for α = 17.0
	Test set:Loss: 31.696225 Acc@1: 0.040185 
	Train Epoch: 6 	Loss: 33.657055 Acc@1: 0.137363 (ε = 1.32, δ = 1e-05) for α = 17.0
	Train Epoch: 6 	Loss: 33.238736 Acc@1: 0.102296 (ε = 1.37, δ = 1e-05) for α = 16.0
	Train Epoch: 6 	Loss: 34.435121 Acc@1: 0.097419 (ε = 1.41, δ = 1e-05) for α = 16.0
	Test set:Loss: 27.152412 Acc@1: 0.168876 
	Train Epoch: 7 	Loss: 23.165899 Acc@1: 0.090395 (ε = 1.44, δ = 1e-05) for α = 16.0
	Train Epoch: 7 	Loss: 18.933600 Acc@1: 0.105289 (ε = 1.48, δ = 1e-05) for α = 15.0
	Train Epoch: 7 	Loss: 25.566522 Acc@1: 0.105953 (ε = 1.52, δ = 1e-05) for α = 15.0
	Test set:Loss: 36.654329 Acc@1: 0.172056 
	Train Epoch: 8 	Loss: 19.432789 Acc@1: 0.139785 (ε = 1.54, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 31.396550 Acc@1: 0.103007 (ε = 1.58, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 43.649525 Acc@1: 0.104673 (ε = 1.62, δ = 1e-05) for α = 14.0
	Test set:Loss: 41.030658 Acc@1: 0.034521 
	Train Epoch: 9 	Loss: 67.987389 Acc@1: 0.115789 (ε = 1.64, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 49.071212 Acc@1: 0.100763 (ε = 1.68, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 70.503254 Acc@1: 0.097900 (ε = 1.71, δ = 1e-05) for α = 14.0
	Test set:Loss: 83.461068 Acc@1: 0.032769 
	Train Epoch: 10 	Loss: 60.377792 Acc@1: 0.120000 (ε = 1.73, δ = 1e-05) for α = 14.0
	Train Epoch: 10 	Loss: 90.969608 Acc@1: 0.098568 (ε = 1.77, δ = 1e-05) for α = 13.0
	Train Epoch: 10 	Loss: 81.950490 Acc@1: 0.097484 (ε = 1.80, δ = 1e-05) for α = 13.0
	Test set:Loss: 71.823135 Acc@1: 0.172043 
	Train Epoch: 11 	Loss: 144.063751 Acc@1: 0.097087 (ε = 1.82, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 135.688105 Acc@1: 0.104663 (ε = 1.85, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 92.171190 Acc@1: 0.101336 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 65.881095 Acc@1: 0.171386 
	Train Epoch: 12 	Loss: 9.996221 Acc@1: 0.091371 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 12 	Loss: 51.923080 Acc@1: 0.098098 (ε = 1.94, δ = 1e-05) for α = 12.0
	Train Epoch: 12 	Loss: 83.732854 Acc@1: 0.097292 (ε = 1.97, δ = 1e-05) for α = 12.0
	Test set:Loss: 126.058467 Acc@1: 0.031476 
	Train Epoch: 13 	Loss: 185.599930 Acc@1: 0.079812 (ε = 1.98, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 90.047762 Acc@1: 0.106946 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 74.514947 Acc@1: 0.104980 (ε = 2.05, δ = 1e-05) for α = 12.0
	Test set:Loss: 38.271179 Acc@1: 0.172040 
	Train Epoch: 14 	Loss: 55.237129 Acc@1: 0.089286 (ε = 2.06, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 82.370679 Acc@1: 0.108112 (ε = 2.09, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 74.654813 Acc@1: 0.100566 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 42.834030 Acc@1: 0.171750 
	Train Epoch: 15 	Loss: 88.136856 Acc@1: 0.105263 (ε = 2.14, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 67.499274 Acc@1: 0.099115 (ε = 2.17, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 53.137538 Acc@1: 0.098399 (ε = 2.20, δ = 1e-05) for α = 10.9
	Test set:Loss: 51.713360 Acc@1: 0.033958 
	Train Epoch: 16 	Loss: 161.074234 Acc@1: 0.113990 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 54.594526 Acc@1: 0.102864 (ε = 2.24, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 52.495290 Acc@1: 0.095193 (ε = 2.26, δ = 1e-05) for α = 10.9
	Test set:Loss: 33.177236 Acc@1: 0.170804 
	Train Epoch: 17 	Loss: 15.334885 Acc@1: 0.076923 (ε = 2.28, δ = 1e-05) for α = 10.9
	Train Epoch: 17 	Loss: 35.961918 Acc@1: 0.104206 (ε = 2.31, δ = 1e-05) for α = 10.7
	Train Epoch: 17 	Loss: 39.346863 Acc@1: 0.107688 (ε = 2.33, δ = 1e-05) for α = 10.6
	Test set:Loss: 51.908446 Acc@1: 0.034791 
	Train Epoch: 18 	Loss: 63.341545 Acc@1: 0.110553 (ε = 2.35, δ = 1e-05) for α = 10.6
	Train Epoch: 18 	Loss: 65.889123 Acc@1: 0.093696 (ε = 2.37, δ = 1e-05) for α = 10.5
	Train Epoch: 18 	Loss: 57.191741 Acc@1: 0.102941 (ε = 2.40, δ = 1e-05) for α = 10.4
	Test set:Loss: 51.961167 Acc@1: 0.034131 
	Train Epoch: 19 	Loss: 26.044649 Acc@1: 0.076142 (ε = 2.41, δ = 1e-05) for α = 10.4
	Train Epoch: 19 	Loss: 26.509914 Acc@1: 0.091311 (ε = 2.44, δ = 1e-05) for α = 10.3
	Train Epoch: 19 	Loss: 52.711042 Acc@1: 0.100447 (ε = 2.47, δ = 1e-05) for α = 10.2
	Test set:Loss: 52.683471 Acc@1: 0.171596 
	Train Epoch: 20 	Loss: 96.619240 Acc@1: 0.127451 (ε = 2.48, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 87.174279 Acc@1: 0.103009 (ε = 2.50, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 62.831348 Acc@1: 0.106422 (ε = 2.53, δ = 1e-05) for α = 10.0
	Test set:Loss: 51.699325 Acc@1: 0.033055 
	Train Epoch: 21 	Loss: 26.987989 Acc@1: 0.120603 (ε = 2.54, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 38.106003 Acc@1: 0.101353 (ε = 2.57, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 37.933942 Acc@1: 0.102986 (ε = 2.59, δ = 1e-05) for α = 9.8
	Test set:Loss: 51.968286 Acc@1: 0.032492 
	Train Epoch: 22 	Loss: 6.711552 Acc@1: 0.103896 (ε = 2.60, δ = 1e-05) for α = 9.8
	Train Epoch: 22 	Loss: 82.442708 Acc@1: 0.097401 (ε = 2.63, δ = 1e-05) for α = 9.7
	Train Epoch: 22 	Loss: 67.232833 Acc@1: 0.097876 (ε = 2.65, δ = 1e-05) for α = 9.6
	Test set:Loss: 51.160682 Acc@1: 0.031869 
	Train Epoch: 23 	Loss: 8.344051 Acc@1: 0.101942 (ε = 2.66, δ = 1e-05) for α = 9.6
	Train Epoch: 23 	Loss: 82.008787 Acc@1: 0.098354 (ε = 2.69, δ = 1e-05) for α = 9.5
	Train Epoch: 23 	Loss: 70.714882 Acc@1: 0.101306 (ε = 2.71, δ = 1e-05) for α = 9.4
	Test set:Loss: 41.916343 Acc@1: 0.165602 
	Train Epoch: 24 	Loss: 31.149591 Acc@1: 0.103604 (ε = 2.72, δ = 1e-05) for α = 9.4
	Train Epoch: 24 	Loss: 27.240831 Acc@1: 0.096834 (ε = 2.75, δ = 1e-05) for α = 9.3
	Train Epoch: 24 	Loss: 37.630436 Acc@1: 0.097024 (ε = 2.77, δ = 1e-05) for α = 9.3
	Test set:Loss: 41.038141 Acc@1: 0.032203 
	Train Epoch: 25 	Loss: 48.698410 Acc@1: 0.108571 (ε = 2.78, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 41.829279 Acc@1: 0.105074 (ε = 2.80, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 44.092609 Acc@1: 0.103246 (ε = 2.83, δ = 1e-05) for α = 9.1
	Test set:Loss: 36.500163 Acc@1: 0.032143 
	Train Epoch: 26 	Loss: 47.660263 Acc@1: 0.092896 (ε = 2.84, δ = 1e-05) for α = 9.1
	Train Epoch: 26 	Loss: 64.521212 Acc@1: 0.092701 (ε = 2.86, δ = 1e-05) for α = 9.0
	Train Epoch: 26 	Loss: 46.620214 Acc@1: 0.096070 (ε = 2.88, δ = 1e-05) for α = 9.0
	Test set:Loss: 37.656437 Acc@1: 0.166637 
	Train Epoch: 27 	Loss: 26.817719 Acc@1: 0.072115 (ε = 2.89, δ = 1e-05) for α = 9.0
	Train Epoch: 27 	Loss: 23.123016 Acc@1: 0.080618 (ε = 2.92, δ = 1e-05) for α = 8.9
	Train Epoch: 27 	Loss: 38.210696 Acc@1: 0.092313 (ε = 2.94, δ = 1e-05) for α = 8.9
	Test set:Loss: 37.082679 Acc@1: 0.166904 
	Train Epoch: 28 	Loss: 40.865574 Acc@1: 0.090909 (ε = 2.95, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 39.178434 Acc@1: 0.092107 (ε = 2.97, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 31.745885 Acc@1: 0.092159 (ε = 2.99, δ = 1e-05) for α = 8.7
	Test set:Loss: 35.842382 Acc@1: 0.031410 
	Train Epoch: 29 	Loss: 88.354004 Acc@1: 0.082051 (ε = 3.00, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 36.169693 Acc@1: 0.094664 (ε = 3.03, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 40.941866 Acc@1: 0.097705 (ε = 3.05, δ = 1e-05) for α = 8.6
	Test set:Loss: 35.969720 Acc@1: 0.031347 
	Train Epoch: 30 	Loss: 53.337566 Acc@1: 0.082524 (ε = 3.06, δ = 1e-05) for α = 8.6
	Train Epoch: 30 	Loss: 28.937568 Acc@1: 0.091423 (ε = 3.08, δ = 1e-05) for α = 8.5
	Train Epoch: 30 	Loss: 31.697388 Acc@1: 0.094894 (ε = 3.10, δ = 1e-05) for α = 8.5
	Test set:Loss: 35.426332 Acc@1: 0.031180 
Base private model test accuracy:  0.031037439268362388
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.03      0.95      0.05       482
         2.0       0.00      0.00      0.00       510
         3.0       0.00      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.18      0.00      0.01      2972
         6.0       0.28      0.01      0.03      3080
         7.0       0.20      0.00      0.00      2961
         8.0       0.15      0.00      0.01      3024
         9.0       0.16      0.00      0.01      3003

    accuracy                           0.03     17495
   macro avg       0.10      0.10      0.01     17495
weighted avg       0.17      0.03      0.01     17495

Base private model train accuracy:  0.0984508764777823
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       522
         1.0       0.10      0.94      0.18       498
         2.0       0.00      0.00      0.00       509
         3.0       0.11      0.00      0.01       493
         4.0       0.00      0.00      0.00       455
         5.0       0.00      0.00      0.00       524
         6.0       0.17      0.02      0.03       465
         7.0       0.00      0.00      0.00       535
         8.0       0.06      0.00      0.01       439
         9.0       0.00      0.00      0.00       466

    accuracy                           0.10      4906
   macro avg       0.04      0.10      0.02      4906
weighted avg       0.04      0.10      0.02      4906

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.9021606196494089
test acc: 0.10987124463519315
min train acc: 0.986159169550173
maj train acc: 0.8108108108108109
min test acc: 0.016464471403812797
maj test acc: 0.2006745362563238
total acc: 0.516203219736567
total min acc: 0.5017316017316017
total maj acc: 0.5054852320675105
precision, recall: (0.5162118031257289, 0.9021606196494089)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 3.107731777432171, 0.031037439268362388, 0.0984508764777823, 0.516203219736567, 0.5017316017316017, 0.5054852320675105, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.03      0.95      0.05       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.00      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.18      0.00      0.01      2972\n         6.0       0.28      0.01      0.03      3080\n         7.0       0.20      0.00      0.00      2961\n         8.0       0.15      0.00      0.01      3024\n         9.0       0.16      0.00      0.01      3003\n\n    accuracy                           0.03     17495\n   macro avg       0.10      0.10      0.01     17495\nweighted avg       0.17      0.03      0.01     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       522\n         1.0       0.10      0.94      0.18       498\n         2.0       0.00      0.00      0.00       509\n         3.0       0.11      0.00      0.01       493\n         4.0       0.00      0.00      0.00       455\n         5.0       0.00      0.00      0.00       524\n         6.0       0.17      0.02      0.03       465\n         7.0       0.00      0.00      0.00       535\n         8.0       0.06      0.00      0.01       439\n         9.0       0.00      0.00      0.00       466\n\n    accuracy                           0.10      4906\n   macro avg       0.04      0.10      0.02      4906\nweighted avg       0.04      0.10      0.02      4906\n']
experiment_number: 15
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-15.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 2.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3079, 2995, 3121, 3001, 3067, 3103, 2919, 3105, 3018, 3010])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30418, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.198466 Acc@1: 0.109827 (ε = 0.48, δ = 1e-05) for α = 26.0
	Train Epoch: 1 	Loss: 2.482367 Acc@1: 0.112169 (ε = 0.58, δ = 1e-05) for α = 25.0
	Train Epoch: 1 	Loss: 2.839142 Acc@1: 0.110264 (ε = 0.67, δ = 1e-05) for α = 24.0
	Test set:Loss: 2.707230 Acc@1: 0.099605 
	Train Epoch: 2 	Loss: 2.454423 Acc@1: 0.132832 (ε = 0.71, δ = 1e-05) for α = 24.0
	Train Epoch: 2 	Loss: 2.951659 Acc@1: 0.145184 (ε = 0.79, δ = 1e-05) for α = 23.0
	Train Epoch: 2 	Loss: 2.599541 Acc@1: 0.155976 (ε = 0.86, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.103129 Acc@1: 0.168932 
	Train Epoch: 3 	Loss: 2.120046 Acc@1: 0.163282 (ε = 0.90, δ = 1e-05) for α = 22.0
	Train Epoch: 3 	Loss: 2.465197 Acc@1: 0.157906 (ε = 0.97, δ = 1e-05) for α = 21.0
	Train Epoch: 3 	Loss: 2.315557 Acc@1: 0.170544 (ε = 1.03, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.087669 Acc@1: 0.174993 
	Train Epoch: 4 	Loss: 2.192308 Acc@1: 0.191814 (ε = 1.06, δ = 1e-05) for α = 20.0
	Train Epoch: 4 	Loss: 2.172998 Acc@1: 0.192762 (ε = 1.12, δ = 1e-05) for α = 19.0
	Train Epoch: 4 	Loss: 2.156639 Acc@1: 0.208126 (ε = 1.17, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.065789 Acc@1: 0.223453 
	Train Epoch: 5 	Loss: 2.076256 Acc@1: 0.223090 (ε = 1.20, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.176663 Acc@1: 0.230432 (ε = 1.25, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.207298 Acc@1: 0.211405 (ε = 1.30, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.122457 Acc@1: 0.183196 
	Train Epoch: 6 	Loss: 2.143857 Acc@1: 0.191438 (ε = 1.32, δ = 1e-05) for α = 17.0
	Train Epoch: 6 	Loss: 2.111207 Acc@1: 0.214599 (ε = 1.37, δ = 1e-05) for α = 16.0
	Train Epoch: 6 	Loss: 2.119091 Acc@1: 0.225280 (ε = 1.41, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.059389 Acc@1: 0.270482 
	Train Epoch: 7 	Loss: 2.149140 Acc@1: 0.253022 (ε = 1.44, δ = 1e-05) for α = 16.0
	Train Epoch: 7 	Loss: 2.205718 Acc@1: 0.231955 (ε = 1.48, δ = 1e-05) for α = 15.0
	Train Epoch: 7 	Loss: 2.179766 Acc@1: 0.245956 (ε = 1.52, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.117106 Acc@1: 0.248400 
	Train Epoch: 8 	Loss: 2.198047 Acc@1: 0.243137 (ε = 1.54, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.195281 Acc@1: 0.269030 (ε = 1.58, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.207966 Acc@1: 0.274894 (ε = 1.62, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.201798 Acc@1: 0.225019 
	Train Epoch: 9 	Loss: 2.299699 Acc@1: 0.224608 (ε = 1.64, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.237996 Acc@1: 0.239493 (ε = 1.68, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.200362 Acc@1: 0.251979 (ε = 1.71, δ = 1e-05) for α = 14.0
	Test set:Loss: 1.975982 Acc@1: 0.307867 
	Train Epoch: 10 	Loss: 2.028862 Acc@1: 0.304538 (ε = 1.73, δ = 1e-05) for α = 14.0
	Train Epoch: 10 	Loss: 2.166417 Acc@1: 0.319757 (ε = 1.77, δ = 1e-05) for α = 13.0
	Train Epoch: 10 	Loss: 2.197517 Acc@1: 0.328517 (ε = 1.80, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.026635 Acc@1: 0.382595 
	Train Epoch: 11 	Loss: 2.239269 Acc@1: 0.347039 (ε = 1.82, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.160591 Acc@1: 0.352681 (ε = 1.85, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.150123 Acc@1: 0.353933 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.993005 Acc@1: 0.381060 
	Train Epoch: 12 	Loss: 2.191834 Acc@1: 0.328671 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 12 	Loss: 2.870708 Acc@1: 0.209684 (ε = 1.94, δ = 1e-05) for α = 12.0
	Train Epoch: 12 	Loss: 2.562922 Acc@1: 0.200880 (ε = 1.97, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.142305 Acc@1: 0.207479 
	Train Epoch: 13 	Loss: 2.176158 Acc@1: 0.222600 (ε = 1.98, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 2.240287 Acc@1: 0.264282 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 2.260848 Acc@1: 0.265254 (ε = 2.05, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.025574 Acc@1: 0.346853 
	Train Epoch: 14 	Loss: 2.121929 Acc@1: 0.319076 (ε = 2.06, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 2.217737 Acc@1: 0.304250 (ε = 2.09, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 2.203217 Acc@1: 0.299141 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.919425 Acc@1: 0.378293 
	Train Epoch: 15 	Loss: 1.953475 Acc@1: 0.343911 (ε = 2.14, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 2.020854 Acc@1: 0.340260 (ε = 2.17, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 2.033292 Acc@1: 0.344341 (ε = 2.20, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.059136 Acc@1: 0.339727 
	Train Epoch: 16 	Loss: 2.038851 Acc@1: 0.331735 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 2.010135 Acc@1: 0.358787 (ε = 2.24, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 2.024394 Acc@1: 0.358138 (ε = 2.26, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.930754 Acc@1: 0.382991 
	Train Epoch: 17 	Loss: 2.081469 Acc@1: 0.356404 (ε = 2.28, δ = 1e-05) for α = 10.9
	Train Epoch: 17 	Loss: 2.013667 Acc@1: 0.364194 (ε = 2.31, δ = 1e-05) for α = 10.7
	Train Epoch: 17 	Loss: 2.010061 Acc@1: 0.370492 (ε = 2.33, δ = 1e-05) for α = 10.6
	Test set:Loss: 2.035645 Acc@1: 0.378676 
	Train Epoch: 18 	Loss: 2.261738 Acc@1: 0.316171 (ε = 2.35, δ = 1e-05) for α = 10.6
	Train Epoch: 18 	Loss: 2.057971 Acc@1: 0.353595 (ε = 2.37, δ = 1e-05) for α = 10.5
	Train Epoch: 18 	Loss: 2.004615 Acc@1: 0.362004 (ε = 2.40, δ = 1e-05) for α = 10.4
	Test set:Loss: 1.779081 Acc@1: 0.438263 
	Train Epoch: 19 	Loss: 1.946911 Acc@1: 0.380952 (ε = 2.41, δ = 1e-05) for α = 10.4
	Train Epoch: 19 	Loss: 1.968869 Acc@1: 0.383704 (ε = 2.44, δ = 1e-05) for α = 10.3
	Train Epoch: 19 	Loss: 1.999362 Acc@1: 0.379538 (ε = 2.47, δ = 1e-05) for α = 10.2
	Test set:Loss: 1.777184 Acc@1: 0.437483 
	Train Epoch: 20 	Loss: 1.840187 Acc@1: 0.386602 (ε = 2.48, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 1.930882 Acc@1: 0.384074 (ε = 2.50, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 1.936785 Acc@1: 0.394599 (ε = 2.53, δ = 1e-05) for α = 10.0
	Test set:Loss: 1.726374 Acc@1: 0.457081 
	Train Epoch: 21 	Loss: 1.924916 Acc@1: 0.391717 (ε = 2.54, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.916211 Acc@1: 0.402607 (ε = 2.57, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.907570 Acc@1: 0.405284 (ε = 2.59, δ = 1e-05) for α = 9.8
	Test set:Loss: 1.821009 Acc@1: 0.440890 
	Train Epoch: 22 	Loss: 1.942645 Acc@1: 0.407674 (ε = 2.60, δ = 1e-05) for α = 9.8
	Train Epoch: 22 	Loss: 1.924380 Acc@1: 0.410337 (ε = 2.63, δ = 1e-05) for α = 9.7
	Train Epoch: 22 	Loss: 1.928774 Acc@1: 0.410406 (ε = 2.65, δ = 1e-05) for α = 9.6
	Test set:Loss: 1.701939 Acc@1: 0.477851 
	Train Epoch: 23 	Loss: 1.904102 Acc@1: 0.419984 (ε = 2.66, δ = 1e-05) for α = 9.6
	Train Epoch: 23 	Loss: 1.883437 Acc@1: 0.418648 (ε = 2.69, δ = 1e-05) for α = 9.5
	Train Epoch: 23 	Loss: 1.899747 Acc@1: 0.416854 (ε = 2.71, δ = 1e-05) for α = 9.4
	Test set:Loss: 1.769011 Acc@1: 0.457361 
	Train Epoch: 24 	Loss: 1.936184 Acc@1: 0.422559 (ε = 2.72, δ = 1e-05) for α = 9.4
	Train Epoch: 24 	Loss: 1.918121 Acc@1: 0.421420 (ε = 2.75, δ = 1e-05) for α = 9.3
	Train Epoch: 24 	Loss: 1.926514 Acc@1: 0.421545 (ε = 2.77, δ = 1e-05) for α = 9.3
	Test set:Loss: 1.741832 Acc@1: 0.470588 
	Train Epoch: 25 	Loss: 2.014469 Acc@1: 0.420752 (ε = 2.78, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.932147 Acc@1: 0.425758 (ε = 2.80, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.911996 Acc@1: 0.427192 (ε = 2.83, δ = 1e-05) for α = 9.1
	Test set:Loss: 1.745922 Acc@1: 0.471953 
	Train Epoch: 26 	Loss: 1.962094 Acc@1: 0.427365 (ε = 2.84, δ = 1e-05) for α = 9.1
	Train Epoch: 26 	Loss: 1.884888 Acc@1: 0.431965 (ε = 2.86, δ = 1e-05) for α = 9.0
	Train Epoch: 26 	Loss: 1.870691 Acc@1: 0.437315 (ε = 2.88, δ = 1e-05) for α = 9.0
	Test set:Loss: 1.724361 Acc@1: 0.481018 
	Train Epoch: 27 	Loss: 1.829812 Acc@1: 0.450751 (ε = 2.89, δ = 1e-05) for α = 9.0
	Train Epoch: 27 	Loss: 1.880748 Acc@1: 0.428020 (ε = 2.92, δ = 1e-05) for α = 8.9
	Train Epoch: 27 	Loss: 1.870456 Acc@1: 0.429387 (ε = 2.94, δ = 1e-05) for α = 8.9
	Test set:Loss: 1.724158 Acc@1: 0.480065 
	Train Epoch: 28 	Loss: 1.954469 Acc@1: 0.419540 (ε = 2.95, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.923221 Acc@1: 0.431603 (ε = 2.97, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.923282 Acc@1: 0.431871 (ε = 2.99, δ = 1e-05) for α = 8.7
	Test set:Loss: 1.705959 Acc@1: 0.483593 
	Train Epoch: 29 	Loss: 1.811172 Acc@1: 0.472481 (ε = 3.00, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.877410 Acc@1: 0.436950 (ε = 3.03, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.877733 Acc@1: 0.435377 (ε = 3.05, δ = 1e-05) for α = 8.6
	Test set:Loss: 1.709667 Acc@1: 0.481451 
	Train Epoch: 30 	Loss: 1.870600 Acc@1: 0.444062 (ε = 3.06, δ = 1e-05) for α = 8.6
	Train Epoch: 30 	Loss: 1.876714 Acc@1: 0.436672 (ε = 3.08, δ = 1e-05) for α = 8.5
	Train Epoch: 30 	Loss: 1.885113 Acc@1: 0.434192 (ε = 3.10, δ = 1e-05) for α = 8.5
	Test set:Loss: 1.707845 Acc@1: 0.482244 
Base private model test accuracy:  0.4817947985138611
              precision    recall  f1-score   support

         0.0       0.24      0.24      0.24       508
         1.0       0.06      0.03      0.04       482
         2.0       0.11      0.15      0.12       510
         3.0       0.04      0.03      0.03       489
         4.0       0.07      0.07      0.07       466
         5.0       0.48      0.49      0.49      2972
         6.0       0.68      0.56      0.61      3080
         7.0       0.42      0.47      0.45      2961
         8.0       0.64      0.63      0.63      3024
         9.0       0.51      0.56      0.53      3003

    accuracy                           0.48     17495
   macro avg       0.32      0.32      0.32     17495
weighted avg       0.48      0.48      0.48     17495

Base private model train accuracy:  0.4394108751397199
              precision    recall  f1-score   support

         0.0       0.54      0.44      0.48      3079
         1.0       0.51      0.45      0.48      2995
         2.0       0.30      0.26      0.28      3121
         3.0       0.35      0.26      0.30      3001
         4.0       0.34      0.29      0.31      3067
         5.0       0.39      0.49      0.43      3103
         6.0       0.53      0.56      0.54      2919
         7.0       0.37      0.47      0.42      3105
         8.0       0.58      0.63      0.60      3018
         9.0       0.46      0.56      0.51      3010

    accuracy                           0.44     30418
   macro avg       0.44      0.44      0.44     30418
weighted avg       0.44      0.44      0.43     30418

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.566177920967848
test acc: 0.5713636363636363
min train acc: 0.5851385059734804
maj train acc: 0.5556268446041319
min test acc: 0.5797660367656512
maj test acc: 0.5625737124885336
total acc: 0.5687869580842236
total min acc: 0.5824240062353858
total maj acc: 0.5590637966804979
precision, recall: (0.566066263476203, 0.566177920967848)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 3.107731777432171, 0.4817947985138611, 0.4394108751397199, 0.5687869580842236, 0.5824240062353858, 0.5590637966804979, '              precision    recall  f1-score   support\n\n         0.0       0.24      0.24      0.24       508\n         1.0       0.06      0.03      0.04       482\n         2.0       0.11      0.15      0.12       510\n         3.0       0.04      0.03      0.03       489\n         4.0       0.07      0.07      0.07       466\n         5.0       0.48      0.49      0.49      2972\n         6.0       0.68      0.56      0.61      3080\n         7.0       0.42      0.47      0.45      2961\n         8.0       0.64      0.63      0.63      3024\n         9.0       0.51      0.56      0.53      3003\n\n    accuracy                           0.48     17495\n   macro avg       0.32      0.32      0.32     17495\nweighted avg       0.48      0.48      0.48     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.54      0.44      0.48      3079\n         1.0       0.51      0.45      0.48      2995\n         2.0       0.30      0.26      0.28      3121\n         3.0       0.35      0.26      0.30      3001\n         4.0       0.34      0.29      0.31      3067\n         5.0       0.39      0.49      0.43      3103\n         6.0       0.53      0.56      0.54      2919\n         7.0       0.37      0.47      0.42      3105\n         8.0       0.58      0.63      0.60      3018\n         9.0       0.46      0.56      0.51      3010\n\n    accuracy                           0.44     30418\n   macro avg       0.44      0.44      0.44     30418\nweighted avg       0.44      0.44      0.43     30418\n']
experiment_number: 13
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-13.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 1.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3020, 3011, 3031, 3039, 3043, 3065, 3077, 3000, 2981, 3076])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30343, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.479564 Acc@1: 0.109698 (ε = 1.93, δ = 1e-05) for α = 7.4
	Train Epoch: 1 	Loss: 2.564796 Acc@1: 0.127727 (ε = 2.42, δ = 1e-05) for α = 6.5
	Train Epoch: 1 	Loss: 2.439245 Acc@1: 0.116834 (ε = 2.68, δ = 1e-05) for α = 6.2
	Test set:Loss: 2.232668 Acc@1: 0.123093 
	Train Epoch: 2 	Loss: 2.268438 Acc@1: 0.131687 (ε = 2.78, δ = 1e-05) for α = 6.1
	Train Epoch: 2 	Loss: 2.341642 Acc@1: 0.158958 (ε = 2.97, δ = 1e-05) for α = 5.9
	Train Epoch: 2 	Loss: 2.510865 Acc@1: 0.148682 (ε = 3.14, δ = 1e-05) for α = 5.8
	Test set:Loss: 2.279641 Acc@1: 0.047714 
	Train Epoch: 3 	Loss: 2.301089 Acc@1: 0.117647 (ε = 3.22, δ = 1e-05) for α = 5.7
	Train Epoch: 3 	Loss: 2.336566 Acc@1: 0.147922 (ε = 3.37, δ = 1e-05) for α = 5.6
	Train Epoch: 3 	Loss: 2.418663 Acc@1: 0.146360 (ε = 3.51, δ = 1e-05) for α = 5.5
	Test set:Loss: 2.484456 Acc@1: 0.169068 
	Train Epoch: 4 	Loss: 2.421015 Acc@1: 0.133277 (ε = 3.58, δ = 1e-05) for α = 5.5
	Train Epoch: 4 	Loss: 2.332279 Acc@1: 0.135764 (ε = 3.71, δ = 1e-05) for α = 5.4
	Train Epoch: 4 	Loss: 2.320566 Acc@1: 0.143288 (ε = 3.84, δ = 1e-05) for α = 5.3
	Test set:Loss: 2.207020 Acc@1: 0.225148 
	Train Epoch: 5 	Loss: 2.235429 Acc@1: 0.188235 (ε = 3.90, δ = 1e-05) for α = 5.3
	Train Epoch: 5 	Loss: 2.244412 Acc@1: 0.195734 (ε = 4.02, δ = 1e-05) for α = 5.2
	Train Epoch: 5 	Loss: 2.330528 Acc@1: 0.175489 (ε = 4.13, δ = 1e-05) for α = 5.2
	Test set:Loss: 2.359149 Acc@1: 0.224828 
	Train Epoch: 6 	Loss: 2.590739 Acc@1: 0.163301 (ε = 4.19, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 2.287804 Acc@1: 0.178479 (ε = 4.30, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 2.247745 Acc@1: 0.196584 (ε = 4.41, δ = 1e-05) for α = 5.0
	Test set:Loss: 2.560791 Acc@1: 0.181460 
	Train Epoch: 7 	Loss: 2.548578 Acc@1: 0.190355 (ε = 4.46, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 2.233146 Acc@1: 0.232070 (ε = 4.56, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 2.193821 Acc@1: 0.243807 (ε = 4.66, δ = 1e-05) for α = 4.9
	Test set:Loss: 2.105896 Acc@1: 0.255014 
	Train Epoch: 8 	Loss: 2.044378 Acc@1: 0.278934 (ε = 4.71, δ = 1e-05) for α = 4.9
	Train Epoch: 8 	Loss: 2.075714 Acc@1: 0.289944 (ε = 4.81, δ = 1e-05) for α = 4.8
	Train Epoch: 8 	Loss: 2.066127 Acc@1: 0.294289 (ε = 4.91, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.940635 Acc@1: 0.333632 
	Train Epoch: 9 	Loss: 1.897731 Acc@1: 0.325728 (ε = 4.96, δ = 1e-05) for α = 4.8
	Train Epoch: 9 	Loss: 1.997073 Acc@1: 0.332532 (ε = 5.05, δ = 1e-05) for α = 4.7
	Train Epoch: 9 	Loss: 2.041133 Acc@1: 0.323054 (ε = 5.14, δ = 1e-05) for α = 4.7
	Test set:Loss: 2.071403 Acc@1: 0.299555 
	Train Epoch: 10 	Loss: 2.056563 Acc@1: 0.307692 (ε = 5.19, δ = 1e-05) for α = 4.7
	Train Epoch: 10 	Loss: 1.950099 Acc@1: 0.337250 (ε = 5.28, δ = 1e-05) for α = 4.6
	Train Epoch: 10 	Loss: 1.938696 Acc@1: 0.348675 (ε = 5.37, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.050638 Acc@1: 0.334601 
	Train Epoch: 11 	Loss: 1.894324 Acc@1: 0.348933 (ε = 5.41, δ = 1e-05) for α = 4.6
	Train Epoch: 11 	Loss: 1.916076 Acc@1: 0.374600 (ε = 5.50, δ = 1e-05) for α = 4.5
	Train Epoch: 11 	Loss: 1.879969 Acc@1: 0.388107 (ε = 5.58, δ = 1e-05) for α = 4.5
	Test set:Loss: 1.900762 Acc@1: 0.420812 
	Train Epoch: 12 	Loss: 1.814641 Acc@1: 0.413823 (ε = 5.62, δ = 1e-05) for α = 4.5
	Train Epoch: 12 	Loss: 1.882522 Acc@1: 0.409863 (ε = 5.71, δ = 1e-05) for α = 4.4
	Train Epoch: 12 	Loss: 1.859163 Acc@1: 0.416465 (ε = 5.79, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.105001 Acc@1: 0.371003 
	Train Epoch: 13 	Loss: 1.969271 Acc@1: 0.402226 (ε = 5.83, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 1.825889 Acc@1: 0.430613 (ε = 5.91, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 1.814735 Acc@1: 0.431034 (ε = 5.99, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.646210 Acc@1: 0.505571 
	Train Epoch: 14 	Loss: 1.738805 Acc@1: 0.445687 (ε = 6.03, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 1.789899 Acc@1: 0.447696 (ε = 6.11, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 1.777390 Acc@1: 0.448996 (ε = 6.18, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.265083 Acc@1: 0.367590 
	Train Epoch: 15 	Loss: 1.881611 Acc@1: 0.447254 (ε = 6.22, δ = 1e-05) for α = 4.3
	Train Epoch: 15 	Loss: 1.707868 Acc@1: 0.477647 (ε = 6.30, δ = 1e-05) for α = 4.2
	Train Epoch: 15 	Loss: 1.722558 Acc@1: 0.484135 (ε = 6.37, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.859104 Acc@1: 0.466579 
	Train Epoch: 16 	Loss: 1.690287 Acc@1: 0.480848 (ε = 6.41, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.690119 Acc@1: 0.503623 (ε = 6.49, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.680814 Acc@1: 0.508522 (ε = 6.56, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.899669 Acc@1: 0.466096 
	Train Epoch: 17 	Loss: 1.644355 Acc@1: 0.498246 (ε = 6.60, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.686966 Acc@1: 0.516413 (ε = 6.67, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.668195 Acc@1: 0.523084 (ε = 6.74, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.878253 Acc@1: 0.481565 
	Train Epoch: 18 	Loss: 1.603291 Acc@1: 0.544020 (ε = 6.77, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.650528 Acc@1: 0.538686 (ε = 6.85, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.648589 Acc@1: 0.539150 (ε = 6.92, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.818975 Acc@1: 0.507849 
	Train Epoch: 19 	Loss: 1.601719 Acc@1: 0.555020 (ε = 6.95, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.642341 Acc@1: 0.540291 (ε = 7.02, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.637664 Acc@1: 0.543860 (ε = 7.09, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.911976 Acc@1: 0.495397 
	Train Epoch: 20 	Loss: 1.549199 Acc@1: 0.573566 (ε = 7.12, δ = 1e-05) for α = 4.0
	Train Epoch: 20 	Loss: 1.621831 Acc@1: 0.558757 (ε = 7.19, δ = 1e-05) for α = 3.9
	Train Epoch: 20 	Loss: 1.625473 Acc@1: 0.557168 (ε = 7.26, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.872585 Acc@1: 0.496035 
	Train Epoch: 21 	Loss: 1.486055 Acc@1: 0.590620 (ε = 7.29, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.564144 Acc@1: 0.572679 (ε = 7.36, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.575295 Acc@1: 0.572994 (ε = 7.42, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.895871 Acc@1: 0.506557 
	Train Epoch: 22 	Loss: 1.623389 Acc@1: 0.558252 (ε = 7.46, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.578730 Acc@1: 0.574229 (ε = 7.52, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.570614 Acc@1: 0.576762 (ε = 7.59, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.897231 Acc@1: 0.517267 
	Train Epoch: 23 	Loss: 1.652767 Acc@1: 0.562292 (ε = 7.62, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.611402 Acc@1: 0.574653 (ε = 7.68, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.587481 Acc@1: 0.575751 (ε = 7.75, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.927506 Acc@1: 0.512918 
	Train Epoch: 24 	Loss: 1.520366 Acc@1: 0.580437 (ε = 7.78, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.531697 Acc@1: 0.589088 (ε = 7.84, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.522882 Acc@1: 0.590790 (ε = 7.91, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.851285 Acc@1: 0.534434 
	Train Epoch: 25 	Loss: 1.564435 Acc@1: 0.592116 (ε = 7.94, δ = 1e-05) for α = 3.8
	Train Epoch: 25 	Loss: 1.543205 Acc@1: 0.592799 (ε = 8.00, δ = 1e-05) for α = 3.7
	Train Epoch: 25 	Loss: 1.534027 Acc@1: 0.592887 (ε = 8.06, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.895838 Acc@1: 0.526625 
	Train Epoch: 26 	Loss: 1.401118 Acc@1: 0.626972 (ε = 8.09, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.556291 Acc@1: 0.594539 (ε = 8.15, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.546192 Acc@1: 0.599041 (ε = 8.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.833374 Acc@1: 0.542319 
	Train Epoch: 27 	Loss: 1.447466 Acc@1: 0.615810 (ε = 8.24, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.511393 Acc@1: 0.601720 (ε = 8.31, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.511300 Acc@1: 0.601701 (ε = 8.37, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.846159 Acc@1: 0.538610 
	Train Epoch: 28 	Loss: 1.469889 Acc@1: 0.611475 (ε = 8.40, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.491580 Acc@1: 0.607498 (ε = 8.45, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.502572 Acc@1: 0.603567 (ε = 8.51, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.884450 Acc@1: 0.530780 
	Train Epoch: 29 	Loss: 1.413174 Acc@1: 0.619574 (ε = 8.54, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.482023 Acc@1: 0.605816 (ε = 8.60, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.509878 Acc@1: 0.601049 (ε = 8.66, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.864407 Acc@1: 0.537091 
	Train Epoch: 30 	Loss: 1.469975 Acc@1: 0.613730 (ε = 8.69, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.526169 Acc@1: 0.599302 (ε = 8.75, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.505325 Acc@1: 0.605191 (ε = 8.81, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.872859 Acc@1: 0.535003 
Base private model test accuracy:  0.5349528436696199
              precision    recall  f1-score   support

         0.0       0.23      0.52      0.31       508
         1.0       0.21      0.56      0.31       482
         2.0       0.18      0.41      0.25       510
         3.0       0.10      0.28      0.15       489
         4.0       0.16      0.38      0.23       466
         5.0       0.64      0.46      0.53      2972
         6.0       0.77      0.63      0.69      3080
         7.0       0.71      0.53      0.61      2961
         8.0       0.75      0.59      0.66      3024
         9.0       0.73      0.55      0.63      3003

    accuracy                           0.53     17495
   macro avg       0.45      0.49      0.44     17495
weighted avg       0.64      0.53      0.57     17495

Base private model train accuracy:  0.6006986784431335
              precision    recall  f1-score   support

         0.0       0.63      0.68      0.66      3020
         1.0       0.69      0.73      0.71      3011
         2.0       0.57      0.58      0.58      3031
         3.0       0.52      0.54      0.53      3039
         4.0       0.61      0.59      0.60      3043
         5.0       0.50      0.46      0.48      3065
         6.0       0.65      0.63      0.64      3077
         7.0       0.62      0.59      0.60      3000
         8.0       0.62      0.62      0.62      2981
         9.0       0.61      0.59      0.60      3076

    accuracy                           0.60     30343
   macro avg       0.60      0.60      0.60     30343
weighted avg       0.60      0.60      0.60     30343

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7663304989783138
test acc: 0.769090909090909
min train acc: 0.9449589838581636
maj train acc: 0.5995924605196128
min test acc: 0.9574358312911131
maj test acc: 0.5785555700666057
total acc: 0.7677210428183573
total min acc: 0.9512768597740187
total maj acc: 0.5892062673286479
precision, recall: (0.7657752601765249, 0.7663304989783138)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 8.829985089544166, 0.5349528436696199, 0.6006986784431335, 0.7677210428183573, 0.9512768597740187, 0.5892062673286479, '              precision    recall  f1-score   support\n\n         0.0       0.23      0.52      0.31       508\n         1.0       0.21      0.56      0.31       482\n         2.0       0.18      0.41      0.25       510\n         3.0       0.10      0.28      0.15       489\n         4.0       0.16      0.38      0.23       466\n         5.0       0.64      0.46      0.53      2972\n         6.0       0.77      0.63      0.69      3080\n         7.0       0.71      0.53      0.61      2961\n         8.0       0.75      0.59      0.66      3024\n         9.0       0.73      0.55      0.63      3003\n\n    accuracy                           0.53     17495\n   macro avg       0.45      0.49      0.44     17495\nweighted avg       0.64      0.53      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.63      0.68      0.66      3020\n         1.0       0.69      0.73      0.71      3011\n         2.0       0.57      0.58      0.58      3031\n         3.0       0.52      0.54      0.53      3039\n         4.0       0.61      0.59      0.60      3043\n         5.0       0.50      0.46      0.48      3065\n         6.0       0.65      0.63      0.64      3077\n         7.0       0.62      0.59      0.60      3000\n         8.0       0.62      0.62      0.62      2981\n         9.0       0.61      0.59      0.60      3076\n\n    accuracy                           0.60     30343\n   macro avg       0.60      0.60      0.60     30343\nweighted avg       0.60      0.60      0.60     30343\n']
experiment_number: 22
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-22.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 1.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([520, 487, 507, 453, 452, 520, 463, 485, 503, 534])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4924, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.733681 Acc@1: 0.105505 (ε = 1.93, δ = 1e-05) for α = 7.4
	Train Epoch: 1 	Loss: 3.426293 Acc@1: 0.110839 (ε = 2.42, δ = 1e-05) for α = 6.5
	Train Epoch: 1 	Loss: 7.543734 Acc@1: 0.108629 (ε = 2.68, δ = 1e-05) for α = 6.2
	Test set:Loss: 2.316711 Acc@1: 0.163011 
	Train Epoch: 2 	Loss: 2.332593 Acc@1: 0.188406 (ε = 2.78, δ = 1e-05) for α = 6.1
	Train Epoch: 2 	Loss: 3.027876 Acc@1: 0.120191 (ε = 2.97, δ = 1e-05) for α = 5.9
	Train Epoch: 2 	Loss: 2.886021 Acc@1: 0.111663 (ε = 3.14, δ = 1e-05) for α = 5.8
	Test set:Loss: 2.571608 Acc@1: 0.028013 
	Train Epoch: 3 	Loss: 2.604141 Acc@1: 0.134615 (ε = 3.22, δ = 1e-05) for α = 5.7
	Train Epoch: 3 	Loss: 2.683669 Acc@1: 0.101188 (ε = 3.37, δ = 1e-05) for α = 5.6
	Train Epoch: 3 	Loss: 2.824215 Acc@1: 0.104262 (ε = 3.51, δ = 1e-05) for α = 5.5
	Test set:Loss: 2.847555 Acc@1: 0.171377 
	Train Epoch: 4 	Loss: 2.575808 Acc@1: 0.107317 (ε = 3.58, δ = 1e-05) for α = 5.5
	Train Epoch: 4 	Loss: 2.804226 Acc@1: 0.121705 (ε = 3.71, δ = 1e-05) for α = 5.4
	Train Epoch: 4 	Loss: 2.948507 Acc@1: 0.113867 (ε = 3.84, δ = 1e-05) for α = 5.3
	Test set:Loss: 3.523862 Acc@1: 0.166272 
	Train Epoch: 5 	Loss: 4.418376 Acc@1: 0.116505 (ε = 3.90, δ = 1e-05) for α = 5.3
	Train Epoch: 5 	Loss: 3.853574 Acc@1: 0.109202 (ε = 4.02, δ = 1e-05) for α = 5.2
	Train Epoch: 5 	Loss: 3.648296 Acc@1: 0.101234 (ε = 4.13, δ = 1e-05) for α = 5.2
	Test set:Loss: 3.155264 Acc@1: 0.164919 
	Train Epoch: 6 	Loss: 2.620930 Acc@1: 0.135135 (ε = 4.19, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 3.838142 Acc@1: 0.101958 (ε = 4.30, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 3.679735 Acc@1: 0.103711 (ε = 4.41, δ = 1e-05) for α = 5.0
	Test set:Loss: 3.838202 Acc@1: 0.164577 
	Train Epoch: 7 	Loss: 2.798820 Acc@1: 0.110577 (ε = 4.46, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 3.665348 Acc@1: 0.106648 (ε = 4.56, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 3.979329 Acc@1: 0.110952 (ε = 4.66, δ = 1e-05) for α = 4.9
	Test set:Loss: 4.725559 Acc@1: 0.031124 
	Train Epoch: 8 	Loss: 3.536972 Acc@1: 0.087719 (ε = 4.71, δ = 1e-05) for α = 4.9
	Train Epoch: 8 	Loss: 6.882812 Acc@1: 0.104624 (ε = 4.81, δ = 1e-05) for α = 4.8
	Train Epoch: 8 	Loss: 5.521591 Acc@1: 0.105628 (ε = 4.91, δ = 1e-05) for α = 4.8
	Test set:Loss: 4.373265 Acc@1: 0.033678 
	Train Epoch: 9 	Loss: 3.085399 Acc@1: 0.098266 (ε = 4.96, δ = 1e-05) for α = 4.8
	Train Epoch: 9 	Loss: 4.508281 Acc@1: 0.098557 (ε = 5.05, δ = 1e-05) for α = 4.7
	Train Epoch: 9 	Loss: 4.443223 Acc@1: 0.102746 (ε = 5.14, δ = 1e-05) for α = 4.7
	Test set:Loss: 4.695504 Acc@1: 0.036622 
	Train Epoch: 10 	Loss: 3.953635 Acc@1: 0.141176 (ε = 5.19, δ = 1e-05) for α = 4.7
	Train Epoch: 10 	Loss: 5.290771 Acc@1: 0.114612 (ε = 5.28, δ = 1e-05) for α = 4.6
	Train Epoch: 10 	Loss: 5.789884 Acc@1: 0.111042 (ε = 5.37, δ = 1e-05) for α = 4.6
	Test set:Loss: 5.708666 Acc@1: 0.035536 
	Train Epoch: 11 	Loss: 8.386169 Acc@1: 0.153005 (ε = 5.41, δ = 1e-05) for α = 4.6
	Train Epoch: 11 	Loss: 9.279884 Acc@1: 0.106856 (ε = 5.50, δ = 1e-05) for α = 4.5
	Train Epoch: 11 	Loss: 8.471865 Acc@1: 0.100164 (ε = 5.58, δ = 1e-05) for α = 4.5
	Test set:Loss: 5.444859 Acc@1: 0.031753 
	Train Epoch: 12 	Loss: 3.760819 Acc@1: 0.121951 (ε = 5.62, δ = 1e-05) for α = 4.5
	Train Epoch: 12 	Loss: 9.115507 Acc@1: 0.101020 (ε = 5.71, δ = 1e-05) for α = 4.4
	Train Epoch: 12 	Loss: 8.178969 Acc@1: 0.109651 (ε = 5.79, δ = 1e-05) for α = 4.4
	Test set:Loss: 6.081500 Acc@1: 0.172386 
	Train Epoch: 13 	Loss: 6.273379 Acc@1: 0.136792 (ε = 5.83, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 5.581099 Acc@1: 0.103899 (ε = 5.91, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 6.099055 Acc@1: 0.102059 (ε = 5.99, δ = 1e-05) for α = 4.3
	Test set:Loss: 6.112068 Acc@1: 0.174480 
	Train Epoch: 14 	Loss: 7.065455 Acc@1: 0.079602 (ε = 6.03, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 5.045631 Acc@1: 0.092304 (ε = 6.11, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 5.300317 Acc@1: 0.095319 (ε = 6.18, δ = 1e-05) for α = 4.3
	Test set:Loss: 6.443004 Acc@1: 0.031590 
	Train Epoch: 15 	Loss: 2.709621 Acc@1: 0.096447 (ε = 6.22, δ = 1e-05) for α = 4.3
	Train Epoch: 15 	Loss: 5.369979 Acc@1: 0.097104 (ε = 6.30, δ = 1e-05) for α = 4.2
	Train Epoch: 15 	Loss: 6.008990 Acc@1: 0.098154 (ε = 6.37, δ = 1e-05) for α = 4.2
	Test set:Loss: 6.053096 Acc@1: 0.174384 
	Train Epoch: 16 	Loss: 5.354047 Acc@1: 0.119816 (ε = 6.41, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 5.257609 Acc@1: 0.110735 (ε = 6.49, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 6.083752 Acc@1: 0.111169 (ε = 6.56, δ = 1e-05) for α = 4.1
	Test set:Loss: 5.344170 Acc@1: 0.031863 
	Train Epoch: 17 	Loss: 5.355232 Acc@1: 0.082927 (ε = 6.60, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 5.260682 Acc@1: 0.096941 (ε = 6.67, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 5.285629 Acc@1: 0.093698 (ε = 6.74, δ = 1e-05) for α = 4.1
	Test set:Loss: 5.792105 Acc@1: 0.031467 
	Train Epoch: 18 	Loss: 4.352940 Acc@1: 0.106061 (ε = 6.77, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 3.986462 Acc@1: 0.100250 (ε = 6.85, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 4.978352 Acc@1: 0.102225 (ε = 6.92, δ = 1e-05) for α = 4.0
	Test set:Loss: 5.246999 Acc@1: 0.174301 
	Train Epoch: 19 	Loss: 2.825415 Acc@1: 0.111111 (ε = 6.95, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 4.551918 Acc@1: 0.099312 (ε = 7.02, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 5.891461 Acc@1: 0.103647 (ε = 7.09, δ = 1e-05) for α = 4.0
	Test set:Loss: 5.421845 Acc@1: 0.167687 
	Train Epoch: 20 	Loss: 3.661762 Acc@1: 0.108374 (ε = 7.12, δ = 1e-05) for α = 4.0
	Train Epoch: 20 	Loss: 5.185712 Acc@1: 0.105628 (ε = 7.19, δ = 1e-05) for α = 3.9
	Train Epoch: 20 	Loss: 5.548649 Acc@1: 0.100072 (ε = 7.26, δ = 1e-05) for α = 3.9
	Test set:Loss: 5.278492 Acc@1: 0.171773 
	Train Epoch: 21 	Loss: 15.858620 Acc@1: 0.155000 (ε = 7.29, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 4.679916 Acc@1: 0.103836 (ε = 7.36, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 5.004377 Acc@1: 0.104227 (ε = 7.42, δ = 1e-05) for α = 3.9
	Test set:Loss: 4.946617 Acc@1: 0.167977 
	Train Epoch: 22 	Loss: 3.213318 Acc@1: 0.087432 (ε = 7.46, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 4.800358 Acc@1: 0.098435 (ε = 7.52, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 4.278654 Acc@1: 0.096430 (ε = 7.59, δ = 1e-05) for α = 3.8
	Test set:Loss: 4.580015 Acc@1: 0.169838 
	Train Epoch: 23 	Loss: 2.324913 Acc@1: 0.107527 (ε = 7.62, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 4.717392 Acc@1: 0.096728 (ε = 7.68, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 4.540958 Acc@1: 0.099198 (ε = 7.75, δ = 1e-05) for α = 3.8
	Test set:Loss: 4.874943 Acc@1: 0.169112 
	Train Epoch: 24 	Loss: 4.234674 Acc@1: 0.090090 (ε = 7.78, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 5.108401 Acc@1: 0.102390 (ε = 7.84, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 4.861628 Acc@1: 0.094818 (ε = 7.91, δ = 1e-05) for α = 3.8
	Test set:Loss: 4.597503 Acc@1: 0.174191 
	Train Epoch: 25 	Loss: 10.118881 Acc@1: 0.081340 (ε = 7.94, δ = 1e-05) for α = 3.8
	Train Epoch: 25 	Loss: 5.451974 Acc@1: 0.098431 (ε = 8.00, δ = 1e-05) for α = 3.7
	Train Epoch: 25 	Loss: 4.464256 Acc@1: 0.103103 (ε = 8.06, δ = 1e-05) for α = 3.7
	Test set:Loss: 4.333530 Acc@1: 0.030158 
	Train Epoch: 26 	Loss: 5.678382 Acc@1: 0.113861 (ε = 8.09, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 3.743627 Acc@1: 0.109598 (ε = 8.15, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 4.283419 Acc@1: 0.104076 (ε = 8.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 4.257882 Acc@1: 0.030451 
	Train Epoch: 27 	Loss: 4.096373 Acc@1: 0.064171 (ε = 8.24, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 4.098430 Acc@1: 0.098063 (ε = 8.31, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 4.000012 Acc@1: 0.101066 (ε = 8.37, δ = 1e-05) for α = 3.6
	Test set:Loss: 4.195729 Acc@1: 0.030708 
	Train Epoch: 28 	Loss: 7.880637 Acc@1: 0.103139 (ε = 8.40, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 3.730412 Acc@1: 0.107626 (ε = 8.45, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 4.019829 Acc@1: 0.106305 (ε = 8.51, δ = 1e-05) for α = 3.6
	Test set:Loss: 4.152893 Acc@1: 0.172552 
	Train Epoch: 29 	Loss: 6.899330 Acc@1: 0.106599 (ε = 8.54, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 3.053903 Acc@1: 0.103036 (ε = 8.60, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 3.771211 Acc@1: 0.103531 (ε = 8.66, δ = 1e-05) for α = 3.6
	Test set:Loss: 4.223724 Acc@1: 0.171613 
	Train Epoch: 30 	Loss: 3.322700 Acc@1: 0.081081 (ε = 8.69, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 4.558631 Acc@1: 0.109255 (ε = 8.75, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 3.911446 Acc@1: 0.103815 (ε = 8.81, δ = 1e-05) for α = 3.6
	Test set:Loss: 4.137505 Acc@1: 0.171996 
Base private model test accuracy:  0.17199199771363247
              precision    recall  f1-score   support

         0.0       0.05      0.00      0.00       508
         1.0       0.00      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.04      0.00      0.01       489
         4.0       0.00      0.00      0.00       466
         5.0       0.20      0.01      0.02      2972
         6.0       0.57      0.00      0.00      3080
         7.0       0.22      0.00      0.00      2961
         8.0       0.15      0.00      0.00      3024
         9.0       0.17      0.99      0.29      3003

    accuracy                           0.17     17495
   macro avg       0.14      0.10      0.03     17495
weighted avg       0.23      0.17      0.06     17495

Base private model train accuracy:  0.109463850528026
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       520
         1.0       0.00      0.00      0.00       487
         2.0       0.00      0.00      0.00       507
         3.0       0.18      0.00      0.01       453
         4.0       0.00      0.00      0.00       452
         5.0       0.24      0.02      0.03       520
         6.0       1.00      0.00      0.00       463
         7.0       0.00      0.00      0.00       485
         8.0       0.00      0.00      0.00       503
         9.0       0.11      0.99      0.20       534

    accuracy                           0.11      4924
   macro avg       0.15      0.10      0.02      4924
weighted avg       0.15      0.11      0.03      4924

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6933387489845654
test acc: 0.30343347639484974
min train acc: 0.41227312013828865
maj train acc: 0.989010989010989
min test acc: 0.5863829787234043
maj test acc: 0.018025751072961338
total acc: 0.5037562604340567
total min acc: 0.5
total maj acc: 0.5072402044293015
precision, recall: (0.5126126126126126, 0.6933387489845654)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 8.829985089544166, 0.17199199771363247, 0.109463850528026, 0.5037562604340567, 0.5, 0.5072402044293015, '              precision    recall  f1-score   support\n\n         0.0       0.05      0.00      0.00       508\n         1.0       0.00      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.04      0.00      0.01       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.20      0.01      0.02      2972\n         6.0       0.57      0.00      0.00      3080\n         7.0       0.22      0.00      0.00      2961\n         8.0       0.15      0.00      0.00      3024\n         9.0       0.17      0.99      0.29      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.14      0.10      0.03     17495\nweighted avg       0.23      0.17      0.06     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       520\n         1.0       0.00      0.00      0.00       487\n         2.0       0.00      0.00      0.00       507\n         3.0       0.18      0.00      0.01       453\n         4.0       0.00      0.00      0.00       452\n         5.0       0.24      0.02      0.03       520\n         6.0       1.00      0.00      0.00       463\n         7.0       0.00      0.00      0.00       485\n         8.0       0.00      0.00      0.00       503\n         9.0       0.11      0.99      0.20       534\n\n    accuracy                           0.11      4924\n   macro avg       0.15      0.10      0.02      4924\nweighted avg       0.15      0.11      0.03      4924\n']
experiment_number: 16
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-16.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 1.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3144, 3055, 3055, 3026, 3023, 3056, 3049, 3097, 3086, 2995])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30586, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.654047 Acc@1: 0.105753 (ε = 1.93, δ = 1e-05) for α = 7.4
	Train Epoch: 1 	Loss: 2.490943 Acc@1: 0.106242 (ε = 2.42, δ = 1e-05) for α = 6.5
	Train Epoch: 1 	Loss: 2.477266 Acc@1: 0.108298 (ε = 2.68, δ = 1e-05) for α = 6.2
	Test set:Loss: 2.239320 Acc@1: 0.236638 
	Train Epoch: 2 	Loss: 2.377091 Acc@1: 0.152373 (ε = 2.78, δ = 1e-05) for α = 6.1
	Train Epoch: 2 	Loss: 2.453294 Acc@1: 0.117224 (ε = 2.97, δ = 1e-05) for α = 5.9
	Train Epoch: 2 	Loss: 2.673926 Acc@1: 0.113494 (ε = 3.14, δ = 1e-05) for α = 5.8
	Test set:Loss: 2.340857 Acc@1: 0.169119 
	Train Epoch: 3 	Loss: 2.309368 Acc@1: 0.109705 (ε = 3.22, δ = 1e-05) for α = 5.7
	Train Epoch: 3 	Loss: 2.318620 Acc@1: 0.099802 (ε = 3.37, δ = 1e-05) for α = 5.6
	Train Epoch: 3 	Loss: 2.426262 Acc@1: 0.103870 (ε = 3.51, δ = 1e-05) for α = 5.5
	Test set:Loss: 2.330982 Acc@1: 0.027164 
	Train Epoch: 4 	Loss: 2.302280 Acc@1: 0.096669 (ε = 3.58, δ = 1e-05) for α = 5.5
	Train Epoch: 4 	Loss: 2.326655 Acc@1: 0.102587 (ε = 3.71, δ = 1e-05) for α = 5.4
	Train Epoch: 4 	Loss: 2.405397 Acc@1: 0.102323 (ε = 3.84, δ = 1e-05) for α = 5.3
	Test set:Loss: 2.318810 Acc@1: 0.031127 
	Train Epoch: 5 	Loss: 2.308792 Acc@1: 0.089125 (ε = 3.90, δ = 1e-05) for α = 5.3
	Train Epoch: 5 	Loss: 2.307001 Acc@1: 0.103311 (ε = 4.02, δ = 1e-05) for α = 5.2
	Train Epoch: 5 	Loss: 2.462963 Acc@1: 0.103397 (ε = 4.13, δ = 1e-05) for α = 5.2
	Test set:Loss: 2.311236 Acc@1: 0.167041 
	Train Epoch: 6 	Loss: 2.302685 Acc@1: 0.109415 (ε = 4.19, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 2.318056 Acc@1: 0.105337 (ε = 4.30, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 2.312574 Acc@1: 0.109707 (ε = 4.41, δ = 1e-05) for α = 5.0
	Test set:Loss: 2.320072 Acc@1: 0.035266 
	Train Epoch: 7 	Loss: 2.309197 Acc@1: 0.111959 (ε = 4.46, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 2.326240 Acc@1: 0.109665 (ε = 4.56, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 2.378074 Acc@1: 0.108289 (ε = 4.66, δ = 1e-05) for α = 4.9
	Test set:Loss: 2.281880 Acc@1: 0.183935 
	Train Epoch: 8 	Loss: 2.302887 Acc@1: 0.101906 (ε = 4.71, δ = 1e-05) for α = 4.9
	Train Epoch: 8 	Loss: 2.304157 Acc@1: 0.112532 (ε = 4.81, δ = 1e-05) for α = 4.8
	Train Epoch: 8 	Loss: 2.307970 Acc@1: 0.115662 (ε = 4.91, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.316392 Acc@1: 0.034917 
	Train Epoch: 9 	Loss: 2.292852 Acc@1: 0.104405 (ε = 4.96, δ = 1e-05) for α = 4.8
	Train Epoch: 9 	Loss: 2.311449 Acc@1: 0.106281 (ε = 5.05, δ = 1e-05) for α = 4.7
	Train Epoch: 9 	Loss: 2.350152 Acc@1: 0.120054 (ε = 5.14, δ = 1e-05) for α = 4.7
	Test set:Loss: 2.310636 Acc@1: 0.217469 
	Train Epoch: 10 	Loss: 2.464849 Acc@1: 0.135607 (ε = 5.19, δ = 1e-05) for α = 4.7
	Train Epoch: 10 	Loss: 2.371677 Acc@1: 0.143914 (ε = 5.28, δ = 1e-05) for α = 4.6
	Train Epoch: 10 	Loss: 2.330185 Acc@1: 0.143945 (ε = 5.37, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.307689 Acc@1: 0.189193 
	Train Epoch: 11 	Loss: 2.305941 Acc@1: 0.135720 (ε = 5.41, δ = 1e-05) for α = 4.6
	Train Epoch: 11 	Loss: 2.477912 Acc@1: 0.158416 (ε = 5.50, δ = 1e-05) for α = 4.5
	Train Epoch: 11 	Loss: 2.446325 Acc@1: 0.167860 (ε = 5.58, δ = 1e-05) for α = 4.5
	Test set:Loss: 3.202930 Acc@1: 0.216257 
	Train Epoch: 12 	Loss: 2.917946 Acc@1: 0.168269 (ε = 5.62, δ = 1e-05) for α = 4.5
	Train Epoch: 12 	Loss: 2.470689 Acc@1: 0.143563 (ε = 5.71, δ = 1e-05) for α = 4.4
	Train Epoch: 12 	Loss: 2.379865 Acc@1: 0.161725 (ε = 5.79, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.128219 Acc@1: 0.251124 
	Train Epoch: 13 	Loss: 2.160131 Acc@1: 0.180099 (ε = 5.83, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 2.223017 Acc@1: 0.220346 (ε = 5.91, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 2.182343 Acc@1: 0.235388 (ε = 5.99, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.106907 Acc@1: 0.361869 
	Train Epoch: 14 	Loss: 2.070000 Acc@1: 0.321459 (ε = 6.03, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 2.016022 Acc@1: 0.310901 (ε = 6.11, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 2.003307 Acc@1: 0.321727 (ε = 6.18, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.800680 Acc@1: 0.412823 
	Train Epoch: 15 	Loss: 1.824723 Acc@1: 0.358615 (ε = 6.22, δ = 1e-05) for α = 4.3
	Train Epoch: 15 	Loss: 2.082289 Acc@1: 0.334449 (ε = 6.30, δ = 1e-05) for α = 4.2
	Train Epoch: 15 	Loss: 2.050655 Acc@1: 0.341105 (ε = 6.37, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.774231 Acc@1: 0.458436 
	Train Epoch: 16 	Loss: 1.815893 Acc@1: 0.386383 (ε = 6.41, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.872209 Acc@1: 0.397815 (ε = 6.49, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.912493 Acc@1: 0.402317 (ε = 6.56, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.092700 Acc@1: 0.404404 
	Train Epoch: 17 	Loss: 2.012668 Acc@1: 0.388935 (ε = 6.60, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.851697 Acc@1: 0.420222 (ε = 6.67, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.866869 Acc@1: 0.419687 (ε = 6.74, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.765363 Acc@1: 0.497466 
	Train Epoch: 18 	Loss: 1.962179 Acc@1: 0.426544 (ε = 6.77, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.821594 Acc@1: 0.447814 (ε = 6.85, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.821787 Acc@1: 0.454479 (ε = 6.92, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.659017 Acc@1: 0.542762 
	Train Epoch: 19 	Loss: 1.926135 Acc@1: 0.463628 (ε = 6.95, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.861380 Acc@1: 0.466964 (ε = 7.02, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.831808 Acc@1: 0.469577 (ε = 7.09, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.570099 Acc@1: 0.546096 
	Train Epoch: 20 	Loss: 1.805945 Acc@1: 0.499169 (ε = 7.12, δ = 1e-05) for α = 4.0
	Train Epoch: 20 	Loss: 1.769444 Acc@1: 0.483717 (ε = 7.19, δ = 1e-05) for α = 3.9
	Train Epoch: 20 	Loss: 1.756460 Acc@1: 0.486875 (ε = 7.26, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.714189 Acc@1: 0.554928 
	Train Epoch: 21 	Loss: 1.774866 Acc@1: 0.513211 (ε = 7.29, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.772262 Acc@1: 0.497551 (ε = 7.36, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.779118 Acc@1: 0.498791 (ε = 7.42, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.633757 Acc@1: 0.555607 
	Train Epoch: 22 	Loss: 1.773221 Acc@1: 0.493734 (ε = 7.46, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.719190 Acc@1: 0.509393 (ε = 7.52, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.722696 Acc@1: 0.510044 (ε = 7.59, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.644861 Acc@1: 0.540192 
	Train Epoch: 23 	Loss: 1.720970 Acc@1: 0.504854 (ε = 7.62, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.742229 Acc@1: 0.513605 (ε = 7.68, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.737674 Acc@1: 0.514745 (ε = 7.75, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.640438 Acc@1: 0.556362 
	Train Epoch: 24 	Loss: 1.576105 Acc@1: 0.518189 (ε = 7.78, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.706360 Acc@1: 0.521414 (ε = 7.84, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.720213 Acc@1: 0.521925 (ε = 7.91, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.588050 Acc@1: 0.577103 
	Train Epoch: 25 	Loss: 1.769189 Acc@1: 0.504105 (ε = 7.94, δ = 1e-05) for α = 3.8
	Train Epoch: 25 	Loss: 1.705543 Acc@1: 0.522612 (ε = 8.00, δ = 1e-05) for α = 3.7
	Train Epoch: 25 	Loss: 1.692797 Acc@1: 0.526248 (ε = 8.06, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.592335 Acc@1: 0.564911 
	Train Epoch: 26 	Loss: 1.570618 Acc@1: 0.529207 (ε = 8.09, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.669980 Acc@1: 0.533416 (ε = 8.15, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.678495 Acc@1: 0.532975 (ε = 8.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.600975 Acc@1: 0.573396 
	Train Epoch: 27 	Loss: 1.777408 Acc@1: 0.523585 (ε = 8.24, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.710157 Acc@1: 0.530453 (ε = 8.31, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.700201 Acc@1: 0.529848 (ε = 8.37, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.600241 Acc@1: 0.577859 
	Train Epoch: 28 	Loss: 1.609356 Acc@1: 0.539592 (ε = 8.40, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.685396 Acc@1: 0.540111 (ε = 8.45, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.686034 Acc@1: 0.535434 (ε = 8.51, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.611106 Acc@1: 0.571851 
	Train Epoch: 29 	Loss: 1.796726 Acc@1: 0.521877 (ε = 8.54, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.667427 Acc@1: 0.537655 (ε = 8.60, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.670831 Acc@1: 0.537393 (ε = 8.66, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.605864 Acc@1: 0.574959 
	Train Epoch: 30 	Loss: 1.691912 Acc@1: 0.515102 (ε = 8.69, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.695801 Acc@1: 0.533553 (ε = 8.75, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.683354 Acc@1: 0.536726 (ε = 8.81, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.599037 Acc@1: 0.577723 
Base private model test accuracy:  0.5773078022292083
              precision    recall  f1-score   support

         0.0       0.20      0.21      0.20       508
         1.0       0.22      0.18      0.20       482
         2.0       0.21      0.19      0.20       510
         3.0       0.10      0.07      0.08       489
         4.0       0.19      0.15      0.16       466
         5.0       0.57      0.57      0.57      2972
         6.0       0.69      0.68      0.68      3080
         7.0       0.59      0.60      0.60      2961
         8.0       0.70      0.72      0.71      3024
         9.0       0.60      0.65      0.62      3003

    accuracy                           0.58     17495
   macro avg       0.41      0.40      0.40     17495
weighted avg       0.57      0.58      0.57     17495

Base private model train accuracy:  0.539952919636435
              precision    recall  f1-score   support

         0.0       0.60      0.52      0.56      3144
         1.0       0.56      0.58      0.57      3055
         2.0       0.41      0.33      0.36      3055
         3.0       0.46      0.39      0.42      3026
         4.0       0.48      0.32      0.39      3023
         5.0       0.52      0.59      0.55      3056
         6.0       0.58      0.68      0.62      3049
         7.0       0.55      0.60      0.57      3097
         8.0       0.62      0.72      0.67      3086
         9.0       0.55      0.67      0.60      2995

    accuracy                           0.54     30586
   macro avg       0.53      0.54      0.53     30586
weighted avg       0.53      0.54      0.53     30586

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5594716536977702
test acc: 0.5985714285714285
min train acc: 0.5721017907634307
maj train acc: 0.5500438431667293
min test acc: 0.6284445605328457
maj test acc: 0.5691990197342964
total acc: 0.5790896947186654
total min acc: 0.6007027313709892
total maj acc: 0.5594814438230808
precision, recall: (0.5805401004206813, 0.5594716536977702)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 8.829985089544166, 0.5773078022292083, 0.539952919636435, 0.5790896947186654, 0.6007027313709892, 0.5594814438230808, '              precision    recall  f1-score   support\n\n         0.0       0.20      0.21      0.20       508\n         1.0       0.22      0.18      0.20       482\n         2.0       0.21      0.19      0.20       510\n         3.0       0.10      0.07      0.08       489\n         4.0       0.19      0.15      0.16       466\n         5.0       0.57      0.57      0.57      2972\n         6.0       0.69      0.68      0.68      3080\n         7.0       0.59      0.60      0.60      2961\n         8.0       0.70      0.72      0.71      3024\n         9.0       0.60      0.65      0.62      3003\n\n    accuracy                           0.58     17495\n   macro avg       0.41      0.40      0.40     17495\nweighted avg       0.57      0.58      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.60      0.52      0.56      3144\n         1.0       0.56      0.58      0.57      3055\n         2.0       0.41      0.33      0.36      3055\n         3.0       0.46      0.39      0.42      3026\n         4.0       0.48      0.32      0.39      3023\n         5.0       0.52      0.59      0.55      3056\n         6.0       0.58      0.68      0.62      3049\n         7.0       0.55      0.60      0.57      3097\n         8.0       0.62      0.72      0.67      3086\n         9.0       0.55      0.67      0.60      2995\n\n    accuracy                           0.54     30586\n   macro avg       0.53      0.54      0.53     30586\nweighted avg       0.53      0.54      0.53     30586\n']
experiment_number: 15
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-15.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3035, 2882, 2919, 2936, 3025, 3032, 2993, 2988, 3012, 2937])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (29759, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.727356 Acc@1: 0.124894 (ε = 6.96, δ = 1e-05) for α = 3.1
	Train Epoch: 1 	Loss: 2.525300 Acc@1: 0.113382 (ε = 10.82, δ = 1e-05) for α = 2.3
	Train Epoch: 1 	Loss: 2.435678 Acc@1: 0.114927 (ε = 12.43, δ = 1e-05) for α = 2.2
	Test set:Loss: 2.527671 Acc@1: 0.023321 
	Train Epoch: 2 	Loss: 2.970729 Acc@1: 0.076603 (ε = 13.11, δ = 1e-05) for α = 2.2
	Train Epoch: 2 	Loss: 2.382028 Acc@1: 0.107429 (ε = 14.23, δ = 1e-05) for α = 2.1
	Train Epoch: 2 	Loss: 2.440344 Acc@1: 0.111476 (ε = 15.27, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.330321 Acc@1: 0.035090 
	Train Epoch: 3 	Loss: 2.284981 Acc@1: 0.114286 (ε = 15.71, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.478552 Acc@1: 0.116805 (ε = 16.53, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.391585 Acc@1: 0.119683 (ε = 17.35, δ = 1e-05) for α = 2.0
	Test set:Loss: 2.299581 Acc@1: 0.069717 
	Train Epoch: 4 	Loss: 2.300314 Acc@1: 0.110549 (ε = 17.77, δ = 1e-05) for α = 2.0
	Train Epoch: 4 	Loss: 2.305684 Acc@1: 0.110229 (ε = 18.46, δ = 1e-05) for α = 1.9
	Train Epoch: 4 	Loss: 2.307676 Acc@1: 0.106775 (ε = 19.12, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.256130 Acc@1: 0.043968 
	Train Epoch: 5 	Loss: 2.275753 Acc@1: 0.111551 (ε = 19.45, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.269527 Acc@1: 0.137518 (ε = 20.11, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.324132 Acc@1: 0.123898 (ε = 20.77, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.312335 Acc@1: 0.027560 
	Train Epoch: 6 	Loss: 2.313115 Acc@1: 0.102400 (ε = 21.10, δ = 1e-05) for α = 1.9
	Train Epoch: 6 	Loss: 2.307465 Acc@1: 0.099661 (ε = 21.69, δ = 1e-05) for α = 1.8
	Train Epoch: 6 	Loss: 2.305383 Acc@1: 0.099850 (ε = 22.22, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.297916 Acc@1: 0.028643 
	Train Epoch: 7 	Loss: 2.302668 Acc@1: 0.107627 (ε = 22.49, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.302288 Acc@1: 0.099755 (ε = 23.03, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.298599 Acc@1: 0.108162 (ε = 23.56, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.257252 Acc@1: 0.198830 
	Train Epoch: 8 	Loss: 2.262863 Acc@1: 0.111987 (ε = 23.83, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.271493 Acc@1: 0.145248 (ε = 24.37, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.247516 Acc@1: 0.170587 (ε = 24.90, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.199890 Acc@1: 0.231423 
	Train Epoch: 9 	Loss: 2.212517 Acc@1: 0.162950 (ε = 25.17, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.375278 Acc@1: 0.170762 (ε = 25.71, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.303848 Acc@1: 0.178571 (ε = 26.22, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.128910 Acc@1: 0.222082 
	Train Epoch: 10 	Loss: 2.107859 Acc@1: 0.242653 (ε = 26.44, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.159839 Acc@1: 0.258527 (ε = 26.88, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.285072 Acc@1: 0.221903 (ε = 27.32, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.095985 Acc@1: 0.258058 
	Train Epoch: 11 	Loss: 2.100391 Acc@1: 0.253642 (ε = 27.54, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.098334 Acc@1: 0.259803 (ε = 27.99, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.172751 Acc@1: 0.263658 (ε = 28.43, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.049772 Acc@1: 0.288664 
	Train Epoch: 12 	Loss: 2.042638 Acc@1: 0.273266 (ε = 28.65, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 2.082999 Acc@1: 0.312739 (ε = 29.09, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 2.022851 Acc@1: 0.326133 (ε = 29.53, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.268172 Acc@1: 0.253322 
	Train Epoch: 13 	Loss: 1.993804 Acc@1: 0.338940 (ε = 29.75, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 1.918208 Acc@1: 0.362913 (ε = 30.20, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 1.948863 Acc@1: 0.354565 (ε = 30.64, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.928503 Acc@1: 0.311310 
	Train Epoch: 14 	Loss: 1.885001 Acc@1: 0.375204 (ε = 30.86, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.870382 Acc@1: 0.384434 (ε = 31.30, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.836589 Acc@1: 0.394868 (ε = 31.74, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.733954 Acc@1: 0.455542 
	Train Epoch: 15 	Loss: 1.792585 Acc@1: 0.409051 (ε = 31.96, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.740360 Acc@1: 0.438554 (ε = 32.41, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.716787 Acc@1: 0.445028 (ε = 32.85, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.764653 Acc@1: 0.426906 
	Train Epoch: 16 	Loss: 1.825744 Acc@1: 0.447552 (ε = 33.04, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.659301 Acc@1: 0.459716 (ε = 33.41, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.666088 Acc@1: 0.468868 (ε = 33.77, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.883000 Acc@1: 0.420846 
	Train Epoch: 17 	Loss: 1.642999 Acc@1: 0.486532 (ε = 33.96, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.616687 Acc@1: 0.506191 (ε = 34.33, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.633276 Acc@1: 0.501649 (ε = 34.69, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.708561 Acc@1: 0.490226 
	Train Epoch: 18 	Loss: 1.578282 Acc@1: 0.491100 (ε = 34.88, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.592792 Acc@1: 0.509861 (ε = 35.25, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.584007 Acc@1: 0.515042 (ε = 35.62, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.714449 Acc@1: 0.479423 
	Train Epoch: 19 	Loss: 1.509637 Acc@1: 0.539516 (ε = 35.80, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.576819 Acc@1: 0.526375 (ε = 36.17, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.566719 Acc@1: 0.527655 (ε = 36.54, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.709954 Acc@1: 0.490086 
	Train Epoch: 20 	Loss: 1.524043 Acc@1: 0.532423 (ε = 36.72, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 1.556192 Acc@1: 0.539296 (ε = 37.09, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 1.556063 Acc@1: 0.543906 (ε = 37.46, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.640794 Acc@1: 0.520695 
	Train Epoch: 21 	Loss: 1.570205 Acc@1: 0.552523 (ε = 37.64, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 1.551045 Acc@1: 0.549653 (ε = 38.01, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 1.542643 Acc@1: 0.547694 (ε = 38.38, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.632017 Acc@1: 0.529729 
	Train Epoch: 22 	Loss: 1.504734 Acc@1: 0.562552 (ε = 38.56, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 1.548720 Acc@1: 0.552315 (ε = 38.93, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 1.532523 Acc@1: 0.555187 (ε = 39.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.681048 Acc@1: 0.521766 
	Train Epoch: 23 	Loss: 1.612457 Acc@1: 0.561290 (ε = 39.48, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 1.518781 Acc@1: 0.560899 (ε = 39.85, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 1.513187 Acc@1: 0.563680 (ε = 40.22, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.685442 Acc@1: 0.520391 
	Train Epoch: 24 	Loss: 1.537487 Acc@1: 0.574419 (ε = 40.40, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 1.520387 Acc@1: 0.564004 (ε = 40.77, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 1.520569 Acc@1: 0.566795 (ε = 41.14, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.625216 Acc@1: 0.537434 
	Train Epoch: 25 	Loss: 1.466657 Acc@1: 0.577813 (ε = 41.32, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 1.469290 Acc@1: 0.573787 (ε = 41.69, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 1.497753 Acc@1: 0.569675 (ε = 42.06, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.600730 Acc@1: 0.545713 
	Train Epoch: 26 	Loss: 1.444011 Acc@1: 0.586322 (ε = 42.24, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 1.483395 Acc@1: 0.579045 (ε = 42.61, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 1.504183 Acc@1: 0.574025 (ε = 42.98, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.629875 Acc@1: 0.542753 
	Train Epoch: 27 	Loss: 1.544647 Acc@1: 0.574941 (ε = 43.17, δ = 1e-05) for α = 1.6
	Train Epoch: 27 	Loss: 1.510569 Acc@1: 0.574115 (ε = 43.48, δ = 1e-05) for α = 1.5
	Train Epoch: 27 	Loss: 1.499703 Acc@1: 0.576118 (ε = 43.79, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.692084 Acc@1: 0.522871 
	Train Epoch: 28 	Loss: 1.578461 Acc@1: 0.569480 (ε = 43.94, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 1.538406 Acc@1: 0.568344 (ε = 44.25, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 1.526047 Acc@1: 0.569636 (ε = 44.56, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.644372 Acc@1: 0.537425 
	Train Epoch: 29 	Loss: 1.537663 Acc@1: 0.566151 (ε = 44.72, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 1.479968 Acc@1: 0.578989 (ε = 45.03, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 1.489166 Acc@1: 0.581766 (ε = 45.34, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.669598 Acc@1: 0.531204 
	Train Epoch: 30 	Loss: 1.557047 Acc@1: 0.570033 (ε = 45.49, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 1.497442 Acc@1: 0.578725 (ε = 45.80, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 1.491514 Acc@1: 0.580065 (ε = 46.11, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.650385 Acc@1: 0.535802 
Base private model test accuracy:  0.5359817090597313
              precision    recall  f1-score   support

         0.0       0.26      0.56      0.36       508
         1.0       0.25      0.63      0.36       482
         2.0       0.18      0.42      0.26       510
         3.0       0.09      0.22      0.13       489
         4.0       0.15      0.44      0.22       466
         5.0       0.64      0.43      0.52      2972
         6.0       0.80      0.62      0.70      3080
         7.0       0.69      0.53      0.60      2961
         8.0       0.79      0.60      0.68      3024
         9.0       0.67      0.56      0.61      3003

    accuracy                           0.54     17495
   macro avg       0.45      0.50      0.44     17495
weighted avg       0.64      0.54      0.57     17495

Base private model train accuracy:  0.5765650727511005
              precision    recall  f1-score   support

         0.0       0.64      0.68      0.66      3035
         1.0       0.68      0.71      0.70      2882
         2.0       0.54      0.53      0.54      2919
         3.0       0.48      0.43      0.45      2936
         4.0       0.51      0.56      0.53      3025
         5.0       0.48      0.43      0.45      3032
         6.0       0.61      0.64      0.63      2993
         7.0       0.60      0.55      0.57      2988
         8.0       0.66      0.62      0.64      3012
         9.0       0.56      0.62      0.59      2937

    accuracy                           0.58     29759
   macro avg       0.58      0.58      0.58     29759
weighted avg       0.58      0.58      0.57     29759

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7663149405201962
test acc: 0.7513636363636363
min train acc: 0.9400569653029518
maj train acc: 0.6060369502992454
min test acc: 0.9379655792447984
maj test acc: 0.5608604407135362
total acc: 0.7587106575514383
total min acc: 0.9390070921985816
total maj acc: 0.5835401698236446
precision, recall: (0.7486048191189022, 0.7663149405201962)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 46.2328138233103, 0.5359817090597313, 0.5765650727511005, 0.7587106575514383, 0.9390070921985816, 0.5835401698236446, '              precision    recall  f1-score   support\n\n         0.0       0.26      0.56      0.36       508\n         1.0       0.25      0.63      0.36       482\n         2.0       0.18      0.42      0.26       510\n         3.0       0.09      0.22      0.13       489\n         4.0       0.15      0.44      0.22       466\n         5.0       0.64      0.43      0.52      2972\n         6.0       0.80      0.62      0.70      3080\n         7.0       0.69      0.53      0.60      2961\n         8.0       0.79      0.60      0.68      3024\n         9.0       0.67      0.56      0.61      3003\n\n    accuracy                           0.54     17495\n   macro avg       0.45      0.50      0.44     17495\nweighted avg       0.64      0.54      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.64      0.68      0.66      3035\n         1.0       0.68      0.71      0.70      2882\n         2.0       0.54      0.53      0.54      2919\n         3.0       0.48      0.43      0.45      2936\n         4.0       0.51      0.56      0.53      3025\n         5.0       0.48      0.43      0.45      3032\n         6.0       0.61      0.64      0.63      2993\n         7.0       0.60      0.55      0.57      2988\n         8.0       0.66      0.62      0.64      3012\n         9.0       0.56      0.62      0.59      2937\n\n    accuracy                           0.58     29759\n   macro avg       0.58      0.58      0.58     29759\nweighted avg       0.58      0.58      0.57     29759\n']
experiment_number: 25
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-25.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([499, 496, 504, 479, 496, 493, 499, 500, 520, 487])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4973, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.510218 Acc@1: 0.108491 (ε = 6.96, δ = 1e-05) for α = 3.1
	Train Epoch: 1 	Loss: 3.404791 Acc@1: 0.113555 (ε = 10.82, δ = 1e-05) for α = 2.3
	Train Epoch: 1 	Loss: 2.901539 Acc@1: 0.109095 (ε = 12.43, δ = 1e-05) for α = 2.2
	Test set:Loss: 2.257659 Acc@1: 0.203390 
	Train Epoch: 2 	Loss: 2.282451 Acc@1: 0.110000 (ε = 13.11, δ = 1e-05) for α = 2.2
	Train Epoch: 2 	Loss: 2.334319 Acc@1: 0.124769 (ε = 14.23, δ = 1e-05) for α = 2.1
	Train Epoch: 2 	Loss: 2.394906 Acc@1: 0.136208 (ε = 15.27, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.358985 Acc@1: 0.064289 
	Train Epoch: 3 	Loss: 2.410166 Acc@1: 0.176471 (ε = 15.71, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.380580 Acc@1: 0.175069 (ε = 16.53, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.446993 Acc@1: 0.176755 (ε = 17.35, δ = 1e-05) for α = 2.0
	Test set:Loss: 3.100906 Acc@1: 0.148169 
	Train Epoch: 4 	Loss: 3.062737 Acc@1: 0.191388 (ε = 17.77, δ = 1e-05) for α = 2.0
	Train Epoch: 4 	Loss: 2.412177 Acc@1: 0.125362 (ε = 18.46, δ = 1e-05) for α = 1.9
	Train Epoch: 4 	Loss: 2.373941 Acc@1: 0.141289 (ε = 19.12, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.263475 Acc@1: 0.176931 
	Train Epoch: 5 	Loss: 2.367498 Acc@1: 0.081633 (ε = 19.45, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.347164 Acc@1: 0.142842 (ε = 20.11, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.342625 Acc@1: 0.158558 (ε = 20.77, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.293946 Acc@1: 0.158239 
	Train Epoch: 6 	Loss: 2.243596 Acc@1: 0.173913 (ε = 21.10, δ = 1e-05) for α = 1.9
	Train Epoch: 6 	Loss: 2.283062 Acc@1: 0.204738 (ε = 21.69, δ = 1e-05) for α = 1.8
	Train Epoch: 6 	Loss: 2.344034 Acc@1: 0.185706 (ε = 22.22, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.519734 Acc@1: 0.179069 
	Train Epoch: 7 	Loss: 2.491666 Acc@1: 0.158163 (ε = 22.49, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.385581 Acc@1: 0.127385 (ε = 23.03, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.378603 Acc@1: 0.133035 (ε = 23.56, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.425838 Acc@1: 0.168593 
	Train Epoch: 8 	Loss: 2.333698 Acc@1: 0.171429 (ε = 23.83, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.339402 Acc@1: 0.139864 (ε = 24.37, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.342886 Acc@1: 0.137407 (ε = 24.90, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.413788 Acc@1: 0.180265 
	Train Epoch: 9 	Loss: 2.214994 Acc@1: 0.191388 (ε = 25.17, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.292108 Acc@1: 0.152450 (ε = 25.71, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.305581 Acc@1: 0.169500 (ε = 26.22, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.331707 Acc@1: 0.201865 
	Train Epoch: 10 	Loss: 2.250014 Acc@1: 0.153846 (ε = 26.44, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.321208 Acc@1: 0.157463 (ε = 26.88, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.310128 Acc@1: 0.170083 (ε = 27.32, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.334277 Acc@1: 0.193615 
	Train Epoch: 11 	Loss: 2.288425 Acc@1: 0.165803 (ε = 27.54, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.331711 Acc@1: 0.187922 (ε = 27.99, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.356575 Acc@1: 0.185676 (ε = 28.43, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.439965 Acc@1: 0.199117 
	Train Epoch: 12 	Loss: 2.302122 Acc@1: 0.140187 (ε = 28.65, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 2.444083 Acc@1: 0.158052 (ε = 29.09, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 2.414204 Acc@1: 0.142590 (ε = 29.53, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.311241 Acc@1: 0.193572 
	Train Epoch: 13 	Loss: 2.229493 Acc@1: 0.161290 (ε = 29.75, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 2.332050 Acc@1: 0.147550 (ε = 30.20, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 2.365041 Acc@1: 0.145635 (ε = 30.64, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.432693 Acc@1: 0.257235 
	Train Epoch: 14 	Loss: 2.576345 Acc@1: 0.162162 (ε = 30.86, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 2.363453 Acc@1: 0.156242 (ε = 31.30, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 2.326055 Acc@1: 0.162929 (ε = 31.74, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.534092 Acc@1: 0.128967 
	Train Epoch: 15 	Loss: 2.434722 Acc@1: 0.129353 (ε = 31.96, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 2.327641 Acc@1: 0.138086 (ε = 32.41, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 2.322214 Acc@1: 0.142503 (ε = 32.85, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.509997 Acc@1: 0.042563 
	Train Epoch: 16 	Loss: 2.253492 Acc@1: 0.133333 (ε = 33.04, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.287177 Acc@1: 0.169892 (ε = 33.41, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.302040 Acc@1: 0.176559 (ε = 33.77, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.453461 Acc@1: 0.169089 
	Train Epoch: 17 	Loss: 2.455222 Acc@1: 0.198980 (ε = 33.96, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 2.271686 Acc@1: 0.183618 (ε = 34.33, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 2.306874 Acc@1: 0.178359 (ε = 34.69, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.495765 Acc@1: 0.236118 
	Train Epoch: 18 	Loss: 2.440932 Acc@1: 0.156977 (ε = 34.88, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 2.340294 Acc@1: 0.164697 (ε = 35.25, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 2.305019 Acc@1: 0.169342 (ε = 35.62, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.325262 Acc@1: 0.237470 
	Train Epoch: 19 	Loss: 2.194540 Acc@1: 0.228723 (ε = 35.80, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 2.230220 Acc@1: 0.194082 (ε = 36.17, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 2.275533 Acc@1: 0.184250 (ε = 36.54, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.368571 Acc@1: 0.183852 
	Train Epoch: 20 	Loss: 2.244203 Acc@1: 0.192308 (ε = 36.72, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 2.283243 Acc@1: 0.163216 (ε = 37.09, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 2.272114 Acc@1: 0.171341 (ε = 37.46, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.292180 Acc@1: 0.303294 
	Train Epoch: 21 	Loss: 2.353476 Acc@1: 0.183099 (ε = 37.64, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 2.221509 Acc@1: 0.198630 (ε = 38.01, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 2.268323 Acc@1: 0.185951 (ε = 38.38, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.311209 Acc@1: 0.279210 
	Train Epoch: 22 	Loss: 2.279124 Acc@1: 0.174359 (ε = 38.56, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 2.233589 Acc@1: 0.200074 (ε = 38.93, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 2.235484 Acc@1: 0.197565 (ε = 39.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.360310 Acc@1: 0.208495 
	Train Epoch: 23 	Loss: 2.394654 Acc@1: 0.202381 (ε = 39.48, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 2.254974 Acc@1: 0.201102 (ε = 39.85, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 2.274465 Acc@1: 0.193510 (ε = 40.22, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.293182 Acc@1: 0.291019 
	Train Epoch: 24 	Loss: 2.210524 Acc@1: 0.213542 (ε = 40.40, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 2.250064 Acc@1: 0.202593 (ε = 40.77, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 2.254064 Acc@1: 0.197801 (ε = 41.14, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.321039 Acc@1: 0.230143 
	Train Epoch: 25 	Loss: 2.105027 Acc@1: 0.223684 (ε = 41.32, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 2.232710 Acc@1: 0.205328 (ε = 41.69, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 2.228176 Acc@1: 0.199084 (ε = 42.06, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.314205 Acc@1: 0.299445 
	Train Epoch: 26 	Loss: 2.178724 Acc@1: 0.185000 (ε = 42.24, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 2.246363 Acc@1: 0.188781 (ε = 42.61, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 2.240929 Acc@1: 0.193913 (ε = 42.98, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.310996 Acc@1: 0.202421 
	Train Epoch: 27 	Loss: 2.150517 Acc@1: 0.204878 (ε = 43.17, δ = 1e-05) for α = 1.6
	Train Epoch: 27 	Loss: 2.232411 Acc@1: 0.209214 (ε = 43.48, δ = 1e-05) for α = 1.5
	Train Epoch: 27 	Loss: 2.225784 Acc@1: 0.206054 (ε = 43.79, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.285517 Acc@1: 0.228895 
	Train Epoch: 28 	Loss: 2.124368 Acc@1: 0.256039 (ε = 43.94, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 2.217112 Acc@1: 0.214417 (ε = 44.25, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 2.226321 Acc@1: 0.214627 (ε = 44.56, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.279902 Acc@1: 0.294570 
	Train Epoch: 29 	Loss: 2.311064 Acc@1: 0.213592 (ε = 44.72, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 2.180177 Acc@1: 0.218780 (ε = 45.03, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 2.191150 Acc@1: 0.206040 (ε = 45.34, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.291965 Acc@1: 0.290563 
	Train Epoch: 30 	Loss: 2.245776 Acc@1: 0.188482 (ε = 45.49, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 2.237881 Acc@1: 0.199271 (ε = 45.80, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 2.227319 Acc@1: 0.195749 (ε = 46.11, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.288602 Acc@1: 0.292564 
Base private model test accuracy:  0.2931694769934267
              precision    recall  f1-score   support

         0.0       0.03      0.01      0.02       508
         1.0       0.04      0.12      0.06       482
         2.0       0.06      0.01      0.01       510
         3.0       0.09      0.07      0.08       489
         4.0       0.02      0.00      0.00       466
         5.0       0.37      0.05      0.09      2972
         6.0       0.23      0.27      0.25      3080
         7.0       0.35      0.39      0.37      2961
         8.0       0.46      0.61      0.53      3024
         9.0       0.26      0.34      0.30      3003

    accuracy                           0.29     17495
   macro avg       0.19      0.19      0.17     17495
weighted avg       0.29      0.29      0.27     17495

Base private model train accuracy:  0.20490649507339634
              precision    recall  f1-score   support

         0.0       0.13      0.02      0.03       499
         1.0       0.17      0.15      0.16       496
         2.0       0.19      0.01      0.01       504
         3.0       0.37      0.12      0.18       479
         4.0       0.07      0.00      0.01       496
         5.0       0.44      0.10      0.17       493
         6.0       0.15      0.30      0.20       499
         7.0       0.21      0.40      0.27       500
         8.0       0.27      0.58      0.37       520
         9.0       0.16      0.34      0.21       487

    accuracy                           0.20      4973
   macro avg       0.22      0.20      0.16      4973
weighted avg       0.22      0.20      0.16      4973

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.667739340305712
test acc: 0.3356223175965666
min train acc: 0.6909398814563928
maj train acc: 0.6436583261432269
min test acc: 0.3145228215767635
maj test acc: 0.36035242290748903
total acc: 0.5070598006644518
total min acc: 0.5008382229673093
total maj acc: 0.5034873583260681
precision, recall: (0.5174563591022444, 0.667739340305712)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 46.2328138233103, 0.2931694769934267, 0.20490649507339634, 0.5070598006644518, 0.5008382229673093, 0.5034873583260681, '              precision    recall  f1-score   support\n\n         0.0       0.03      0.01      0.02       508\n         1.0       0.04      0.12      0.06       482\n         2.0       0.06      0.01      0.01       510\n         3.0       0.09      0.07      0.08       489\n         4.0       0.02      0.00      0.00       466\n         5.0       0.37      0.05      0.09      2972\n         6.0       0.23      0.27      0.25      3080\n         7.0       0.35      0.39      0.37      2961\n         8.0       0.46      0.61      0.53      3024\n         9.0       0.26      0.34      0.30      3003\n\n    accuracy                           0.29     17495\n   macro avg       0.19      0.19      0.17     17495\nweighted avg       0.29      0.29      0.27     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.13      0.02      0.03       499\n         1.0       0.17      0.15      0.16       496\n         2.0       0.19      0.01      0.01       504\n         3.0       0.37      0.12      0.18       479\n         4.0       0.07      0.00      0.01       496\n         5.0       0.44      0.10      0.17       493\n         6.0       0.15      0.30      0.20       499\n         7.0       0.21      0.40      0.27       500\n         8.0       0.27      0.58      0.37       520\n         9.0       0.16      0.34      0.21       487\n\n    accuracy                           0.20      4973\n   macro avg       0.22      0.20      0.16      4973\nweighted avg       0.22      0.20      0.16      4973\n']
experiment_number: 17
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-17.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3061, 2984, 3079, 3023, 3022, 3064, 2992, 3042, 3095, 3086])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30448, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.587494 Acc@1: 0.095118 (ε = 6.96, δ = 1e-05) for α = 3.1
	Train Epoch: 1 	Loss: 2.450720 Acc@1: 0.106181 (ε = 10.82, δ = 1e-05) for α = 2.3
	Train Epoch: 1 	Loss: 2.359281 Acc@1: 0.101205 (ε = 12.43, δ = 1e-05) for α = 2.2
	Test set:Loss: 2.413200 Acc@1: 0.110798 
	Train Epoch: 2 	Loss: 2.232228 Acc@1: 0.147287 (ε = 13.11, δ = 1e-05) for α = 2.2
	Train Epoch: 2 	Loss: 4.383478 Acc@1: 0.160138 (ε = 14.23, δ = 1e-05) for α = 2.1
	Train Epoch: 2 	Loss: 3.489837 Acc@1: 0.139954 (ε = 15.27, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.387722 Acc@1: 0.142114 
	Train Epoch: 3 	Loss: 2.292586 Acc@1: 0.148902 (ε = 15.71, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.216067 Acc@1: 0.166103 (ε = 16.53, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 2.205323 Acc@1: 0.165911 (ε = 17.35, δ = 1e-05) for α = 2.0
	Test set:Loss: 2.197270 Acc@1: 0.181454 
	Train Epoch: 4 	Loss: 2.176430 Acc@1: 0.174679 (ε = 17.77, δ = 1e-05) for α = 2.0
	Train Epoch: 4 	Loss: 2.270722 Acc@1: 0.165934 (ε = 18.46, δ = 1e-05) for α = 1.9
	Train Epoch: 4 	Loss: 3.531863 Acc@1: 0.142256 (ε = 19.12, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.148808 Acc@1: 0.169285 
	Train Epoch: 5 	Loss: 2.343530 Acc@1: 0.087912 (ε = 19.45, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.315461 Acc@1: 0.100056 (ε = 20.11, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 2.310759 Acc@1: 0.100772 (ε = 20.77, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.337183 Acc@1: 0.025752 
	Train Epoch: 6 	Loss: 2.306915 Acc@1: 0.097279 (ε = 21.10, δ = 1e-05) for α = 1.9
	Train Epoch: 6 	Loss: 2.303139 Acc@1: 0.100101 (ε = 21.69, δ = 1e-05) for α = 1.8
	Train Epoch: 6 	Loss: 2.302479 Acc@1: 0.110294 (ε = 22.22, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.391141 Acc@1: 0.129940 
	Train Epoch: 7 	Loss: 2.312248 Acc@1: 0.138799 (ε = 22.49, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.284544 Acc@1: 0.155124 (ε = 23.03, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 2.256503 Acc@1: 0.153613 (ε = 23.56, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.179904 Acc@1: 0.179802 
	Train Epoch: 8 	Loss: 2.128501 Acc@1: 0.180921 (ε = 23.83, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.138859 Acc@1: 0.176569 (ε = 24.37, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 2.116310 Acc@1: 0.192833 (ε = 24.90, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.098156 Acc@1: 0.199057 
	Train Epoch: 9 	Loss: 2.116531 Acc@1: 0.203191 (ε = 25.17, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.061401 Acc@1: 0.206420 (ε = 25.71, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 2.058660 Acc@1: 0.220871 (ε = 26.22, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.418849 Acc@1: 0.164806 
	Train Epoch: 10 	Loss: 2.221756 Acc@1: 0.204082 (ε = 26.44, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.163088 Acc@1: 0.199921 (ε = 26.88, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 2.117556 Acc@1: 0.229055 (ε = 27.32, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.094887 Acc@1: 0.270462 
	Train Epoch: 11 	Loss: 1.990877 Acc@1: 0.271930 (ε = 27.54, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.009220 Acc@1: 0.269479 (ε = 27.99, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 2.033624 Acc@1: 0.267340 (ε = 28.43, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.211793 Acc@1: 0.274196 
	Train Epoch: 12 	Loss: 2.183942 Acc@1: 0.256757 (ε = 28.65, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 1.982221 Acc@1: 0.299753 (ε = 29.09, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 1.971652 Acc@1: 0.306903 (ε = 29.53, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.878384 Acc@1: 0.373075 
	Train Epoch: 13 	Loss: 1.975484 Acc@1: 0.329362 (ε = 29.75, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 2.072590 Acc@1: 0.314774 (ε = 30.20, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 2.010238 Acc@1: 0.323394 (ε = 30.64, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.804942 Acc@1: 0.391697 
	Train Epoch: 14 	Loss: 1.822268 Acc@1: 0.358386 (ε = 30.86, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.873855 Acc@1: 0.359975 (ε = 31.30, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.873931 Acc@1: 0.370244 (ε = 31.74, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.891588 Acc@1: 0.381017 
	Train Epoch: 15 	Loss: 2.107125 Acc@1: 0.360275 (ε = 31.96, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.976556 Acc@1: 0.348452 (ε = 32.41, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.906975 Acc@1: 0.359189 (ε = 32.85, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.709911 Acc@1: 0.434442 
	Train Epoch: 16 	Loss: 1.837518 Acc@1: 0.388797 (ε = 33.04, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.881556 Acc@1: 0.379730 (ε = 33.41, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.883425 Acc@1: 0.379149 (ε = 33.77, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.622789 Acc@1: 0.469506 
	Train Epoch: 17 	Loss: 1.803897 Acc@1: 0.381513 (ε = 33.96, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.803780 Acc@1: 0.413119 (ε = 34.33, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.818531 Acc@1: 0.414515 (ε = 34.69, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.621511 Acc@1: 0.492771 
	Train Epoch: 18 	Loss: 1.729236 Acc@1: 0.436306 (ε = 34.88, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.715910 Acc@1: 0.442773 (ε = 35.25, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.745807 Acc@1: 0.441922 (ε = 35.62, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.532234 Acc@1: 0.521806 
	Train Epoch: 19 	Loss: 1.674908 Acc@1: 0.473258 (ε = 35.80, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.701458 Acc@1: 0.458242 (ε = 36.17, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.708452 Acc@1: 0.458627 (ε = 36.54, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.503318 Acc@1: 0.536318 
	Train Epoch: 20 	Loss: 1.705012 Acc@1: 0.479642 (ε = 36.72, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 1.665705 Acc@1: 0.470271 (ε = 37.09, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 1.689631 Acc@1: 0.468266 (ε = 37.46, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.575375 Acc@1: 0.528276 
	Train Epoch: 21 	Loss: 1.624839 Acc@1: 0.475325 (ε = 37.64, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 1.665175 Acc@1: 0.467995 (ε = 38.01, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 1.670432 Acc@1: 0.470714 (ε = 38.38, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.614115 Acc@1: 0.507640 
	Train Epoch: 22 	Loss: 1.615330 Acc@1: 0.469919 (ε = 38.56, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 1.666821 Acc@1: 0.477089 (ε = 38.93, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 1.657020 Acc@1: 0.479070 (ε = 39.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.568667 Acc@1: 0.529375 
	Train Epoch: 23 	Loss: 1.695527 Acc@1: 0.498011 (ε = 39.48, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 1.669767 Acc@1: 0.482645 (ε = 39.85, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 1.658725 Acc@1: 0.484367 (ε = 40.22, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.497316 Acc@1: 0.555261 
	Train Epoch: 24 	Loss: 1.587650 Acc@1: 0.495895 (ε = 40.40, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 1.651689 Acc@1: 0.488053 (ε = 40.77, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 1.641725 Acc@1: 0.489971 (ε = 41.14, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.491102 Acc@1: 0.552689 
	Train Epoch: 25 	Loss: 1.638878 Acc@1: 0.495495 (ε = 41.32, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 1.616111 Acc@1: 0.501403 (ε = 41.69, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 1.621639 Acc@1: 0.502082 (ε = 42.06, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.515124 Acc@1: 0.553722 
	Train Epoch: 26 	Loss: 1.709308 Acc@1: 0.483705 (ε = 42.24, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 1.665746 Acc@1: 0.494767 (ε = 42.61, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 1.657425 Acc@1: 0.496525 (ε = 42.98, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.519554 Acc@1: 0.553849 
	Train Epoch: 27 	Loss: 1.692738 Acc@1: 0.482008 (ε = 43.17, δ = 1e-05) for α = 1.6
	Train Epoch: 27 	Loss: 1.652934 Acc@1: 0.497695 (ε = 43.48, δ = 1e-05) for α = 1.5
	Train Epoch: 27 	Loss: 1.651559 Acc@1: 0.498265 (ε = 43.79, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.522166 Acc@1: 0.557245 
	Train Epoch: 28 	Loss: 1.642189 Acc@1: 0.512863 (ε = 43.94, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 1.628442 Acc@1: 0.497135 (ε = 44.25, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 1.627295 Acc@1: 0.497692 (ε = 44.56, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.533196 Acc@1: 0.552213 
	Train Epoch: 29 	Loss: 1.669128 Acc@1: 0.489627 (ε = 44.72, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 1.611091 Acc@1: 0.501036 (ε = 45.03, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 1.612702 Acc@1: 0.503485 (ε = 45.34, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.521450 Acc@1: 0.556293 
	Train Epoch: 30 	Loss: 1.591880 Acc@1: 0.503279 (ε = 45.49, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 1.649081 Acc@1: 0.500822 (ε = 45.80, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 1.645666 Acc@1: 0.499797 (ε = 46.11, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.518154 Acc@1: 0.556636 
Base private model test accuracy:  0.5570162903686767
              precision    recall  f1-score   support

         0.0       0.23      0.25      0.24       508
         1.0       0.23      0.16      0.19       482
         2.0       0.13      0.08      0.10       510
         3.0       0.03      0.01      0.02       489
         4.0       0.15      0.08      0.11       466
         5.0       0.52      0.60      0.56      2972
         6.0       0.63      0.65      0.64      3080
         7.0       0.53      0.53      0.53      2961
         8.0       0.70      0.72      0.71      3024
         9.0       0.60      0.63      0.62      3003

    accuracy                           0.56     17495
   macro avg       0.38      0.37      0.37     17495
weighted avg       0.54      0.56      0.55     17495

Base private model train accuracy:  0.5021019442984761
              precision    recall  f1-score   support

         0.0       0.57      0.44      0.50      3061
         1.0       0.56      0.56      0.56      2984
         2.0       0.40      0.27      0.33      3079
         3.0       0.41      0.33      0.37      3023
         4.0       0.44      0.31      0.36      3022
         5.0       0.46      0.59      0.52      3064
         6.0       0.46      0.64      0.54      2992
         7.0       0.48      0.54      0.51      3042
         8.0       0.63      0.73      0.68      3095
         9.0       0.55      0.62      0.58      3086

    accuracy                           0.50     30448
   macro avg       0.50      0.50      0.49     30448
weighted avg       0.50      0.50      0.49     30448

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.516684182869154
test acc: 0.6162987012987013
min train acc: 0.5465880144791527
maj train acc: 0.49276820525720033
min test acc: 0.6338598094243572
maj test acc: 0.598786940250355
total acc: 0.5667776907001045
total min acc: 0.5908068783068783
total maj acc: 0.5450955414012739
precision, recall: (0.5710344827586207, 0.516684182869154)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 46.2328138233103, 0.5570162903686767, 0.5021019442984761, 0.5667776907001045, 0.5908068783068783, 0.5450955414012739, '              precision    recall  f1-score   support\n\n         0.0       0.23      0.25      0.24       508\n         1.0       0.23      0.16      0.19       482\n         2.0       0.13      0.08      0.10       510\n         3.0       0.03      0.01      0.02       489\n         4.0       0.15      0.08      0.11       466\n         5.0       0.52      0.60      0.56      2972\n         6.0       0.63      0.65      0.64      3080\n         7.0       0.53      0.53      0.53      2961\n         8.0       0.70      0.72      0.71      3024\n         9.0       0.60      0.63      0.62      3003\n\n    accuracy                           0.56     17495\n   macro avg       0.38      0.37      0.37     17495\nweighted avg       0.54      0.56      0.55     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.44      0.50      3061\n         1.0       0.56      0.56      0.56      2984\n         2.0       0.40      0.27      0.33      3079\n         3.0       0.41      0.33      0.37      3023\n         4.0       0.44      0.31      0.36      3022\n         5.0       0.46      0.59      0.52      3064\n         6.0       0.46      0.64      0.54      2992\n         7.0       0.48      0.54      0.51      3042\n         8.0       0.63      0.73      0.68      3095\n         9.0       0.55      0.62      0.58      3086\n\n    accuracy                           0.50     30448\n   macro avg       0.50      0.50      0.49     30448\nweighted avg       0.50      0.50      0.49     30448\n']
experiment_number: 16
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-16.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.3, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3081, 3070, 3041, 3017, 2957, 3010, 3139, 3003, 3120, 3060])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30498, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.314962 Acc@1: 0.097908 (ε = 15.92, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.480545 Acc@1: 0.110982 (ε = 31.59, δ = 1e-05) for α = 1.5
	Train Epoch: 1 	Loss: 2.520730 Acc@1: 0.111449 (ε = 38.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.354254 Acc@1: 0.158123 
	Train Epoch: 2 	Loss: 2.319501 Acc@1: 0.129784 (ε = 41.02, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 4.851282 Acc@1: 0.099748 (ε = 45.73, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 3.862845 Acc@1: 0.100130 (ε = 50.43, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.290947 Acc@1: 0.175956 
	Train Epoch: 3 	Loss: 2.303307 Acc@1: 0.098072 (ε = 52.79, δ = 1e-05) for α = 1.4
	Train Epoch: 3 	Loss: 2.308208 Acc@1: 0.112523 (ε = 56.32, δ = 1e-05) for α = 1.3
	Train Epoch: 3 	Loss: 2.429210 Acc@1: 0.114426 (ε = 59.26, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.263446 Acc@1: 0.213423 
	Train Epoch: 4 	Loss: 2.306188 Acc@1: 0.138514 (ε = 60.73, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.371684 Acc@1: 0.113102 (ε = 63.67, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.339303 Acc@1: 0.104957 (ε = 66.61, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.298153 Acc@1: 0.173854 
	Train Epoch: 5 	Loss: 2.302217 Acc@1: 0.097176 (ε = 68.08, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.307031 Acc@1: 0.100826 (ε = 71.02, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.303552 Acc@1: 0.103104 (ε = 73.96, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.292802 Acc@1: 0.195320 
	Train Epoch: 6 	Loss: 2.299607 Acc@1: 0.131789 (ε = 75.43, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.293750 Acc@1: 0.138729 (ε = 78.37, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.285289 Acc@1: 0.134412 (ε = 81.31, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.649967 Acc@1: 0.076870 
	Train Epoch: 7 	Loss: 2.553067 Acc@1: 0.124495 (ε = 82.78, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.279294 Acc@1: 0.160849 (ε = 85.73, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.250509 Acc@1: 0.178931 (ε = 88.67, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.032305 Acc@1: 0.310504 
	Train Epoch: 8 	Loss: 2.164861 Acc@1: 0.241214 (ε = 90.14, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.140375 Acc@1: 0.250782 (ε = 93.08, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.141736 Acc@1: 0.256275 (ε = 95.27, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.121261 Acc@1: 0.269387 
	Train Epoch: 9 	Loss: 2.230039 Acc@1: 0.287077 (ε = 96.23, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 2.028173 Acc@1: 0.314131 (ε = 98.15, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 2.020283 Acc@1: 0.330450 (ε = 100.07, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.914261 Acc@1: 0.346121 
	Train Epoch: 10 	Loss: 1.957487 Acc@1: 0.324525 (ε = 101.04, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 2.131431 Acc@1: 0.291324 (ε = 102.96, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 2.068195 Acc@1: 0.294618 (ε = 104.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.059516 Acc@1: 0.347405 
	Train Epoch: 11 	Loss: 1.991677 Acc@1: 0.368724 (ε = 105.85, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.920767 Acc@1: 0.374561 (ε = 107.77, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.896188 Acc@1: 0.375512 (ε = 109.69, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.790049 Acc@1: 0.395530 
	Train Epoch: 12 	Loss: 1.775727 Acc@1: 0.406452 (ε = 110.65, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.774407 Acc@1: 0.420468 (ε = 112.58, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.793519 Acc@1: 0.415893 (ε = 114.50, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.889726 Acc@1: 0.400874 
	Train Epoch: 13 	Loss: 1.884017 Acc@1: 0.389901 (ε = 115.46, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.766307 Acc@1: 0.426496 (ε = 117.39, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.745597 Acc@1: 0.437070 (ε = 119.31, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.642056 Acc@1: 0.485814 
	Train Epoch: 14 	Loss: 1.581110 Acc@1: 0.491765 (ε = 120.27, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.643531 Acc@1: 0.488275 (ε = 122.20, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.640265 Acc@1: 0.490745 (ε = 124.12, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.494411 Acc@1: 0.516664 
	Train Epoch: 15 	Loss: 1.636426 Acc@1: 0.474338 (ε = 125.08, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.609837 Acc@1: 0.502159 (ε = 127.00, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.615359 Acc@1: 0.503072 (ε = 128.93, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.687608 Acc@1: 0.493356 
	Train Epoch: 16 	Loss: 1.540517 Acc@1: 0.505238 (ε = 129.89, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.590663 Acc@1: 0.511508 (ε = 131.81, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.583456 Acc@1: 0.514701 (ε = 133.74, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.591244 Acc@1: 0.548414 
	Train Epoch: 17 	Loss: 1.600602 Acc@1: 0.512093 (ε = 134.70, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.561610 Acc@1: 0.523882 (ε = 136.62, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.569436 Acc@1: 0.525520 (ε = 138.55, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.620783 Acc@1: 0.517992 
	Train Epoch: 18 	Loss: 1.471804 Acc@1: 0.543786 (ε = 139.51, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.514300 Acc@1: 0.537934 (ε = 141.43, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.506207 Acc@1: 0.541667 (ε = 143.35, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.566119 Acc@1: 0.560762 
	Train Epoch: 19 	Loss: 1.403178 Acc@1: 0.574913 (ε = 144.32, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.502825 Acc@1: 0.561086 (ε = 146.24, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.497216 Acc@1: 0.561985 (ε = 148.16, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.557591 Acc@1: 0.583441 
	Train Epoch: 20 	Loss: 1.540875 Acc@1: 0.548940 (ε = 149.12, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.449333 Acc@1: 0.575832 (ε = 151.05, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.461393 Acc@1: 0.575432 (ε = 152.97, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.519687 Acc@1: 0.579591 
	Train Epoch: 21 	Loss: 1.481728 Acc@1: 0.575900 (ε = 153.93, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.434501 Acc@1: 0.583303 (ε = 155.86, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.445178 Acc@1: 0.577687 (ε = 157.78, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.616461 Acc@1: 0.562447 
	Train Epoch: 22 	Loss: 1.499688 Acc@1: 0.569992 (ε = 158.74, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.439871 Acc@1: 0.584948 (ε = 160.67, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.449760 Acc@1: 0.587936 (ε = 162.59, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.603003 Acc@1: 0.559600 
	Train Epoch: 23 	Loss: 1.485932 Acc@1: 0.572016 (ε = 163.55, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.429335 Acc@1: 0.589349 (ε = 165.47, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.443452 Acc@1: 0.587795 (ε = 167.40, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.620146 Acc@1: 0.574323 
	Train Epoch: 24 	Loss: 1.405176 Acc@1: 0.600655 (ε = 168.36, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.416727 Acc@1: 0.591032 (ε = 170.28, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.402068 Acc@1: 0.595366 (ε = 172.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.524416 Acc@1: 0.589081 
	Train Epoch: 25 	Loss: 1.395740 Acc@1: 0.589850 (ε = 173.17, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.414716 Acc@1: 0.589726 (ε = 175.09, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.403219 Acc@1: 0.594442 (ε = 177.02, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.497174 Acc@1: 0.596462 
	Train Epoch: 26 	Loss: 1.406682 Acc@1: 0.611535 (ε = 177.98, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.387219 Acc@1: 0.602363 (ε = 179.90, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.395165 Acc@1: 0.601344 (ε = 181.82, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.589412 Acc@1: 0.583180 
	Train Epoch: 27 	Loss: 1.396762 Acc@1: 0.600490 (ε = 182.79, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.398236 Acc@1: 0.601042 (ε = 184.71, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.388396 Acc@1: 0.604828 (ε = 186.63, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.552215 Acc@1: 0.588656 
	Train Epoch: 28 	Loss: 1.411466 Acc@1: 0.600492 (ε = 187.60, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.377330 Acc@1: 0.604478 (ε = 189.52, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.383980 Acc@1: 0.603338 (ε = 191.44, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.539323 Acc@1: 0.592062 
	Train Epoch: 29 	Loss: 1.325995 Acc@1: 0.628297 (ε = 192.40, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.364201 Acc@1: 0.620330 (ε = 194.33, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.385892 Acc@1: 0.610293 (ε = 196.25, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.552820 Acc@1: 0.589425 
	Train Epoch: 30 	Loss: 1.419217 Acc@1: 0.608624 (ε = 197.21, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.411775 Acc@1: 0.609895 (ε = 199.14, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.408644 Acc@1: 0.607146 (ε = 201.06, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.547505 Acc@1: 0.589731 
Base private model test accuracy:  0.5896541869105458
              precision    recall  f1-score   support

         0.0       0.28      0.56      0.38       508
         1.0       0.27      0.65      0.38       482
         2.0       0.24      0.46      0.32       510
         3.0       0.13      0.33      0.18       489
         4.0       0.19      0.42      0.26       466
         5.0       0.66      0.47      0.55      2972
         6.0       0.79      0.67      0.73      3080
         7.0       0.72      0.59      0.65      2961
         8.0       0.84      0.67      0.75      3024
         9.0       0.76      0.62      0.68      3003

    accuracy                           0.59     17495
   macro avg       0.49      0.54      0.49     17495
weighted avg       0.68      0.59      0.62     17495

Base private model train accuracy:  0.6082693947144076
              precision    recall  f1-score   support

         0.0       0.67      0.65      0.66      3081
         1.0       0.67      0.73      0.70      3070
         2.0       0.56      0.52      0.54      3041
         3.0       0.52      0.52      0.52      3017
         4.0       0.56      0.53      0.54      2957
         5.0       0.50      0.48      0.49      3010
         6.0       0.63      0.67      0.65      3139
         7.0       0.60      0.60      0.60      3003
         8.0       0.69      0.70      0.70      3120
         9.0       0.66      0.66      0.66      3060

    accuracy                           0.61     30498
   macro avg       0.61      0.61      0.61     30498
weighted avg       0.61      0.61      0.61     30498

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6951275493474982
test acc: 0.7968831168831169
min train acc: 0.8866294524189261
maj train acc: 0.5173725589652549
min test acc: 0.9674110620618022
maj test acc: 0.6266216917488323
total acc: 0.7462559953016412
total min acc: 0.9274924471299094
total maj acc: 0.5713736052327818
precision, recall: (0.7721445221445221, 0.6951275493474982)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 201.8292382774743, 0.5896541869105458, 0.6082693947144076, 0.7462559953016412, 0.9274924471299094, 0.5713736052327818, '              precision    recall  f1-score   support\n\n         0.0       0.28      0.56      0.38       508\n         1.0       0.27      0.65      0.38       482\n         2.0       0.24      0.46      0.32       510\n         3.0       0.13      0.33      0.18       489\n         4.0       0.19      0.42      0.26       466\n         5.0       0.66      0.47      0.55      2972\n         6.0       0.79      0.67      0.73      3080\n         7.0       0.72      0.59      0.65      2961\n         8.0       0.84      0.67      0.75      3024\n         9.0       0.76      0.62      0.68      3003\n\n    accuracy                           0.59     17495\n   macro avg       0.49      0.54      0.49     17495\nweighted avg       0.68      0.59      0.62     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.67      0.65      0.66      3081\n         1.0       0.67      0.73      0.70      3070\n         2.0       0.56      0.52      0.54      3041\n         3.0       0.52      0.52      0.52      3017\n         4.0       0.56      0.53      0.54      2957\n         5.0       0.50      0.48      0.49      3010\n         6.0       0.63      0.67      0.65      3139\n         7.0       0.60      0.60      0.60      3003\n         8.0       0.69      0.70      0.70      3120\n         9.0       0.66      0.66      0.66      3060\n\n    accuracy                           0.61     30498\n   macro avg       0.61      0.61      0.61     30498\nweighted avg       0.61      0.61      0.61     30498\n']
experiment_number: 28
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-28.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.3, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([521, 448, 508, 492, 514, 515, 473, 500, 504, 535])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (5010, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.677269 Acc@1: 0.085106 (ε = 15.92, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.415933 Acc@1: 0.109408 (ε = 31.59, δ = 1e-05) for α = 1.5
	Train Epoch: 1 	Loss: 2.390386 Acc@1: 0.120080 (ε = 38.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.324767 Acc@1: 0.037065 
	Train Epoch: 2 	Loss: 2.288364 Acc@1: 0.151659 (ε = 41.02, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 2.434654 Acc@1: 0.129776 (ε = 45.73, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 2.353026 Acc@1: 0.141756 (ε = 50.43, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.186256 Acc@1: 0.179352 
	Train Epoch: 3 	Loss: 2.373059 Acc@1: 0.114130 (ε = 52.79, δ = 1e-05) for α = 1.4
	Train Epoch: 3 	Loss: 2.436059 Acc@1: 0.140525 (ε = 56.32, δ = 1e-05) for α = 1.3
	Train Epoch: 3 	Loss: 2.393812 Acc@1: 0.155342 (ε = 59.26, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.212882 Acc@1: 0.166605 
	Train Epoch: 4 	Loss: 2.154227 Acc@1: 0.193833 (ε = 60.73, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.941698 Acc@1: 0.159373 (ε = 63.67, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.711675 Acc@1: 0.130369 (ε = 66.61, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.347576 Acc@1: 0.073467 
	Train Epoch: 5 	Loss: 2.302490 Acc@1: 0.115226 (ε = 68.08, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.293994 Acc@1: 0.135229 (ε = 71.02, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.315410 Acc@1: 0.131315 (ε = 73.96, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.412132 Acc@1: 0.160327 
	Train Epoch: 6 	Loss: 2.565251 Acc@1: 0.202073 (ε = 75.43, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.524163 Acc@1: 0.153548 (ε = 78.37, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.463721 Acc@1: 0.152909 (ε = 81.31, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.170916 Acc@1: 0.276379 
	Train Epoch: 7 	Loss: 2.264564 Acc@1: 0.182266 (ε = 82.78, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.290567 Acc@1: 0.175641 (ε = 85.73, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.283820 Acc@1: 0.180224 (ε = 88.67, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.601363 Acc@1: 0.254284 
	Train Epoch: 8 	Loss: 2.825869 Acc@1: 0.216080 (ε = 90.14, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.372307 Acc@1: 0.203454 (ε = 93.08, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.289025 Acc@1: 0.229899 (ε = 95.27, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.404076 Acc@1: 0.165190 
	Train Epoch: 9 	Loss: 2.301089 Acc@1: 0.198895 (ε = 96.23, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 2.507553 Acc@1: 0.191059 (ε = 98.15, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 2.427160 Acc@1: 0.198174 (ε = 100.07, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.238530 Acc@1: 0.157356 
	Train Epoch: 10 	Loss: 2.113062 Acc@1: 0.237569 (ε = 101.04, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 2.218853 Acc@1: 0.239776 (ε = 102.96, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 2.186579 Acc@1: 0.266266 (ε = 104.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.259811 Acc@1: 0.230190 
	Train Epoch: 11 	Loss: 2.297416 Acc@1: 0.285714 (ε = 105.85, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 2.143837 Acc@1: 0.274872 (ε = 107.77, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 2.127945 Acc@1: 0.281737 (ε = 109.69, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.310700 Acc@1: 0.321363 
	Train Epoch: 12 	Loss: 2.365268 Acc@1: 0.333333 (ε = 110.65, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 2.141074 Acc@1: 0.297762 (ε = 112.58, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 2.120563 Acc@1: 0.304322 (ε = 114.50, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.199694 Acc@1: 0.352850 
	Train Epoch: 13 	Loss: 2.329856 Acc@1: 0.336683 (ε = 115.46, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 2.160999 Acc@1: 0.302302 (ε = 117.39, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 2.079276 Acc@1: 0.313977 (ε = 119.31, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.294567 Acc@1: 0.269730 
	Train Epoch: 14 	Loss: 2.258364 Acc@1: 0.336898 (ε = 120.27, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 2.026286 Acc@1: 0.336098 (ε = 122.20, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 2.076689 Acc@1: 0.331840 (ε = 124.12, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.195682 Acc@1: 0.295246 
	Train Epoch: 15 	Loss: 1.879762 Acc@1: 0.385870 (ε = 125.08, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 2.118032 Acc@1: 0.319001 (ε = 127.00, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 2.099085 Acc@1: 0.324554 (ε = 128.93, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.984633 Acc@1: 0.353537 
	Train Epoch: 16 	Loss: 1.764402 Acc@1: 0.382488 (ε = 129.89, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.908740 Acc@1: 0.354613 (ε = 131.81, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.984908 Acc@1: 0.352593 (ε = 133.74, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.950545 Acc@1: 0.345244 
	Train Epoch: 17 	Loss: 1.922531 Acc@1: 0.325359 (ε = 134.70, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.959549 Acc@1: 0.348147 (ε = 136.62, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.979087 Acc@1: 0.341515 (ε = 138.55, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.015030 Acc@1: 0.355151 
	Train Epoch: 18 	Loss: 1.991891 Acc@1: 0.384615 (ε = 139.51, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 2.045070 Acc@1: 0.363538 (ε = 141.43, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.961838 Acc@1: 0.369793 (ε = 143.35, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.056286 Acc@1: 0.359717 
	Train Epoch: 19 	Loss: 1.933938 Acc@1: 0.387435 (ε = 144.32, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.939833 Acc@1: 0.410016 (ε = 146.24, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.951874 Acc@1: 0.402789 (ε = 148.16, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.627097 Acc@1: 0.313475 
	Train Epoch: 20 	Loss: 2.855143 Acc@1: 0.335052 (ε = 149.12, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.974282 Acc@1: 0.390743 (ε = 151.05, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.926919 Acc@1: 0.399900 (ε = 152.97, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.985193 Acc@1: 0.383973 
	Train Epoch: 21 	Loss: 1.792721 Acc@1: 0.374408 (ε = 153.93, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.873014 Acc@1: 0.388478 (ε = 155.86, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.851184 Acc@1: 0.401461 (ε = 157.78, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.065742 Acc@1: 0.371528 
	Train Epoch: 22 	Loss: 1.881742 Acc@1: 0.391705 (ε = 158.74, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.865996 Acc@1: 0.421475 (ε = 160.67, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.850822 Acc@1: 0.422344 (ε = 162.59, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.131434 Acc@1: 0.369308 
	Train Epoch: 23 	Loss: 1.929266 Acc@1: 0.398876 (ε = 163.55, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.790889 Acc@1: 0.439464 (ε = 165.47, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.772944 Acc@1: 0.445296 (ε = 167.40, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.062394 Acc@1: 0.374856 
	Train Epoch: 24 	Loss: 1.959218 Acc@1: 0.425414 (ε = 168.36, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.916960 Acc@1: 0.428156 (ε = 170.28, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.879973 Acc@1: 0.431913 (ε = 172.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.149278 Acc@1: 0.371766 
	Train Epoch: 25 	Loss: 1.768565 Acc@1: 0.443850 (ε = 173.17, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.785414 Acc@1: 0.437254 (ε = 175.09, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.811987 Acc@1: 0.428365 (ε = 177.02, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.015731 Acc@1: 0.376411 
	Train Epoch: 26 	Loss: 1.766838 Acc@1: 0.415094 (ε = 177.98, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.712556 Acc@1: 0.453363 (ε = 179.90, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.717102 Acc@1: 0.450767 (ε = 181.82, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.019934 Acc@1: 0.391323 
	Train Epoch: 27 	Loss: 1.615992 Acc@1: 0.491620 (ε = 182.79, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.738494 Acc@1: 0.444817 (ε = 184.71, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.721238 Acc@1: 0.452821 (ε = 186.63, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.087033 Acc@1: 0.386348 
	Train Epoch: 28 	Loss: 1.600455 Acc@1: 0.482759 (ε = 187.60, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.729117 Acc@1: 0.460015 (ε = 189.52, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.735686 Acc@1: 0.456696 (ε = 191.44, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.027430 Acc@1: 0.383271 
	Train Epoch: 29 	Loss: 1.506250 Acc@1: 0.528205 (ε = 192.40, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.694762 Acc@1: 0.464370 (ε = 194.33, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.698496 Acc@1: 0.467954 (ε = 196.25, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.028565 Acc@1: 0.388237 
	Train Epoch: 30 	Loss: 1.524047 Acc@1: 0.473958 (ε = 197.21, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.665755 Acc@1: 0.458691 (ε = 199.14, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.645130 Acc@1: 0.467767 (ε = 201.06, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.023267 Acc@1: 0.388879 
Base private model test accuracy:  0.3890825950271506
              precision    recall  f1-score   support

         0.0       0.16      0.41      0.23       508
         1.0       0.14      0.46      0.21       482
         2.0       0.12      0.26      0.16       510
         3.0       0.07      0.18      0.10       489
         4.0       0.10      0.34      0.16       466
         5.0       0.43      0.26      0.32      2972
         6.0       0.51      0.41      0.45      3080
         7.0       0.55      0.37      0.44      2961
         8.0       0.72      0.52      0.61      3024
         9.0       0.59      0.43      0.50      3003

    accuracy                           0.39     17495
   macro avg       0.34      0.36      0.32     17495
weighted avg       0.50      0.39      0.42     17495

Base private model train accuracy:  0.4668662674650699
              precision    recall  f1-score   support

         0.0       0.55      0.52      0.54       521
         1.0       0.49      0.52      0.50       448
         2.0       0.40      0.33      0.36       508
         3.0       0.36      0.29      0.32       492
         4.0       0.42      0.45      0.43       514
         5.0       0.43      0.40      0.42       515
         6.0       0.40      0.57      0.47       473
         7.0       0.48      0.45      0.46       500
         8.0       0.60      0.62      0.60       504
         9.0       0.53      0.54      0.54       535

    accuracy                           0.47      5010
   macro avg       0.47      0.47      0.46      5010
weighted avg       0.47      0.47      0.46      5010

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7217564870259481
test acc: 0.4394849785407725
min train acc: 0.7197664720600501
maj train acc: 0.7326906222611744
min test acc: 0.4418011894647409
maj test acc: 0.4385210662080825
total acc: 0.5857290589451913
total min acc: 0.5820707070707071
total maj acc: 0.5842013888888888
precision, recall: (0.5806037251123957, 0.7217564870259481)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 201.8292382774743, 0.3890825950271506, 0.4668662674650699, 0.5857290589451913, 0.5820707070707071, 0.5842013888888888, '              precision    recall  f1-score   support\n\n         0.0       0.16      0.41      0.23       508\n         1.0       0.14      0.46      0.21       482\n         2.0       0.12      0.26      0.16       510\n         3.0       0.07      0.18      0.10       489\n         4.0       0.10      0.34      0.16       466\n         5.0       0.43      0.26      0.32      2972\n         6.0       0.51      0.41      0.45      3080\n         7.0       0.55      0.37      0.44      2961\n         8.0       0.72      0.52      0.61      3024\n         9.0       0.59      0.43      0.50      3003\n\n    accuracy                           0.39     17495\n   macro avg       0.34      0.36      0.32     17495\nweighted avg       0.50      0.39      0.42     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.55      0.52      0.54       521\n         1.0       0.49      0.52      0.50       448\n         2.0       0.40      0.33      0.36       508\n         3.0       0.36      0.29      0.32       492\n         4.0       0.42      0.45      0.43       514\n         5.0       0.43      0.40      0.42       515\n         6.0       0.40      0.57      0.47       473\n         7.0       0.48      0.45      0.46       500\n         8.0       0.60      0.62      0.60       504\n         9.0       0.53      0.54      0.54       535\n\n    accuracy                           0.47      5010\n   macro avg       0.47      0.47      0.46      5010\nweighted avg       0.47      0.47      0.46      5010\n']
experiment_number: 21
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-21.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.3, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3077, 3065, 3176, 2977, 3024, 3020, 2979, 3042, 3023, 2948])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30331, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.574471 Acc@1: 0.105505 (ε = 15.92, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.609780 Acc@1: 0.110229 (ε = 31.59, δ = 1e-05) for α = 1.5
	Train Epoch: 1 	Loss: 2.571330 Acc@1: 0.112200 (ε = 38.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.378170 Acc@1: 0.169355 
	Train Epoch: 2 	Loss: 2.360651 Acc@1: 0.094215 (ε = 41.02, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 4.053852 Acc@1: 0.143061 (ε = 45.73, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 3.407727 Acc@1: 0.142632 (ε = 50.43, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.190761 Acc@1: 0.199513 
	Train Epoch: 3 	Loss: 2.185118 Acc@1: 0.138956 (ε = 52.79, δ = 1e-05) for α = 1.4
	Train Epoch: 3 	Loss: 2.561706 Acc@1: 0.135109 (ε = 56.32, δ = 1e-05) for α = 1.3
	Train Epoch: 3 	Loss: 2.538232 Acc@1: 0.125187 (ε = 59.26, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.326410 Acc@1: 0.210266 
	Train Epoch: 4 	Loss: 2.242638 Acc@1: 0.229133 (ε = 60.73, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.208243 Acc@1: 0.193860 (ε = 63.67, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 2.182935 Acc@1: 0.195317 (ε = 66.61, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.122287 Acc@1: 0.205897 
	Train Epoch: 5 	Loss: 2.231160 Acc@1: 0.161367 (ε = 68.08, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.312575 Acc@1: 0.161017 (ε = 71.02, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 2.238687 Acc@1: 0.179466 (ε = 73.96, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.110175 Acc@1: 0.258037 
	Train Epoch: 6 	Loss: 2.136705 Acc@1: 0.222492 (ε = 75.43, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.115235 Acc@1: 0.217838 (ε = 78.37, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 2.099943 Acc@1: 0.224144 (ε = 81.31, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.943258 Acc@1: 0.313438 
	Train Epoch: 7 	Loss: 2.028775 Acc@1: 0.300412 (ε = 82.78, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.049132 Acc@1: 0.271586 (ε = 85.73, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 2.145769 Acc@1: 0.257287 (ε = 88.67, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.280585 Acc@1: 0.209910 
	Train Epoch: 8 	Loss: 2.466069 Acc@1: 0.220049 (ε = 90.14, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.095280 Acc@1: 0.241240 (ε = 93.08, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 2.033026 Acc@1: 0.266150 (ε = 95.27, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.887057 Acc@1: 0.345231 
	Train Epoch: 9 	Loss: 1.921281 Acc@1: 0.320787 (ε = 96.23, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.972307 Acc@1: 0.301446 (ε = 98.15, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.971421 Acc@1: 0.310424 (ε = 100.07, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.881099 Acc@1: 0.363450 
	Train Epoch: 10 	Loss: 1.966977 Acc@1: 0.315409 (ε = 101.04, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.868861 Acc@1: 0.349597 (ε = 102.96, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.932296 Acc@1: 0.347822 (ε = 104.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.737432 Acc@1: 0.421402 
	Train Epoch: 11 	Loss: 1.802124 Acc@1: 0.376186 (ε = 105.85, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.787104 Acc@1: 0.378885 (ε = 107.77, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.801837 Acc@1: 0.384625 (ε = 109.69, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.915841 Acc@1: 0.392216 
	Train Epoch: 12 	Loss: 1.873181 Acc@1: 0.387238 (ε = 110.65, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.934599 Acc@1: 0.384493 (ε = 112.58, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.914539 Acc@1: 0.373580 (ε = 114.50, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.715492 Acc@1: 0.442116 
	Train Epoch: 13 	Loss: 1.758723 Acc@1: 0.383550 (ε = 115.46, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.724804 Acc@1: 0.407611 (ε = 117.39, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.753890 Acc@1: 0.417240 (ε = 119.31, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.694160 Acc@1: 0.473712 
	Train Epoch: 14 	Loss: 1.821554 Acc@1: 0.426160 (ε = 120.27, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.794980 Acc@1: 0.426587 (ε = 122.20, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.840512 Acc@1: 0.411519 (ε = 124.12, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.663157 Acc@1: 0.478414 
	Train Epoch: 15 	Loss: 1.674018 Acc@1: 0.415447 (ε = 125.08, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.696918 Acc@1: 0.438226 (ε = 127.00, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.720813 Acc@1: 0.449564 (ε = 128.93, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.599049 Acc@1: 0.510100 
	Train Epoch: 16 	Loss: 1.783240 Acc@1: 0.436829 (ε = 129.89, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.683923 Acc@1: 0.456190 (ε = 131.81, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.713668 Acc@1: 0.454837 (ε = 133.74, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.632887 Acc@1: 0.490736 
	Train Epoch: 17 	Loss: 1.595302 Acc@1: 0.498753 (ε = 134.70, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.637830 Acc@1: 0.475648 (ε = 136.62, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.658823 Acc@1: 0.473818 (ε = 138.55, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.645046 Acc@1: 0.496467 
	Train Epoch: 18 	Loss: 1.720128 Acc@1: 0.485569 (ε = 139.51, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.671410 Acc@1: 0.484977 (ε = 141.43, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.674061 Acc@1: 0.484579 (ε = 143.35, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.728420 Acc@1: 0.507546 
	Train Epoch: 19 	Loss: 1.708045 Acc@1: 0.490295 (ε = 144.32, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.677241 Acc@1: 0.490441 (ε = 146.24, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.677620 Acc@1: 0.492937 (ε = 148.16, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.690712 Acc@1: 0.504433 
	Train Epoch: 20 	Loss: 1.765838 Acc@1: 0.488124 (ε = 149.12, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.675823 Acc@1: 0.500428 (ε = 151.05, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.669573 Acc@1: 0.500532 (ε = 152.97, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.555033 Acc@1: 0.549983 
	Train Epoch: 21 	Loss: 1.795234 Acc@1: 0.488019 (ε = 153.93, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.631421 Acc@1: 0.505067 (ε = 155.86, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.629716 Acc@1: 0.509661 (ε = 157.78, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.620925 Acc@1: 0.553975 
	Train Epoch: 22 	Loss: 1.616326 Acc@1: 0.529218 (ε = 158.74, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.632341 Acc@1: 0.515267 (ε = 160.67, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 1.625530 Acc@1: 0.517511 (ε = 162.59, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.549291 Acc@1: 0.555554 
	Train Epoch: 23 	Loss: 1.513613 Acc@1: 0.539787 (ε = 163.55, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.597023 Acc@1: 0.527202 (ε = 165.47, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 1.612969 Acc@1: 0.531179 (ε = 167.40, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.511113 Acc@1: 0.578918 
	Train Epoch: 24 	Loss: 1.648609 Acc@1: 0.517551 (ε = 168.36, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.596119 Acc@1: 0.540001 (ε = 170.28, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 1.599678 Acc@1: 0.533230 (ε = 172.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.554180 Acc@1: 0.563639 
	Train Epoch: 25 	Loss: 1.509650 Acc@1: 0.540865 (ε = 173.17, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.584942 Acc@1: 0.540210 (ε = 175.09, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 1.596134 Acc@1: 0.539685 (ε = 177.02, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.528777 Acc@1: 0.583894 
	Train Epoch: 26 	Loss: 1.583617 Acc@1: 0.525342 (ε = 177.98, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.614507 Acc@1: 0.537924 (ε = 179.90, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 1.602333 Acc@1: 0.541659 (ε = 181.82, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.566232 Acc@1: 0.564466 
	Train Epoch: 27 	Loss: 1.547888 Acc@1: 0.555734 (ε = 182.79, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.555655 Acc@1: 0.546515 (ε = 184.71, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 1.570618 Acc@1: 0.548191 (ε = 186.63, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.517522 Acc@1: 0.579224 
	Train Epoch: 28 	Loss: 1.616280 Acc@1: 0.549542 (ε = 187.60, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.569064 Acc@1: 0.549690 (ε = 189.52, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 1.581356 Acc@1: 0.548091 (ε = 191.44, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.535529 Acc@1: 0.573713 
	Train Epoch: 29 	Loss: 1.635324 Acc@1: 0.520066 (ε = 192.40, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.633927 Acc@1: 0.542735 (ε = 194.33, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 1.603811 Acc@1: 0.544607 (ε = 196.25, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.523795 Acc@1: 0.579774 
	Train Epoch: 30 	Loss: 1.596479 Acc@1: 0.542105 (ε = 197.21, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.556355 Acc@1: 0.553226 (ε = 199.14, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 1.577726 Acc@1: 0.551545 (ε = 201.06, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.530965 Acc@1: 0.577676 
Base private model test accuracy:  0.5775935981709059
              precision    recall  f1-score   support

         0.0       0.27      0.29      0.28       508
         1.0       0.25      0.18      0.21       482
         2.0       0.16      0.15      0.16       510
         3.0       0.06      0.03      0.04       489
         4.0       0.19      0.20      0.20       466
         5.0       0.56      0.62      0.59      2972
         6.0       0.70      0.67      0.69      3080
         7.0       0.56      0.57      0.56      2961
         8.0       0.70      0.73      0.72      3024
         9.0       0.65      0.62      0.64      3003

    accuracy                           0.58     17495
   macro avg       0.41      0.41      0.41     17495
weighted avg       0.57      0.58      0.57     17495

Base private model train accuracy:  0.5474596947017902
              precision    recall  f1-score   support

         0.0       0.62      0.54      0.57      3077
         1.0       0.61      0.60      0.61      3065
         2.0       0.43      0.33      0.37      3176
         3.0       0.44      0.36      0.40      2977
         4.0       0.48      0.39      0.43      3024
         5.0       0.51      0.64      0.57      3020
         6.0       0.56      0.67      0.61      2979
         7.0       0.52      0.57      0.54      3042
         8.0       0.64      0.74      0.69      3023
         9.0       0.60      0.65      0.63      2948

    accuracy                           0.55     30331
   macro avg       0.54      0.55      0.54     30331
weighted avg       0.54      0.55      0.54     30331

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.571513353115727
test acc: 0.5601298701298701
min train acc: 0.5944055944055944
maj train acc: 0.5540799387051463
min test acc: 0.5723975997912862
maj test acc: 0.5477789256198347
total acc: 0.5657778504825781
total min acc: 0.5833387996064283
total maj acc: 0.5509470304975923
precision, recall: (0.5612978434039246, 0.571513353115727)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 201.8292382774743, 0.5775935981709059, 0.5474596947017902, 0.5657778504825781, 0.5833387996064283, 0.5509470304975923, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.29      0.28       508\n         1.0       0.25      0.18      0.21       482\n         2.0       0.16      0.15      0.16       510\n         3.0       0.06      0.03      0.04       489\n         4.0       0.19      0.20      0.20       466\n         5.0       0.56      0.62      0.59      2972\n         6.0       0.70      0.67      0.69      3080\n         7.0       0.56      0.57      0.56      2961\n         8.0       0.70      0.73      0.72      3024\n         9.0       0.65      0.62      0.64      3003\n\n    accuracy                           0.58     17495\n   macro avg       0.41      0.41      0.41     17495\nweighted avg       0.57      0.58      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.62      0.54      0.57      3077\n         1.0       0.61      0.60      0.61      3065\n         2.0       0.43      0.33      0.37      3176\n         3.0       0.44      0.36      0.40      2977\n         4.0       0.48      0.39      0.43      3024\n         5.0       0.51      0.64      0.57      3020\n         6.0       0.56      0.67      0.61      2979\n         7.0       0.52      0.57      0.54      3042\n         8.0       0.64      0.74      0.69      3023\n         9.0       0.60      0.65      0.63      2948\n\n    accuracy                           0.55     30331\n   macro avg       0.54      0.55      0.54     30331\nweighted avg       0.54      0.55      0.54     30331\n']
experiment_number: 17
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-17.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.2, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3069, 2922, 2975, 3013, 2944, 3039, 3015, 3082, 3043, 2985])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30087, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.905222 Acc@1: 0.105949 (ε = 29.65, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.720737 Acc@1: 0.108820 (ε = 75.10, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.550237 Acc@1: 0.107149 (ε = 91.04, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.269440 Acc@1: 0.233851 
	Train Epoch: 2 	Loss: 2.306780 Acc@1: 0.135357 (ε = 99.01, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.301966 Acc@1: 0.113254 (ε = 114.94, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.573340 Acc@1: 0.110941 (ε = 130.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.308356 Acc@1: 0.037011 
	Train Epoch: 3 	Loss: 2.303132 Acc@1: 0.091954 (ε = 138.85, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 3.792095 Acc@1: 0.097903 (ε = 154.79, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 3.083519 Acc@1: 0.099914 (ε = 164.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.293164 Acc@1: 0.172945 
	Train Epoch: 4 	Loss: 2.303143 Acc@1: 0.104724 (ε = 167.50, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.301727 Acc@1: 0.106333 (ε = 174.39, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.309268 Acc@1: 0.105878 (ε = 181.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.316874 Acc@1: 0.029772 
	Train Epoch: 5 	Loss: 2.303216 Acc@1: 0.103030 (ε = 184.73, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.303599 Acc@1: 0.098123 (ε = 191.62, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.303156 Acc@1: 0.097459 (ε = 198.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.294049 Acc@1: 0.176125 
	Train Epoch: 6 	Loss: 2.301163 Acc@1: 0.115171 (ε = 201.96, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.302140 Acc@1: 0.111329 (ε = 208.85, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.302128 Acc@1: 0.107584 (ε = 215.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.296084 Acc@1: 0.174274 
	Train Epoch: 7 	Loss: 2.302240 Acc@1: 0.105611 (ε = 219.18, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.302169 Acc@1: 0.098573 (ε = 226.07, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.328369 Acc@1: 0.100348 (ε = 232.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.303064 Acc@1: 0.028979 
	Train Epoch: 8 	Loss: 2.302156 Acc@1: 0.100415 (ε = 236.41, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.302338 Acc@1: 0.105115 (ε = 243.30, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.300574 Acc@1: 0.105604 (ε = 250.19, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.286503 Acc@1: 0.228652 
	Train Epoch: 9 	Loss: 2.296777 Acc@1: 0.144000 (ε = 253.64, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.303083 Acc@1: 0.105556 (ε = 260.53, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.303339 Acc@1: 0.102004 (ε = 267.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.308546 Acc@1: 0.028702 
	Train Epoch: 10 	Loss: 2.302896 Acc@1: 0.100083 (ε = 270.87, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.302623 Acc@1: 0.103083 (ε = 277.76, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.302689 Acc@1: 0.101636 (ε = 284.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.295135 Acc@1: 0.170288 
	Train Epoch: 11 	Loss: 2.302630 Acc@1: 0.099099 (ε = 288.09, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.302440 Acc@1: 0.101631 (ε = 294.98, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.302236 Acc@1: 0.098448 (ε = 301.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.301606 Acc@1: 0.040791 
	Train Epoch: 12 	Loss: 2.299643 Acc@1: 0.126972 (ε = 305.32, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.298092 Acc@1: 0.130496 (ε = 312.21, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.350470 Acc@1: 0.125010 (ε = 319.10, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.305245 Acc@1: 0.037527 
	Train Epoch: 13 	Loss: 2.299412 Acc@1: 0.116489 (ε = 322.55, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 2.296295 Acc@1: 0.126948 (ε = 329.44, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 2.311859 Acc@1: 0.127559 (ε = 336.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.291185 Acc@1: 0.157950 
	Train Epoch: 14 	Loss: 2.288196 Acc@1: 0.125932 (ε = 339.78, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 2.329949 Acc@1: 0.114551 (ε = 346.67, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 2.336201 Acc@1: 0.108689 (ε = 353.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.507809 Acc@1: 0.170544 
	Train Epoch: 15 	Loss: 2.725981 Acc@1: 0.104603 (ε = 357.00, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 2.337251 Acc@1: 0.109084 (ε = 363.90, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 2.316731 Acc@1: 0.117149 (ε = 370.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.173160 Acc@1: 0.230467 
	Train Epoch: 16 	Loss: 2.379149 Acc@1: 0.151771 (ε = 374.23, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 2.422401 Acc@1: 0.140207 (ε = 381.12, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 2.345878 Acc@1: 0.145488 (ε = 388.01, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.250019 Acc@1: 0.262953 
	Train Epoch: 17 	Loss: 2.273838 Acc@1: 0.173045 (ε = 391.46, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 2.229763 Acc@1: 0.201886 (ε = 398.35, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 2.201670 Acc@1: 0.217544 (ε = 405.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.133278 Acc@1: 0.270812 
	Train Epoch: 18 	Loss: 2.108910 Acc@1: 0.244389 (ε = 408.69, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 2.113397 Acc@1: 0.253339 (ε = 415.58, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 2.085496 Acc@1: 0.261038 (ε = 422.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.248662 Acc@1: 0.284166 
	Train Epoch: 19 	Loss: 2.296300 Acc@1: 0.237649 (ε = 425.91, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 2.038379 Acc@1: 0.281849 (ε = 432.81, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 2.022350 Acc@1: 0.292116 (ε = 439.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.017457 Acc@1: 0.324977 
	Train Epoch: 20 	Loss: 2.007113 Acc@1: 0.316627 (ε = 443.14, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.968819 Acc@1: 0.311912 (ε = 450.03, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.970665 Acc@1: 0.314562 (ε = 456.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.009971 Acc@1: 0.335947 
	Train Epoch: 21 	Loss: 1.960713 Acc@1: 0.317772 (ε = 460.37, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.931057 Acc@1: 0.330460 (ε = 467.26, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.934148 Acc@1: 0.330391 (ε = 474.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.928008 Acc@1: 0.362964 
	Train Epoch: 22 	Loss: 2.001667 Acc@1: 0.337531 (ε = 477.60, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.939425 Acc@1: 0.331455 (ε = 484.49, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.917003 Acc@1: 0.334610 (ε = 491.38, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.885987 Acc@1: 0.373980 
	Train Epoch: 23 	Loss: 1.908311 Acc@1: 0.347792 (ε = 494.82, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.928841 Acc@1: 0.349456 (ε = 501.72, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.906219 Acc@1: 0.350301 (ε = 508.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.831413 Acc@1: 0.389832 
	Train Epoch: 24 	Loss: 1.838583 Acc@1: 0.360376 (ε = 512.05, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.881199 Acc@1: 0.356431 (ε = 518.94, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.865471 Acc@1: 0.362789 (ε = 525.83, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.772091 Acc@1: 0.412457 
	Train Epoch: 25 	Loss: 1.878798 Acc@1: 0.391304 (ε = 529.28, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.860529 Acc@1: 0.376330 (ε = 536.17, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.858805 Acc@1: 0.374530 (ε = 543.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.958229 Acc@1: 0.350019 
	Train Epoch: 26 	Loss: 1.891710 Acc@1: 0.374590 (ε = 546.51, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.830446 Acc@1: 0.376133 (ε = 553.40, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.827248 Acc@1: 0.377730 (ε = 560.29, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.862970 Acc@1: 0.378636 
	Train Epoch: 27 	Loss: 1.801058 Acc@1: 0.396197 (ε = 563.73, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.821133 Acc@1: 0.388340 (ε = 570.63, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.821488 Acc@1: 0.385045 (ε = 577.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.884838 Acc@1: 0.368242 
	Train Epoch: 28 	Loss: 1.792532 Acc@1: 0.389073 (ε = 580.96, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.828479 Acc@1: 0.382004 (ε = 587.85, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.827911 Acc@1: 0.382629 (ε = 594.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.816287 Acc@1: 0.399906 
	Train Epoch: 29 	Loss: 1.722550 Acc@1: 0.406738 (ε = 598.19, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.834692 Acc@1: 0.380102 (ε = 605.08, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.824389 Acc@1: 0.383996 (ε = 611.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.815036 Acc@1: 0.404161 
	Train Epoch: 30 	Loss: 1.756852 Acc@1: 0.405560 (ε = 615.42, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.841533 Acc@1: 0.379849 (ε = 622.31, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.820899 Acc@1: 0.384333 (ε = 629.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.809904 Acc@1: 0.403538 
Base private model test accuracy:  0.4037725064304087
              precision    recall  f1-score   support

         0.0       0.15      0.42      0.22       508
         1.0       0.13      0.42      0.20       482
         2.0       0.11      0.20      0.14       510
         3.0       0.06      0.11      0.08       489
         4.0       0.10      0.35      0.16       466
         5.0       0.52      0.37      0.43      2972
         6.0       0.62      0.45      0.52      3080
         7.0       0.52      0.40      0.46      2961
         8.0       0.68      0.46      0.55      3024
         9.0       0.53      0.41      0.46      3003

    accuracy                           0.40     17495
   macro avg       0.34      0.36      0.32     17495
weighted avg       0.51      0.40      0.44     17495

Base private model train accuracy:  0.3842523348954698
              precision    recall  f1-score   support

         0.0       0.45      0.47      0.46      3069
         1.0       0.42      0.49      0.45      2922
         2.0       0.34      0.24      0.28      2975
         3.0       0.28      0.16      0.20      3013
         4.0       0.33      0.37      0.35      2944
         5.0       0.33      0.39      0.36      3039
         6.0       0.39      0.44      0.41      3015
         7.0       0.42      0.42      0.42      3082
         8.0       0.46      0.46      0.46      3043
         9.0       0.37      0.41      0.39      2985

    accuracy                           0.38     30087
   macro avg       0.38      0.38      0.38     30087
weighted avg       0.38      0.38      0.38     30087

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6771255733563784
test acc: 0.7684415584415585
min train acc: 0.8597667247620324
maj train acc: 0.5113822160734499
min test acc: 0.9113891060724524
maj test acc: 0.6265511892450879
total acc: 0.7233189895870972
total min acc: 0.8859446243309324
total maj acc: 0.5681774717919297
precision, recall: (0.7406922629435718, 0.6771255733563784)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 631.9557259647397, 0.4037725064304087, 0.3842523348954698, 0.7233189895870972, 0.8859446243309324, 0.5681774717919297, '              precision    recall  f1-score   support\n\n         0.0       0.15      0.42      0.22       508\n         1.0       0.13      0.42      0.20       482\n         2.0       0.11      0.20      0.14       510\n         3.0       0.06      0.11      0.08       489\n         4.0       0.10      0.35      0.16       466\n         5.0       0.52      0.37      0.43      2972\n         6.0       0.62      0.45      0.52      3080\n         7.0       0.52      0.40      0.46      2961\n         8.0       0.68      0.46      0.55      3024\n         9.0       0.53      0.41      0.46      3003\n\n    accuracy                           0.40     17495\n   macro avg       0.34      0.36      0.32     17495\nweighted avg       0.51      0.40      0.44     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.45      0.47      0.46      3069\n         1.0       0.42      0.49      0.45      2922\n         2.0       0.34      0.24      0.28      2975\n         3.0       0.28      0.16      0.20      3013\n         4.0       0.33      0.37      0.35      2944\n         5.0       0.33      0.39      0.36      3039\n         6.0       0.39      0.44      0.41      3015\n         7.0       0.42      0.42      0.42      3082\n         8.0       0.46      0.46      0.46      3043\n         9.0       0.37      0.41      0.39      2985\n\n    accuracy                           0.38     30087\n   macro avg       0.38      0.38      0.38     30087\nweighted avg       0.38      0.38      0.38     30087\n']
experiment_number: 29
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-29.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.2, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([505, 467, 522, 510, 465, 505, 476, 485, 521, 524])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4980, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.787255 Acc@1: 0.107477 (ε = 29.65, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.466448 Acc@1: 0.105264 (ε = 75.10, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.463851 Acc@1: 0.110071 (ε = 91.04, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.351464 Acc@1: 0.030668 
	Train Epoch: 2 	Loss: 2.341714 Acc@1: 0.110048 (ε = 99.01, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.327534 Acc@1: 0.134669 (ε = 114.94, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.332711 Acc@1: 0.129889 (ε = 130.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.317912 Acc@1: 0.049803 
	Train Epoch: 3 	Loss: 2.286034 Acc@1: 0.111650 (ε = 138.85, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 2.366384 Acc@1: 0.136031 (ε = 154.79, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 2.385992 Acc@1: 0.148392 (ε = 164.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.340650 Acc@1: 0.059603 
	Train Epoch: 4 	Loss: 2.300320 Acc@1: 0.119565 (ε = 167.50, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.325366 Acc@1: 0.133314 (ε = 174.39, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.321264 Acc@1: 0.134628 (ε = 181.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.268499 Acc@1: 0.230187 
	Train Epoch: 5 	Loss: 2.236313 Acc@1: 0.145729 (ε = 184.73, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.363386 Acc@1: 0.162278 (ε = 191.62, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.321766 Acc@1: 0.162940 (ε = 198.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.363016 Acc@1: 0.190435 
	Train Epoch: 6 	Loss: 2.270517 Acc@1: 0.184211 (ε = 201.96, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.323035 Acc@1: 0.182163 (ε = 208.85, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.287765 Acc@1: 0.196594 (ε = 215.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.207087 Acc@1: 0.250011 
	Train Epoch: 7 	Loss: 2.334188 Acc@1: 0.224880 (ε = 219.18, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.170983 Acc@1: 0.234310 (ε = 226.07, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.173711 Acc@1: 0.246831 (ε = 232.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.143551 Acc@1: 0.290480 
	Train Epoch: 8 	Loss: 2.204098 Acc@1: 0.251337 (ε = 236.41, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.116170 Acc@1: 0.259134 (ε = 243.30, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.077692 Acc@1: 0.261393 (ε = 250.19, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.290895 Acc@1: 0.197625 
	Train Epoch: 9 	Loss: 2.022100 Acc@1: 0.369668 (ε = 253.64, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.074945 Acc@1: 0.304862 (ε = 260.53, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.035834 Acc@1: 0.318509 (ε = 267.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.471598 Acc@1: 0.225739 
	Train Epoch: 10 	Loss: 2.158496 Acc@1: 0.258216 (ε = 270.87, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.988562 Acc@1: 0.325145 (ε = 277.76, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.993808 Acc@1: 0.345791 (ε = 284.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.404441 Acc@1: 0.210696 
	Train Epoch: 11 	Loss: 2.044573 Acc@1: 0.364078 (ε = 288.09, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.891955 Acc@1: 0.370577 (ε = 294.98, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.889657 Acc@1: 0.382099 (ε = 301.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.901870 Acc@1: 0.417019 
	Train Epoch: 12 	Loss: 2.292238 Acc@1: 0.344086 (ε = 305.32, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.907804 Acc@1: 0.371700 (ε = 312.21, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.909849 Acc@1: 0.379494 (ε = 319.10, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.205812 Acc@1: 0.334062 
	Train Epoch: 13 	Loss: 1.983237 Acc@1: 0.336898 (ε = 322.55, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.917566 Acc@1: 0.365556 (ε = 329.44, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.900990 Acc@1: 0.377797 (ε = 336.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.975548 Acc@1: 0.377267 
	Train Epoch: 14 	Loss: 1.737418 Acc@1: 0.433180 (ε = 339.78, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.847641 Acc@1: 0.419730 (ε = 346.67, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.783081 Acc@1: 0.440525 (ε = 353.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.854021 Acc@1: 0.426853 
	Train Epoch: 15 	Loss: 1.711347 Acc@1: 0.457286 (ε = 357.00, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.725266 Acc@1: 0.456435 (ε = 363.90, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.747283 Acc@1: 0.453728 (ε = 370.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.884043 Acc@1: 0.456511 
	Train Epoch: 16 	Loss: 1.513881 Acc@1: 0.481132 (ε = 374.23, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.643304 Acc@1: 0.476439 (ε = 381.12, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.687487 Acc@1: 0.483478 (ε = 388.01, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.011940 Acc@1: 0.458599 
	Train Epoch: 17 	Loss: 1.988663 Acc@1: 0.464646 (ε = 391.46, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.670274 Acc@1: 0.477832 (ε = 398.35, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.623565 Acc@1: 0.493187 (ε = 405.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.108589 Acc@1: 0.404627 
	Train Epoch: 18 	Loss: 1.541332 Acc@1: 0.515306 (ε = 408.69, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.648480 Acc@1: 0.501750 (ε = 415.58, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.603850 Acc@1: 0.509083 (ε = 422.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.321085 Acc@1: 0.347999 
	Train Epoch: 19 	Loss: 1.715422 Acc@1: 0.487805 (ε = 425.91, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.545211 Acc@1: 0.522206 (ε = 432.81, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.578989 Acc@1: 0.527883 (ε = 439.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.820546 Acc@1: 0.499194 
	Train Epoch: 20 	Loss: 1.516653 Acc@1: 0.516667 (ε = 443.14, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.508338 Acc@1: 0.539795 (ε = 450.03, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.529419 Acc@1: 0.534828 (ε = 456.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.077863 Acc@1: 0.454760 
	Train Epoch: 21 	Loss: 1.725600 Acc@1: 0.506849 (ε = 460.37, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.540335 Acc@1: 0.543362 (ε = 467.26, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.536547 Acc@1: 0.540680 (ε = 474.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.831764 Acc@1: 0.493557 
	Train Epoch: 22 	Loss: 1.311499 Acc@1: 0.527638 (ε = 477.60, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.457331 Acc@1: 0.561874 (ε = 484.49, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.434811 Acc@1: 0.567903 (ε = 491.38, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.086752 Acc@1: 0.441579 
	Train Epoch: 23 	Loss: 1.407964 Acc@1: 0.592920 (ε = 494.82, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.373619 Acc@1: 0.581324 (ε = 501.72, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.385492 Acc@1: 0.588431 (ε = 508.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.177663 Acc@1: 0.458433 
	Train Epoch: 24 	Loss: 1.722317 Acc@1: 0.539683 (ε = 512.05, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.430974 Acc@1: 0.585864 (ε = 518.94, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.378518 Acc@1: 0.594022 (ε = 525.83, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.021814 Acc@1: 0.480269 
	Train Epoch: 25 	Loss: 1.293688 Acc@1: 0.603960 (ε = 529.28, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.341753 Acc@1: 0.619390 (ε = 536.17, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.340897 Acc@1: 0.604704 (ε = 543.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.107715 Acc@1: 0.473372 
	Train Epoch: 26 	Loss: 1.289783 Acc@1: 0.592760 (ε = 546.51, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.398795 Acc@1: 0.594347 (ε = 553.40, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.372868 Acc@1: 0.597088 (ε = 560.29, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.028617 Acc@1: 0.488191 
	Train Epoch: 27 	Loss: 1.551383 Acc@1: 0.610000 (ε = 563.73, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.326783 Acc@1: 0.622269 (ε = 570.63, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.356624 Acc@1: 0.615936 (ε = 577.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.015941 Acc@1: 0.493324 
	Train Epoch: 28 	Loss: 1.366143 Acc@1: 0.588785 (ε = 580.96, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.351284 Acc@1: 0.600781 (ε = 587.85, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.324129 Acc@1: 0.609448 (ε = 594.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.974014 Acc@1: 0.493618 
	Train Epoch: 29 	Loss: 1.252837 Acc@1: 0.599034 (ε = 598.19, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.310177 Acc@1: 0.595311 (ε = 605.08, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.336932 Acc@1: 0.605410 (ε = 611.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.012866 Acc@1: 0.485877 
	Train Epoch: 30 	Loss: 1.494591 Acc@1: 0.577143 (ε = 615.42, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.269653 Acc@1: 0.608709 (ε = 622.31, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.275725 Acc@1: 0.611085 (ε = 629.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.003333 Acc@1: 0.488691 
Base private model test accuracy:  0.48808230923120893
              precision    recall  f1-score   support

         0.0       0.24      0.51      0.33       508
         1.0       0.20      0.62      0.30       482
         2.0       0.19      0.41      0.26       510
         3.0       0.10      0.35      0.16       489
         4.0       0.14      0.39      0.21       466
         5.0       0.55      0.35      0.43      2972
         6.0       0.72      0.57      0.64      3080
         7.0       0.64      0.45      0.53      2961
         8.0       0.78      0.61      0.69      3024
         9.0       0.71      0.48      0.57      3003

    accuracy                           0.49     17495
   macro avg       0.43      0.47      0.41     17495
weighted avg       0.61      0.49      0.53     17495

Base private model train accuracy:  0.6198795180722891
              precision    recall  f1-score   support

         0.0       0.67      0.60      0.64       505
         1.0       0.69      0.77      0.73       467
         2.0       0.54      0.49      0.51       522
         3.0       0.49      0.54      0.51       510
         4.0       0.57      0.56      0.56       465
         5.0       0.61      0.52      0.56       505
         6.0       0.59      0.64      0.62       476
         7.0       0.65      0.66      0.65       485
         8.0       0.68      0.71      0.70       521
         9.0       0.72      0.71      0.71       524

    accuracy                           0.62      4980
   macro avg       0.62      0.62      0.62      4980
weighted avg       0.62      0.62      0.62      4980

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5979919678714859
test acc: 0.5763948497854077
min train acc: 0.5856307435254804
maj train acc: 0.6027996500437446
min test acc: 0.5651808242220353
maj test acc: 0.5873153779322329
total acc: 0.5875518672199169
total min acc: 0.5754400670578373
total maj acc: 0.5950305143853531
precision, recall: (0.601373182552504, 0.5979919678714859)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 631.9557259647397, 0.48808230923120893, 0.6198795180722891, 0.5875518672199169, 0.5754400670578373, 0.5950305143853531, '              precision    recall  f1-score   support\n\n         0.0       0.24      0.51      0.33       508\n         1.0       0.20      0.62      0.30       482\n         2.0       0.19      0.41      0.26       510\n         3.0       0.10      0.35      0.16       489\n         4.0       0.14      0.39      0.21       466\n         5.0       0.55      0.35      0.43      2972\n         6.0       0.72      0.57      0.64      3080\n         7.0       0.64      0.45      0.53      2961\n         8.0       0.78      0.61      0.69      3024\n         9.0       0.71      0.48      0.57      3003\n\n    accuracy                           0.49     17495\n   macro avg       0.43      0.47      0.41     17495\nweighted avg       0.61      0.49      0.53     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.67      0.60      0.64       505\n         1.0       0.69      0.77      0.73       467\n         2.0       0.54      0.49      0.51       522\n         3.0       0.49      0.54      0.51       510\n         4.0       0.57      0.56      0.56       465\n         5.0       0.61      0.52      0.56       505\n         6.0       0.59      0.64      0.62       476\n         7.0       0.65      0.66      0.65       485\n         8.0       0.68      0.71      0.70       521\n         9.0       0.72      0.71      0.71       524\n\n    accuracy                           0.62      4980\n   macro avg       0.62      0.62      0.62      4980\nweighted avg       0.62      0.62      0.62      4980\n']
experiment_number: 23
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-23.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.2, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3031, 3122, 3018, 3028, 3185, 3036, 3156, 3156, 2988, 3069])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30789, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.002647 Acc@1: 0.079498 (ε = 29.65, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.608895 Acc@1: 0.103579 (ε = 75.10, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.457622 Acc@1: 0.102868 (ε = 91.04, δ = 1e-05) for α = 1.2
	Test set:Loss: 3.291340 Acc@1: 0.024903 
	Train Epoch: 2 	Loss: 2.834931 Acc@1: 0.104269 (ε = 99.01, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.309646 Acc@1: 0.149865 (ε = 114.94, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 2.268780 Acc@1: 0.150699 (ε = 130.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.164690 Acc@1: 0.181258 
	Train Epoch: 3 	Loss: 2.191632 Acc@1: 0.164948 (ε = 138.85, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 2.818147 Acc@1: 0.134529 (ε = 154.79, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 3.174479 Acc@1: 0.116766 (ε = 164.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.278832 Acc@1: 0.164643 
	Train Epoch: 4 	Loss: 2.310492 Acc@1: 0.151115 (ε = 167.50, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.363349 Acc@1: 0.123081 (ε = 174.39, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.431693 Acc@1: 0.118863 (ε = 181.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.265184 Acc@1: 0.169741 
	Train Epoch: 5 	Loss: 2.238462 Acc@1: 0.137318 (ε = 184.73, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.286646 Acc@1: 0.139580 (ε = 191.62, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.226057 Acc@1: 0.150540 (ε = 198.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.132894 Acc@1: 0.161746 
	Train Epoch: 6 	Loss: 2.127451 Acc@1: 0.148179 (ε = 201.96, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.107057 Acc@1: 0.181262 (ε = 208.85, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.089231 Acc@1: 0.190498 (ε = 215.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.043546 Acc@1: 0.247950 
	Train Epoch: 7 	Loss: 2.135861 Acc@1: 0.224507 (ε = 219.18, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.119513 Acc@1: 0.246967 (ε = 226.07, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.287054 Acc@1: 0.237687 (ε = 232.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.339020 Acc@1: 0.176325 
	Train Epoch: 8 	Loss: 2.402209 Acc@1: 0.153102 (ε = 236.41, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.344666 Acc@1: 0.185263 (ε = 243.30, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.222461 Acc@1: 0.186591 (ε = 250.19, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.085905 Acc@1: 0.271391 
	Train Epoch: 9 	Loss: 2.113937 Acc@1: 0.221138 (ε = 253.64, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.056587 Acc@1: 0.268777 (ε = 260.53, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.101591 Acc@1: 0.254064 (ε = 267.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.144990 Acc@1: 0.247594 
	Train Epoch: 10 	Loss: 2.062320 Acc@1: 0.241883 (ε = 270.87, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.045431 Acc@1: 0.275794 (ε = 277.76, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.057627 Acc@1: 0.284958 (ε = 284.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.045391 Acc@1: 0.288591 
	Train Epoch: 11 	Loss: 2.148936 Acc@1: 0.293570 (ε = 288.09, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.122803 Acc@1: 0.285281 (ε = 294.98, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.061348 Acc@1: 0.291757 (ε = 301.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.159264 Acc@1: 0.279977 
	Train Epoch: 12 	Loss: 2.233114 Acc@1: 0.282051 (ε = 305.32, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.032891 Acc@1: 0.312596 (ε = 312.21, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.991237 Acc@1: 0.323130 (ε = 319.10, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.763875 Acc@1: 0.422014 
	Train Epoch: 13 	Loss: 1.911892 Acc@1: 0.366345 (ε = 322.55, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.951490 Acc@1: 0.366082 (ε = 329.44, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.932253 Acc@1: 0.378022 (ε = 336.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.662667 Acc@1: 0.458753 
	Train Epoch: 14 	Loss: 1.698849 Acc@1: 0.411570 (ε = 339.78, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.860121 Acc@1: 0.393124 (ε = 346.67, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.846461 Acc@1: 0.400953 (ε = 353.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.674738 Acc@1: 0.478131 
	Train Epoch: 15 	Loss: 1.782397 Acc@1: 0.438751 (ε = 357.00, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.844796 Acc@1: 0.424768 (ε = 363.90, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.810301 Acc@1: 0.426211 (ε = 370.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.657766 Acc@1: 0.502395 
	Train Epoch: 16 	Loss: 1.791091 Acc@1: 0.436782 (ε = 374.23, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.788458 Acc@1: 0.442217 (ε = 381.12, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.768577 Acc@1: 0.441137 (ε = 388.01, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.519209 Acc@1: 0.526169 
	Train Epoch: 17 	Loss: 1.652171 Acc@1: 0.476680 (ε = 391.46, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.713589 Acc@1: 0.454663 (ε = 398.35, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.720975 Acc@1: 0.456383 (ε = 405.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.611722 Acc@1: 0.529596 
	Train Epoch: 18 	Loss: 1.771832 Acc@1: 0.460213 (ε = 408.69, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.683837 Acc@1: 0.474533 (ε = 415.58, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.678646 Acc@1: 0.477346 (ε = 422.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.743860 Acc@1: 0.508698 
	Train Epoch: 19 	Loss: 1.736772 Acc@1: 0.475166 (ε = 425.91, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.681302 Acc@1: 0.487871 (ε = 432.81, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.673517 Acc@1: 0.488956 (ε = 439.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.595942 Acc@1: 0.533188 
	Train Epoch: 20 	Loss: 1.743617 Acc@1: 0.493209 (ε = 443.14, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.668369 Acc@1: 0.492596 (ε = 450.03, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.670988 Acc@1: 0.492303 (ε = 456.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.513153 Acc@1: 0.556060 
	Train Epoch: 21 	Loss: 1.599248 Acc@1: 0.501587 (ε = 460.37, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.647374 Acc@1: 0.506029 (ε = 467.26, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.631759 Acc@1: 0.509620 (ε = 474.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.522523 Acc@1: 0.560353 
	Train Epoch: 22 	Loss: 1.594645 Acc@1: 0.506462 (ε = 477.60, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.612730 Acc@1: 0.515949 (ε = 484.49, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.631174 Acc@1: 0.512910 (ε = 491.38, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.544591 Acc@1: 0.558784 
	Train Epoch: 23 	Loss: 1.666450 Acc@1: 0.510050 (ε = 494.82, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.648964 Acc@1: 0.521779 (ε = 501.72, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.654951 Acc@1: 0.518525 (ε = 508.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.544745 Acc@1: 0.570069 
	Train Epoch: 24 	Loss: 1.762347 Acc@1: 0.504132 (ε = 512.05, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.642942 Acc@1: 0.515564 (ε = 518.94, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.626491 Acc@1: 0.520408 (ε = 525.83, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.567562 Acc@1: 0.563885 
	Train Epoch: 25 	Loss: 1.741897 Acc@1: 0.508264 (ε = 529.28, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.686701 Acc@1: 0.510638 (ε = 536.17, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.680071 Acc@1: 0.510743 (ε = 543.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.521126 Acc@1: 0.571069 
	Train Epoch: 26 	Loss: 1.481999 Acc@1: 0.544800 (ε = 546.51, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.606802 Acc@1: 0.527397 (ε = 553.40, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.612072 Acc@1: 0.527301 (ε = 560.29, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.537724 Acc@1: 0.572927 
	Train Epoch: 27 	Loss: 1.752431 Acc@1: 0.502974 (ε = 563.73, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.624970 Acc@1: 0.523838 (ε = 570.63, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.633757 Acc@1: 0.524471 (ε = 577.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.555177 Acc@1: 0.575782 
	Train Epoch: 28 	Loss: 1.691157 Acc@1: 0.519405 (ε = 580.96, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.623854 Acc@1: 0.530163 (ε = 587.85, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.629623 Acc@1: 0.524975 (ε = 594.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.535441 Acc@1: 0.578312 
	Train Epoch: 29 	Loss: 1.564519 Acc@1: 0.528163 (ε = 598.19, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.613269 Acc@1: 0.531608 (ε = 605.08, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.608155 Acc@1: 0.532939 (ε = 611.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.540816 Acc@1: 0.574902 
	Train Epoch: 30 	Loss: 1.563871 Acc@1: 0.546417 (ε = 615.42, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.623699 Acc@1: 0.537332 (ε = 622.31, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.629380 Acc@1: 0.533233 (ε = 629.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.546891 Acc@1: 0.574425 
Base private model test accuracy:  0.575421549014004
              precision    recall  f1-score   support

         0.0       0.27      0.23      0.25       508
         1.0       0.22      0.19      0.20       482
         2.0       0.21      0.18      0.19       510
         3.0       0.07      0.04      0.05       489
         4.0       0.13      0.08      0.09       466
         5.0       0.54      0.65      0.59      2972
         6.0       0.69      0.67      0.68      3080
         7.0       0.61      0.55      0.58      2961
         8.0       0.69      0.73      0.71      3024
         9.0       0.59      0.63      0.61      3003

    accuracy                           0.58     17495
   macro avg       0.40      0.39      0.40     17495
weighted avg       0.56      0.58      0.57     17495

Base private model train accuracy:  0.5239533599662217
              precision    recall  f1-score   support

         0.0       0.58      0.46      0.51      3031
         1.0       0.54      0.56      0.55      3122
         2.0       0.47      0.35      0.40      3018
         3.0       0.41      0.34      0.37      3028
         4.0       0.44      0.32      0.37      3185
         5.0       0.47      0.64      0.54      3036
         6.0       0.53      0.66      0.58      3156
         7.0       0.60      0.57      0.59      3156
         8.0       0.60      0.71      0.65      2988
         9.0       0.56      0.63      0.59      3069

    accuracy                           0.52     30789
   macro avg       0.52      0.52      0.52     30789
weighted avg       0.52      0.52      0.52     30789

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6214109393270105
test acc: 0.5217532467532467
min train acc: 0.6125752508361204
maj train acc: 0.629867674858223
min test acc: 0.5554103502352326
maj test acc: 0.488527971126579
total acc: 0.5715723842306943
total min acc: 0.5836583592252265
total maj acc: 0.5599949021856879
precision, recall: (0.5649991140511488, 0.6214109393270105)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 631.9557259647397, 0.575421549014004, 0.5239533599662217, 0.5715723842306943, 0.5836583592252265, 0.5599949021856879, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.23      0.25       508\n         1.0       0.22      0.19      0.20       482\n         2.0       0.21      0.18      0.19       510\n         3.0       0.07      0.04      0.05       489\n         4.0       0.13      0.08      0.09       466\n         5.0       0.54      0.65      0.59      2972\n         6.0       0.69      0.67      0.68      3080\n         7.0       0.61      0.55      0.58      2961\n         8.0       0.69      0.73      0.71      3024\n         9.0       0.59      0.63      0.61      3003\n\n    accuracy                           0.58     17495\n   macro avg       0.40      0.39      0.40     17495\nweighted avg       0.56      0.58      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.58      0.46      0.51      3031\n         1.0       0.54      0.56      0.55      3122\n         2.0       0.47      0.35      0.40      3018\n         3.0       0.41      0.34      0.37      3028\n         4.0       0.44      0.32      0.37      3185\n         5.0       0.47      0.64      0.54      3036\n         6.0       0.53      0.66      0.58      3156\n         7.0       0.60      0.57      0.59      3156\n         8.0       0.60      0.71      0.65      2988\n         9.0       0.56      0.63      0.59      3069\n\n    accuracy                           0.52     30789\n   macro avg       0.52      0.52      0.52     30789\nweighted avg       0.52      0.52      0.52     30789\n']
experiment_number: 20
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-20.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.1, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing oversampling at  0.5
resampled train counts:  tensor([3039, 2992, 3099, 3061, 3055, 2968, 3087, 3023, 3086, 2974])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30384, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.894433 Acc@1: 0.106250 (ε = 87.52, δ = 1e-05) for α = 1.4
	Train Epoch: 1 	Loss: 2.403758 Acc@1: 0.112040 (ε = 344.55, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.378952 Acc@1: 0.110519 (ε = 553.12, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.307941 Acc@1: 0.026711 
	Train Epoch: 2 	Loss: 2.303865 Acc@1: 0.099237 (ε = 657.40, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.303359 Acc@1: 0.103115 (ε = 865.97, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.303245 Acc@1: 0.098653 (ε = 1074.54, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.290712 Acc@1: 0.174590 
	Train Epoch: 3 	Loss: 2.304393 Acc@1: 0.099762 (ε = 1178.82, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.397771 Acc@1: 0.102783 (ε = 1387.39, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.350047 Acc@1: 0.125029 (ε = 1595.96, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.335147 Acc@1: 0.224356 
	Train Epoch: 4 	Loss: 2.313872 Acc@1: 0.132588 (ε = 1700.24, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.918951 Acc@1: 0.100658 (ε = 1908.81, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.626340 Acc@1: 0.110984 (ε = 2117.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.298255 Acc@1: 0.170874 
	Train Epoch: 5 	Loss: 2.297756 Acc@1: 0.116376 (ε = 2221.66, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.304410 Acc@1: 0.107626 (ε = 2430.23, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.304205 Acc@1: 0.106761 (ε = 2638.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.277495 Acc@1: 0.116689 
	Train Epoch: 6 	Loss: 2.292897 Acc@1: 0.125604 (ε = 2743.08, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.350845 Acc@1: 0.133923 (ε = 2951.64, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.329433 Acc@1: 0.128570 (ε = 3160.21, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.295427 Acc@1: 0.156484 
	Train Epoch: 7 	Loss: 2.259200 Acc@1: 0.133758 (ε = 3264.49, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.311650 Acc@1: 0.140502 (ε = 3473.06, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.305676 Acc@1: 0.155140 (ε = 3681.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.256286 Acc@1: 0.168489 
	Train Epoch: 8 	Loss: 2.282680 Acc@1: 0.160547 (ε = 3785.91, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.265040 Acc@1: 0.175223 (ε = 3994.48, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.275967 Acc@1: 0.173851 (ε = 4203.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.230746 Acc@1: 0.166108 
	Train Epoch: 9 	Loss: 2.208873 Acc@1: 0.180395 (ε = 4307.33, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.225694 Acc@1: 0.190300 (ε = 4515.90, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.217227 Acc@1: 0.193714 (ε = 4724.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.341051 Acc@1: 0.171100 
	Train Epoch: 10 	Loss: 2.477928 Acc@1: 0.099768 (ε = 4828.75, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.333981 Acc@1: 0.155374 (ε = 5037.31, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.288861 Acc@1: 0.163496 (ε = 5245.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.064627 Acc@1: 0.289887 
	Train Epoch: 11 	Loss: 2.105807 Acc@1: 0.233553 (ε = 5350.17, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.133346 Acc@1: 0.221366 (ε = 5558.73, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.141388 Acc@1: 0.230488 (ε = 5767.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.042260 Acc@1: 0.318969 
	Train Epoch: 12 	Loss: 2.163632 Acc@1: 0.243819 (ε = 5871.58, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.066339 Acc@1: 0.256817 (ε = 6080.15, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.058161 Acc@1: 0.263571 (ε = 6288.72, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.987072 Acc@1: 0.307560 
	Train Epoch: 13 	Loss: 2.031587 Acc@1: 0.269828 (ε = 6393.00, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.979560 Acc@1: 0.284615 (ε = 6601.57, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.962816 Acc@1: 0.301039 (ε = 6810.14, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.008577 Acc@1: 0.315633 
	Train Epoch: 14 	Loss: 1.911573 Acc@1: 0.331104 (ε = 6914.42, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.932371 Acc@1: 0.332578 (ε = 7122.99, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.923366 Acc@1: 0.338111 (ε = 7331.55, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.775135 Acc@1: 0.425481 
	Train Epoch: 15 	Loss: 1.822628 Acc@1: 0.374183 (ε = 7435.84, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.874388 Acc@1: 0.356453 (ε = 7644.40, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.872805 Acc@1: 0.359685 (ε = 7852.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.721530 Acc@1: 0.423959 
	Train Epoch: 16 	Loss: 1.863069 Acc@1: 0.362258 (ε = 7957.26, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.826405 Acc@1: 0.382109 (ε = 8165.82, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.808112 Acc@1: 0.385852 (ε = 8374.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.861803 Acc@1: 0.406686 
	Train Epoch: 17 	Loss: 1.758064 Acc@1: 0.399510 (ε = 8478.67, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.790364 Acc@1: 0.402504 (ε = 8687.24, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.773813 Acc@1: 0.408814 (ε = 8895.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.854776 Acc@1: 0.423453 
	Train Epoch: 18 	Loss: 1.805979 Acc@1: 0.419628 (ε = 9000.09, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.739065 Acc@1: 0.423695 (ε = 9208.66, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.751048 Acc@1: 0.427466 (ε = 9417.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.749923 Acc@1: 0.446231 
	Train Epoch: 19 	Loss: 1.803933 Acc@1: 0.461538 (ε = 9521.51, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.706131 Acc@1: 0.448349 (ε = 9730.08, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.714784 Acc@1: 0.448028 (ε = 9938.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.825770 Acc@1: 0.433423 
	Train Epoch: 20 	Loss: 1.783213 Acc@1: 0.441009 (ε = 10042.93, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.726115 Acc@1: 0.450468 (ε = 10251.49, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.716364 Acc@1: 0.454810 (ε = 10460.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.731086 Acc@1: 0.478354 
	Train Epoch: 21 	Loss: 1.641447 Acc@1: 0.482558 (ε = 10564.35, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.683008 Acc@1: 0.470446 (ε = 10772.91, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.691793 Acc@1: 0.469836 (ε = 10981.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.606756 Acc@1: 0.516997 
	Train Epoch: 22 	Loss: 1.680171 Acc@1: 0.471108 (ε = 11085.76, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.679467 Acc@1: 0.478283 (ε = 11294.33, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.679181 Acc@1: 0.478713 (ε = 11502.90, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.644275 Acc@1: 0.511157 
	Train Epoch: 23 	Loss: 1.635147 Acc@1: 0.477796 (ε = 11607.18, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.639542 Acc@1: 0.481036 (ε = 11815.75, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.647003 Acc@1: 0.483207 (ε = 12024.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.640289 Acc@1: 0.513677 
	Train Epoch: 24 	Loss: 1.649974 Acc@1: 0.473318 (ε = 12128.60, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.645857 Acc@1: 0.491080 (ε = 12337.17, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.659493 Acc@1: 0.491855 (ε = 12545.73, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.670294 Acc@1: 0.513416 
	Train Epoch: 25 	Loss: 1.627681 Acc@1: 0.496689 (ε = 12650.02, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.661444 Acc@1: 0.483506 (ε = 12858.58, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.642767 Acc@1: 0.490372 (ε = 13067.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.810376 Acc@1: 0.473665 
	Train Epoch: 26 	Loss: 1.655221 Acc@1: 0.498859 (ε = 13171.44, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.636608 Acc@1: 0.487811 (ε = 13380.00, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.639888 Acc@1: 0.488587 (ε = 13588.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.675900 Acc@1: 0.508059 
	Train Epoch: 27 	Loss: 1.538439 Acc@1: 0.508044 (ε = 13692.85, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.606769 Acc@1: 0.505276 (ε = 13901.42, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.603474 Acc@1: 0.506297 (ε = 14109.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.717979 Acc@1: 0.503826 
	Train Epoch: 28 	Loss: 1.629694 Acc@1: 0.483553 (ε = 14214.27, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.624420 Acc@1: 0.498792 (ε = 14422.84, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.630702 Acc@1: 0.500573 (ε = 14631.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.677787 Acc@1: 0.512571 
	Train Epoch: 29 	Loss: 1.693518 Acc@1: 0.473815 (ε = 14735.69, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.647377 Acc@1: 0.494773 (ε = 14944.26, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.632892 Acc@1: 0.502054 (ε = 15152.82, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.676246 Acc@1: 0.511909 
	Train Epoch: 30 	Loss: 1.661860 Acc@1: 0.489221 (ε = 15257.11, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.619698 Acc@1: 0.499279 (ε = 15465.67, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.615823 Acc@1: 0.503155 (ε = 15674.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.692354 Acc@1: 0.508835 
Base private model test accuracy:  0.5080880251500429
              precision    recall  f1-score   support

         0.0       0.25      0.48      0.33       508
         1.0       0.21      0.58      0.31       482
         2.0       0.16      0.31      0.21       510
         3.0       0.08      0.21      0.12       489
         4.0       0.14      0.35      0.20       466
         5.0       0.59      0.41      0.48      2972
         6.0       0.66      0.56      0.60      3080
         7.0       0.66      0.53      0.59      2961
         8.0       0.76      0.62      0.68      3024
         9.0       0.68      0.53      0.60      3003

    accuracy                           0.51     17495
   macro avg       0.42      0.46      0.41     17495
weighted avg       0.60      0.51      0.54     17495

Base private model train accuracy:  0.5022380200105319
              precision    recall  f1-score   support

         0.0       0.57      0.54      0.56      3039
         1.0       0.57      0.62      0.60      2992
         2.0       0.43      0.36      0.39      3099
         3.0       0.42      0.35      0.38      3061
         4.0       0.45      0.43      0.44      3055
         5.0       0.45      0.44      0.44      2968
         6.0       0.45      0.58      0.51      3087
         7.0       0.53      0.53      0.53      3023
         8.0       0.57      0.62      0.60      3086
         9.0       0.55      0.54      0.54      2974

    accuracy                           0.50     30384
   macro avg       0.50      0.50      0.50     30384
weighted avg       0.50      0.50      0.50     30384

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7580963665086888
test acc: 0.7298051948051948
min train acc: 0.9142447543333768
maj train acc: 0.6075998449011245
min test acc: 0.9186907390570204
maj test acc: 0.541174944883932
total acc: 0.7438546025104602
total min acc: 0.9164715066354411
total maj acc: 0.5744432936302434
precision, recall: (0.7345962495216226, 0.7580963665086888)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.5, 15757.668603415104, 0.5080880251500429, 0.5022380200105319, 0.7438546025104602, 0.9164715066354411, 0.5744432936302434, '              precision    recall  f1-score   support\n\n         0.0       0.25      0.48      0.33       508\n         1.0       0.21      0.58      0.31       482\n         2.0       0.16      0.31      0.21       510\n         3.0       0.08      0.21      0.12       489\n         4.0       0.14      0.35      0.20       466\n         5.0       0.59      0.41      0.48      2972\n         6.0       0.66      0.56      0.60      3080\n         7.0       0.66      0.53      0.59      2961\n         8.0       0.76      0.62      0.68      3024\n         9.0       0.68      0.53      0.60      3003\n\n    accuracy                           0.51     17495\n   macro avg       0.42      0.46      0.41     17495\nweighted avg       0.60      0.51      0.54     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.54      0.56      3039\n         1.0       0.57      0.62      0.60      2992\n         2.0       0.43      0.36      0.39      3099\n         3.0       0.42      0.35      0.38      3061\n         4.0       0.45      0.43      0.44      3055\n         5.0       0.45      0.44      0.44      2968\n         6.0       0.45      0.58      0.51      3087\n         7.0       0.53      0.53      0.53      3023\n         8.0       0.57      0.62      0.60      3086\n         9.0       0.55      0.54      0.54      2974\n\n    accuracy                           0.50     30384\n   macro avg       0.50      0.50      0.50     30384\nweighted avg       0.50      0.50      0.50     30384\n']
experiment_number: 30
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-30.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.1, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing undersampling at  0.5
resampled train counts:  tensor([514, 458, 480, 494, 514, 482, 502, 494, 529, 482])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4949, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.412646 Acc@1: 0.072464 (ε = 87.52, δ = 1e-05) for α = 1.4
	Train Epoch: 1 	Loss: 2.999914 Acc@1: 0.097048 (ε = 344.55, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.775094 Acc@1: 0.107065 (ε = 553.12, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.280492 Acc@1: 0.078715 
	Train Epoch: 2 	Loss: 2.269571 Acc@1: 0.141553 (ε = 657.40, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.293875 Acc@1: 0.112499 (ε = 865.97, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.344867 Acc@1: 0.109266 (ε = 1074.54, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.297052 Acc@1: 0.168169 
	Train Epoch: 3 	Loss: 2.286482 Acc@1: 0.132353 (ε = 1178.82, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.606109 Acc@1: 0.111588 (ε = 1387.39, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.461951 Acc@1: 0.104953 (ε = 1595.96, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.309422 Acc@1: 0.174204 
	Train Epoch: 4 	Loss: 2.303936 Acc@1: 0.101449 (ε = 1700.24, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.303685 Acc@1: 0.105329 (ε = 1908.81, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.304622 Acc@1: 0.104392 (ε = 2117.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.313827 Acc@1: 0.035939 
	Train Epoch: 5 	Loss: 2.298676 Acc@1: 0.129187 (ε = 2221.66, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.300682 Acc@1: 0.119958 (ε = 2430.23, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.303112 Acc@1: 0.112490 (ε = 2638.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.303069 Acc@1: 0.028070 
	Train Epoch: 6 	Loss: 2.301971 Acc@1: 0.104167 (ε = 2743.08, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.296896 Acc@1: 0.112710 (ε = 2951.64, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.316354 Acc@1: 0.114074 (ε = 3160.21, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.317042 Acc@1: 0.172899 
	Train Epoch: 7 	Loss: 2.313594 Acc@1: 0.121547 (ε = 3264.49, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.308819 Acc@1: 0.119356 (ε = 3473.06, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.305451 Acc@1: 0.116942 (ε = 3681.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.284771 Acc@1: 0.168260 
	Train Epoch: 8 	Loss: 2.306935 Acc@1: 0.121053 (ε = 3785.91, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.305290 Acc@1: 0.101617 (ε = 3994.48, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 2.300441 Acc@1: 0.105703 (ε = 4203.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.327860 Acc@1: 0.030904 
	Train Epoch: 9 	Loss: 2.299878 Acc@1: 0.113402 (ε = 4307.33, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.299018 Acc@1: 0.119427 (ε = 4515.90, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 2.296041 Acc@1: 0.121229 (ε = 4724.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.259072 Acc@1: 0.196210 
	Train Epoch: 10 	Loss: 2.259101 Acc@1: 0.123810 (ε = 4828.75, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.288826 Acc@1: 0.134839 (ε = 5037.31, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 2.286703 Acc@1: 0.156144 (ε = 5245.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.310153 Acc@1: 0.069081 
	Train Epoch: 11 	Loss: 2.306140 Acc@1: 0.141509 (ε = 5350.17, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.243294 Acc@1: 0.153329 (ε = 5558.73, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 2.218340 Acc@1: 0.158863 (ε = 5767.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.028533 Acc@1: 0.261760 
	Train Epoch: 12 	Loss: 2.128231 Acc@1: 0.206009 (ε = 5871.58, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.126919 Acc@1: 0.222401 (ε = 6080.15, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 2.091694 Acc@1: 0.223452 (ε = 6288.72, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.987920 Acc@1: 0.247434 
	Train Epoch: 13 	Loss: 2.068737 Acc@1: 0.272300 (ε = 6393.00, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 2.025511 Acc@1: 0.269880 (ε = 6601.57, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.999798 Acc@1: 0.280474 (ε = 6810.14, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.022643 Acc@1: 0.273519 
	Train Epoch: 14 	Loss: 2.085853 Acc@1: 0.318182 (ε = 6914.42, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 2.101396 Acc@1: 0.304995 (ε = 7122.99, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 2.037060 Acc@1: 0.300421 (ε = 7331.55, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.064434 Acc@1: 0.254470 
	Train Epoch: 15 	Loss: 2.110335 Acc@1: 0.266667 (ε = 7435.84, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 2.010427 Acc@1: 0.293915 (ε = 7644.40, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.992600 Acc@1: 0.305654 (ε = 7852.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.237417 Acc@1: 0.294689 
	Train Epoch: 16 	Loss: 2.009763 Acc@1: 0.302222 (ε = 7957.26, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.942386 Acc@1: 0.333876 (ε = 8165.82, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.905024 Acc@1: 0.345488 (ε = 8374.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.887959 Acc@1: 0.396738 
	Train Epoch: 17 	Loss: 1.803950 Acc@1: 0.427184 (ε = 8478.67, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.866806 Acc@1: 0.372333 (ε = 8687.24, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.863167 Acc@1: 0.371460 (ε = 8895.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.064907 Acc@1: 0.313695 
	Train Epoch: 18 	Loss: 1.878836 Acc@1: 0.345178 (ε = 9000.09, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.830196 Acc@1: 0.404759 (ε = 9208.66, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.833792 Acc@1: 0.403547 (ε = 9417.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.049810 Acc@1: 0.371363 
	Train Epoch: 19 	Loss: 1.810537 Acc@1: 0.379747 (ε = 9521.51, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.805221 Acc@1: 0.404414 (ε = 9730.08, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.792630 Acc@1: 0.411797 (ε = 9938.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.838918 Acc@1: 0.403047 
	Train Epoch: 20 	Loss: 1.805186 Acc@1: 0.390110 (ε = 10042.93, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.695962 Acc@1: 0.423490 (ε = 10251.49, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.686820 Acc@1: 0.438508 (ε = 10460.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.013842 Acc@1: 0.367410 
	Train Epoch: 21 	Loss: 1.602358 Acc@1: 0.463768 (ε = 10564.35, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.685138 Acc@1: 0.459778 (ε = 10772.91, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.696958 Acc@1: 0.460716 (ε = 10981.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.895164 Acc@1: 0.427869 
	Train Epoch: 22 	Loss: 1.847755 Acc@1: 0.434389 (ε = 11085.76, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.688113 Acc@1: 0.470092 (ε = 11294.33, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.710159 Acc@1: 0.462857 (ε = 11502.90, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.976549 Acc@1: 0.425934 
	Train Epoch: 23 	Loss: 1.887495 Acc@1: 0.400943 (ε = 11607.18, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.756724 Acc@1: 0.442228 (ε = 11815.75, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.705380 Acc@1: 0.454603 (ε = 12024.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.952403 Acc@1: 0.412590 
	Train Epoch: 24 	Loss: 1.682802 Acc@1: 0.474227 (ε = 12128.60, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.687388 Acc@1: 0.462101 (ε = 12337.17, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.648008 Acc@1: 0.472218 (ε = 12545.73, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.841043 Acc@1: 0.446708 
	Train Epoch: 25 	Loss: 1.481380 Acc@1: 0.537234 (ε = 12650.02, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.620696 Acc@1: 0.503212 (ε = 12858.58, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.592624 Acc@1: 0.498692 (ε = 13067.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.858352 Acc@1: 0.445789 
	Train Epoch: 26 	Loss: 1.596787 Acc@1: 0.474178 (ε = 13171.44, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.600833 Acc@1: 0.489703 (ε = 13380.00, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.589631 Acc@1: 0.488312 (ε = 13588.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.856981 Acc@1: 0.444176 
	Train Epoch: 27 	Loss: 1.812206 Acc@1: 0.470000 (ε = 13692.85, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.558350 Acc@1: 0.503164 (ε = 13901.42, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.544523 Acc@1: 0.509386 (ε = 14109.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.897257 Acc@1: 0.455989 
	Train Epoch: 28 	Loss: 1.625269 Acc@1: 0.476684 (ε = 14214.27, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.547444 Acc@1: 0.515192 (ε = 14422.84, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.598551 Acc@1: 0.507361 (ε = 14631.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.844266 Acc@1: 0.460764 
	Train Epoch: 29 	Loss: 1.734078 Acc@1: 0.479381 (ε = 14735.69, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.568296 Acc@1: 0.502028 (ε = 14944.26, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.594682 Acc@1: 0.503113 (ε = 15152.82, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.806475 Acc@1: 0.467625 
	Train Epoch: 30 	Loss: 1.646189 Acc@1: 0.524510 (ε = 15257.11, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.517811 Acc@1: 0.525890 (ε = 15465.67, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.564031 Acc@1: 0.516536 (ε = 15674.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.819736 Acc@1: 0.466126 
Base private model test accuracy:  0.46607602172049156
              precision    recall  f1-score   support

         0.0       0.18      0.48      0.26       508
         1.0       0.19      0.57      0.28       482
         2.0       0.17      0.31      0.22       510
         3.0       0.07      0.27      0.12       489
         4.0       0.13      0.30      0.18       466
         5.0       0.59      0.36      0.45      2972
         6.0       0.62      0.51      0.56      3080
         7.0       0.62      0.46      0.53      2961
         8.0       0.77      0.58      0.67      3024
         9.0       0.67      0.48      0.56      3003

    accuracy                           0.47     17495
   macro avg       0.40      0.43      0.38     17495
weighted avg       0.59      0.47      0.51     17495

Base private model train accuracy:  0.5306122448979592
              precision    recall  f1-score   support

         0.0       0.59      0.62      0.60       514
         1.0       0.58      0.68      0.62       458
         2.0       0.55      0.42      0.48       480
         3.0       0.38      0.39      0.39       494
         4.0       0.45      0.39      0.42       514
         5.0       0.49      0.48      0.48       482
         6.0       0.45      0.54      0.49       502
         7.0       0.53      0.50      0.51       494
         8.0       0.66      0.66      0.66       529
         9.0       0.64      0.63      0.64       482

    accuracy                           0.53      4949
   macro avg       0.53      0.53      0.53      4949
weighted avg       0.53      0.53      0.53      4949

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6220695230396119
test acc: 0.5051502145922746
min train acc: 0.5678104575163399
maj train acc: 0.6783154121863799
min test acc: 0.5117252931323283
maj test acc: 0.4973821989528796
total acc: 0.5653621981681932
total min acc: 0.5401157981803143
total maj acc: 0.5866489832007074
precision, recall: (0.5716939078751857, 0.6220695230396119)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.5, 15757.668603415104, 0.46607602172049156, 0.5306122448979592, 0.5653621981681932, 0.5401157981803143, 0.5866489832007074, '              precision    recall  f1-score   support\n\n         0.0       0.18      0.48      0.26       508\n         1.0       0.19      0.57      0.28       482\n         2.0       0.17      0.31      0.22       510\n         3.0       0.07      0.27      0.12       489\n         4.0       0.13      0.30      0.18       466\n         5.0       0.59      0.36      0.45      2972\n         6.0       0.62      0.51      0.56      3080\n         7.0       0.62      0.46      0.53      2961\n         8.0       0.77      0.58      0.67      3024\n         9.0       0.67      0.48      0.56      3003\n\n    accuracy                           0.47     17495\n   macro avg       0.40      0.43      0.38     17495\nweighted avg       0.59      0.47      0.51     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.59      0.62      0.60       514\n         1.0       0.58      0.68      0.62       458\n         2.0       0.55      0.42      0.48       480\n         3.0       0.38      0.39      0.39       494\n         4.0       0.45      0.39      0.42       514\n         5.0       0.49      0.48      0.48       482\n         6.0       0.45      0.54      0.49       502\n         7.0       0.53      0.50      0.51       494\n         8.0       0.66      0.66      0.66       529\n         9.0       0.64      0.63      0.64       482\n\n    accuracy                           0.53      4949\n   macro avg       0.53      0.53      0.53      4949\nweighted avg       0.53      0.53      0.53      4949\n']
experiment_number: 24
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-24.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 30, 'noise_multiplier': 0.1, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
performing smote resampling at  0.5
resampled train counts:  tensor([3059, 3055, 2988, 3019, 2987, 3058, 3026, 3085, 3072, 2965])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30314, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.806990 Acc@1: 0.088662 (ε = 87.52, δ = 1e-05) for α = 1.4
	Train Epoch: 1 	Loss: 3.559804 Acc@1: 0.100914 (ε = 344.55, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 3.690319 Acc@1: 0.099922 (ε = 553.12, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.291938 Acc@1: 0.171254 
	Train Epoch: 2 	Loss: 2.302627 Acc@1: 0.098716 (ε = 657.40, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.315206 Acc@1: 0.107247 (ε = 865.97, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 2.414071 Acc@1: 0.105650 (ε = 1074.54, δ = 1e-05) for α = 1.1
	Test set:Loss: 3.279408 Acc@1: 0.037188 
	Train Epoch: 3 	Loss: 2.717940 Acc@1: 0.114971 (ε = 1178.82, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.339178 Acc@1: 0.130444 (ε = 1387.39, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 2.301904 Acc@1: 0.147347 (ε = 1595.96, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.192777 Acc@1: 0.231699 
	Train Epoch: 4 	Loss: 2.125659 Acc@1: 0.243864 (ε = 1700.24, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.425451 Acc@1: 0.157615 (ε = 1908.81, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 2.338939 Acc@1: 0.163911 (ε = 2117.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.203354 Acc@1: 0.173814 
	Train Epoch: 5 	Loss: 2.150527 Acc@1: 0.181745 (ε = 2221.66, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.187275 Acc@1: 0.187919 (ε = 2430.23, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 2.164443 Acc@1: 0.199395 (ε = 2638.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.045068 Acc@1: 0.223384 
	Train Epoch: 6 	Loss: 2.118050 Acc@1: 0.192456 (ε = 2743.08, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.146780 Acc@1: 0.219280 (ε = 2951.64, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 2.149594 Acc@1: 0.234341 (ε = 3160.21, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.933671 Acc@1: 0.321111 
	Train Epoch: 7 	Loss: 1.939798 Acc@1: 0.279534 (ε = 3264.49, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.994413 Acc@1: 0.288331 (ε = 3473.06, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 2.006540 Acc@1: 0.286249 (ε = 3681.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.047521 Acc@1: 0.292794 
	Train Epoch: 8 	Loss: 1.952759 Acc@1: 0.286062 (ε = 3785.91, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.860953 Acc@1: 0.329561 (ε = 3994.48, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.924417 Acc@1: 0.329581 (ε = 4203.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.117182 Acc@1: 0.266060 
	Train Epoch: 9 	Loss: 2.105036 Acc@1: 0.255044 (ε = 4307.33, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.892934 Acc@1: 0.331384 (ε = 4515.90, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.876278 Acc@1: 0.342244 (ε = 4724.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.962080 Acc@1: 0.356410 
	Train Epoch: 10 	Loss: 1.847979 Acc@1: 0.344741 (ε = 4828.75, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.816107 Acc@1: 0.371061 (ε = 5037.31, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.828405 Acc@1: 0.379746 (ε = 5245.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.913149 Acc@1: 0.354769 
	Train Epoch: 11 	Loss: 1.906529 Acc@1: 0.340778 (ε = 5350.17, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.801547 Acc@1: 0.378345 (ε = 5558.73, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.834775 Acc@1: 0.386475 (ε = 5767.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.637337 Acc@1: 0.446538 
	Train Epoch: 12 	Loss: 1.684052 Acc@1: 0.408319 (ε = 5871.58, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.721070 Acc@1: 0.414586 (ε = 6080.15, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.752996 Acc@1: 0.417759 (ε = 6288.72, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.610846 Acc@1: 0.461826 
	Train Epoch: 13 	Loss: 1.808287 Acc@1: 0.419932 (ε = 6393.00, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.757625 Acc@1: 0.421519 (ε = 6601.57, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.795541 Acc@1: 0.412155 (ε = 6810.14, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.582346 Acc@1: 0.469746 
	Train Epoch: 14 	Loss: 1.651863 Acc@1: 0.423408 (ε = 6914.42, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.759075 Acc@1: 0.414481 (ε = 7122.99, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.741817 Acc@1: 0.424101 (ε = 7331.55, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.583559 Acc@1: 0.489520 
	Train Epoch: 15 	Loss: 1.647272 Acc@1: 0.464613 (ε = 7435.84, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.716318 Acc@1: 0.449441 (ε = 7644.40, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.766408 Acc@1: 0.438590 (ε = 7852.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.760638 Acc@1: 0.389076 
	Train Epoch: 16 	Loss: 1.702486 Acc@1: 0.416391 (ε = 7957.26, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.713705 Acc@1: 0.406731 (ε = 8165.82, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.749648 Acc@1: 0.417278 (ε = 8374.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.682039 Acc@1: 0.448013 
	Train Epoch: 17 	Loss: 1.774162 Acc@1: 0.420278 (ε = 8478.67, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.712692 Acc@1: 0.446157 (ε = 8687.24, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.720602 Acc@1: 0.448332 (ε = 8895.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.582368 Acc@1: 0.499684 
	Train Epoch: 18 	Loss: 1.652406 Acc@1: 0.477011 (ε = 9000.09, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.669588 Acc@1: 0.466248 (ε = 9208.66, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.660419 Acc@1: 0.474604 (ε = 9417.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.534416 Acc@1: 0.535846 
	Train Epoch: 19 	Loss: 1.676945 Acc@1: 0.480231 (ε = 9521.51, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.667351 Acc@1: 0.487398 (ε = 9730.08, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.678509 Acc@1: 0.487128 (ε = 9938.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.543692 Acc@1: 0.515838 
	Train Epoch: 20 	Loss: 1.564339 Acc@1: 0.494157 (ε = 10042.93, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.642661 Acc@1: 0.488510 (ε = 10251.49, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.640568 Acc@1: 0.488314 (ε = 10460.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.524582 Acc@1: 0.530025 
	Train Epoch: 21 	Loss: 1.567061 Acc@1: 0.479899 (ε = 10564.35, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.620830 Acc@1: 0.496363 (ε = 10772.91, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.627004 Acc@1: 0.499889 (ε = 10981.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.603662 Acc@1: 0.521099 
	Train Epoch: 22 	Loss: 1.699752 Acc@1: 0.498697 (ε = 11085.76, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.650587 Acc@1: 0.507669 (ε = 11294.33, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.632687 Acc@1: 0.509258 (ε = 11502.90, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.511886 Acc@1: 0.542850 
	Train Epoch: 23 	Loss: 1.511612 Acc@1: 0.529316 (ε = 11607.18, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.595141 Acc@1: 0.510027 (ε = 11815.75, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.603995 Acc@1: 0.513932 (ε = 12024.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.505096 Acc@1: 0.556403 
	Train Epoch: 24 	Loss: 1.585636 Acc@1: 0.520903 (ε = 12128.60, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.603349 Acc@1: 0.513214 (ε = 12337.17, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.621313 Acc@1: 0.514934 (ε = 12545.73, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.525942 Acc@1: 0.550012 
	Train Epoch: 25 	Loss: 1.654888 Acc@1: 0.507154 (ε = 12650.02, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.611369 Acc@1: 0.520834 (ε = 12858.58, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.604619 Acc@1: 0.521942 (ε = 13067.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.516131 Acc@1: 0.555880 
	Train Epoch: 26 	Loss: 1.691924 Acc@1: 0.488353 (ε = 13171.44, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.627561 Acc@1: 0.515784 (ε = 13380.00, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 1.624339 Acc@1: 0.516750 (ε = 13588.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.506051 Acc@1: 0.558007 
	Train Epoch: 27 	Loss: 1.482259 Acc@1: 0.558775 (ε = 13692.85, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.623154 Acc@1: 0.520817 (ε = 13901.42, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 1.620606 Acc@1: 0.519712 (ε = 14109.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.496947 Acc@1: 0.560919 
	Train Epoch: 28 	Loss: 1.615697 Acc@1: 0.520222 (ε = 14214.27, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.556705 Acc@1: 0.530746 (ε = 14422.84, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 1.588229 Acc@1: 0.524188 (ε = 14631.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.502786 Acc@1: 0.558101 
	Train Epoch: 29 	Loss: 1.603964 Acc@1: 0.544563 (ε = 14735.69, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.618045 Acc@1: 0.518708 (ε = 14944.26, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 1.593601 Acc@1: 0.524499 (ε = 15152.82, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.508571 Acc@1: 0.557189 
	Train Epoch: 30 	Loss: 1.644003 Acc@1: 0.511864 (ε = 15257.11, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.605997 Acc@1: 0.518864 (ε = 15465.67, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 1.601261 Acc@1: 0.520389 (ε = 15674.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.508417 Acc@1: 0.557991 
Base private model test accuracy:  0.5582737925121464
              precision    recall  f1-score   support

         0.0       0.27      0.29      0.28       508
         1.0       0.23      0.18      0.20       482
         2.0       0.12      0.10      0.11       510
         3.0       0.06      0.03      0.04       489
         4.0       0.18      0.15      0.16       466
         5.0       0.53      0.57      0.55      2972
         6.0       0.64      0.63      0.63      3080
         7.0       0.58      0.56      0.57      2961
         8.0       0.70      0.74      0.72      3024
         9.0       0.59      0.63      0.61      3003

    accuracy                           0.56     17495
   macro avg       0.39      0.39      0.39     17495
weighted avg       0.55      0.56      0.55     17495

Base private model train accuracy:  0.5189021574190144
              precision    recall  f1-score   support

         0.0       0.56      0.51      0.54      3059
         1.0       0.62      0.56      0.59      3055
         2.0       0.40      0.34      0.37      2988
         3.0       0.44      0.33      0.38      3019
         4.0       0.43      0.33      0.37      2987
         5.0       0.46      0.57      0.51      3058
         6.0       0.54      0.62      0.58      3026
         7.0       0.53      0.57      0.55      3085
         8.0       0.63      0.71      0.67      3072
         9.0       0.53      0.63      0.57      2965

    accuracy                           0.52     30314
   macro avg       0.51      0.52      0.51     30314
weighted avg       0.51      0.52      0.51     30314

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6092234611070793
test acc: 0.5057142857142858
min train acc: 0.6336368505623996
maj train acc: 0.5922941324603375
min test acc: 0.5192758530867414
maj test acc: 0.49236937403000514
total acc: 0.5570573027456884
total min acc: 0.5756635415291166
total maj acc: 0.5430011483986219
precision, recall: (0.548141992164312, 0.6092234611070793)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.5, 15757.668603415104, 0.5582737925121464, 0.5189021574190144, 0.5570573027456884, 0.5756635415291166, 0.5430011483986219, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.29      0.28       508\n         1.0       0.23      0.18      0.20       482\n         2.0       0.12      0.10      0.11       510\n         3.0       0.06      0.03      0.04       489\n         4.0       0.18      0.15      0.16       466\n         5.0       0.53      0.57      0.55      2972\n         6.0       0.64      0.63      0.63      3080\n         7.0       0.58      0.56      0.57      2961\n         8.0       0.70      0.74      0.72      3024\n         9.0       0.59      0.63      0.61      3003\n\n    accuracy                           0.56     17495\n   macro avg       0.39      0.39      0.39     17495\nweighted avg       0.55      0.56      0.55     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.56      0.51      0.54      3059\n         1.0       0.62      0.56      0.59      3055\n         2.0       0.40      0.34      0.37      2988\n         3.0       0.44      0.33      0.38      3019\n         4.0       0.43      0.33      0.37      2987\n         5.0       0.46      0.57      0.51      3058\n         6.0       0.54      0.62      0.58      3026\n         7.0       0.53      0.57      0.55      3085\n         8.0       0.63      0.71      0.67      3072\n         9.0       0.53      0.63      0.57      2965\n\n    accuracy                           0.52     30314\n   macro avg       0.51      0.52      0.51     30314\nweighted avg       0.51      0.52      0.51     30314\n']
experiment_number: 22
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-22.json
Wed Jun  9 20:11:14 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:06.0 Off |                    0 |
| N/A   54C    P0    37W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 20:11:14 up  2:43,  2 users,  load average: 2.91, 3.47, 5.01
