Python 2.7.18
Python 3.8.5
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 1, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
resampled train counts:  tensor([ 519,  489,  527,  485,  492, 3040, 2874, 3064, 2915, 3130])
resampled test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
training set size:  (17535, 3, 32, 32)
test set size:  (17495, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.630774 Acc@1: 0.054054 (ε = 30.71, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.306122 Acc@1: 0.167071 (ε = 77.59, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.318269 Acc@1: 0.178021 (ε = 95.80, δ = 1e-05) for α = 1.2
	Test set:Loss: 2.032763 Acc@1: 0.215458 
Base private model test accuracy:  0.21531866247499284
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.00      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.00      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.18      0.94      0.30      2972
         6.0       0.56      0.18      0.27      3080
         7.0       0.02      0.00      0.00      2961
         8.0       0.00      0.00      0.00      3024
         9.0       0.45      0.13      0.21      3003

    accuracy                           0.22     17495
   macro avg       0.12      0.13      0.08     17495
weighted avg       0.21      0.22      0.14     17495

Base private model train accuracy:  0.21887653264898774
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       519
         1.0       0.00      0.00      0.00       489
         2.0       0.00      0.00      0.00       527
         3.0       0.00      0.00      0.00       485
         4.0       0.00      0.00      0.00       492
         5.0       0.19      0.94      0.31      3040
         6.0       0.52      0.19      0.27      2874
         7.0       0.00      0.00      0.00      3064
         8.0       0.00      0.00      0.00      2915
         9.0       0.47      0.14      0.21      3130

    accuracy                           0.22     17535
   macro avg       0.12      0.13      0.08     17535
weighted avg       0.20      0.22      0.14     17535

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.46230181361925404
test acc: 0.5467017263061621
min train acc: 0.7026378896882494
maj train acc: 0.42219557687183584
min test acc: 0.2928571428571428
maj test acc: 0.5894357743097238
total acc: 0.5044535799931483
total min acc: 0.4970131421744325
total maj acc: 0.5057655135639538
precision, recall: (0.5054876527812422, 0.46230181361925404)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['none', 0.5, 103.08085088876503, 0.21531866247499284, 0.21887653264898774, 0.5044535799931483, 0.4970131421744325, 0.5057655135639538, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.00      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.00      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.18      0.94      0.30      2972\n         6.0       0.56      0.18      0.27      3080\n         7.0       0.02      0.00      0.00      2961\n         8.0       0.00      0.00      0.00      3024\n         9.0       0.45      0.13      0.21      3003\n\n    accuracy                           0.22     17495\n   macro avg       0.12      0.13      0.08     17495\nweighted avg       0.21      0.22      0.14     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       519\n         1.0       0.00      0.00      0.00       489\n         2.0       0.00      0.00      0.00       527\n         3.0       0.00      0.00      0.00       485\n         4.0       0.00      0.00      0.00       492\n         5.0       0.19      0.94      0.31      3040\n         6.0       0.52      0.19      0.27      2874\n         7.0       0.00      0.00      0.00      3064\n         8.0       0.00      0.00      0.00      2915\n         9.0       0.47      0.14      0.21      3130\n\n    accuracy                           0.22     17535\n   macro avg       0.12      0.13      0.08     17535\nweighted avg       0.20      0.22      0.14     17535\n']
experiment_number: 175
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-175.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
resampled train counts:  tensor([ 496,  492,  509,  484,  471, 3010, 2926, 3035, 2977, 2954])
resampled test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
training set size:  (17354, 3, 32, 32)
test set size:  (17495, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.949771 Acc@1: 0.035461 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.678092 Acc@1: 0.159656 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.989010 Acc@1: 0.173609 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.996073 Acc@1: 0.173591 
	Train Epoch: 2 	Loss: 1.946934 Acc@1: 0.181180 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.806830 Acc@1: 0.180585 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.469373 Acc@1: 0.188261 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.954741 Acc@1: 0.295349 
	Train Epoch: 3 	Loss: 1.950405 Acc@1: 0.286301 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.108601 Acc@1: 0.201675 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.039005 Acc@1: 0.233960 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.927283 Acc@1: 0.266226 
	Train Epoch: 4 	Loss: 1.847895 Acc@1: 0.266376 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 1.958254 Acc@1: 0.292040 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 1.928212 Acc@1: 0.309962 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.788840 Acc@1: 0.337881 
	Train Epoch: 5 	Loss: 1.885010 Acc@1: 0.302149 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 1.875539 Acc@1: 0.376359 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 1.832713 Acc@1: 0.406167 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.762495 Acc@1: 0.441642 
	Train Epoch: 6 	Loss: 1.866189 Acc@1: 0.444928 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.922289 Acc@1: 0.386482 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.794742 Acc@1: 0.428216 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.662224 Acc@1: 0.488305 
	Train Epoch: 7 	Loss: 1.664923 Acc@1: 0.479137 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.636208 Acc@1: 0.498481 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.644424 Acc@1: 0.502216 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.604675 Acc@1: 0.530364 
	Train Epoch: 8 	Loss: 1.460012 Acc@1: 0.532325 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.567295 Acc@1: 0.523555 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.563333 Acc@1: 0.526534 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.491515 Acc@1: 0.548271 
	Train Epoch: 9 	Loss: 1.527839 Acc@1: 0.531065 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.614863 Acc@1: 0.538881 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.556528 Acc@1: 0.547007 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.485345 Acc@1: 0.557595 
	Train Epoch: 10 	Loss: 1.567460 Acc@1: 0.541209 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.505623 Acc@1: 0.556364 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.468206 Acc@1: 0.566217 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.512989 Acc@1: 0.584759 
	Train Epoch: 11 	Loss: 1.420403 Acc@1: 0.605674 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.413053 Acc@1: 0.582175 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.423216 Acc@1: 0.588993 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.461646 Acc@1: 0.572720 
	Train Epoch: 12 	Loss: 1.436726 Acc@1: 0.575589 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.350502 Acc@1: 0.609873 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.331641 Acc@1: 0.621001 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.400862 Acc@1: 0.628164 
	Train Epoch: 13 	Loss: 1.290761 Acc@1: 0.636616 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.321961 Acc@1: 0.642738 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.326022 Acc@1: 0.642624 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.310093 Acc@1: 0.630622 
	Train Epoch: 14 	Loss: 1.296246 Acc@1: 0.627260 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.343000 Acc@1: 0.638803 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.349290 Acc@1: 0.634084 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.321059 Acc@1: 0.641395 
	Train Epoch: 15 	Loss: 1.238200 Acc@1: 0.668135 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.308031 Acc@1: 0.653941 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.279032 Acc@1: 0.658398 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.370940 Acc@1: 0.639983 
	Train Epoch: 16 	Loss: 1.336398 Acc@1: 0.643052 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.298198 Acc@1: 0.655454 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.288241 Acc@1: 0.657735 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.303720 Acc@1: 0.646937 
	Train Epoch: 17 	Loss: 1.150397 Acc@1: 0.672439 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.255351 Acc@1: 0.662046 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.254055 Acc@1: 0.663366 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.371119 Acc@1: 0.646374 
	Train Epoch: 18 	Loss: 1.299507 Acc@1: 0.655509 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.199195 Acc@1: 0.674615 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.219130 Acc@1: 0.677749 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.350253 Acc@1: 0.655539 
	Train Epoch: 19 	Loss: 1.115097 Acc@1: 0.713296 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.224971 Acc@1: 0.678018 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.233881 Acc@1: 0.676678 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.312759 Acc@1: 0.661283 
	Train Epoch: 20 	Loss: 1.334662 Acc@1: 0.636620 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.213696 Acc@1: 0.673931 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.202766 Acc@1: 0.677938 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.296097 Acc@1: 0.663031 
	Train Epoch: 21 	Loss: 1.110427 Acc@1: 0.703077 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.170867 Acc@1: 0.686058 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.178688 Acc@1: 0.686351 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.320560 Acc@1: 0.665239 
	Train Epoch: 22 	Loss: 1.276410 Acc@1: 0.663636 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.161370 Acc@1: 0.685045 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.191725 Acc@1: 0.689758 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.320578 Acc@1: 0.667021 
	Train Epoch: 23 	Loss: 1.180691 Acc@1: 0.680174 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.202091 Acc@1: 0.688016 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.202364 Acc@1: 0.688710 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.304643 Acc@1: 0.667004 
	Train Epoch: 24 	Loss: 1.377482 Acc@1: 0.658741 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.175179 Acc@1: 0.691615 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.191801 Acc@1: 0.687782 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.309759 Acc@1: 0.668450 
	Train Epoch: 25 	Loss: 1.210912 Acc@1: 0.698324 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.196450 Acc@1: 0.689961 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.200184 Acc@1: 0.689382 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.310607 Acc@1: 0.667117 
Base private model test accuracy:  0.6676764789939983
              precision    recall  f1-score   support

         0.0       0.52      0.23      0.32       508
         1.0       0.46      0.17      0.25       482
         2.0       0.24      0.06      0.10       510
         3.0       0.11      0.01      0.02       489
         4.0       0.31      0.05      0.08       466
         5.0       0.58      0.72      0.64      2972
         6.0       0.73      0.78      0.76      3080
         7.0       0.68      0.72      0.69      2961
         8.0       0.74      0.83      0.78      3024
         9.0       0.67      0.75      0.71      3003

    accuracy                           0.67     17495
   macro avg       0.50      0.43      0.44     17495
weighted avg       0.63      0.67      0.64     17495

Base private model train accuracy:  0.6935576812262303
              precision    recall  f1-score   support

         0.0       0.60      0.25      0.35       496
         1.0       0.54      0.20      0.30       492
         2.0       0.32      0.07      0.12       509
         3.0       0.35      0.03      0.06       484
         4.0       0.34      0.05      0.09       471
         5.0       0.61      0.75      0.67      3010
         6.0       0.72      0.80      0.76      2926
         7.0       0.71      0.74      0.72      3035
         8.0       0.77      0.87      0.81      2977
         9.0       0.71      0.78      0.74      2954

    accuracy                           0.69     17354
   macro avg       0.57      0.45      0.46     17354
weighted avg       0.66      0.69      0.66     17354

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.614382851215858
test acc: 0.5001714873670973
min train acc: 0.5816993464052288
maj train acc: 0.6213991769547325
min test acc: 0.5141430948419301
maj test acc: 0.49781601588352087
total acc: 0.5570477502295684
total min acc: 0.5482275350370981
total maj acc: 0.5595174973488866
precision, recall: (0.5494177058641657, 0.614382851215858)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['none', 0.5, 96.86618915789894, 0.6676764789939983, 0.6935576812262303, 0.5570477502295684, 0.5482275350370981, 0.5595174973488866, '              precision    recall  f1-score   support\n\n         0.0       0.52      0.23      0.32       508\n         1.0       0.46      0.17      0.25       482\n         2.0       0.24      0.06      0.10       510\n         3.0       0.11      0.01      0.02       489\n         4.0       0.31      0.05      0.08       466\n         5.0       0.58      0.72      0.64      2972\n         6.0       0.73      0.78      0.76      3080\n         7.0       0.68      0.72      0.69      2961\n         8.0       0.74      0.83      0.78      3024\n         9.0       0.67      0.75      0.71      3003\n\n    accuracy                           0.67     17495\n   macro avg       0.50      0.43      0.44     17495\nweighted avg       0.63      0.67      0.64     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.60      0.25      0.35       496\n         1.0       0.54      0.20      0.30       492\n         2.0       0.32      0.07      0.12       509\n         3.0       0.35      0.03      0.06       484\n         4.0       0.34      0.05      0.09       471\n         5.0       0.61      0.75      0.67      3010\n         6.0       0.72      0.80      0.76      2926\n         7.0       0.71      0.74      0.72      3035\n         8.0       0.77      0.87      0.81      2977\n         9.0       0.71      0.78      0.74      2954\n\n    accuracy                           0.69     17354\n   macro avg       0.57      0.45      0.46     17354\nweighted avg       0.66      0.69      0.66     17354\n']
experiment_number: 176
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-176.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1248, 1225, 1253, 1219, 1273, 3005, 3122, 3132, 3148, 3093])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21718, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.615089 Acc@1: 0.061224 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.427936 Acc@1: 0.159034 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.551456 Acc@1: 0.153620 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.052318 Acc@1: 0.178963 
	Train Epoch: 2 	Loss: 2.268772 Acc@1: 0.150502 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.461038 Acc@1: 0.148189 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.360218 Acc@1: 0.171969 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.118423 Acc@1: 0.167983 
	Train Epoch: 3 	Loss: 2.225345 Acc@1: 0.130841 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.210862 Acc@1: 0.157803 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.199151 Acc@1: 0.172176 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.016483 Acc@1: 0.298625 
	Train Epoch: 4 	Loss: 2.167623 Acc@1: 0.220073 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.159501 Acc@1: 0.199888 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.182369 Acc@1: 0.210623 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.909524 Acc@1: 0.331301 
	Train Epoch: 5 	Loss: 2.048525 Acc@1: 0.254695 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.035767 Acc@1: 0.296601 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.004665 Acc@1: 0.312475 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.971150 Acc@1: 0.332251 
	Train Epoch: 6 	Loss: 2.064606 Acc@1: 0.293275 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.940604 Acc@1: 0.341123 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.985721 Acc@1: 0.357432 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.645416 Acc@1: 0.454420 
	Train Epoch: 7 	Loss: 1.838279 Acc@1: 0.387665 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.824331 Acc@1: 0.397095 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.805827 Acc@1: 0.409185 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.567760 Acc@1: 0.512355 
	Train Epoch: 8 	Loss: 1.656388 Acc@1: 0.452273 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.781411 Acc@1: 0.446379 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.756525 Acc@1: 0.444607 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.623230 Acc@1: 0.515265 
	Train Epoch: 9 	Loss: 1.768164 Acc@1: 0.463768 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.681698 Acc@1: 0.476030 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.698138 Acc@1: 0.476018 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.511778 Acc@1: 0.538770 
	Train Epoch: 10 	Loss: 1.693007 Acc@1: 0.474453 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.620673 Acc@1: 0.495721 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.636788 Acc@1: 0.494202 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.465476 Acc@1: 0.555204 
	Train Epoch: 11 	Loss: 1.643265 Acc@1: 0.492537 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.607947 Acc@1: 0.506407 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.621998 Acc@1: 0.505475 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.447245 Acc@1: 0.563753 
	Train Epoch: 12 	Loss: 1.583593 Acc@1: 0.505669 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.605455 Acc@1: 0.517607 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.576382 Acc@1: 0.522786 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.442016 Acc@1: 0.574009 
	Train Epoch: 13 	Loss: 1.601997 Acc@1: 0.496910 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.539147 Acc@1: 0.538761 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.558974 Acc@1: 0.536965 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.410286 Acc@1: 0.588965 
	Train Epoch: 14 	Loss: 1.482547 Acc@1: 0.549824 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.505307 Acc@1: 0.556597 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.502262 Acc@1: 0.559009 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.343942 Acc@1: 0.618267 
	Train Epoch: 15 	Loss: 1.387347 Acc@1: 0.592866 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.482755 Acc@1: 0.566027 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.462889 Acc@1: 0.575473 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.363936 Acc@1: 0.623689 
	Train Epoch: 16 	Loss: 1.429140 Acc@1: 0.563164 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.443172 Acc@1: 0.588023 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.433683 Acc@1: 0.591425 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.383508 Acc@1: 0.624218 
	Train Epoch: 17 	Loss: 1.537580 Acc@1: 0.589569 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.458507 Acc@1: 0.601401 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.460198 Acc@1: 0.599841 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.372668 Acc@1: 0.639534 
	Train Epoch: 18 	Loss: 1.454158 Acc@1: 0.591232 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.444529 Acc@1: 0.600780 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.428614 Acc@1: 0.600049 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.339565 Acc@1: 0.638118 
	Train Epoch: 19 	Loss: 1.321408 Acc@1: 0.627358 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.355571 Acc@1: 0.620482 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.378626 Acc@1: 0.620255 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.387911 Acc@1: 0.633243 
	Train Epoch: 20 	Loss: 1.376602 Acc@1: 0.618056 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.372343 Acc@1: 0.620176 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.371991 Acc@1: 0.623151 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.385294 Acc@1: 0.645598 
	Train Epoch: 21 	Loss: 1.377896 Acc@1: 0.613610 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.396323 Acc@1: 0.622168 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.411620 Acc@1: 0.620737 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.357886 Acc@1: 0.647369 
	Train Epoch: 22 	Loss: 1.269020 Acc@1: 0.644128 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.390321 Acc@1: 0.628375 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.376902 Acc@1: 0.629024 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.353015 Acc@1: 0.650513 
	Train Epoch: 23 	Loss: 1.359037 Acc@1: 0.624429 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.378882 Acc@1: 0.628329 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.368568 Acc@1: 0.628263 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.341276 Acc@1: 0.649362 
	Train Epoch: 24 	Loss: 1.469298 Acc@1: 0.594022 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.363436 Acc@1: 0.623614 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.343594 Acc@1: 0.626526 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.345808 Acc@1: 0.651472 
	Train Epoch: 25 	Loss: 1.326206 Acc@1: 0.644342 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.351446 Acc@1: 0.627635 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.354393 Acc@1: 0.629689 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.346840 Acc@1: 0.649727 
Base private model test accuracy:  0.6497856530437268
              precision    recall  f1-score   support

         0.0       0.38      0.35      0.37       508
         1.0       0.32      0.43      0.36       482
         2.0       0.28      0.25      0.27       510
         3.0       0.13      0.06      0.08       489
         4.0       0.24      0.21      0.23       466
         5.0       0.60      0.65      0.62      2972
         6.0       0.74      0.75      0.75      3080
         7.0       0.69      0.67      0.68      2961
         8.0       0.79      0.77      0.78      3024
         9.0       0.72      0.71      0.72      3003

    accuracy                           0.65     17495
   macro avg       0.49      0.49      0.48     17495
weighted avg       0.64      0.65      0.65     17495

Base private model train accuracy:  0.633667925223317
              precision    recall  f1-score   support

         0.0       0.65      0.51      0.57      1248
         1.0       0.60      0.57      0.59      1225
         2.0       0.52      0.32      0.40      1253
         3.0       0.45      0.14      0.22      1219
         4.0       0.60      0.38      0.47      1273
         5.0       0.54      0.69      0.61      3005
         6.0       0.64      0.77      0.70      3122
         7.0       0.64      0.69      0.67      3132
         8.0       0.73      0.80      0.76      3148
         9.0       0.68      0.72      0.70      3093

    accuracy                           0.63     21718
   macro avg       0.61      0.56      0.57     21718
weighted avg       0.63      0.63      0.62     21718

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5825582466157104
test acc: 0.6551020408163265
min train acc: 0.7340983606557377
maj train acc: 0.5231266149870801
min test acc: 0.7945911139729556
maj test acc: 0.5985163977095262
total acc: 0.6186977217061786
total min acc: 0.7646198830409356
total maj acc: 0.5606846473029046
precision, recall: (0.6298287534846675, 0.5825582466157104)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.4, 96.86618915789894, 0.6497856530437268, 0.633667925223317, 0.6186977217061786, 0.7646198830409356, 0.5606846473029046, '              precision    recall  f1-score   support\n\n         0.0       0.38      0.35      0.37       508\n         1.0       0.32      0.43      0.36       482\n         2.0       0.28      0.25      0.27       510\n         3.0       0.13      0.06      0.08       489\n         4.0       0.24      0.21      0.23       466\n         5.0       0.60      0.65      0.62      2972\n         6.0       0.74      0.75      0.75      3080\n         7.0       0.69      0.67      0.68      2961\n         8.0       0.79      0.77      0.78      3024\n         9.0       0.72      0.71      0.72      3003\n\n    accuracy                           0.65     17495\n   macro avg       0.49      0.49      0.48     17495\nweighted avg       0.64      0.65      0.65     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.65      0.51      0.57      1248\n         1.0       0.60      0.57      0.59      1225\n         2.0       0.52      0.32      0.40      1253\n         3.0       0.45      0.14      0.22      1219\n         4.0       0.60      0.38      0.47      1273\n         5.0       0.54      0.69      0.61      3005\n         6.0       0.64      0.77      0.70      3122\n         7.0       0.64      0.69      0.67      3132\n         8.0       0.73      0.80      0.76      3148\n         9.0       0.68      0.72      0.70      3093\n\n    accuracy                           0.63     21718\n   macro avg       0.61      0.56      0.57     21718\nweighted avg       0.63      0.63      0.62     21718\n']
experiment_number: 14
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-14.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1852, 1826, 1922, 1817, 1767, 3104, 3022, 3104, 3089, 3049])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (24552, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.730841 Acc@1: 0.119166 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.499016 Acc@1: 0.129701 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.429250 Acc@1: 0.131399 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.198526 Acc@1: 0.234140 
	Train Epoch: 2 	Loss: 2.274714 Acc@1: 0.161935 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.250480 Acc@1: 0.173602 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.281742 Acc@1: 0.157710 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.185436 Acc@1: 0.163983 
	Train Epoch: 3 	Loss: 2.268332 Acc@1: 0.132820 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.271113 Acc@1: 0.143804 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.272153 Acc@1: 0.147545 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.094636 Acc@1: 0.244587 
	Train Epoch: 4 	Loss: 2.262243 Acc@1: 0.161161 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.340572 Acc@1: 0.165137 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.272874 Acc@1: 0.183968 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.024939 Acc@1: 0.353839 
	Train Epoch: 5 	Loss: 2.163795 Acc@1: 0.253717 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.289755 Acc@1: 0.214083 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.203149 Acc@1: 0.236382 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.004368 Acc@1: 0.370333 
	Train Epoch: 6 	Loss: 2.097155 Acc@1: 0.309053 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.261266 Acc@1: 0.258619 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.169097 Acc@1: 0.264036 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.806409 Acc@1: 0.429967 
	Train Epoch: 7 	Loss: 1.990877 Acc@1: 0.307389 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.953988 Acc@1: 0.331304 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.950374 Acc@1: 0.335261 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.745170 Acc@1: 0.435625 
	Train Epoch: 8 	Loss: 1.780229 Acc@1: 0.359649 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.866487 Acc@1: 0.363965 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.988330 Acc@1: 0.344432 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.738197 Acc@1: 0.423853 
	Train Epoch: 9 	Loss: 1.793562 Acc@1: 0.345149 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.864261 Acc@1: 0.362080 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.872715 Acc@1: 0.364777 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.003847 Acc@1: 0.436524 
	Train Epoch: 10 	Loss: 2.284731 Acc@1: 0.349349 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.937068 Acc@1: 0.377231 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.877960 Acc@1: 0.385575 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.863785 Acc@1: 0.407658 
	Train Epoch: 11 	Loss: 1.816857 Acc@1: 0.381198 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.804643 Acc@1: 0.406644 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.765461 Acc@1: 0.421124 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.716853 Acc@1: 0.491881 
	Train Epoch: 12 	Loss: 1.840469 Acc@1: 0.435771 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.779662 Acc@1: 0.442256 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.741040 Acc@1: 0.451171 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.503460 Acc@1: 0.538950 
	Train Epoch: 13 	Loss: 1.547960 Acc@1: 0.502096 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.649013 Acc@1: 0.490491 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.666154 Acc@1: 0.486751 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.493226 Acc@1: 0.552657 
	Train Epoch: 14 	Loss: 1.589054 Acc@1: 0.512742 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.570554 Acc@1: 0.514486 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.585164 Acc@1: 0.516599 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.489620 Acc@1: 0.567788 
	Train Epoch: 15 	Loss: 1.601630 Acc@1: 0.521649 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.570466 Acc@1: 0.524655 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.565024 Acc@1: 0.526679 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.423437 Acc@1: 0.577110 
	Train Epoch: 16 	Loss: 1.380158 Acc@1: 0.570450 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.505801 Acc@1: 0.543785 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.514026 Acc@1: 0.543858 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.555479 Acc@1: 0.556343 
	Train Epoch: 17 	Loss: 1.596074 Acc@1: 0.535857 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.538776 Acc@1: 0.552229 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.523379 Acc@1: 0.554166 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.481121 Acc@1: 0.588263 
	Train Epoch: 18 	Loss: 1.572760 Acc@1: 0.546169 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.515047 Acc@1: 0.551673 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.510280 Acc@1: 0.556545 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.433987 Acc@1: 0.599249 
	Train Epoch: 19 	Loss: 1.557750 Acc@1: 0.584585 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.511988 Acc@1: 0.559789 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.483797 Acc@1: 0.567047 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.521137 Acc@1: 0.592056 
	Train Epoch: 20 	Loss: 1.589404 Acc@1: 0.562124 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.516271 Acc@1: 0.566472 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.505255 Acc@1: 0.566552 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.473527 Acc@1: 0.589807 
	Train Epoch: 21 	Loss: 1.459429 Acc@1: 0.583416 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.483254 Acc@1: 0.571263 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.458795 Acc@1: 0.577278 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.473587 Acc@1: 0.597347 
	Train Epoch: 22 	Loss: 1.438450 Acc@1: 0.566253 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.493794 Acc@1: 0.573657 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.479424 Acc@1: 0.577818 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.460718 Acc@1: 0.598610 
	Train Epoch: 23 	Loss: 1.487843 Acc@1: 0.563731 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.499638 Acc@1: 0.572392 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.495404 Acc@1: 0.573358 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.478266 Acc@1: 0.597401 
	Train Epoch: 24 	Loss: 1.559035 Acc@1: 0.576271 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.472859 Acc@1: 0.580086 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.461135 Acc@1: 0.583805 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.466163 Acc@1: 0.599608 
	Train Epoch: 25 	Loss: 1.490146 Acc@1: 0.599409 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.464083 Acc@1: 0.580822 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.458061 Acc@1: 0.581486 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.458022 Acc@1: 0.601487 
Base private model test accuracy:  0.6008573878250929
              precision    recall  f1-score   support

         0.0       0.30      0.43      0.35       508
         1.0       0.31      0.57      0.40       482
         2.0       0.22      0.33      0.26       510
         3.0       0.12      0.15      0.14       489
         4.0       0.19      0.29      0.23       466
         5.0       0.60      0.54      0.57      2972
         6.0       0.76      0.70      0.73      3080
         7.0       0.68      0.64      0.66      2961
         8.0       0.75      0.69      0.72      3024
         9.0       0.70      0.63      0.66      3003

    accuracy                           0.60     17495
   macro avg       0.46      0.50      0.47     17495
weighted avg       0.63      0.60      0.61     17495

Base private model train accuracy:  0.5825594656239818
              precision    recall  f1-score   support

         0.0       0.60      0.55      0.58      1852
         1.0       0.65      0.64      0.64      1826
         2.0       0.46      0.42      0.44      1922
         3.0       0.43      0.28      0.34      1817
         4.0       0.48      0.36      0.41      1767
         5.0       0.52      0.58      0.55      3104
         6.0       0.62      0.69      0.66      3022
         7.0       0.59      0.65      0.62      3104
         8.0       0.66      0.71      0.68      3089
         9.0       0.64      0.68      0.66      3049

    accuracy                           0.58     24552
   macro avg       0.57      0.56      0.56     24552
weighted avg       0.58      0.58      0.58     24552

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6738351254480287
test acc: 0.6920454545454545
min train acc: 0.8532596685082873
maj train acc: 0.5709160794362588
min test acc: 0.881213686249193
maj test acc: 0.5777691006117402
total acc: 0.6829565783054156
total min acc: 0.8674225904928042
total maj acc: 0.5743155991735537
precision, recall: (0.6855627382728328, 0.6738351254480287)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.6, 96.86618915789894, 0.6008573878250929, 0.5825594656239818, 0.6829565783054156, 0.8674225904928042, 0.5743155991735537, '              precision    recall  f1-score   support\n\n         0.0       0.30      0.43      0.35       508\n         1.0       0.31      0.57      0.40       482\n         2.0       0.22      0.33      0.26       510\n         3.0       0.12      0.15      0.14       489\n         4.0       0.19      0.29      0.23       466\n         5.0       0.60      0.54      0.57      2972\n         6.0       0.76      0.70      0.73      3080\n         7.0       0.68      0.64      0.66      2961\n         8.0       0.75      0.69      0.72      3024\n         9.0       0.70      0.63      0.66      3003\n\n    accuracy                           0.60     17495\n   macro avg       0.46      0.50      0.47     17495\nweighted avg       0.63      0.60      0.61     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.60      0.55      0.58      1852\n         1.0       0.65      0.64      0.64      1826\n         2.0       0.46      0.42      0.44      1922\n         3.0       0.43      0.28      0.34      1817\n         4.0       0.48      0.36      0.41      1767\n         5.0       0.52      0.58      0.55      3104\n         6.0       0.62      0.69      0.66      3022\n         7.0       0.59      0.65      0.62      3104\n         8.0       0.66      0.71      0.68      3089\n         9.0       0.64      0.68      0.66      3049\n\n    accuracy                           0.58     24552\n   macro avg       0.57      0.56      0.56     24552\nweighted avg       0.58      0.58      0.58     24552\n']
experiment_number: 16
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-16.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2482, 2450, 2427, 2473, 2546, 3069, 3092, 3076, 3077, 3092])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (27784, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.828413 Acc@1: 0.074141 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.635785 Acc@1: 0.126890 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.494992 Acc@1: 0.121695 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.251226 Acc@1: 0.232445 
	Train Epoch: 2 	Loss: 2.279021 Acc@1: 0.146781 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.280398 Acc@1: 0.149167 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.324277 Acc@1: 0.144447 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.224664 Acc@1: 0.208681 
	Train Epoch: 3 	Loss: 2.263688 Acc@1: 0.151832 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.616107 Acc@1: 0.120956 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.469108 Acc@1: 0.120774 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.207003 Acc@1: 0.189049 
	Train Epoch: 4 	Loss: 2.287445 Acc@1: 0.123312 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.274371 Acc@1: 0.122683 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.280645 Acc@1: 0.131530 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 3.616556 Acc@1: 0.186576 
	Train Epoch: 5 	Loss: 3.289944 Acc@1: 0.132224 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.388358 Acc@1: 0.144079 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.325172 Acc@1: 0.159338 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.360232 Acc@1: 0.242459 
	Train Epoch: 6 	Loss: 2.434483 Acc@1: 0.158424 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.226352 Acc@1: 0.204192 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.225119 Acc@1: 0.215343 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.967440 Acc@1: 0.281392 
	Train Epoch: 7 	Loss: 3.193319 Acc@1: 0.189312 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.346911 Acc@1: 0.209362 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.247565 Acc@1: 0.217712 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.977069 Acc@1: 0.333782 
	Train Epoch: 8 	Loss: 2.094398 Acc@1: 0.241055 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.562009 Acc@1: 0.258833 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.402052 Acc@1: 0.240089 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.023927 Acc@1: 0.304170 
	Train Epoch: 9 	Loss: 2.116836 Acc@1: 0.237273 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.069721 Acc@1: 0.268278 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.038316 Acc@1: 0.279219 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.993197 Acc@1: 0.392043 
	Train Epoch: 10 	Loss: 2.108192 Acc@1: 0.303957 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.042398 Acc@1: 0.317428 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.001903 Acc@1: 0.326847 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.861215 Acc@1: 0.427136 
	Train Epoch: 11 	Loss: 1.935522 Acc@1: 0.365366 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.913675 Acc@1: 0.356959 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.881430 Acc@1: 0.363178 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.764341 Acc@1: 0.428872 
	Train Epoch: 12 	Loss: 1.829775 Acc@1: 0.412511 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.840913 Acc@1: 0.396965 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.885601 Acc@1: 0.394163 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.879525 Acc@1: 0.361715 
	Train Epoch: 13 	Loss: 1.790854 Acc@1: 0.373394 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.785643 Acc@1: 0.393589 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.807562 Acc@1: 0.400261 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.659074 Acc@1: 0.488145 
	Train Epoch: 14 	Loss: 1.827564 Acc@1: 0.420354 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.752389 Acc@1: 0.451410 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.755552 Acc@1: 0.453524 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.773685 Acc@1: 0.463848 
	Train Epoch: 15 	Loss: 1.771486 Acc@1: 0.445242 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.670987 Acc@1: 0.465956 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.670942 Acc@1: 0.472372 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.565373 Acc@1: 0.529355 
	Train Epoch: 16 	Loss: 1.537675 Acc@1: 0.504314 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.621915 Acc@1: 0.499311 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.651075 Acc@1: 0.496399 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.645771 Acc@1: 0.496347 
	Train Epoch: 17 	Loss: 1.701166 Acc@1: 0.496833 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.631519 Acc@1: 0.505606 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.637122 Acc@1: 0.503771 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.604431 Acc@1: 0.522735 
	Train Epoch: 18 	Loss: 1.659924 Acc@1: 0.489242 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.587591 Acc@1: 0.519083 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.598185 Acc@1: 0.519998 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.606875 Acc@1: 0.537341 
	Train Epoch: 19 	Loss: 1.698784 Acc@1: 0.499099 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.622875 Acc@1: 0.523656 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.613918 Acc@1: 0.520554 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.639724 Acc@1: 0.523048 
	Train Epoch: 20 	Loss: 1.623286 Acc@1: 0.528881 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.604943 Acc@1: 0.532078 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.593945 Acc@1: 0.529410 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.646725 Acc@1: 0.522932 
	Train Epoch: 21 	Loss: 1.423784 Acc@1: 0.560731 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.565997 Acc@1: 0.535885 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.578372 Acc@1: 0.535610 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.609065 Acc@1: 0.539665 
	Train Epoch: 22 	Loss: 1.530974 Acc@1: 0.547093 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.576781 Acc@1: 0.538998 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.572983 Acc@1: 0.540789 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.610882 Acc@1: 0.542453 
	Train Epoch: 23 	Loss: 1.609145 Acc@1: 0.528725 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.567153 Acc@1: 0.541629 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.559213 Acc@1: 0.542377 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.591603 Acc@1: 0.548201 
	Train Epoch: 24 	Loss: 1.478819 Acc@1: 0.556728 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.551366 Acc@1: 0.543948 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.547400 Acc@1: 0.540992 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.596715 Acc@1: 0.548011 
	Train Epoch: 25 	Loss: 1.655930 Acc@1: 0.504554 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.556316 Acc@1: 0.546940 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.559610 Acc@1: 0.547801 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.589166 Acc@1: 0.548401 
Base private model test accuracy:  0.5478136610460131
              precision    recall  f1-score   support

         0.0       0.27      0.50      0.35       508
         1.0       0.24      0.57      0.33       482
         2.0       0.18      0.35      0.24       510
         3.0       0.10      0.20      0.13       489
         4.0       0.17      0.33      0.23       466
         5.0       0.57      0.48      0.52      2972
         6.0       0.75      0.62      0.68      3080
         7.0       0.68      0.57      0.62      2961
         8.0       0.77      0.66      0.71      3024
         9.0       0.66      0.53      0.59      3003

    accuracy                           0.55     17495
   macro avg       0.44      0.48      0.44     17495
weighted avg       0.62      0.55      0.57     17495

Base private model train accuracy:  0.5422545349841635
              precision    recall  f1-score   support

         0.0       0.58      0.60      0.59      2482
         1.0       0.58      0.64      0.61      2450
         2.0       0.43      0.44      0.44      2427
         3.0       0.46      0.36      0.40      2473
         4.0       0.53      0.43      0.47      2546
         5.0       0.44      0.50      0.47      3069
         6.0       0.58      0.63      0.61      3092
         7.0       0.57      0.56      0.57      3076
         8.0       0.63      0.65      0.64      3077
         9.0       0.58      0.56      0.57      3092

    accuracy                           0.54     27784
   macro avg       0.54      0.54      0.54     27784
weighted avg       0.54      0.54      0.54     27784

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7134321911891737
test acc: 0.7129870129870131
min train acc: 0.8945878434637802
maj train acc: 0.575333757151939
min test acc: 0.8883826879271071
maj test acc: 0.5732780942516831
total acc: 0.713209858748919
total min acc: 0.8914492634351082
total maj acc: 0.574315222272115
precision, recall: (0.7135862913096696, 0.7134321911891737)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.8, 96.86618915789894, 0.5478136610460131, 0.5422545349841635, 0.713209858748919, 0.8914492634351082, 0.574315222272115, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.50      0.35       508\n         1.0       0.24      0.57      0.33       482\n         2.0       0.18      0.35      0.24       510\n         3.0       0.10      0.20      0.13       489\n         4.0       0.17      0.33      0.23       466\n         5.0       0.57      0.48      0.52      2972\n         6.0       0.75      0.62      0.68      3080\n         7.0       0.68      0.57      0.62      2961\n         8.0       0.77      0.66      0.71      3024\n         9.0       0.66      0.53      0.59      3003\n\n    accuracy                           0.55     17495\n   macro avg       0.44      0.48      0.44     17495\nweighted avg       0.62      0.55      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.58      0.60      0.59      2482\n         1.0       0.58      0.64      0.61      2450\n         2.0       0.43      0.44      0.44      2427\n         3.0       0.46      0.36      0.40      2473\n         4.0       0.53      0.43      0.47      2546\n         5.0       0.44      0.50      0.47      3069\n         6.0       0.58      0.63      0.61      3092\n         7.0       0.57      0.56      0.57      3076\n         8.0       0.63      0.65      0.64      3077\n         9.0       0.58      0.56      0.57      3092\n\n    accuracy                           0.54     27784\n   macro avg       0.54      0.54      0.54     27784\nweighted avg       0.54      0.54      0.54     27784\n']
experiment_number: 17
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-17.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([3125, 3042, 3093, 2999, 3091, 3060, 3108, 3043, 3043, 3001])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30605, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.504271 Acc@1: 0.104441 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.315352 Acc@1: 0.131525 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.474716 Acc@1: 0.119024 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.267857 Acc@1: 0.128458 
	Train Epoch: 2 	Loss: 2.271644 Acc@1: 0.122466 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.483174 Acc@1: 0.112992 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.385779 Acc@1: 0.126561 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.304195 Acc@1: 0.040238 
	Train Epoch: 3 	Loss: 2.293300 Acc@1: 0.151004 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.287154 Acc@1: 0.140726 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.339914 Acc@1: 0.131855 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.189668 Acc@1: 0.199906 
	Train Epoch: 4 	Loss: 2.299317 Acc@1: 0.151438 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.293659 Acc@1: 0.166075 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.330668 Acc@1: 0.142686 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.221703 Acc@1: 0.131774 
	Train Epoch: 5 	Loss: 2.363598 Acc@1: 0.075833 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.293208 Acc@1: 0.125557 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.310726 Acc@1: 0.122393 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.291808 Acc@1: 0.083474 
	Train Epoch: 6 	Loss: 2.289140 Acc@1: 0.112530 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.279183 Acc@1: 0.114958 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.281225 Acc@1: 0.124922 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.294995 Acc@1: 0.132877 
	Train Epoch: 7 	Loss: 2.276292 Acc@1: 0.103586 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.349687 Acc@1: 0.146993 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.299991 Acc@1: 0.174949 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.177550 Acc@1: 0.198311 
	Train Epoch: 8 	Loss: 2.202163 Acc@1: 0.205021 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.669819 Acc@1: 0.198032 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.541386 Acc@1: 0.151148 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.323497 Acc@1: 0.171889 
	Train Epoch: 9 	Loss: 2.300853 Acc@1: 0.094197 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.290864 Acc@1: 0.106096 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.294607 Acc@1: 0.117475 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.272006 Acc@1: 0.106635 
	Train Epoch: 10 	Loss: 2.274227 Acc@1: 0.139937 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.282768 Acc@1: 0.119157 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.265554 Acc@1: 0.129938 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.145345 Acc@1: 0.226654 
	Train Epoch: 11 	Loss: 2.244730 Acc@1: 0.201946 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.208349 Acc@1: 0.224900 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.276101 Acc@1: 0.226757 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.232104 Acc@1: 0.264934 
	Train Epoch: 12 	Loss: 2.223958 Acc@1: 0.243822 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.284686 Acc@1: 0.243993 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.243225 Acc@1: 0.237902 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.222902 Acc@1: 0.125354 
	Train Epoch: 13 	Loss: 2.120391 Acc@1: 0.229654 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.106085 Acc@1: 0.264289 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.065468 Acc@1: 0.278256 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.878954 Acc@1: 0.306298 
	Train Epoch: 14 	Loss: 1.909250 Acc@1: 0.313273 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.948291 Acc@1: 0.321859 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.930383 Acc@1: 0.330926 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.781416 Acc@1: 0.405563 
	Train Epoch: 15 	Loss: 1.846021 Acc@1: 0.365254 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.860913 Acc@1: 0.369106 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.865908 Acc@1: 0.371641 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.891365 Acc@1: 0.388423 
	Train Epoch: 16 	Loss: 1.737360 Acc@1: 0.395175 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.827559 Acc@1: 0.397663 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.833917 Acc@1: 0.399261 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.747149 Acc@1: 0.439144 
	Train Epoch: 17 	Loss: 1.712948 Acc@1: 0.409201 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.787082 Acc@1: 0.415060 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.780624 Acc@1: 0.419522 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.803116 Acc@1: 0.423107 
	Train Epoch: 18 	Loss: 1.703158 Acc@1: 0.449351 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.739673 Acc@1: 0.436545 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.763208 Acc@1: 0.434418 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.720457 Acc@1: 0.455240 
	Train Epoch: 19 	Loss: 1.730088 Acc@1: 0.446473 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.716660 Acc@1: 0.447480 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.724417 Acc@1: 0.448537 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.855312 Acc@1: 0.434017 
	Train Epoch: 20 	Loss: 1.738093 Acc@1: 0.435418 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.760830 Acc@1: 0.442383 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.744439 Acc@1: 0.446890 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.768563 Acc@1: 0.448340 
	Train Epoch: 21 	Loss: 1.703424 Acc@1: 0.471831 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.745902 Acc@1: 0.451053 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.738036 Acc@1: 0.453634 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.741767 Acc@1: 0.455222 
	Train Epoch: 22 	Loss: 1.804654 Acc@1: 0.429975 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.744993 Acc@1: 0.445274 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.725803 Acc@1: 0.450739 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.775139 Acc@1: 0.447284 
	Train Epoch: 23 	Loss: 1.728934 Acc@1: 0.466437 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.692148 Acc@1: 0.461883 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.703047 Acc@1: 0.461384 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.734865 Acc@1: 0.456558 
	Train Epoch: 24 	Loss: 1.740837 Acc@1: 0.448363 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.709352 Acc@1: 0.461920 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.700651 Acc@1: 0.461838 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.746596 Acc@1: 0.456964 
	Train Epoch: 25 	Loss: 1.740031 Acc@1: 0.442786 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.732818 Acc@1: 0.454263 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.729005 Acc@1: 0.458513 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.738491 Acc@1: 0.460471 
Base private model test accuracy:  0.4605887396398971
              precision    recall  f1-score   support

         0.0       0.19      0.48      0.27       508
         1.0       0.19      0.56      0.28       482
         2.0       0.15      0.39      0.21       510
         3.0       0.08      0.22      0.12       489
         4.0       0.13      0.28      0.17       466
         5.0       0.62      0.40      0.48      2972
         6.0       0.62      0.53      0.57      3080
         7.0       0.63      0.50      0.56      2961
         8.0       0.77      0.52      0.62      3024
         9.0       0.57      0.42      0.48      3003

    accuracy                           0.46     17495
   macro avg       0.39      0.43      0.38     17495
weighted avg       0.57      0.46      0.50     17495

Base private model train accuracy:  0.46273484724718184
              precision    recall  f1-score   support

         0.0       0.55      0.56      0.56      3125
         1.0       0.53      0.60      0.56      3042
         2.0       0.42      0.44      0.43      3093
         3.0       0.35      0.28      0.31      2999
         4.0       0.44      0.33      0.38      3091
         5.0       0.41      0.39      0.40      3060
         6.0       0.45      0.54      0.49      3108
         7.0       0.48      0.51      0.49      3043
         8.0       0.61      0.53      0.57      3043
         9.0       0.39      0.44      0.41      3001

    accuracy                           0.46     30605
   macro avg       0.46      0.46      0.46     30605
weighted avg       0.46      0.46      0.46     30605

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7285322180107175
test acc: 0.7163636363636363
min train acc: 0.8929142248268513
maj train acc: 0.5731460389774741
min test acc: 0.8842281879194631
maj test acc: 0.5465935787000783
total acc: 0.7224285062862355
total min acc: 0.8885028841111694
total maj acc: 0.5600745309689026
precision, recall: (0.7184841453982985, 0.7285322180107175)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 1.0, 96.86618915789894, 0.4605887396398971, 0.46273484724718184, 0.7224285062862355, 0.8885028841111694, 0.5600745309689026, '              precision    recall  f1-score   support\n\n         0.0       0.19      0.48      0.27       508\n         1.0       0.19      0.56      0.28       482\n         2.0       0.15      0.39      0.21       510\n         3.0       0.08      0.22      0.12       489\n         4.0       0.13      0.28      0.17       466\n         5.0       0.62      0.40      0.48      2972\n         6.0       0.62      0.53      0.57      3080\n         7.0       0.63      0.50      0.56      2961\n         8.0       0.77      0.52      0.62      3024\n         9.0       0.57      0.42      0.48      3003\n\n    accuracy                           0.46     17495\n   macro avg       0.39      0.43      0.38     17495\nweighted avg       0.57      0.46      0.50     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.55      0.56      0.56      3125\n         1.0       0.53      0.60      0.56      3042\n         2.0       0.42      0.44      0.43      3093\n         3.0       0.35      0.28      0.31      2999\n         4.0       0.44      0.33      0.38      3091\n         5.0       0.41      0.39      0.40      3060\n         6.0       0.45      0.54      0.49      3108\n         7.0       0.48      0.51      0.49      3043\n         8.0       0.61      0.53      0.57      3043\n         9.0       0.39      0.44      0.41      3001\n\n    accuracy                           0.46     30605\n   macro avg       0.46      0.46      0.46     30605\nweighted avg       0.46      0.46      0.46     30605\n']
experiment_number: 18
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-18.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.4
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 1165, 6.0: 1165, 7.0: 1165, 8.0: 1165, 9.0: 1165}
resampled train counts:  tensor([ 483,  484,  421,  497,  437, 1193, 1122, 1182, 1161, 1171])
resampled test counts:  tensor([ 466,  466,  466,  466,  466, 1165, 1165, 1165, 1165, 1165])
training set size:  (8151, 3, 32, 32)
test set size:  (8155, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.758132 Acc@1: 0.061584 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.686232 Acc@1: 0.132227 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.516442 Acc@1: 0.134605 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.082001 Acc@1: 0.169182 
	Train Epoch: 2 	Loss: 2.223566 Acc@1: 0.148515 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.246016 Acc@1: 0.162052 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.451133 Acc@1: 0.176472 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.105944 Acc@1: 0.174537 
	Train Epoch: 3 	Loss: 2.207725 Acc@1: 0.126984 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.205243 Acc@1: 0.169421 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.209773 Acc@1: 0.168646 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.041943 Acc@1: 0.235685 
	Train Epoch: 4 	Loss: 2.141292 Acc@1: 0.211144 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.197204 Acc@1: 0.210919 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.184265 Acc@1: 0.241294 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.377524 Acc@1: 0.235958 
	Train Epoch: 5 	Loss: 2.430319 Acc@1: 0.235849 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.288752 Acc@1: 0.201529 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.247500 Acc@1: 0.214042 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.927451 Acc@1: 0.325842 
	Train Epoch: 6 	Loss: 2.069813 Acc@1: 0.264957 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.146600 Acc@1: 0.300187 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.148535 Acc@1: 0.295169 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.016118 Acc@1: 0.328251 
	Train Epoch: 7 	Loss: 2.073278 Acc@1: 0.298413 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.151267 Acc@1: 0.272649 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.135883 Acc@1: 0.288004 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.885461 Acc@1: 0.342200 
	Train Epoch: 8 	Loss: 1.990080 Acc@1: 0.351515 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.044306 Acc@1: 0.317505 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.054722 Acc@1: 0.326624 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.872925 Acc@1: 0.367726 
	Train Epoch: 9 	Loss: 2.000346 Acc@1: 0.314935 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.000949 Acc@1: 0.344024 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 1.995137 Acc@1: 0.357062 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.760843 Acc@1: 0.448446 
	Train Epoch: 10 	Loss: 1.872101 Acc@1: 0.402439 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.958592 Acc@1: 0.371447 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.978945 Acc@1: 0.367818 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.787657 Acc@1: 0.434975 
	Train Epoch: 11 	Loss: 1.885697 Acc@1: 0.381503 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.833997 Acc@1: 0.410360 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.844196 Acc@1: 0.412802 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.676286 Acc@1: 0.486716 
	Train Epoch: 12 	Loss: 1.800012 Acc@1: 0.452096 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.812770 Acc@1: 0.439476 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.795317 Acc@1: 0.438541 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.678155 Acc@1: 0.483166 
	Train Epoch: 13 	Loss: 1.936713 Acc@1: 0.420063 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.817172 Acc@1: 0.447334 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.768275 Acc@1: 0.452326 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.603131 Acc@1: 0.523458 
	Train Epoch: 14 	Loss: 1.627050 Acc@1: 0.490683 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.768781 Acc@1: 0.466608 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.773692 Acc@1: 0.462541 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.624015 Acc@1: 0.511509 
	Train Epoch: 15 	Loss: 1.741340 Acc@1: 0.472727 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.700546 Acc@1: 0.473413 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.702313 Acc@1: 0.477227 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.730221 Acc@1: 0.506267 
	Train Epoch: 16 	Loss: 1.790852 Acc@1: 0.474522 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.724714 Acc@1: 0.465498 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.701716 Acc@1: 0.474296 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.663004 Acc@1: 0.508012 
	Train Epoch: 17 	Loss: 1.533700 Acc@1: 0.529412 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.710500 Acc@1: 0.491587 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.688778 Acc@1: 0.489803 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.679728 Acc@1: 0.527487 
	Train Epoch: 18 	Loss: 1.876726 Acc@1: 0.458580 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.632900 Acc@1: 0.505090 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.641288 Acc@1: 0.511238 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.581652 Acc@1: 0.551301 
	Train Epoch: 19 	Loss: 1.640061 Acc@1: 0.511111 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.648277 Acc@1: 0.520923 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.652766 Acc@1: 0.515919 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.587677 Acc@1: 0.552657 
	Train Epoch: 20 	Loss: 1.757033 Acc@1: 0.510753 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.630898 Acc@1: 0.513042 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.636742 Acc@1: 0.507770 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.637675 Acc@1: 0.536419 
	Train Epoch: 21 	Loss: 1.687160 Acc@1: 0.488024 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.664016 Acc@1: 0.514474 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.617979 Acc@1: 0.521370 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.614927 Acc@1: 0.552247 
	Train Epoch: 22 	Loss: 1.902791 Acc@1: 0.484375 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.621498 Acc@1: 0.526700 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.623254 Acc@1: 0.530279 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.590093 Acc@1: 0.552407 
	Train Epoch: 23 	Loss: 1.604785 Acc@1: 0.546479 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.562250 Acc@1: 0.539980 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.574926 Acc@1: 0.536163 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.603273 Acc@1: 0.552534 
	Train Epoch: 24 	Loss: 1.704652 Acc@1: 0.537815 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.618126 Acc@1: 0.531595 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.595244 Acc@1: 0.537319 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.581634 Acc@1: 0.555025 
	Train Epoch: 25 	Loss: 1.515211 Acc@1: 0.554318 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.621166 Acc@1: 0.529917 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.603906 Acc@1: 0.532478 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.585655 Acc@1: 0.555051 
Base private model test accuracy:  0.5554158330951701
              precision    recall  f1-score   support

         0.0       0.20      0.16      0.18       508
         1.0       0.18      0.14      0.16       482
         2.0       0.19      0.18      0.19       510
         3.0       0.07      0.05      0.06       489
         4.0       0.13      0.10      0.12       466
         5.0       0.50      0.56      0.53      2972
         6.0       0.69      0.67      0.68      3080
         7.0       0.61      0.54      0.57      2961
         8.0       0.68      0.70      0.69      3024
         9.0       0.57      0.65      0.61      3003

    accuracy                           0.56     17495
   macro avg       0.38      0.38      0.38     17495
weighted avg       0.55      0.56      0.55     17495

Base private model train accuracy:  0.5379708011286959
              precision    recall  f1-score   support

         0.0       0.57      0.27      0.36       483
         1.0       0.48      0.20      0.28       484
         2.0       0.33      0.24      0.28       421
         3.0       0.24      0.09      0.14       497
         4.0       0.35      0.11      0.17       437
         5.0       0.48      0.63      0.55      1193
         6.0       0.60      0.70      0.65      1122
         7.0       0.56      0.61      0.58      1182
         8.0       0.61      0.75      0.67      1161
         9.0       0.55      0.71      0.62      1171

    accuracy                           0.54      8151
   macro avg       0.48      0.43      0.43      8151
weighted avg       0.51      0.54      0.51      8151

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6039263803680982
test acc: 0.5351974491047339
min train acc: 0.5858921161825726
maj train acc: 0.611380985426787
min test acc: 0.5538971807628523
maj test acc: 0.5275945852134676
total acc: 0.5695534838076546
total min acc: 0.569888013272501
total maj acc: 0.5694950546590317
precision, recall: (0.5649678604224059, 0.6039263803680982)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.4, 96.86618915789894, 0.5554158330951701, 0.5379708011286959, 0.5695534838076546, 0.569888013272501, 0.5694950546590317, '              precision    recall  f1-score   support\n\n         0.0       0.20      0.16      0.18       508\n         1.0       0.18      0.14      0.16       482\n         2.0       0.19      0.18      0.19       510\n         3.0       0.07      0.05      0.06       489\n         4.0       0.13      0.10      0.12       466\n         5.0       0.50      0.56      0.53      2972\n         6.0       0.69      0.67      0.68      3080\n         7.0       0.61      0.54      0.57      2961\n         8.0       0.68      0.70      0.69      3024\n         9.0       0.57      0.65      0.61      3003\n\n    accuracy                           0.56     17495\n   macro avg       0.38      0.38      0.38     17495\nweighted avg       0.55      0.56      0.55     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.27      0.36       483\n         1.0       0.48      0.20      0.28       484\n         2.0       0.33      0.24      0.28       421\n         3.0       0.24      0.09      0.14       497\n         4.0       0.35      0.11      0.17       437\n         5.0       0.48      0.63      0.55      1193\n         6.0       0.60      0.70      0.65      1122\n         7.0       0.56      0.61      0.58      1182\n         8.0       0.61      0.75      0.67      1161\n         9.0       0.55      0.71      0.62      1171\n\n    accuracy                           0.54      8151\n   macro avg       0.48      0.43      0.43      8151\nweighted avg       0.51      0.54      0.51      8151\n']
experiment_number: 9
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-9.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.6
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 776, 6.0: 776, 7.0: 776, 8.0: 776, 9.0: 776}
resampled train counts:  tensor([432, 461, 442, 457, 523, 787, 867, 787, 807, 732])
resampled test counts:  tensor([466, 466, 466, 466, 466, 776, 776, 776, 776, 776])
training set size:  (6295, 3, 32, 32)
test set size:  (6210, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.219949 Acc@1: 0.048583 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 3.001393 Acc@1: 0.109531 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.943346 Acc@1: 0.115194 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.185798 Acc@1: 0.190042 
	Train Epoch: 2 	Loss: 2.246114 Acc@1: 0.187739 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.289583 Acc@1: 0.128565 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.544538 Acc@1: 0.142794 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.176292 Acc@1: 0.192989 
	Train Epoch: 3 	Loss: 2.251869 Acc@1: 0.159483 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.380525 Acc@1: 0.133836 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.325819 Acc@1: 0.155597 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.052356 Acc@1: 0.296058 
	Train Epoch: 4 	Loss: 2.118878 Acc@1: 0.241935 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.293825 Acc@1: 0.185123 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.282755 Acc@1: 0.180134 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.037125 Acc@1: 0.277099 
	Train Epoch: 5 	Loss: 2.173282 Acc@1: 0.244898 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.361310 Acc@1: 0.220743 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.260045 Acc@1: 0.233713 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.921466 Acc@1: 0.376748 
	Train Epoch: 6 	Loss: 2.069758 Acc@1: 0.273810 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.248686 Acc@1: 0.257812 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.182012 Acc@1: 0.270891 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.894725 Acc@1: 0.397484 
	Train Epoch: 7 	Loss: 1.908559 Acc@1: 0.333333 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.070649 Acc@1: 0.316825 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.091021 Acc@1: 0.316539 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.879574 Acc@1: 0.419050 
	Train Epoch: 8 	Loss: 2.155406 Acc@1: 0.351351 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.130096 Acc@1: 0.310113 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.106383 Acc@1: 0.316227 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.826904 Acc@1: 0.395805 
	Train Epoch: 9 	Loss: 1.905224 Acc@1: 0.329502 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.001504 Acc@1: 0.316886 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.031018 Acc@1: 0.330551 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.005828 Acc@1: 0.421082 
	Train Epoch: 10 	Loss: 2.257150 Acc@1: 0.376068 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.133730 Acc@1: 0.332798 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.095806 Acc@1: 0.347144 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.890218 Acc@1: 0.393198 
	Train Epoch: 11 	Loss: 2.166413 Acc@1: 0.356828 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.983631 Acc@1: 0.357681 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.959989 Acc@1: 0.364315 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.843770 Acc@1: 0.418738 
	Train Epoch: 12 	Loss: 1.802508 Acc@1: 0.369748 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.878179 Acc@1: 0.402148 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.896502 Acc@1: 0.402418 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.760479 Acc@1: 0.452772 
	Train Epoch: 13 	Loss: 2.042937 Acc@1: 0.387352 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.027758 Acc@1: 0.383063 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.026376 Acc@1: 0.385636 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.709043 Acc@1: 0.452709 
	Train Epoch: 14 	Loss: 2.078014 Acc@1: 0.357664 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.971764 Acc@1: 0.370758 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.971283 Acc@1: 0.389537 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.764329 Acc@1: 0.436310 
	Train Epoch: 15 	Loss: 1.923839 Acc@1: 0.423664 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.851048 Acc@1: 0.406740 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.948244 Acc@1: 0.391197 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.737118 Acc@1: 0.442604 
	Train Epoch: 16 	Loss: 1.827889 Acc@1: 0.369099 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.819743 Acc@1: 0.409560 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.810192 Acc@1: 0.421620 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.690670 Acc@1: 0.473476 
	Train Epoch: 17 	Loss: 1.759189 Acc@1: 0.408072 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.761758 Acc@1: 0.439454 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.766760 Acc@1: 0.447010 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.785324 Acc@1: 0.452165 
	Train Epoch: 18 	Loss: 1.850866 Acc@1: 0.381743 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.774023 Acc@1: 0.448288 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.759247 Acc@1: 0.453737 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.644549 Acc@1: 0.491718 
	Train Epoch: 19 	Loss: 1.579056 Acc@1: 0.517375 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.681007 Acc@1: 0.467621 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.728502 Acc@1: 0.462294 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.725715 Acc@1: 0.478517 
	Train Epoch: 20 	Loss: 1.713893 Acc@1: 0.485944 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.641893 Acc@1: 0.472134 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.655753 Acc@1: 0.480472 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.701793 Acc@1: 0.498725 
	Train Epoch: 21 	Loss: 1.520979 Acc@1: 0.495798 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.679833 Acc@1: 0.489682 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.676588 Acc@1: 0.494418 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.709961 Acc@1: 0.489110 
	Train Epoch: 22 	Loss: 1.692365 Acc@1: 0.468000 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.675865 Acc@1: 0.477512 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.674409 Acc@1: 0.478627 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.724801 Acc@1: 0.497825 
	Train Epoch: 23 	Loss: 1.745107 Acc@1: 0.467433 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.694709 Acc@1: 0.499299 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.702426 Acc@1: 0.495146 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.687937 Acc@1: 0.500250 
	Train Epoch: 24 	Loss: 1.622893 Acc@1: 0.506383 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.662264 Acc@1: 0.489745 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.652790 Acc@1: 0.487473 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.700555 Acc@1: 0.498681 
	Train Epoch: 25 	Loss: 1.625914 Acc@1: 0.532787 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.582301 Acc@1: 0.513877 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.624048 Acc@1: 0.504900 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.695450 Acc@1: 0.503501 
Base private model test accuracy:  0.5022577879394112
              precision    recall  f1-score   support

         0.0       0.22      0.35      0.27       508
         1.0       0.19      0.32      0.24       482
         2.0       0.16      0.28      0.20       510
         3.0       0.06      0.10      0.08       489
         4.0       0.11      0.17      0.14       466
         5.0       0.48      0.38      0.43      2972
         6.0       0.60      0.60      0.60      3080
         7.0       0.57      0.48      0.52      2961
         8.0       0.73      0.67      0.70      3024
         9.0       0.62      0.58      0.60      3003

    accuracy                           0.50     17495
   macro avg       0.38      0.39      0.38     17495
weighted avg       0.54      0.50      0.52     17495

Base private model train accuracy:  0.5078633836378078
              precision    recall  f1-score   support

         0.0       0.53      0.43      0.48       432
         1.0       0.55      0.40      0.46       461
         2.0       0.36      0.33      0.35       442
         3.0       0.36      0.24      0.28       457
         4.0       0.41      0.23      0.29       523
         5.0       0.43      0.49      0.46       787
         6.0       0.52      0.65      0.58       867
         7.0       0.53      0.53      0.53       787
         8.0       0.63      0.70      0.66       807
         9.0       0.55      0.71      0.62       732

    accuracy                           0.51      6295
   macro avg       0.49      0.47      0.47      6295
weighted avg       0.50      0.51      0.50      6295

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6024785510009533
test acc: 0.5780998389694042
min train acc: 0.5658978583196046
maj train acc: 0.6217780115728564
min test acc: 0.6031195840554593
maj test acc: 0.5639979602243753
total acc: 0.5903710812539987
total min acc: 0.5840371621621622
total maj acc: 0.5924391506991197
precision, recall: (0.5913911416094823, 0.6024785510009533)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.6, 96.86618915789894, 0.5022577879394112, 0.5078633836378078, 0.5903710812539987, 0.5840371621621622, 0.5924391506991197, '              precision    recall  f1-score   support\n\n         0.0       0.22      0.35      0.27       508\n         1.0       0.19      0.32      0.24       482\n         2.0       0.16      0.28      0.20       510\n         3.0       0.06      0.10      0.08       489\n         4.0       0.11      0.17      0.14       466\n         5.0       0.48      0.38      0.43      2972\n         6.0       0.60      0.60      0.60      3080\n         7.0       0.57      0.48      0.52      2961\n         8.0       0.73      0.67      0.70      3024\n         9.0       0.62      0.58      0.60      3003\n\n    accuracy                           0.50     17495\n   macro avg       0.38      0.39      0.38     17495\nweighted avg       0.54      0.50      0.52     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.53      0.43      0.48       432\n         1.0       0.55      0.40      0.46       461\n         2.0       0.36      0.33      0.35       442\n         3.0       0.36      0.24      0.28       457\n         4.0       0.41      0.23      0.29       523\n         5.0       0.43      0.49      0.46       787\n         6.0       0.52      0.65      0.58       867\n         7.0       0.53      0.53      0.53       787\n         8.0       0.63      0.70      0.66       807\n         9.0       0.55      0.71      0.62       732\n\n    accuracy                           0.51      6295\n   macro avg       0.49      0.47      0.47      6295\nweighted avg       0.50      0.51      0.50      6295\n']
experiment_number: 10
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-10.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.8
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 582, 6.0: 582, 7.0: 582, 8.0: 582, 9.0: 582}
resampled train counts:  tensor([449, 491, 454, 436, 459, 586, 535, 624, 616, 574])
resampled test counts:  tensor([466, 466, 466, 466, 466, 582, 582, 582, 582, 582])
training set size:  (5224, 3, 32, 32)
test set size:  (5240, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.210103 Acc@1: 0.148148 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.490879 Acc@1: 0.131202 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.476378 Acc@1: 0.115610 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.224865 Acc@1: 0.202733 
	Train Epoch: 2 	Loss: 2.247331 Acc@1: 0.172727 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.280618 Acc@1: 0.142951 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.402286 Acc@1: 0.143431 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 5.371299 Acc@1: 0.205564 
	Train Epoch: 3 	Loss: 7.548683 Acc@1: 0.113402 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.968795 Acc@1: 0.140158 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.741107 Acc@1: 0.138215 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.231491 Acc@1: 0.187184 
	Train Epoch: 4 	Loss: 2.361602 Acc@1: 0.093617 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.300035 Acc@1: 0.124029 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.318935 Acc@1: 0.138287 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.197756 Acc@1: 0.200579 
	Train Epoch: 5 	Loss: 2.279146 Acc@1: 0.127854 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.322384 Acc@1: 0.129525 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.437152 Acc@1: 0.137830 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.450296 Acc@1: 0.178553 
	Train Epoch: 6 	Loss: 2.464596 Acc@1: 0.102941 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.314249 Acc@1: 0.120225 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.434327 Acc@1: 0.136441 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.195884 Acc@1: 0.193382 
	Train Epoch: 7 	Loss: 2.313281 Acc@1: 0.116183 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.398959 Acc@1: 0.152360 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.402156 Acc@1: 0.136029 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.326278 Acc@1: 0.231269 
	Train Epoch: 8 	Loss: 2.567633 Acc@1: 0.126638 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.426220 Acc@1: 0.147984 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.364114 Acc@1: 0.154046 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.285139 Acc@1: 0.238316 
	Train Epoch: 9 	Loss: 2.275106 Acc@1: 0.153439 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.427231 Acc@1: 0.179679 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.378282 Acc@1: 0.172551 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.301757 Acc@1: 0.242805 
	Train Epoch: 10 	Loss: 2.256894 Acc@1: 0.192118 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.311477 Acc@1: 0.171900 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.303952 Acc@1: 0.181690 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.214808 Acc@1: 0.265131 
	Train Epoch: 11 	Loss: 2.385425 Acc@1: 0.195980 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.355465 Acc@1: 0.204772 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.475602 Acc@1: 0.205875 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.328286 Acc@1: 0.190259 
	Train Epoch: 12 	Loss: 2.326539 Acc@1: 0.137255 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.416184 Acc@1: 0.183479 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.389046 Acc@1: 0.186665 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.417161 Acc@1: 0.281078 
	Train Epoch: 13 	Loss: 2.451240 Acc@1: 0.155440 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.336816 Acc@1: 0.201705 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.369796 Acc@1: 0.204134 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.268042 Acc@1: 0.297643 
	Train Epoch: 14 	Loss: 2.296238 Acc@1: 0.230435 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.355811 Acc@1: 0.219184 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.300803 Acc@1: 0.231388 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.204504 Acc@1: 0.319615 
	Train Epoch: 15 	Loss: 2.174000 Acc@1: 0.287554 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 2.292406 Acc@1: 0.228999 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 2.288566 Acc@1: 0.237917 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.383021 Acc@1: 0.279773 
	Train Epoch: 16 	Loss: 2.149673 Acc@1: 0.313084 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 2.173884 Acc@1: 0.257544 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 2.194853 Acc@1: 0.258175 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.148668 Acc@1: 0.312072 
	Train Epoch: 17 	Loss: 2.070735 Acc@1: 0.292453 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 2.281121 Acc@1: 0.271755 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 2.243725 Acc@1: 0.270162 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.138493 Acc@1: 0.324773 
	Train Epoch: 18 	Loss: 2.159898 Acc@1: 0.275424 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 2.131338 Acc@1: 0.287520 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 2.144209 Acc@1: 0.285752 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.167571 Acc@1: 0.312382 
	Train Epoch: 19 	Loss: 2.064969 Acc@1: 0.285714 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 2.171095 Acc@1: 0.276741 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 2.142866 Acc@1: 0.286979 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.080069 Acc@1: 0.346549 
	Train Epoch: 20 	Loss: 2.262863 Acc@1: 0.318386 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 2.077010 Acc@1: 0.316997 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 2.088315 Acc@1: 0.312512 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.089406 Acc@1: 0.342486 
	Train Epoch: 21 	Loss: 2.115653 Acc@1: 0.267943 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 2.144314 Acc@1: 0.295471 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 2.112942 Acc@1: 0.304207 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.068682 Acc@1: 0.324238 
	Train Epoch: 22 	Loss: 1.991587 Acc@1: 0.315068 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 2.070268 Acc@1: 0.312934 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 2.080879 Acc@1: 0.312724 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.062124 Acc@1: 0.342800 
	Train Epoch: 23 	Loss: 2.200508 Acc@1: 0.282927 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.999158 Acc@1: 0.330273 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 2.001211 Acc@1: 0.327428 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.097840 Acc@1: 0.345301 
	Train Epoch: 24 	Loss: 2.184748 Acc@1: 0.335052 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.987880 Acc@1: 0.341764 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.992300 Acc@1: 0.331688 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.045881 Acc@1: 0.347319 
	Train Epoch: 25 	Loss: 2.146451 Acc@1: 0.310000 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 2.037729 Acc@1: 0.317230 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 2.026214 Acc@1: 0.324295 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.059154 Acc@1: 0.343263 
Base private model test accuracy:  0.3434695627322092
              precision    recall  f1-score   support

         0.0       0.10      0.27      0.15       508
         1.0       0.08      0.15      0.10       482
         2.0       0.10      0.16      0.12       510
         3.0       0.07      0.12      0.08       489
         4.0       0.06      0.15      0.09       466
         5.0       0.37      0.26      0.31      2972
         6.0       0.47      0.34      0.40      3080
         7.0       0.35      0.27      0.31      2961
         8.0       0.52      0.51      0.51      3024
         9.0       0.51      0.47      0.49      3003

    accuracy                           0.34     17495
   macro avg       0.26      0.27      0.26     17495
weighted avg       0.39      0.34      0.36     17495

Base private model train accuracy:  0.32006125574272587
              precision    recall  f1-score   support

         0.0       0.26      0.24      0.25       449
         1.0       0.36      0.21      0.26       491
         2.0       0.30      0.22      0.26       454
         3.0       0.32      0.19      0.24       436
         4.0       0.25      0.20      0.22       459
         5.0       0.26      0.26      0.26       586
         6.0       0.35      0.39      0.37       535
         7.0       0.33      0.37      0.35       624
         8.0       0.35      0.52      0.42       616
         9.0       0.35      0.47      0.40       574

    accuracy                           0.32      5224
   macro avg       0.31      0.31      0.30      5224
weighted avg       0.32      0.32      0.31      5224

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5892036753445635
test acc: 0.5561068702290076
min train acc: 0.5670367207514945
maj train acc: 0.6086360520904729
min test acc: 0.5799828913601368
maj test acc: 0.5366187542778919
total acc: 0.5726299694189603
total min acc: 0.5735042735042735
total maj acc: 0.5726027397260274
precision, recall: (0.569578090303479, 0.5892036753445635)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.8, 96.86618915789894, 0.3434695627322092, 0.32006125574272587, 0.5726299694189603, 0.5735042735042735, 0.5726027397260274, '              precision    recall  f1-score   support\n\n         0.0       0.10      0.27      0.15       508\n         1.0       0.08      0.15      0.10       482\n         2.0       0.10      0.16      0.12       510\n         3.0       0.07      0.12      0.08       489\n         4.0       0.06      0.15      0.09       466\n         5.0       0.37      0.26      0.31      2972\n         6.0       0.47      0.34      0.40      3080\n         7.0       0.35      0.27      0.31      2961\n         8.0       0.52      0.51      0.51      3024\n         9.0       0.51      0.47      0.49      3003\n\n    accuracy                           0.34     17495\n   macro avg       0.26      0.27      0.26     17495\nweighted avg       0.39      0.34      0.36     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.26      0.24      0.25       449\n         1.0       0.36      0.21      0.26       491\n         2.0       0.30      0.22      0.26       454\n         3.0       0.32      0.19      0.24       436\n         4.0       0.25      0.20      0.22       459\n         5.0       0.26      0.26      0.26       586\n         6.0       0.35      0.39      0.37       535\n         7.0       0.33      0.37      0.35       624\n         8.0       0.35      0.52      0.42       616\n         9.0       0.35      0.47      0.40       574\n\n    accuracy                           0.32      5224\n   macro avg       0.31      0.31      0.30      5224\nweighted avg       0.32      0.32      0.31      5224\n']
experiment_number: 11
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-11.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  1.0
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 466, 6.0: 466, 7.0: 466, 8.0: 466, 9.0: 466}
resampled train counts:  tensor([494, 483, 477, 468, 467, 458, 493, 458, 490, 470])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4758, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.494384 Acc@1: 0.101266 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.496665 Acc@1: 0.130834 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.421531 Acc@1: 0.131193 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.284397 Acc@1: 0.091010 
	Train Epoch: 2 	Loss: 2.277106 Acc@1: 0.160194 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.261744 Acc@1: 0.156070 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.670384 Acc@1: 0.133465 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.377463 Acc@1: 0.054784 
	Train Epoch: 3 	Loss: 2.250752 Acc@1: 0.112821 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.362450 Acc@1: 0.137166 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.364154 Acc@1: 0.132869 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.275698 Acc@1: 0.074259 
	Train Epoch: 4 	Loss: 2.287065 Acc@1: 0.108911 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.368512 Acc@1: 0.109685 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.364662 Acc@1: 0.113523 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.317875 Acc@1: 0.056653 
	Train Epoch: 5 	Loss: 2.287685 Acc@1: 0.108911 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.354431 Acc@1: 0.115304 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.391542 Acc@1: 0.117752 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.293975 Acc@1: 0.125074 
	Train Epoch: 6 	Loss: 2.296303 Acc@1: 0.094241 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.306665 Acc@1: 0.135430 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.344245 Acc@1: 0.146413 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.351915 Acc@1: 0.274328 
	Train Epoch: 7 	Loss: 2.328852 Acc@1: 0.145946 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.500599 Acc@1: 0.182995 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.482910 Acc@1: 0.152000 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.520197 Acc@1: 0.076401 
	Train Epoch: 8 	Loss: 2.564997 Acc@1: 0.116505 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.355158 Acc@1: 0.105679 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.335560 Acc@1: 0.104027 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.298771 Acc@1: 0.168512 
	Train Epoch: 9 	Loss: 2.289291 Acc@1: 0.072626 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.374386 Acc@1: 0.127156 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.377881 Acc@1: 0.123896 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.395366 Acc@1: 0.060835 
	Train Epoch: 10 	Loss: 2.356841 Acc@1: 0.123656 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.301723 Acc@1: 0.134876 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.362731 Acc@1: 0.155091 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.450998 Acc@1: 0.160727 
	Train Epoch: 11 	Loss: 2.324821 Acc@1: 0.177665 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.370194 Acc@1: 0.171957 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.337781 Acc@1: 0.177728 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.311256 Acc@1: 0.192027 
	Train Epoch: 12 	Loss: 2.216348 Acc@1: 0.161905 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.329612 Acc@1: 0.184235 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.307250 Acc@1: 0.177230 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.516515 Acc@1: 0.173688 
	Train Epoch: 13 	Loss: 2.371949 Acc@1: 0.184211 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.393139 Acc@1: 0.174869 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.358541 Acc@1: 0.184353 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.278874 Acc@1: 0.262597 
	Train Epoch: 14 	Loss: 2.606375 Acc@1: 0.192547 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.448663 Acc@1: 0.203443 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.396877 Acc@1: 0.192039 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.365089 Acc@1: 0.262899 
	Train Epoch: 15 	Loss: 2.319633 Acc@1: 0.177419 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 2.423235 Acc@1: 0.181354 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 2.417455 Acc@1: 0.195379 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.406282 Acc@1: 0.222877 
	Train Epoch: 16 	Loss: 2.322997 Acc@1: 0.204082 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 2.220059 Acc@1: 0.213248 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 2.244416 Acc@1: 0.219763 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.405091 Acc@1: 0.193502 
	Train Epoch: 17 	Loss: 2.142362 Acc@1: 0.205128 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 2.305657 Acc@1: 0.242874 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 2.316960 Acc@1: 0.234920 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.321870 Acc@1: 0.216763 
	Train Epoch: 18 	Loss: 2.153548 Acc@1: 0.211823 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 2.341387 Acc@1: 0.229945 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 2.301273 Acc@1: 0.236982 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.323955 Acc@1: 0.239615 
	Train Epoch: 19 	Loss: 2.173430 Acc@1: 0.234450 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 2.266868 Acc@1: 0.261566 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 2.316696 Acc@1: 0.253900 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.411698 Acc@1: 0.262197 
	Train Epoch: 20 	Loss: 2.343003 Acc@1: 0.241026 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 2.269309 Acc@1: 0.255027 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 2.269143 Acc@1: 0.253135 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.389914 Acc@1: 0.256193 
	Train Epoch: 21 	Loss: 2.124335 Acc@1: 0.275132 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 2.230406 Acc@1: 0.274605 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 2.225461 Acc@1: 0.268715 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.279593 Acc@1: 0.240141 
	Train Epoch: 22 	Loss: 2.190774 Acc@1: 0.275676 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 2.246601 Acc@1: 0.262746 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 2.220720 Acc@1: 0.264555 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.384256 Acc@1: 0.229184 
	Train Epoch: 23 	Loss: 2.274395 Acc@1: 0.256281 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 2.246197 Acc@1: 0.258241 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 2.232709 Acc@1: 0.278170 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.242128 Acc@1: 0.270066 
	Train Epoch: 24 	Loss: 2.169296 Acc@1: 0.263158 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 2.194166 Acc@1: 0.275776 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 2.193712 Acc@1: 0.274508 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.271200 Acc@1: 0.254551 
	Train Epoch: 25 	Loss: 1.950662 Acc@1: 0.295699 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 2.137751 Acc@1: 0.282315 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 2.187555 Acc@1: 0.275688 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 2.283310 Acc@1: 0.256269 
Base private model test accuracy:  0.2563018005144327
              precision    recall  f1-score   support

         0.0       0.07      0.19      0.10       508
         1.0       0.08      0.26      0.13       482
         2.0       0.05      0.11      0.07       510
         3.0       0.06      0.28      0.09       489
         4.0       0.07      0.31      0.11       466
         5.0       0.31      0.13      0.18      2972
         6.0       0.40      0.17      0.24      3080
         7.0       0.38      0.28      0.32      2961
         8.0       0.58      0.48      0.52      3024
         9.0       0.46      0.25      0.33      3003

    accuracy                           0.26     17495
   macro avg       0.25      0.25      0.21     17495
weighted avg       0.38      0.26      0.29     17495

Base private model train accuracy:  0.27889869693148384
              precision    recall  f1-score   support

         0.0       0.25      0.20      0.22       494
         1.0       0.30      0.28      0.29       483
         2.0       0.21      0.14      0.17       477
         3.0       0.21      0.31      0.25       468
         4.0       0.27      0.34      0.30       467
         5.0       0.26      0.17      0.20       458
         6.0       0.32      0.27      0.29       493
         7.0       0.24      0.28      0.26       458
         8.0       0.38      0.50      0.43       490
         9.0       0.32      0.29      0.31       470

    accuracy                           0.28      4758
   macro avg       0.28      0.28      0.27      4758
weighted avg       0.28      0.28      0.27      4758

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6292559899117276
test acc: 0.49442060085836914
min train acc: 0.6439966414777498
maj train acc: 0.618798955613577
min test acc: 0.48347107438016534
maj test acc: 0.5053097345132743
total acc: 0.5625398173709917
total min acc: 0.5630987088713036
total maj acc: 0.5625274243089075
precision, recall: (0.5596261682242991, 0.6292559899117276)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 1.0, 96.86618915789894, 0.2563018005144327, 0.27889869693148384, 0.5625398173709917, 0.5630987088713036, 0.5625274243089075, '              precision    recall  f1-score   support\n\n         0.0       0.07      0.19      0.10       508\n         1.0       0.08      0.26      0.13       482\n         2.0       0.05      0.11      0.07       510\n         3.0       0.06      0.28      0.09       489\n         4.0       0.07      0.31      0.11       466\n         5.0       0.31      0.13      0.18      2972\n         6.0       0.40      0.17      0.24      3080\n         7.0       0.38      0.28      0.32      2961\n         8.0       0.58      0.48      0.52      3024\n         9.0       0.46      0.25      0.33      3003\n\n    accuracy                           0.26     17495\n   macro avg       0.25      0.25      0.21     17495\nweighted avg       0.38      0.26      0.29     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.25      0.20      0.22       494\n         1.0       0.30      0.28      0.29       483\n         2.0       0.21      0.14      0.17       477\n         3.0       0.21      0.31      0.25       468\n         4.0       0.27      0.34      0.30       467\n         5.0       0.26      0.17      0.20       458\n         6.0       0.32      0.27      0.29       493\n         7.0       0.24      0.28      0.26       458\n         8.0       0.38      0.50      0.43       490\n         9.0       0.32      0.29      0.31       470\n\n    accuracy                           0.28      4758\n   macro avg       0.28      0.28      0.27      4758\nweighted avg       0.28      0.28      0.27      4758\n']
experiment_number: 12
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-12.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1252, 1264, 1203, 1178, 1213, 3114, 3039, 3091, 3075, 3131])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21560, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.368836 Acc@1: 0.070078 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.357354 Acc@1: 0.137189 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.318551 Acc@1: 0.148924 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.110013 Acc@1: 0.173525 
	Train Epoch: 2 	Loss: 2.198411 Acc@1: 0.142377 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.263433 Acc@1: 0.161853 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.261963 Acc@1: 0.161205 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.104568 Acc@1: 0.173009 
	Train Epoch: 3 	Loss: 2.222950 Acc@1: 0.147059 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.210944 Acc@1: 0.149447 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.199857 Acc@1: 0.158871 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.055466 Acc@1: 0.168973 
	Train Epoch: 4 	Loss: 2.193290 Acc@1: 0.140680 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.172316 Acc@1: 0.167938 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.165412 Acc@1: 0.171225 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.038432 Acc@1: 0.192770 
	Train Epoch: 5 	Loss: 2.141730 Acc@1: 0.169832 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.188972 Acc@1: 0.178850 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.178558 Acc@1: 0.174591 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.023269 Acc@1: 0.169562 
	Train Epoch: 6 	Loss: 2.130053 Acc@1: 0.158693 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.236365 Acc@1: 0.169256 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.215997 Acc@1: 0.178528 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 6.920122 Acc@1: 0.027674 
	Train Epoch: 7 	Loss: 6.194883 Acc@1: 0.051251 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.525009 Acc@1: 0.161218 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.373160 Acc@1: 0.167948 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.027567 Acc@1: 0.200119 
	Train Epoch: 8 	Loss: 2.103812 Acc@1: 0.176136 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.126550 Acc@1: 0.193266 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.147374 Acc@1: 0.185045 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.055753 Acc@1: 0.170977 
	Train Epoch: 9 	Loss: 2.125510 Acc@1: 0.166863 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.247151 Acc@1: 0.178869 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.222619 Acc@1: 0.186953 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.026301 Acc@1: 0.225063 
	Train Epoch: 10 	Loss: 2.095696 Acc@1: 0.251101 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.095781 Acc@1: 0.224203 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.085874 Acc@1: 0.238396 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.954869 Acc@1: 0.285318 
	Train Epoch: 11 	Loss: 2.024973 Acc@1: 0.252081 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.046702 Acc@1: 0.277906 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.044091 Acc@1: 0.287169 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.850150 Acc@1: 0.374610 
	Train Epoch: 12 	Loss: 1.987265 Acc@1: 0.350056 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.091340 Acc@1: 0.290116 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.021381 Acc@1: 0.298906 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.761320 Acc@1: 0.394594 
	Train Epoch: 13 	Loss: 1.821376 Acc@1: 0.347582 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.900223 Acc@1: 0.343112 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.882311 Acc@1: 0.354484 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.648993 Acc@1: 0.417525 
	Train Epoch: 14 	Loss: 1.779172 Acc@1: 0.368542 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.783294 Acc@1: 0.398125 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.831258 Acc@1: 0.399453 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.571537 Acc@1: 0.471095 
	Train Epoch: 15 	Loss: 1.768137 Acc@1: 0.406553 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.757739 Acc@1: 0.431942 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.790899 Acc@1: 0.438803 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.517441 Acc@1: 0.504759 
	Train Epoch: 16 	Loss: 1.766985 Acc@1: 0.449711 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.783490 Acc@1: 0.455840 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.760503 Acc@1: 0.460818 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.581258 Acc@1: 0.520334 
	Train Epoch: 17 	Loss: 1.857813 Acc@1: 0.440137 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.766277 Acc@1: 0.477382 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.748054 Acc@1: 0.482352 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.495690 Acc@1: 0.552260 
	Train Epoch: 18 	Loss: 1.837693 Acc@1: 0.459148 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.737263 Acc@1: 0.481974 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.709777 Acc@1: 0.488958 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.484108 Acc@1: 0.563942 
	Train Epoch: 19 	Loss: 1.701015 Acc@1: 0.512472 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.712197 Acc@1: 0.501206 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.692149 Acc@1: 0.503962 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.446638 Acc@1: 0.569681 
	Train Epoch: 20 	Loss: 1.674787 Acc@1: 0.525882 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.669217 Acc@1: 0.508312 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.685471 Acc@1: 0.508114 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.455817 Acc@1: 0.573750 
	Train Epoch: 21 	Loss: 1.614151 Acc@1: 0.535885 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.658682 Acc@1: 0.515336 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.660393 Acc@1: 0.517240 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.444348 Acc@1: 0.576997 
	Train Epoch: 22 	Loss: 1.781755 Acc@1: 0.516364 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.678404 Acc@1: 0.510778 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.661765 Acc@1: 0.518288 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.477858 Acc@1: 0.576773 
	Train Epoch: 23 	Loss: 1.614033 Acc@1: 0.533728 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.624503 Acc@1: 0.527314 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.641753 Acc@1: 0.525197 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.438638 Acc@1: 0.583014 
	Train Epoch: 24 	Loss: 1.603457 Acc@1: 0.522422 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.656485 Acc@1: 0.523218 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.642207 Acc@1: 0.525817 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.443029 Acc@1: 0.585066 
	Train Epoch: 25 	Loss: 1.580749 Acc@1: 0.522752 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.651846 Acc@1: 0.528071 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.652790 Acc@1: 0.527782 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.442812 Acc@1: 0.585615 
Base private model test accuracy:  0.5860531580451558
              precision    recall  f1-score   support

         0.0       0.22      0.09      0.13       508
         1.0       0.24      0.08      0.12       482
         2.0       0.11      0.02      0.04       510
         3.0       0.08      0.01      0.01       489
         4.0       0.13      0.02      0.04       466
         5.0       0.52      0.68      0.59      2972
         6.0       0.63      0.72      0.67      3080
         7.0       0.54      0.52      0.53      2961
         8.0       0.69      0.76      0.73      3024
         9.0       0.61      0.68      0.65      3003

    accuracy                           0.59     17495
   macro avg       0.38      0.36      0.35     17495
weighted avg       0.54      0.59      0.56     17495

Base private model train accuracy:  0.5261595547309833
              precision    recall  f1-score   support

         0.0       0.46      0.23      0.31      1252
         1.0       0.50      0.31      0.38      1264
         2.0       0.30      0.10      0.14      1203
         3.0       0.30      0.18      0.23      1178
         4.0       0.31      0.06      0.10      1213
         5.0       0.49      0.67      0.57      3114
         6.0       0.51      0.70      0.59      3039
         7.0       0.51      0.53      0.52      3091
         8.0       0.64      0.75      0.69      3075
         9.0       0.57      0.67      0.62      3131

    accuracy                           0.53     21560
   macro avg       0.46      0.42      0.42     21560
weighted avg       0.50      0.53      0.50     21560

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5326530612244897
test acc: 0.5700371057513915
min train acc: 0.5919787868743785
maj train acc: 0.5098417599382478
min test acc: 0.556135770234987
maj test acc: 0.575588920528087
total acc: 0.5513450834879406
total min acc: 0.5739187633612892
total maj acc: 0.5426156526227498
precision, recall: (0.5533391153512576, 0.5326530612244897)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.4, 96.86618915789894, 0.5860531580451558, 0.5261595547309833, 0.5513450834879406, 0.5739187633612892, 0.5426156526227498, '              precision    recall  f1-score   support\n\n         0.0       0.22      0.09      0.13       508\n         1.0       0.24      0.08      0.12       482\n         2.0       0.11      0.02      0.04       510\n         3.0       0.08      0.01      0.01       489\n         4.0       0.13      0.02      0.04       466\n         5.0       0.52      0.68      0.59      2972\n         6.0       0.63      0.72      0.67      3080\n         7.0       0.54      0.52      0.53      2961\n         8.0       0.69      0.76      0.73      3024\n         9.0       0.61      0.68      0.65      3003\n\n    accuracy                           0.59     17495\n   macro avg       0.38      0.36      0.35     17495\nweighted avg       0.54      0.59      0.56     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.46      0.23      0.31      1252\n         1.0       0.50      0.31      0.38      1264\n         2.0       0.30      0.10      0.14      1203\n         3.0       0.30      0.18      0.23      1178\n         4.0       0.31      0.06      0.10      1213\n         5.0       0.49      0.67      0.57      3114\n         6.0       0.51      0.70      0.59      3039\n         7.0       0.51      0.53      0.52      3091\n         8.0       0.64      0.75      0.69      3075\n         9.0       0.57      0.67      0.62      3131\n\n    accuracy                           0.53     21560\n   macro avg       0.46      0.42      0.42     21560\nweighted avg       0.50      0.53      0.50     21560\n']
experiment_number: 8
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-8.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1853, 1753, 1856, 1812, 1874, 3029, 3096, 3105, 3023, 3045])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (24446, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.587316 Acc@1: 0.149947 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.447701 Acc@1: 0.134042 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.416162 Acc@1: 0.142744 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.204727 Acc@1: 0.266186 
	Train Epoch: 2 	Loss: 2.266226 Acc@1: 0.196970 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.462225 Acc@1: 0.143118 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.534563 Acc@1: 0.161484 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.142639 Acc@1: 0.218166 
	Train Epoch: 3 	Loss: 2.272426 Acc@1: 0.162626 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.288977 Acc@1: 0.158009 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.264129 Acc@1: 0.153842 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.125582 Acc@1: 0.175093 
	Train Epoch: 4 	Loss: 2.214399 Acc@1: 0.155260 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.211534 Acc@1: 0.154017 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.198422 Acc@1: 0.164014 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.062269 Acc@1: 0.185224 
	Train Epoch: 5 	Loss: 2.151462 Acc@1: 0.189216 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.220991 Acc@1: 0.187827 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.687229 Acc@1: 0.175397 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.046096 Acc@1: 0.189049 
	Train Epoch: 6 	Loss: 2.245512 Acc@1: 0.151976 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.354030 Acc@1: 0.143514 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.299303 Acc@1: 0.154217 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.120232 Acc@1: 0.240820 
	Train Epoch: 7 	Loss: 2.128121 Acc@1: 0.220305 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.207501 Acc@1: 0.236388 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.213979 Acc@1: 0.247869 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.914545 Acc@1: 0.323552 
	Train Epoch: 8 	Loss: 2.153590 Acc@1: 0.267368 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.112202 Acc@1: 0.269583 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.109735 Acc@1: 0.288811 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.829899 Acc@1: 0.386784 
	Train Epoch: 9 	Loss: 2.061925 Acc@1: 0.325651 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.253094 Acc@1: 0.301232 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.187373 Acc@1: 0.302162 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.722143 Acc@1: 0.420103 
	Train Epoch: 10 	Loss: 1.970894 Acc@1: 0.382958 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.937942 Acc@1: 0.388153 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.889223 Acc@1: 0.398787 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.659051 Acc@1: 0.474951 
	Train Epoch: 11 	Loss: 1.839997 Acc@1: 0.424490 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.857012 Acc@1: 0.427897 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.840631 Acc@1: 0.429469 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.842433 Acc@1: 0.468261 
	Train Epoch: 12 	Loss: 2.017923 Acc@1: 0.398969 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.828982 Acc@1: 0.438775 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.817403 Acc@1: 0.450937 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.559012 Acc@1: 0.546509 
	Train Epoch: 13 	Loss: 1.808433 Acc@1: 0.471384 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.784002 Acc@1: 0.466241 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.801224 Acc@1: 0.476025 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.542753 Acc@1: 0.533897 
	Train Epoch: 14 	Loss: 1.659172 Acc@1: 0.464105 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.723028 Acc@1: 0.473500 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.725221 Acc@1: 0.478418 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.523901 Acc@1: 0.556299 
	Train Epoch: 15 	Loss: 1.784207 Acc@1: 0.490476 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.756109 Acc@1: 0.497136 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.744537 Acc@1: 0.486406 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.520605 Acc@1: 0.566244 
	Train Epoch: 16 	Loss: 1.667372 Acc@1: 0.513228 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.671248 Acc@1: 0.504500 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.692860 Acc@1: 0.502040 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.474153 Acc@1: 0.575264 
	Train Epoch: 17 	Loss: 1.638812 Acc@1: 0.525253 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.641389 Acc@1: 0.518841 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.655060 Acc@1: 0.513666 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.579371 Acc@1: 0.550295 
	Train Epoch: 18 	Loss: 1.683717 Acc@1: 0.526741 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.639765 Acc@1: 0.522445 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.631318 Acc@1: 0.524260 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.529653 Acc@1: 0.579617 
	Train Epoch: 19 	Loss: 1.821273 Acc@1: 0.500509 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.674059 Acc@1: 0.522688 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.641979 Acc@1: 0.528567 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.486915 Acc@1: 0.583184 
	Train Epoch: 20 	Loss: 1.676836 Acc@1: 0.524178 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.650181 Acc@1: 0.535635 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.641480 Acc@1: 0.533424 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.433349 Acc@1: 0.589568 
	Train Epoch: 21 	Loss: 1.620860 Acc@1: 0.529787 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.628043 Acc@1: 0.531526 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.629098 Acc@1: 0.531108 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.438786 Acc@1: 0.589548 
	Train Epoch: 22 	Loss: 1.618999 Acc@1: 0.538763 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.618807 Acc@1: 0.538983 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.615801 Acc@1: 0.542414 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.461533 Acc@1: 0.590244 
	Train Epoch: 23 	Loss: 1.580919 Acc@1: 0.536585 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.613615 Acc@1: 0.534583 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.606299 Acc@1: 0.540637 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.456534 Acc@1: 0.596018 
	Train Epoch: 24 	Loss: 1.739225 Acc@1: 0.514170 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.614631 Acc@1: 0.541741 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.620668 Acc@1: 0.540585 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.439990 Acc@1: 0.596251 
	Train Epoch: 25 	Loss: 1.682009 Acc@1: 0.525284 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.619825 Acc@1: 0.540609 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.614492 Acc@1: 0.540245 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.440816 Acc@1: 0.595355 
Base private model test accuracy:  0.5959988568162332
              precision    recall  f1-score   support

         0.0       0.24      0.23      0.23       508
         1.0       0.26      0.13      0.18       482
         2.0       0.14      0.08      0.10       510
         3.0       0.08      0.04      0.05       489
         4.0       0.16      0.05      0.08       466
         5.0       0.58      0.64      0.61      2972
         6.0       0.62      0.70      0.66      3080
         7.0       0.62      0.59      0.60      2961
         8.0       0.73      0.75      0.74      3024
         9.0       0.61      0.70      0.65      3003

    accuracy                           0.60     17495
   macro avg       0.40      0.39      0.39     17495
weighted avg       0.57      0.60      0.58     17495

Base private model train accuracy:  0.5432790640595598
              precision    recall  f1-score   support

         0.0       0.55      0.45      0.50      1853
         1.0       0.54      0.46      0.50      1753
         2.0       0.42      0.27      0.33      1856
         3.0       0.41      0.30      0.35      1812
         4.0       0.45      0.18      0.26      1874
         5.0       0.51      0.62      0.56      3029
         6.0       0.50      0.68      0.58      3096
         7.0       0.57      0.59      0.58      3105
         8.0       0.67      0.74      0.71      3023
         9.0       0.58      0.71      0.64      3045

    accuracy                           0.54     24446
   macro avg       0.52      0.50      0.50     24446
weighted avg       0.53      0.54      0.53     24446

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.523521230467152
test acc: 0.5878246753246753
min train acc: 0.5657894736842105
maj train acc: 0.5014019882742798
min test acc: 0.5986394557823129
maj test acc: 0.5816287147819375
total acc: 0.5558000244468891
total min acc: 0.5823470854993916
total maj acc: 0.5413278699020424
precision, recall: (0.5575498823734425, 0.523521230467152)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.6, 96.86618915789894, 0.5959988568162332, 0.5432790640595598, 0.5558000244468891, 0.5823470854993916, 0.5413278699020424, '              precision    recall  f1-score   support\n\n         0.0       0.24      0.23      0.23       508\n         1.0       0.26      0.13      0.18       482\n         2.0       0.14      0.08      0.10       510\n         3.0       0.08      0.04      0.05       489\n         4.0       0.16      0.05      0.08       466\n         5.0       0.58      0.64      0.61      2972\n         6.0       0.62      0.70      0.66      3080\n         7.0       0.62      0.59      0.60      2961\n         8.0       0.73      0.75      0.74      3024\n         9.0       0.61      0.70      0.65      3003\n\n    accuracy                           0.60     17495\n   macro avg       0.40      0.39      0.39     17495\nweighted avg       0.57      0.60      0.58     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.55      0.45      0.50      1853\n         1.0       0.54      0.46      0.50      1753\n         2.0       0.42      0.27      0.33      1856\n         3.0       0.41      0.30      0.35      1812\n         4.0       0.45      0.18      0.26      1874\n         5.0       0.51      0.62      0.56      3029\n         6.0       0.50      0.68      0.58      3096\n         7.0       0.57      0.59      0.58      3105\n         8.0       0.67      0.74      0.71      3023\n         9.0       0.58      0.71      0.64      3045\n\n    accuracy                           0.54     24446\n   macro avg       0.52      0.50      0.50     24446\nweighted avg       0.53      0.54      0.53     24446\n']
experiment_number: 10
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-10.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2524, 2467, 2474, 2463, 2568, 3039, 3066, 3081, 3047, 3037])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (27766, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.303177 Acc@1: 0.085143 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.599117 Acc@1: 0.127793 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.522379 Acc@1: 0.117572 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.261037 Acc@1: 0.169279 
	Train Epoch: 2 	Loss: 2.291137 Acc@1: 0.108656 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.390486 Acc@1: 0.116798 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.346656 Acc@1: 0.117321 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.244642 Acc@1: 0.179655 
	Train Epoch: 3 	Loss: 2.299880 Acc@1: 0.104962 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.417696 Acc@1: 0.110855 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.652214 Acc@1: 0.117836 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.264853 Acc@1: 0.154676 
	Train Epoch: 4 	Loss: 2.298856 Acc@1: 0.107735 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.893757 Acc@1: 0.109290 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.589733 Acc@1: 0.124703 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.304941 Acc@1: 0.171786 
	Train Epoch: 5 	Loss: 2.297779 Acc@1: 0.158085 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.333625 Acc@1: 0.144820 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.315096 Acc@1: 0.153124 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 3.491951 Acc@1: 0.039493 
	Train Epoch: 6 	Loss: 3.204900 Acc@1: 0.083480 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.369420 Acc@1: 0.152585 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.472385 Acc@1: 0.145024 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.085061 Acc@1: 0.170218 
	Train Epoch: 7 	Loss: 2.199281 Acc@1: 0.165354 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.222116 Acc@1: 0.170711 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.175331 Acc@1: 0.171638 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.116492 Acc@1: 0.166558 
	Train Epoch: 8 	Loss: 2.221729 Acc@1: 0.189560 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.178875 Acc@1: 0.187470 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.155726 Acc@1: 0.190399 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.045479 Acc@1: 0.208671 
	Train Epoch: 9 	Loss: 2.133659 Acc@1: 0.200364 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.136847 Acc@1: 0.218441 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.183123 Acc@1: 0.224725 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.064439 Acc@1: 0.171317 
	Train Epoch: 10 	Loss: 2.077205 Acc@1: 0.173060 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.090095 Acc@1: 0.187189 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 2.075364 Acc@1: 0.196893 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.033805 Acc@1: 0.212251 
	Train Epoch: 11 	Loss: 2.080335 Acc@1: 0.191564 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.065124 Acc@1: 0.214427 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 2.059176 Acc@1: 0.223149 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.008049 Acc@1: 0.305339 
	Train Epoch: 12 	Loss: 2.027851 Acc@1: 0.275214 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.088166 Acc@1: 0.289645 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 2.182508 Acc@1: 0.268207 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.946759 Acc@1: 0.340299 
	Train Epoch: 13 	Loss: 2.155803 Acc@1: 0.272646 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.100941 Acc@1: 0.292521 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 2.029380 Acc@1: 0.313624 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.716886 Acc@1: 0.423406 
	Train Epoch: 14 	Loss: 2.037602 Acc@1: 0.373675 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.190191 Acc@1: 0.312845 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 2.059237 Acc@1: 0.329389 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.641180 Acc@1: 0.423443 
	Train Epoch: 15 	Loss: 1.867507 Acc@1: 0.350181 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.849372 Acc@1: 0.377421 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.877936 Acc@1: 0.388274 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.677545 Acc@1: 0.475696 
	Train Epoch: 16 	Loss: 1.868494 Acc@1: 0.409879 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.860085 Acc@1: 0.414950 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.870226 Acc@1: 0.415826 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.635918 Acc@1: 0.472423 
	Train Epoch: 17 	Loss: 1.748754 Acc@1: 0.429470 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.845260 Acc@1: 0.417800 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.850890 Acc@1: 0.422249 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.588219 Acc@1: 0.505219 
	Train Epoch: 18 	Loss: 1.833047 Acc@1: 0.448430 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.817452 Acc@1: 0.444679 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.822547 Acc@1: 0.440312 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.565367 Acc@1: 0.512727 
	Train Epoch: 19 	Loss: 1.705900 Acc@1: 0.450089 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.774997 Acc@1: 0.451232 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.812481 Acc@1: 0.449993 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.549272 Acc@1: 0.525989 
	Train Epoch: 20 	Loss: 1.865007 Acc@1: 0.441944 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.859689 Acc@1: 0.445169 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.809895 Acc@1: 0.450418 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.561437 Acc@1: 0.524980 
	Train Epoch: 21 	Loss: 1.801901 Acc@1: 0.442220 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.801406 Acc@1: 0.465083 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.805960 Acc@1: 0.462246 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.549759 Acc@1: 0.531663 
	Train Epoch: 22 	Loss: 1.614746 Acc@1: 0.462825 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.786475 Acc@1: 0.469403 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.789669 Acc@1: 0.469164 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.589891 Acc@1: 0.529308 
	Train Epoch: 23 	Loss: 1.795862 Acc@1: 0.446809 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.764484 Acc@1: 0.468157 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.779931 Acc@1: 0.469898 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.576399 Acc@1: 0.533431 
	Train Epoch: 24 	Loss: 1.787000 Acc@1: 0.459982 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.816133 Acc@1: 0.462792 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.814675 Acc@1: 0.464356 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.571079 Acc@1: 0.531390 
	Train Epoch: 25 	Loss: 1.803136 Acc@1: 0.453571 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.748902 Acc@1: 0.475231 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.756457 Acc@1: 0.473225 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.570507 Acc@1: 0.532622 
Base private model test accuracy:  0.5324378393826807
              precision    recall  f1-score   support

         0.0       0.23      0.15      0.18       508
         1.0       0.19      0.07      0.11       482
         2.0       0.13      0.04      0.06       510
         3.0       0.02      0.00      0.00       489
         4.0       0.06      0.01      0.01       466
         5.0       0.45      0.64      0.53      2972
         6.0       0.58      0.63      0.60      3080
         7.0       0.52      0.49      0.51      2961
         8.0       0.64      0.70      0.67      3024
         9.0       0.58      0.59      0.58      3003

    accuracy                           0.53     17495
   macro avg       0.34      0.33      0.33     17495
weighted avg       0.49      0.53      0.51     17495

Base private model train accuracy:  0.46531729453288195
              precision    recall  f1-score   support

         0.0       0.53      0.35      0.42      2524
         1.0       0.49      0.44      0.46      2467
         2.0       0.38      0.24      0.30      2474
         3.0       0.34      0.22      0.27      2463
         4.0       0.37      0.26      0.30      2568
         5.0       0.40      0.63      0.49      3039
         6.0       0.44      0.61      0.51      3066
         7.0       0.47      0.47      0.47      3081
         8.0       0.61      0.70      0.65      3047
         9.0       0.54      0.59      0.56      3037

    accuracy                           0.47     27766
   macro avg       0.46      0.45      0.44     27766
weighted avg       0.46      0.47      0.45     27766

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6089461931859108
test acc: 0.4833333333333333
min train acc: 0.5720338983050848
maj train acc: 0.6377036462373933
min test acc: 0.5373403209957419
maj test acc: 0.4408809891808346
total acc: 0.5461918321738817
total min acc: 0.5547296193432446
total maj acc: 0.5391018195896244
precision, recall: (0.541402497598463, 0.6089461931859108)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.8, 96.86618915789894, 0.5324378393826807, 0.46531729453288195, 0.5461918321738817, 0.5547296193432446, 0.5391018195896244, '              precision    recall  f1-score   support\n\n         0.0       0.23      0.15      0.18       508\n         1.0       0.19      0.07      0.11       482\n         2.0       0.13      0.04      0.06       510\n         3.0       0.02      0.00      0.00       489\n         4.0       0.06      0.01      0.01       466\n         5.0       0.45      0.64      0.53      2972\n         6.0       0.58      0.63      0.60      3080\n         7.0       0.52      0.49      0.51      2961\n         8.0       0.64      0.70      0.67      3024\n         9.0       0.58      0.59      0.58      3003\n\n    accuracy                           0.53     17495\n   macro avg       0.34      0.33      0.33     17495\nweighted avg       0.49      0.53      0.51     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.53      0.35      0.42      2524\n         1.0       0.49      0.44      0.46      2467\n         2.0       0.38      0.24      0.30      2474\n         3.0       0.34      0.22      0.27      2463\n         4.0       0.37      0.26      0.30      2568\n         5.0       0.40      0.63      0.49      3039\n         6.0       0.44      0.61      0.51      3066\n         7.0       0.47      0.47      0.47      3081\n         8.0       0.61      0.70      0.65      3047\n         9.0       0.54      0.59      0.56      3037\n\n    accuracy                           0.47     27766\n   macro avg       0.46      0.45      0.44     27766\nweighted avg       0.46      0.47      0.45     27766\n']
experiment_number: 12
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-12.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 100.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([3115, 3113, 3028, 3103, 3145, 3102, 2975, 3011, 3075, 3128])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30795, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.190426 Acc@1: 0.096618 (ε = 11.39, δ = 1e-05) for α = 2.5
	Train Epoch: 1 	Loss: 2.670378 Acc@1: 0.110542 (ε = 20.40, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.529855 Acc@1: 0.108467 (ε = 24.13, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.322928 Acc@1: 0.028020 
	Train Epoch: 2 	Loss: 2.298635 Acc@1: 0.098491 (ε = 25.67, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.286265 Acc@1: 0.112749 (ε = 28.16, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 2.279827 Acc@1: 0.123707 (ε = 30.66, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.387248 Acc@1: 0.160897 
	Train Epoch: 3 	Loss: 2.260889 Acc@1: 0.178803 (ε = 31.90, δ = 1e-05) for α = 1.6
	Train Epoch: 3 	Loss: 2.238860 Acc@1: 0.165714 (ε = 33.69, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 2.637003 Acc@1: 0.151739 (ε = 35.44, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.098170 Acc@1: 0.169678 
	Train Epoch: 4 	Loss: 2.339726 Acc@1: 0.104754 (ε = 36.31, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.790281 Acc@1: 0.106371 (ε = 38.06, δ = 1e-05) for α = 1.5
	Train Epoch: 4 	Loss: 2.562842 Acc@1: 0.103443 (ε = 39.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.301068 Acc@1: 0.029435 
	Train Epoch: 5 	Loss: 2.285567 Acc@1: 0.085319 (ε = 40.68, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.292421 Acc@1: 0.116162 (ε = 42.43, δ = 1e-05) for α = 1.5
	Train Epoch: 5 	Loss: 2.265046 Acc@1: 0.151516 (ε = 44.05, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.234516 Acc@1: 0.220553 
	Train Epoch: 6 	Loss: 2.197503 Acc@1: 0.190514 (ε = 44.68, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.188395 Acc@1: 0.242886 (ε = 45.94, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 2.247882 Acc@1: 0.236302 (ε = 47.21, δ = 1e-05) for α = 1.4
	Test set:Loss: 2.058885 Acc@1: 0.301769 
	Train Epoch: 7 	Loss: 2.166286 Acc@1: 0.280899 (ε = 47.84, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.178808 Acc@1: 0.259319 (ε = 49.10, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 2.171329 Acc@1: 0.260798 (ε = 50.36, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.998682 Acc@1: 0.383472 
	Train Epoch: 8 	Loss: 2.161692 Acc@1: 0.322841 (ε = 50.99, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.048735 Acc@1: 0.330078 (ε = 52.25, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 2.054073 Acc@1: 0.329823 (ε = 53.51, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.807061 Acc@1: 0.409616 
	Train Epoch: 9 	Loss: 1.936518 Acc@1: 0.372093 (ε = 54.15, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.117487 Acc@1: 0.330974 (ε = 55.41, δ = 1e-05) for α = 1.4
	Train Epoch: 9 	Loss: 2.041863 Acc@1: 0.337692 (ε = 56.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.848883 Acc@1: 0.386868 
	Train Epoch: 10 	Loss: 1.959956 Acc@1: 0.357664 (ε = 57.30, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.954883 Acc@1: 0.366853 (ε = 58.56, δ = 1e-05) for α = 1.4
	Train Epoch: 10 	Loss: 1.953268 Acc@1: 0.363020 (ε = 59.82, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.646718 Acc@1: 0.468384 
	Train Epoch: 11 	Loss: 1.853394 Acc@1: 0.389338 (ε = 60.45, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.855408 Acc@1: 0.398212 (ε = 61.72, δ = 1e-05) for α = 1.4
	Train Epoch: 11 	Loss: 1.879578 Acc@1: 0.393739 (ε = 62.98, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.731742 Acc@1: 0.452982 
	Train Epoch: 12 	Loss: 1.912563 Acc@1: 0.392971 (ε = 63.61, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.879001 Acc@1: 0.404405 (ε = 64.87, δ = 1e-05) for α = 1.4
	Train Epoch: 12 	Loss: 1.858343 Acc@1: 0.404330 (ε = 66.08, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.690290 Acc@1: 0.493322 
	Train Epoch: 13 	Loss: 1.925737 Acc@1: 0.425446 (ε = 66.55, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.836228 Acc@1: 0.438314 (ε = 67.48, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.830065 Acc@1: 0.436860 (ε = 68.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.679150 Acc@1: 0.504150 
	Train Epoch: 14 	Loss: 1.904015 Acc@1: 0.421553 (ε = 68.88, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.864264 Acc@1: 0.427507 (ε = 69.82, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.834476 Acc@1: 0.429247 (ε = 70.76, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.641363 Acc@1: 0.508732 
	Train Epoch: 15 	Loss: 1.851918 Acc@1: 0.445364 (ε = 71.22, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.797801 Acc@1: 0.443911 (ε = 72.16, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.768606 Acc@1: 0.449059 (ε = 73.10, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.661794 Acc@1: 0.516368 
	Train Epoch: 16 	Loss: 1.779042 Acc@1: 0.467297 (ε = 73.56, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.785208 Acc@1: 0.452220 (ε = 74.50, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.759749 Acc@1: 0.456155 (ε = 75.44, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.712927 Acc@1: 0.501822 
	Train Epoch: 17 	Loss: 1.973536 Acc@1: 0.457770 (ε = 75.90, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.818099 Acc@1: 0.449835 (ε = 76.84, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.775561 Acc@1: 0.455829 (ε = 77.78, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.661539 Acc@1: 0.518912 
	Train Epoch: 18 	Loss: 1.725241 Acc@1: 0.469945 (ε = 78.24, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.775098 Acc@1: 0.467003 (ε = 79.18, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.757986 Acc@1: 0.470343 (ε = 80.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.586150 Acc@1: 0.529798 
	Train Epoch: 19 	Loss: 1.642260 Acc@1: 0.473466 (ε = 80.58, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.689689 Acc@1: 0.477798 (ε = 81.52, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.706539 Acc@1: 0.480894 (ε = 82.45, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.610656 Acc@1: 0.528129 
	Train Epoch: 20 	Loss: 1.675397 Acc@1: 0.458154 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.702964 Acc@1: 0.474614 (ε = 83.86, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.703712 Acc@1: 0.481454 (ε = 84.79, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.655573 Acc@1: 0.523467 
	Train Epoch: 21 	Loss: 1.777017 Acc@1: 0.495547 (ε = 85.26, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.702824 Acc@1: 0.491718 (ε = 86.20, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.699012 Acc@1: 0.488046 (ε = 87.13, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.559580 Acc@1: 0.554138 
	Train Epoch: 22 	Loss: 1.774728 Acc@1: 0.481452 (ε = 87.60, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.663991 Acc@1: 0.495904 (ε = 88.54, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 1.683480 Acc@1: 0.494492 (ε = 89.47, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.593756 Acc@1: 0.548826 
	Train Epoch: 23 	Loss: 1.818998 Acc@1: 0.494523 (ε = 89.94, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.711257 Acc@1: 0.493589 (ε = 90.88, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 1.704291 Acc@1: 0.494749 (ε = 91.81, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.603859 Acc@1: 0.539249 
	Train Epoch: 24 	Loss: 1.627306 Acc@1: 0.508567 (ε = 92.28, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.692848 Acc@1: 0.499769 (ε = 93.22, δ = 1e-05) for α = 1.3
	Train Epoch: 24 	Loss: 1.701758 Acc@1: 0.499995 (ε = 94.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.595793 Acc@1: 0.548053 
	Train Epoch: 25 	Loss: 1.753376 Acc@1: 0.500000 (ε = 94.62, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.687252 Acc@1: 0.499378 (ε = 95.56, δ = 1e-05) for α = 1.3
	Train Epoch: 25 	Loss: 1.684276 Acc@1: 0.501363 (ε = 96.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.579994 Acc@1: 0.551304 
Base private model test accuracy:  0.5513003715347242
              precision    recall  f1-score   support

         0.0       0.26      0.23      0.24       508
         1.0       0.27      0.31      0.29       482
         2.0       0.17      0.18      0.17       510
         3.0       0.08      0.09      0.09       489
         4.0       0.06      0.08      0.06       466
         5.0       0.56      0.56      0.56      2972
         6.0       0.61      0.65      0.63      3080
         7.0       0.59      0.56      0.57      2961
         8.0       0.73      0.66      0.69      3024
         9.0       0.64      0.63      0.64      3003

    accuracy                           0.55     17495
   macro avg       0.40      0.40      0.39     17495
weighted avg       0.56      0.55      0.56     17495

Base private model train accuracy:  0.4964767007631109
              precision    recall  f1-score   support

         0.0       0.57      0.40      0.47      3115
         1.0       0.54      0.58      0.56      3113
         2.0       0.40      0.31      0.35      3028
         3.0       0.40      0.36      0.38      3103
         4.0       0.37      0.31      0.34      3145
         5.0       0.48      0.55      0.51      3102
         6.0       0.45      0.63      0.53      2975
         7.0       0.54      0.56      0.55      3011
         8.0       0.62      0.63      0.63      3075
         9.0       0.57      0.63      0.60      3128

    accuracy                           0.50     30795
   macro avg       0.49      0.50      0.49     30795
weighted avg       0.49      0.50      0.49     30795

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5779047866467494
test acc: 0.5812337662337662
min train acc: 0.6191675503711559
maj train acc: 0.5382659547419273
min test acc: 0.5933281412253375
maj test acc: 0.5691668829483519
total acc: 0.5795694385816801
total min acc: 0.6061122770199371
total maj acc: 0.5535576676085281
precision, recall: (0.5797875806346517, 0.5779047866467494)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 1.0, 96.86618915789894, 0.5513003715347242, 0.4964767007631109, 0.5795694385816801, 0.6061122770199371, 0.5535576676085281, '              precision    recall  f1-score   support\n\n         0.0       0.26      0.23      0.24       508\n         1.0       0.27      0.31      0.29       482\n         2.0       0.17      0.18      0.17       510\n         3.0       0.08      0.09      0.09       489\n         4.0       0.06      0.08      0.06       466\n         5.0       0.56      0.56      0.56      2972\n         6.0       0.61      0.65      0.63      3080\n         7.0       0.59      0.56      0.57      2961\n         8.0       0.73      0.66      0.69      3024\n         9.0       0.64      0.63      0.64      3003\n\n    accuracy                           0.55     17495\n   macro avg       0.40      0.40      0.39     17495\nweighted avg       0.56      0.55      0.56     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.40      0.47      3115\n         1.0       0.54      0.58      0.56      3113\n         2.0       0.40      0.31      0.35      3028\n         3.0       0.40      0.36      0.38      3103\n         4.0       0.37      0.31      0.34      3145\n         5.0       0.48      0.55      0.51      3102\n         6.0       0.45      0.63      0.53      2975\n         7.0       0.54      0.56      0.55      3011\n         8.0       0.62      0.63      0.63      3075\n         9.0       0.57      0.63      0.60      3128\n\n    accuracy                           0.50     30795\n   macro avg       0.49      0.50      0.49     30795\nweighted avg       0.49      0.50      0.49     30795\n']
experiment_number: 14
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-14.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
resampled train counts:  tensor([ 534,  502,  539,  485,  545, 3002, 2958, 3152, 2992, 3039])
resampled test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
training set size:  (17748, 3, 32, 32)
test set size:  (17495, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.028684 Acc@1: 0.161725 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.866521 Acc@1: 0.160890 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 3.003944 Acc@1: 0.168036 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.002776 Acc@1: 0.218062 
	Train Epoch: 2 	Loss: 1.998028 Acc@1: 0.214186 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.029450 Acc@1: 0.210321 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.003375 Acc@1: 0.240095 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 1.959252 Acc@1: 0.234250 
	Train Epoch: 3 	Loss: 1.965708 Acc@1: 0.227207 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 1.964950 Acc@1: 0.274641 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 1.901450 Acc@1: 0.303551 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.719774 Acc@1: 0.371146 
	Train Epoch: 4 	Loss: 1.716725 Acc@1: 0.387141 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 1.875322 Acc@1: 0.374692 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 1.848074 Acc@1: 0.371071 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.764469 Acc@1: 0.386099 
	Train Epoch: 5 	Loss: 1.844079 Acc@1: 0.398529 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 1.722842 Acc@1: 0.424485 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 1.769656 Acc@1: 0.423690 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.850168 Acc@1: 0.421041 
	Train Epoch: 6 	Loss: 1.785980 Acc@1: 0.425352 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 1.708345 Acc@1: 0.446060 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 1.632198 Acc@1: 0.467939 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.694036 Acc@1: 0.523937 
	Train Epoch: 7 	Loss: 1.662497 Acc@1: 0.481534 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.612341 Acc@1: 0.525714 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.590361 Acc@1: 0.526179 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.625476 Acc@1: 0.529598 
	Train Epoch: 8 	Loss: 1.517357 Acc@1: 0.540984 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.573836 Acc@1: 0.546167 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.526358 Acc@1: 0.563183 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.545572 Acc@1: 0.570756 
	Train Epoch: 9 	Loss: 1.443206 Acc@1: 0.606149 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.497820 Acc@1: 0.576610 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.491165 Acc@1: 0.580112 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.470559 Acc@1: 0.595256 
	Train Epoch: 10 	Loss: 1.521815 Acc@1: 0.593343 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.473925 Acc@1: 0.587561 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.449446 Acc@1: 0.598431 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.403463 Acc@1: 0.606332 
	Train Epoch: 11 	Loss: 1.483465 Acc@1: 0.562408 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.433710 Acc@1: 0.610485 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.416009 Acc@1: 0.614182 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.444582 Acc@1: 0.617558 
	Train Epoch: 12 	Loss: 1.423694 Acc@1: 0.624658 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.412211 Acc@1: 0.618638 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.381162 Acc@1: 0.627287 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.495823 Acc@1: 0.617877 
	Train Epoch: 13 	Loss: 1.443231 Acc@1: 0.596291 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.368656 Acc@1: 0.624855 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.336499 Acc@1: 0.637246 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.537351 Acc@1: 0.612700 
	Train Epoch: 14 	Loss: 1.358018 Acc@1: 0.628415 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.339713 Acc@1: 0.637948 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.356029 Acc@1: 0.637167 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.420464 Acc@1: 0.630529 
	Train Epoch: 15 	Loss: 1.392148 Acc@1: 0.608629 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.290161 Acc@1: 0.651408 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.306909 Acc@1: 0.654616 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.377800 Acc@1: 0.636559 
	Train Epoch: 16 	Loss: 1.337698 Acc@1: 0.639653 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.288302 Acc@1: 0.657114 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.311819 Acc@1: 0.652685 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.466294 Acc@1: 0.616776 
	Train Epoch: 17 	Loss: 1.300839 Acc@1: 0.654728 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.270156 Acc@1: 0.665449 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.290532 Acc@1: 0.660124 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.384638 Acc@1: 0.640056 
	Train Epoch: 18 	Loss: 1.353143 Acc@1: 0.655172 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.301695 Acc@1: 0.652619 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.288306 Acc@1: 0.655254 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.352825 Acc@1: 0.642368 
	Train Epoch: 19 	Loss: 1.249284 Acc@1: 0.664336 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.256833 Acc@1: 0.659156 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.264775 Acc@1: 0.660224 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.364704 Acc@1: 0.645744 
	Train Epoch: 20 	Loss: 1.154009 Acc@1: 0.670868 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.235150 Acc@1: 0.668992 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.236238 Acc@1: 0.674632 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.415945 Acc@1: 0.643953 
	Train Epoch: 21 	Loss: 1.176349 Acc@1: 0.691429 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.256621 Acc@1: 0.666130 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.212956 Acc@1: 0.674114 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.382209 Acc@1: 0.653900 
	Train Epoch: 22 	Loss: 1.249517 Acc@1: 0.656848 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.200281 Acc@1: 0.680127 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.225659 Acc@1: 0.681322 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.355575 Acc@1: 0.655023 
	Train Epoch: 23 	Loss: 1.285476 Acc@1: 0.659969 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.245572 Acc@1: 0.672524 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.241593 Acc@1: 0.674987 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.377957 Acc@1: 0.654376 
	Train Epoch: 24 	Loss: 1.160740 Acc@1: 0.690962 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.252150 Acc@1: 0.675652 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.243158 Acc@1: 0.675055 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.362404 Acc@1: 0.655202 
	Train Epoch: 25 	Loss: 1.286158 Acc@1: 0.671562 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.237211 Acc@1: 0.673914 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.203545 Acc@1: 0.678776 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.353977 Acc@1: 0.657900 
Base private model test accuracy:  0.6568162332094885
              precision    recall  f1-score   support

         0.0       0.43      0.12      0.19       508
         1.0       0.39      0.15      0.22       482
         2.0       0.26      0.08      0.13       510
         3.0       0.19      0.02      0.03       489
         4.0       0.27      0.04      0.07       466
         5.0       0.59      0.69      0.64      2972
         6.0       0.70      0.79      0.74      3080
         7.0       0.64      0.71      0.67      2961
         8.0       0.73      0.84      0.78      3024
         9.0       0.68      0.73      0.70      3003

    accuracy                           0.66     17495
   macro avg       0.49      0.42      0.42     17495
weighted avg       0.62      0.66      0.63     17495

Base private model train accuracy:  0.6801893171061528
              precision    recall  f1-score   support

         0.0       0.57      0.19      0.28       534
         1.0       0.61      0.16      0.26       502
         2.0       0.45      0.18      0.26       539
         3.0       0.27      0.02      0.04       485
         4.0       0.42      0.05      0.09       545
         5.0       0.59      0.70      0.64      3002
         6.0       0.70      0.81      0.75      2958
         7.0       0.68      0.73      0.70      3152
         8.0       0.74      0.87      0.80      2992
         9.0       0.72      0.78      0.75      3039

    accuracy                           0.68     17748
   macro avg       0.58      0.45      0.46     17748
weighted avg       0.65      0.68      0.65     17748

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.4796033355871084
test acc: 0.6475362981593689
min train acc: 0.5610717100078803
maj train acc: 0.4652777777777778
min test acc: 0.5880000000000001
maj test acc: 0.6573864393232982
total acc: 0.5629646444583167
total min acc: 0.574434299325129
total maj acc: 0.5614538179393131
precision, recall: (0.5799155198255893, 0.4796033355871084)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['none', 0.5, 50.24151667068924, 0.6568162332094885, 0.6801893171061528, 0.5629646444583167, 0.574434299325129, 0.5614538179393131, '              precision    recall  f1-score   support\n\n         0.0       0.43      0.12      0.19       508\n         1.0       0.39      0.15      0.22       482\n         2.0       0.26      0.08      0.13       510\n         3.0       0.19      0.02      0.03       489\n         4.0       0.27      0.04      0.07       466\n         5.0       0.59      0.69      0.64      2972\n         6.0       0.70      0.79      0.74      3080\n         7.0       0.64      0.71      0.67      2961\n         8.0       0.73      0.84      0.78      3024\n         9.0       0.68      0.73      0.70      3003\n\n    accuracy                           0.66     17495\n   macro avg       0.49      0.42      0.42     17495\nweighted avg       0.62      0.66      0.63     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.19      0.28       534\n         1.0       0.61      0.16      0.26       502\n         2.0       0.45      0.18      0.26       539\n         3.0       0.27      0.02      0.04       485\n         4.0       0.42      0.05      0.09       545\n         5.0       0.59      0.70      0.64      3002\n         6.0       0.70      0.81      0.75      2958\n         7.0       0.68      0.73      0.70      3152\n         8.0       0.74      0.87      0.80      2992\n         9.0       0.72      0.78      0.75      3039\n\n    accuracy                           0.68     17748\n   macro avg       0.58      0.45      0.46     17748\nweighted avg       0.65      0.68      0.65     17748\n']
experiment_number: 178
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-178.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1256, 1172, 1260, 1261, 1260, 3159, 3062, 3052, 3084, 3091])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21657, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.151752 Acc@1: 0.055879 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.636949 Acc@1: 0.132067 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.600008 Acc@1: 0.144421 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.120475 Acc@1: 0.182972 
	Train Epoch: 2 	Loss: 2.216547 Acc@1: 0.170388 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.261443 Acc@1: 0.141481 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.233915 Acc@1: 0.143795 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.058499 Acc@1: 0.171893 
	Train Epoch: 3 	Loss: 2.189310 Acc@1: 0.145928 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.195988 Acc@1: 0.176309 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.193580 Acc@1: 0.188249 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.077562 Acc@1: 0.212188 
	Train Epoch: 4 	Loss: 2.200132 Acc@1: 0.182139 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.183308 Acc@1: 0.198274 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.212213 Acc@1: 0.188517 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.035316 Acc@1: 0.191454 
	Train Epoch: 5 	Loss: 2.148681 Acc@1: 0.161329 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.081316 Acc@1: 0.215379 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.137815 Acc@1: 0.238294 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.797927 Acc@1: 0.362875 
	Train Epoch: 6 	Loss: 1.931327 Acc@1: 0.305310 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 1.956538 Acc@1: 0.316205 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 1.951282 Acc@1: 0.331519 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.736029 Acc@1: 0.434690 
	Train Epoch: 7 	Loss: 1.874020 Acc@1: 0.356808 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.866957 Acc@1: 0.375245 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.870705 Acc@1: 0.375258 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.769267 Acc@1: 0.424812 
	Train Epoch: 8 	Loss: 1.750806 Acc@1: 0.382386 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.866119 Acc@1: 0.378303 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.906108 Acc@1: 0.382098 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.709295 Acc@1: 0.478061 
	Train Epoch: 9 	Loss: 1.722170 Acc@1: 0.423810 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.800369 Acc@1: 0.415261 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.778145 Acc@1: 0.429895 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.575409 Acc@1: 0.525839 
	Train Epoch: 10 	Loss: 1.741978 Acc@1: 0.497630 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.738685 Acc@1: 0.461962 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.723567 Acc@1: 0.468172 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.526241 Acc@1: 0.549962 
	Train Epoch: 11 	Loss: 1.598615 Acc@1: 0.493258 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.707248 Acc@1: 0.476446 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.697223 Acc@1: 0.484598 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.485464 Acc@1: 0.563529 
	Train Epoch: 12 	Loss: 1.769273 Acc@1: 0.481271 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.682110 Acc@1: 0.502789 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.666946 Acc@1: 0.508118 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.591663 Acc@1: 0.548890 
	Train Epoch: 13 	Loss: 1.624205 Acc@1: 0.482838 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.578572 Acc@1: 0.522152 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.625274 Acc@1: 0.518002 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.447515 Acc@1: 0.588043 
	Train Epoch: 14 	Loss: 1.577425 Acc@1: 0.507042 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.572245 Acc@1: 0.529125 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.585624 Acc@1: 0.530120 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.465720 Acc@1: 0.593518 
	Train Epoch: 15 	Loss: 1.516256 Acc@1: 0.549539 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.557595 Acc@1: 0.547405 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.568293 Acc@1: 0.545193 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.367311 Acc@1: 0.613385 
	Train Epoch: 16 	Loss: 1.389088 Acc@1: 0.589041 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.523267 Acc@1: 0.554518 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.519310 Acc@1: 0.559011 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.408815 Acc@1: 0.617745 
	Train Epoch: 17 	Loss: 1.420089 Acc@1: 0.587319 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.484507 Acc@1: 0.576251 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.489288 Acc@1: 0.571479 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.397582 Acc@1: 0.623538 
	Train Epoch: 18 	Loss: 1.491754 Acc@1: 0.586905 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.478483 Acc@1: 0.580263 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.478318 Acc@1: 0.582924 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.384693 Acc@1: 0.631178 
	Train Epoch: 19 	Loss: 1.507756 Acc@1: 0.601675 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.475963 Acc@1: 0.583693 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.465217 Acc@1: 0.589998 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.403462 Acc@1: 0.629563 
	Train Epoch: 20 	Loss: 1.387028 Acc@1: 0.602620 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.429569 Acc@1: 0.600707 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.452294 Acc@1: 0.596434 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.461513 Acc@1: 0.615763 
	Train Epoch: 21 	Loss: 1.438029 Acc@1: 0.592000 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.480782 Acc@1: 0.589152 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.475010 Acc@1: 0.592075 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.381696 Acc@1: 0.640276 
	Train Epoch: 22 	Loss: 1.395019 Acc@1: 0.592244 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.425932 Acc@1: 0.596181 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.436183 Acc@1: 0.597866 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.370084 Acc@1: 0.640043 
	Train Epoch: 23 	Loss: 1.442759 Acc@1: 0.615108 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.438176 Acc@1: 0.606049 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.414066 Acc@1: 0.607277 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.373558 Acc@1: 0.643286 
	Train Epoch: 24 	Loss: 1.554722 Acc@1: 0.582492 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.443941 Acc@1: 0.605323 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.427057 Acc@1: 0.607780 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.369690 Acc@1: 0.641428 
	Train Epoch: 25 	Loss: 1.434290 Acc@1: 0.601863 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.416664 Acc@1: 0.610121 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.406361 Acc@1: 0.608700 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.363917 Acc@1: 0.642944 
Base private model test accuracy:  0.6432695055730209
              precision    recall  f1-score   support

         0.0       0.38      0.29      0.33       508
         1.0       0.35      0.37      0.36       482
         2.0       0.26      0.24      0.25       510
         3.0       0.12      0.04      0.06       489
         4.0       0.20      0.20      0.20       466
         5.0       0.58      0.66      0.62      2972
         6.0       0.75      0.74      0.74      3080
         7.0       0.66      0.64      0.65      2961
         8.0       0.77      0.79      0.78      3024
         9.0       0.71      0.72      0.71      3003

    accuracy                           0.64     17495
   macro avg       0.48      0.47      0.47     17495
weighted avg       0.63      0.64      0.64     17495

Base private model train accuracy:  0.6082559911345061
              precision    recall  f1-score   support

         0.0       0.62      0.40      0.48      1256
         1.0       0.59      0.43      0.49      1172
         2.0       0.54      0.32      0.40      1260
         3.0       0.30      0.07      0.12      1261
         4.0       0.46      0.27      0.34      1260
         5.0       0.52      0.69      0.59      3159
         6.0       0.64      0.74      0.68      3062
         7.0       0.62      0.68      0.65      3052
         8.0       0.68      0.81      0.74      3084
         9.0       0.68      0.76      0.72      3091

    accuracy                           0.61     21657
   macro avg       0.56      0.52      0.52     21657
weighted avg       0.59      0.61      0.59     21657

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6778721832286664
test acc: 0.5501855287569573
min train acc: 0.7877296587926509
maj train acc: 0.6353655386205115
min test acc: 0.6901998710509349
maj test acc: 0.4934963579604579
total acc: 0.614170677526842
total min acc: 0.7385365853658536
total maj acc: 0.5646791963707064
precision, recall: (0.6021822955123471, 0.6778721832286664)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.4, 50.24151667068924, 0.6432695055730209, 0.6082559911345061, 0.614170677526842, 0.7385365853658536, 0.5646791963707064, '              precision    recall  f1-score   support\n\n         0.0       0.38      0.29      0.33       508\n         1.0       0.35      0.37      0.36       482\n         2.0       0.26      0.24      0.25       510\n         3.0       0.12      0.04      0.06       489\n         4.0       0.20      0.20      0.20       466\n         5.0       0.58      0.66      0.62      2972\n         6.0       0.75      0.74      0.74      3080\n         7.0       0.66      0.64      0.65      2961\n         8.0       0.77      0.79      0.78      3024\n         9.0       0.71      0.72      0.71      3003\n\n    accuracy                           0.64     17495\n   macro avg       0.48      0.47      0.47     17495\nweighted avg       0.63      0.64      0.64     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.62      0.40      0.48      1256\n         1.0       0.59      0.43      0.49      1172\n         2.0       0.54      0.32      0.40      1260\n         3.0       0.30      0.07      0.12      1261\n         4.0       0.46      0.27      0.34      1260\n         5.0       0.52      0.69      0.59      3159\n         6.0       0.64      0.74      0.68      3062\n         7.0       0.62      0.68      0.65      3052\n         8.0       0.68      0.81      0.74      3084\n         9.0       0.68      0.76      0.72      3091\n\n    accuracy                           0.61     21657\n   macro avg       0.56      0.52      0.52     21657\nweighted avg       0.59      0.61      0.59     21657\n']
experiment_number: 23
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-23.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1830, 1970, 1858, 1854, 1818, 3029, 3058, 3018, 3145, 2986])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (24566, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.658259 Acc@1: 0.130612 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.424227 Acc@1: 0.143212 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.354023 Acc@1: 0.141235 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.117757 Acc@1: 0.209030 
	Train Epoch: 2 	Loss: 2.300073 Acc@1: 0.138746 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.309833 Acc@1: 0.135296 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.307814 Acc@1: 0.154821 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.195121 Acc@1: 0.175726 
	Train Epoch: 3 	Loss: 2.276767 Acc@1: 0.122594 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.287556 Acc@1: 0.141891 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.281002 Acc@1: 0.134655 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.142861 Acc@1: 0.152138 
	Train Epoch: 4 	Loss: 2.274731 Acc@1: 0.110526 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.296631 Acc@1: 0.131161 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.402889 Acc@1: 0.141235 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.097551 Acc@1: 0.285918 
	Train Epoch: 5 	Loss: 2.262578 Acc@1: 0.221545 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.253967 Acc@1: 0.199241 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.320062 Acc@1: 0.193947 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.186318 Acc@1: 0.184224 
	Train Epoch: 6 	Loss: 2.257282 Acc@1: 0.151423 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 3.236675 Acc@1: 0.161523 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.762923 Acc@1: 0.179071 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.006739 Acc@1: 0.300077 
	Train Epoch: 7 	Loss: 2.220534 Acc@1: 0.219008 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.200386 Acc@1: 0.215446 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.252519 Acc@1: 0.206885 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.022899 Acc@1: 0.351536 
	Train Epoch: 8 	Loss: 2.110221 Acc@1: 0.267947 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.137424 Acc@1: 0.273008 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.122050 Acc@1: 0.292660 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.994222 Acc@1: 0.380211 
	Train Epoch: 9 	Loss: 2.214015 Acc@1: 0.262926 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.962319 Acc@1: 0.320472 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.966843 Acc@1: 0.334040 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.629792 Acc@1: 0.480238 
	Train Epoch: 10 	Loss: 1.898558 Acc@1: 0.351795 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.852486 Acc@1: 0.383755 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.832918 Acc@1: 0.394342 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.842573 Acc@1: 0.436178 
	Train Epoch: 11 	Loss: 2.005576 Acc@1: 0.354906 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.793121 Acc@1: 0.395730 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.801091 Acc@1: 0.400408 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.601623 Acc@1: 0.487761 
	Train Epoch: 12 	Loss: 1.769789 Acc@1: 0.414132 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.704218 Acc@1: 0.428866 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.705780 Acc@1: 0.438829 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.515010 Acc@1: 0.535413 
	Train Epoch: 13 	Loss: 1.681422 Acc@1: 0.473846 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.650314 Acc@1: 0.470378 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.662862 Acc@1: 0.471599 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.565800 Acc@1: 0.529019 
	Train Epoch: 14 	Loss: 1.664149 Acc@1: 0.466151 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.640982 Acc@1: 0.488464 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.628139 Acc@1: 0.490834 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.433634 Acc@1: 0.560316 
	Train Epoch: 15 	Loss: 1.574685 Acc@1: 0.508130 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.585665 Acc@1: 0.496309 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.595377 Acc@1: 0.498152 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.433002 Acc@1: 0.570546 
	Train Epoch: 16 	Loss: 1.504285 Acc@1: 0.522927 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.557800 Acc@1: 0.528607 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.561339 Acc@1: 0.528953 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.472680 Acc@1: 0.573210 
	Train Epoch: 17 	Loss: 1.552544 Acc@1: 0.523121 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.532884 Acc@1: 0.535810 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.513214 Acc@1: 0.542273 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.464766 Acc@1: 0.582618 
	Train Epoch: 18 	Loss: 1.472972 Acc@1: 0.535240 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.524023 Acc@1: 0.547260 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.532297 Acc@1: 0.549484 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.482373 Acc@1: 0.581289 
	Train Epoch: 19 	Loss: 1.505555 Acc@1: 0.549139 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.489848 Acc@1: 0.556424 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.498521 Acc@1: 0.553656 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.449751 Acc@1: 0.587386 
	Train Epoch: 20 	Loss: 1.411842 Acc@1: 0.580943 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.467309 Acc@1: 0.566197 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.468465 Acc@1: 0.568033 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.411557 Acc@1: 0.602283 
	Train Epoch: 21 	Loss: 1.354685 Acc@1: 0.594650 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.447248 Acc@1: 0.575717 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.464375 Acc@1: 0.573740 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.429420 Acc@1: 0.601497 
	Train Epoch: 22 	Loss: 1.504691 Acc@1: 0.572125 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.466395 Acc@1: 0.572790 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.457960 Acc@1: 0.575029 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.394191 Acc@1: 0.616945 
	Train Epoch: 23 	Loss: 1.541911 Acc@1: 0.557308 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.490499 Acc@1: 0.571784 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.494941 Acc@1: 0.572739 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.407707 Acc@1: 0.608873 
	Train Epoch: 24 	Loss: 1.384444 Acc@1: 0.568880 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.474521 Acc@1: 0.574849 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.461674 Acc@1: 0.577012 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.401598 Acc@1: 0.610731 
	Train Epoch: 25 	Loss: 1.524524 Acc@1: 0.587978 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.447627 Acc@1: 0.592999 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.435914 Acc@1: 0.590515 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.398316 Acc@1: 0.613106 
Base private model test accuracy:  0.6130322949414119
              precision    recall  f1-score   support

         0.0       0.32      0.45      0.37       508
         1.0       0.29      0.52      0.37       482
         2.0       0.22      0.34      0.27       510
         3.0       0.13      0.17      0.15       489
         4.0       0.18      0.28      0.22       466
         5.0       0.61      0.58      0.60      2972
         6.0       0.77      0.71      0.74      3080
         7.0       0.70      0.60      0.65      2961
         8.0       0.79      0.72      0.75      3024
         9.0       0.72      0.65      0.69      3003

    accuracy                           0.61     17495
   macro avg       0.47      0.50      0.48     17495
weighted avg       0.65      0.61      0.63     17495

Base private model train accuracy:  0.5811283888300903
              precision    recall  f1-score   support

         0.0       0.57      0.54      0.55      1830
         1.0       0.65      0.58      0.61      1970
         2.0       0.48      0.39      0.43      1858
         3.0       0.38      0.25      0.30      1854
         4.0       0.51      0.37      0.43      1818
         5.0       0.52      0.61      0.56      3029
         6.0       0.63      0.74      0.68      3058
         7.0       0.60      0.62      0.61      3018
         8.0       0.65      0.72      0.68      3145
         9.0       0.63      0.68      0.65      2986

    accuracy                           0.58     24566
   macro avg       0.56      0.55      0.55     24566
weighted avg       0.57      0.58      0.57     24566

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7626801270048034
test acc: 0.5706168831168832
min train acc: 0.9011754462342185
maj train acc: 0.6809720785935884
min test acc: 0.751974386339381
maj test acc: 0.4595160235448005
total acc: 0.6665040848676991
total min acc: 0.8258433020799655
total maj acc: 0.5708991613029062
precision, recall: (0.6391049256378769, 0.7626801270048034)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.6, 50.24151667068924, 0.6130322949414119, 0.5811283888300903, 0.6665040848676991, 0.8258433020799655, 0.5708991613029062, '              precision    recall  f1-score   support\n\n         0.0       0.32      0.45      0.37       508\n         1.0       0.29      0.52      0.37       482\n         2.0       0.22      0.34      0.27       510\n         3.0       0.13      0.17      0.15       489\n         4.0       0.18      0.28      0.22       466\n         5.0       0.61      0.58      0.60      2972\n         6.0       0.77      0.71      0.74      3080\n         7.0       0.70      0.60      0.65      2961\n         8.0       0.79      0.72      0.75      3024\n         9.0       0.72      0.65      0.69      3003\n\n    accuracy                           0.61     17495\n   macro avg       0.47      0.50      0.48     17495\nweighted avg       0.65      0.61      0.63     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.54      0.55      1830\n         1.0       0.65      0.58      0.61      1970\n         2.0       0.48      0.39      0.43      1858\n         3.0       0.38      0.25      0.30      1854\n         4.0       0.51      0.37      0.43      1818\n         5.0       0.52      0.61      0.56      3029\n         6.0       0.63      0.74      0.68      3058\n         7.0       0.60      0.62      0.61      3018\n         8.0       0.65      0.72      0.68      3145\n         9.0       0.63      0.68      0.65      2986\n\n    accuracy                           0.58     24566\n   macro avg       0.56      0.55      0.55     24566\nweighted avg       0.57      0.58      0.57     24566\n']
experiment_number: 24
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-24.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2376, 2374, 2555, 2436, 2460, 3085, 2996, 3161, 3087, 3117])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (27647, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.821008 Acc@1: 0.081517 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.795897 Acc@1: 0.120410 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.585376 Acc@1: 0.129710 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.279034 Acc@1: 0.176582 
	Train Epoch: 2 	Loss: 2.343230 Acc@1: 0.139983 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 3.144639 Acc@1: 0.125502 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.718324 Acc@1: 0.145107 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.150189 Acc@1: 0.287466 
	Train Epoch: 3 	Loss: 2.209729 Acc@1: 0.199816 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.215400 Acc@1: 0.186413 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.234075 Acc@1: 0.190482 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.045544 Acc@1: 0.326219 
	Train Epoch: 4 	Loss: 2.185222 Acc@1: 0.217430 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.127148 Acc@1: 0.217798 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.154168 Acc@1: 0.224991 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.933436 Acc@1: 0.349241 
	Train Epoch: 5 	Loss: 2.038553 Acc@1: 0.257590 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.034181 Acc@1: 0.270645 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.019310 Acc@1: 0.283995 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.860199 Acc@1: 0.361708 
	Train Epoch: 6 	Loss: 2.088093 Acc@1: 0.261494 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.014031 Acc@1: 0.277328 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.007960 Acc@1: 0.303743 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.790876 Acc@1: 0.449888 
	Train Epoch: 7 	Loss: 1.879007 Acc@1: 0.378105 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.943678 Acc@1: 0.360288 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.908498 Acc@1: 0.366070 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.778058 Acc@1: 0.424762 
	Train Epoch: 8 	Loss: 1.804647 Acc@1: 0.385353 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.815179 Acc@1: 0.396237 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.833192 Acc@1: 0.393769 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.777349 Acc@1: 0.452372 
	Train Epoch: 9 	Loss: 1.783384 Acc@1: 0.396658 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.789294 Acc@1: 0.415002 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.793579 Acc@1: 0.423143 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.611464 Acc@1: 0.485244 
	Train Epoch: 10 	Loss: 1.679109 Acc@1: 0.426536 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.712633 Acc@1: 0.448051 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.720150 Acc@1: 0.452153 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.971044 Acc@1: 0.405526 
	Train Epoch: 11 	Loss: 1.766339 Acc@1: 0.446182 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.666729 Acc@1: 0.464763 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.664739 Acc@1: 0.473417 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.804217 Acc@1: 0.472007 
	Train Epoch: 12 	Loss: 1.706126 Acc@1: 0.476106 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.642613 Acc@1: 0.488648 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.624441 Acc@1: 0.500412 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.851566 Acc@1: 0.476625 
	Train Epoch: 13 	Loss: 1.670031 Acc@1: 0.504889 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.594902 Acc@1: 0.508456 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.603007 Acc@1: 0.509428 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.787275 Acc@1: 0.492314 
	Train Epoch: 14 	Loss: 1.748401 Acc@1: 0.498657 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.531817 Acc@1: 0.538127 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.522738 Acc@1: 0.546831 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.573317 Acc@1: 0.560856 
	Train Epoch: 15 	Loss: 1.504362 Acc@1: 0.553682 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.512148 Acc@1: 0.556129 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.510991 Acc@1: 0.558168 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.610179 Acc@1: 0.566696 
	Train Epoch: 16 	Loss: 1.528950 Acc@1: 0.563177 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.505435 Acc@1: 0.566824 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.497119 Acc@1: 0.570075 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.637476 Acc@1: 0.561239 
	Train Epoch: 17 	Loss: 1.423218 Acc@1: 0.582326 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.483423 Acc@1: 0.584208 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.479346 Acc@1: 0.583311 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.594054 Acc@1: 0.567612 
	Train Epoch: 18 	Loss: 1.461237 Acc@1: 0.587665 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.439071 Acc@1: 0.595733 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.441921 Acc@1: 0.594391 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.506268 Acc@1: 0.594420 
	Train Epoch: 19 	Loss: 1.430334 Acc@1: 0.602324 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.428305 Acc@1: 0.598614 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.421201 Acc@1: 0.598633 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.576132 Acc@1: 0.586537 
	Train Epoch: 20 	Loss: 1.390870 Acc@1: 0.615709 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.429084 Acc@1: 0.602738 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.428185 Acc@1: 0.604820 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.513210 Acc@1: 0.596817 
	Train Epoch: 21 	Loss: 1.424716 Acc@1: 0.620419 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.393765 Acc@1: 0.613023 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.381676 Acc@1: 0.610258 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.572681 Acc@1: 0.592056 
	Train Epoch: 22 	Loss: 1.353693 Acc@1: 0.632075 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.411996 Acc@1: 0.610017 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.416876 Acc@1: 0.608422 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.590283 Acc@1: 0.590307 
	Train Epoch: 23 	Loss: 1.304497 Acc@1: 0.625330 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.357509 Acc@1: 0.621482 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.363321 Acc@1: 0.618246 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.584123 Acc@1: 0.592735 
	Train Epoch: 24 	Loss: 1.403394 Acc@1: 0.596050 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.377345 Acc@1: 0.617204 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.381851 Acc@1: 0.617598 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.561566 Acc@1: 0.594940 
	Train Epoch: 25 	Loss: 1.344298 Acc@1: 0.625571 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.385097 Acc@1: 0.617016 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.392607 Acc@1: 0.614444 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.553499 Acc@1: 0.598943 
Base private model test accuracy:  0.5983995427264933
              precision    recall  f1-score   support

         0.0       0.34      0.52      0.41       508
         1.0       0.27      0.61      0.38       482
         2.0       0.23      0.41      0.29       510
         3.0       0.12      0.26      0.16       489
         4.0       0.18      0.37      0.25       466
         5.0       0.65      0.52      0.58      2972
         6.0       0.78      0.69      0.73      3080
         7.0       0.73      0.59      0.65      2961
         8.0       0.81      0.70      0.75      3024
         9.0       0.73      0.62      0.67      3003

    accuracy                           0.60     17495
   macro avg       0.48      0.53      0.49     17495
weighted avg       0.67      0.60      0.62     17495

Base private model train accuracy:  0.6144247115419395
              precision    recall  f1-score   support

         0.0       0.67      0.65      0.66      2376
         1.0       0.65      0.70      0.67      2374
         2.0       0.56      0.56      0.56      2555
         3.0       0.47      0.46      0.47      2436
         4.0       0.57      0.52      0.54      2460
         5.0       0.55      0.55      0.55      3085
         6.0       0.65      0.70      0.67      2996
         7.0       0.63      0.60      0.62      3161
         8.0       0.71      0.72      0.71      3087
         9.0       0.65      0.66      0.66      3117

    accuracy                           0.61     27647
   macro avg       0.61      0.61      0.61     27647
weighted avg       0.61      0.61      0.61     27647

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.675902481371627
test acc: 0.7578643578643578
min train acc: 0.8925114620478859
maj train acc: 0.5164766320010024
min test acc: 0.9158696709353218
maj test acc: 0.6313465783664459
total acc: 0.716938193114908
total min acc: 0.9044617681207497
total maj acc: 0.5728861114653743
precision, recall: (0.735727222615954, 0.675902481371627)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.8, 50.24151667068924, 0.5983995427264933, 0.6144247115419395, 0.716938193114908, 0.9044617681207497, 0.5728861114653743, '              precision    recall  f1-score   support\n\n         0.0       0.34      0.52      0.41       508\n         1.0       0.27      0.61      0.38       482\n         2.0       0.23      0.41      0.29       510\n         3.0       0.12      0.26      0.16       489\n         4.0       0.18      0.37      0.25       466\n         5.0       0.65      0.52      0.58      2972\n         6.0       0.78      0.69      0.73      3080\n         7.0       0.73      0.59      0.65      2961\n         8.0       0.81      0.70      0.75      3024\n         9.0       0.73      0.62      0.67      3003\n\n    accuracy                           0.60     17495\n   macro avg       0.48      0.53      0.49     17495\nweighted avg       0.67      0.60      0.62     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.67      0.65      0.66      2376\n         1.0       0.65      0.70      0.67      2374\n         2.0       0.56      0.56      0.56      2555\n         3.0       0.47      0.46      0.47      2436\n         4.0       0.57      0.52      0.54      2460\n         5.0       0.55      0.55      0.55      3085\n         6.0       0.65      0.70      0.67      2996\n         7.0       0.63      0.60      0.62      3161\n         8.0       0.71      0.72      0.71      3087\n         9.0       0.65      0.66      0.66      3117\n\n    accuracy                           0.61     27647\n   macro avg       0.61      0.61      0.61     27647\nweighted avg       0.61      0.61      0.61     27647\n']
experiment_number: 26
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-26.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([3113, 3052, 3095, 3035, 3163, 3048, 3036, 3036, 3079, 3119])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30776, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.950320 Acc@1: 0.106700 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 3.893216 Acc@1: 0.119423 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 3.134167 Acc@1: 0.124240 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.496163 Acc@1: 0.032665 
	Train Epoch: 2 	Loss: 2.561537 Acc@1: 0.101068 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.349839 Acc@1: 0.122053 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.539465 Acc@1: 0.114885 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.304911 Acc@1: 0.032486 
	Train Epoch: 3 	Loss: 2.300767 Acc@1: 0.097682 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.299534 Acc@1: 0.130262 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.506552 Acc@1: 0.143292 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.341331 Acc@1: 0.069564 
	Train Epoch: 4 	Loss: 2.315914 Acc@1: 0.105854 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.326412 Acc@1: 0.099142 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.336088 Acc@1: 0.098073 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.318521 Acc@1: 0.028290 
	Train Epoch: 5 	Loss: 2.302432 Acc@1: 0.101297 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.302976 Acc@1: 0.101590 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.302455 Acc@1: 0.105158 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.303216 Acc@1: 0.027397 
	Train Epoch: 6 	Loss: 2.299407 Acc@1: 0.099243 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.287579 Acc@1: 0.108458 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.299300 Acc@1: 0.133745 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.293700 Acc@1: 0.220084 
	Train Epoch: 7 	Loss: 2.459306 Acc@1: 0.174355 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.237779 Acc@1: 0.191817 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.203470 Acc@1: 0.210216 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.041754 Acc@1: 0.318533 
	Train Epoch: 8 	Loss: 2.082156 Acc@1: 0.254545 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.083270 Acc@1: 0.268513 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.206005 Acc@1: 0.260804 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.053277 Acc@1: 0.272190 
	Train Epoch: 9 	Loss: 2.014626 Acc@1: 0.274542 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.001657 Acc@1: 0.300061 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.119323 Acc@1: 0.288198 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.074302 Acc@1: 0.322539 
	Train Epoch: 10 	Loss: 2.082667 Acc@1: 0.322169 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.906238 Acc@1: 0.330792 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.903756 Acc@1: 0.345988 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.904481 Acc@1: 0.375299 
	Train Epoch: 11 	Loss: 1.867051 Acc@1: 0.384988 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.832296 Acc@1: 0.385579 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.816725 Acc@1: 0.397041 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.912190 Acc@1: 0.386555 
	Train Epoch: 12 	Loss: 1.775911 Acc@1: 0.413278 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.772665 Acc@1: 0.423817 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.790380 Acc@1: 0.425133 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.732307 Acc@1: 0.447554 
	Train Epoch: 13 	Loss: 1.812220 Acc@1: 0.410980 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.777162 Acc@1: 0.433390 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.774443 Acc@1: 0.435880 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.837059 Acc@1: 0.435461 
	Train Epoch: 14 	Loss: 1.820842 Acc@1: 0.450693 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.720870 Acc@1: 0.462883 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.720043 Acc@1: 0.464976 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.725989 Acc@1: 0.466858 
	Train Epoch: 15 	Loss: 1.667428 Acc@1: 0.471758 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.652635 Acc@1: 0.482754 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.658624 Acc@1: 0.485920 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.651849 Acc@1: 0.499973 
	Train Epoch: 16 	Loss: 1.725070 Acc@1: 0.481452 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.627913 Acc@1: 0.500793 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.625001 Acc@1: 0.502218 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.730739 Acc@1: 0.496790 
	Train Epoch: 17 	Loss: 1.710049 Acc@1: 0.506132 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.637209 Acc@1: 0.508492 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.634718 Acc@1: 0.506787 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.740942 Acc@1: 0.474351 
	Train Epoch: 18 	Loss: 1.598678 Acc@1: 0.502117 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.566508 Acc@1: 0.515387 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.586542 Acc@1: 0.520671 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.749965 Acc@1: 0.497882 
	Train Epoch: 19 	Loss: 1.504738 Acc@1: 0.548714 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.578316 Acc@1: 0.529178 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.587189 Acc@1: 0.527786 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.677626 Acc@1: 0.509311 
	Train Epoch: 20 	Loss: 1.561150 Acc@1: 0.520270 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.540022 Acc@1: 0.534653 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.548099 Acc@1: 0.539772 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.770963 Acc@1: 0.503354 
	Train Epoch: 21 	Loss: 1.645397 Acc@1: 0.532020 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.571348 Acc@1: 0.543056 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.563767 Acc@1: 0.544564 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.694545 Acc@1: 0.518149 
	Train Epoch: 22 	Loss: 1.605919 Acc@1: 0.539872 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.557954 Acc@1: 0.546235 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.560252 Acc@1: 0.549686 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.723156 Acc@1: 0.514513 
	Train Epoch: 23 	Loss: 1.501344 Acc@1: 0.561569 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.546426 Acc@1: 0.550198 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.565057 Acc@1: 0.546289 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.670855 Acc@1: 0.530128 
	Train Epoch: 24 	Loss: 1.535442 Acc@1: 0.559190 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.546468 Acc@1: 0.551570 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.552740 Acc@1: 0.551110 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.683934 Acc@1: 0.527094 
	Train Epoch: 25 	Loss: 1.493003 Acc@1: 0.555913 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.559757 Acc@1: 0.545793 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.560658 Acc@1: 0.546528 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.683559 Acc@1: 0.527830 
Base private model test accuracy:  0.5282652186338954
              precision    recall  f1-score   support

         0.0       0.27      0.50      0.35       508
         1.0       0.21      0.59      0.30       482
         2.0       0.18      0.39      0.24       510
         3.0       0.10      0.24      0.14       489
         4.0       0.14      0.37      0.20       466
         5.0       0.60      0.46      0.52      2972
         6.0       0.79      0.59      0.68      3080
         7.0       0.69      0.52      0.59      2961
         8.0       0.78      0.60      0.68      3024
         9.0       0.68      0.55      0.61      3003

    accuracy                           0.53     17495
   macro avg       0.44      0.48      0.43     17495
weighted avg       0.64      0.53      0.57     17495

Base private model train accuracy:  0.5554652976345205
              precision    recall  f1-score   support

         0.0       0.61      0.56      0.58      3113
         1.0       0.61      0.69      0.65      3052
         2.0       0.54      0.52      0.53      3095
         3.0       0.47      0.41      0.44      3035
         4.0       0.54      0.53      0.53      3163
         5.0       0.46      0.48      0.47      3048
         6.0       0.57      0.61      0.59      3036
         7.0       0.55      0.54      0.55      3036
         8.0       0.60      0.64      0.62      3079
         9.0       0.59      0.58      0.58      3119

    accuracy                           0.56     30776
   macro avg       0.55      0.56      0.55     30776
weighted avg       0.55      0.56      0.55     30776

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.8314920717442162
test acc: 0.620064935064935
min train acc: 0.9648027626510824
maj train acc: 0.704225352112676
min test acc: 0.8336138806163408
maj test acc: 0.40548978795368806
total acc: 0.7257373002468495
total min acc: 0.8983739837398373
total maj acc: 0.556718910585817
precision, recall: (0.6862061568164753, 0.8314920717442162)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 1.0, 50.24151667068924, 0.5282652186338954, 0.5554652976345205, 0.7257373002468495, 0.8983739837398373, 0.556718910585817, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.50      0.35       508\n         1.0       0.21      0.59      0.30       482\n         2.0       0.18      0.39      0.24       510\n         3.0       0.10      0.24      0.14       489\n         4.0       0.14      0.37      0.20       466\n         5.0       0.60      0.46      0.52      2972\n         6.0       0.79      0.59      0.68      3080\n         7.0       0.69      0.52      0.59      2961\n         8.0       0.78      0.60      0.68      3024\n         9.0       0.68      0.55      0.61      3003\n\n    accuracy                           0.53     17495\n   macro avg       0.44      0.48      0.43     17495\nweighted avg       0.64      0.53      0.57     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.61      0.56      0.58      3113\n         1.0       0.61      0.69      0.65      3052\n         2.0       0.54      0.52      0.53      3095\n         3.0       0.47      0.41      0.44      3035\n         4.0       0.54      0.53      0.53      3163\n         5.0       0.46      0.48      0.47      3048\n         6.0       0.57      0.61      0.59      3036\n         7.0       0.55      0.54      0.55      3036\n         8.0       0.60      0.64      0.62      3079\n         9.0       0.59      0.58      0.58      3119\n\n    accuracy                           0.56     30776\n   macro avg       0.55      0.56      0.55     30776\nweighted avg       0.55      0.56      0.55     30776\n']
experiment_number: 27
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-27.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.4
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 1165, 6.0: 1165, 7.0: 1165, 8.0: 1165, 9.0: 1165}
resampled train counts:  tensor([ 482,  450,  461,  470,  442, 1139, 1166, 1125, 1156, 1122])
resampled test counts:  tensor([ 466,  466,  466,  466,  466, 1165, 1165, 1165, 1165, 1165])
training set size:  (8013, 3, 32, 32)
test set size:  (8155, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.878586 Acc@1: 0.145695 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.840570 Acc@1: 0.133820 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.759143 Acc@1: 0.136633 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.188909 Acc@1: 0.172412 
	Train Epoch: 2 	Loss: 2.232542 Acc@1: 0.155556 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.230053 Acc@1: 0.145917 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.212528 Acc@1: 0.178443 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.048096 Acc@1: 0.237933 
	Train Epoch: 3 	Loss: 2.159446 Acc@1: 0.195584 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.283996 Acc@1: 0.146623 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.269308 Acc@1: 0.149857 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.068057 Acc@1: 0.188140 
	Train Epoch: 4 	Loss: 2.204086 Acc@1: 0.129450 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.203344 Acc@1: 0.175053 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.229687 Acc@1: 0.192071 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.163309 Acc@1: 0.274328 
	Train Epoch: 5 	Loss: 2.237914 Acc@1: 0.269795 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.924293 Acc@1: 0.247387 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.627127 Acc@1: 0.216331 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.008486 Acc@1: 0.265138 
	Train Epoch: 6 	Loss: 2.237895 Acc@1: 0.190625 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.217274 Acc@1: 0.228997 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.255724 Acc@1: 0.239945 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.142537 Acc@1: 0.352261 
	Train Epoch: 7 	Loss: 2.476109 Acc@1: 0.311321 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.186253 Acc@1: 0.291974 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.192866 Acc@1: 0.303381 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.804681 Acc@1: 0.387634 
	Train Epoch: 8 	Loss: 1.943947 Acc@1: 0.359756 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.140299 Acc@1: 0.333471 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.110454 Acc@1: 0.332860 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.927735 Acc@1: 0.346966 
	Train Epoch: 9 	Loss: 2.030337 Acc@1: 0.306785 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.164098 Acc@1: 0.321264 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.159408 Acc@1: 0.345390 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.141102 Acc@1: 0.414924 
	Train Epoch: 10 	Loss: 2.387280 Acc@1: 0.379870 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.075539 Acc@1: 0.373542 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.000624 Acc@1: 0.385460 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.836465 Acc@1: 0.451496 
	Train Epoch: 11 	Loss: 1.991915 Acc@1: 0.378882 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.027917 Acc@1: 0.399530 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.973647 Acc@1: 0.413347 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.748534 Acc@1: 0.485371 
	Train Epoch: 12 	Loss: 1.899371 Acc@1: 0.428125 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.834431 Acc@1: 0.435880 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.882531 Acc@1: 0.436400 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.844164 Acc@1: 0.473489 
	Train Epoch: 13 	Loss: 1.860562 Acc@1: 0.456716 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.927729 Acc@1: 0.440067 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.870927 Acc@1: 0.456304 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.714988 Acc@1: 0.509610 
	Train Epoch: 14 	Loss: 1.980861 Acc@1: 0.468657 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.857074 Acc@1: 0.461658 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.835497 Acc@1: 0.467141 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.773794 Acc@1: 0.504523 
	Train Epoch: 15 	Loss: 1.888636 Acc@1: 0.428969 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.837536 Acc@1: 0.471336 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.846939 Acc@1: 0.474757 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.684710 Acc@1: 0.520980 
	Train Epoch: 16 	Loss: 1.814428 Acc@1: 0.491582 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.812234 Acc@1: 0.486568 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.786304 Acc@1: 0.487723 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.677786 Acc@1: 0.510007 
	Train Epoch: 17 	Loss: 1.774271 Acc@1: 0.467456 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.784129 Acc@1: 0.490296 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.748785 Acc@1: 0.488782 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.677978 Acc@1: 0.505984 
	Train Epoch: 18 	Loss: 1.738816 Acc@1: 0.524096 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.708562 Acc@1: 0.510536 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.704156 Acc@1: 0.513304 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.621147 Acc@1: 0.545011 
	Train Epoch: 19 	Loss: 1.589738 Acc@1: 0.526490 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.637987 Acc@1: 0.528245 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.637871 Acc@1: 0.522399 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.634540 Acc@1: 0.547012 
	Train Epoch: 20 	Loss: 1.723846 Acc@1: 0.488136 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.712432 Acc@1: 0.513693 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.677873 Acc@1: 0.523748 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.638611 Acc@1: 0.547219 
	Train Epoch: 21 	Loss: 1.514470 Acc@1: 0.509434 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.581631 Acc@1: 0.538764 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.658857 Acc@1: 0.528580 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.622934 Acc@1: 0.549833 
	Train Epoch: 22 	Loss: 1.655873 Acc@1: 0.537092 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.575798 Acc@1: 0.546240 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.623818 Acc@1: 0.538573 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.643679 Acc@1: 0.553679 
	Train Epoch: 23 	Loss: 1.605758 Acc@1: 0.567335 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.649330 Acc@1: 0.552614 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.628656 Acc@1: 0.542431 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.626185 Acc@1: 0.557022 
	Train Epoch: 24 	Loss: 1.670027 Acc@1: 0.510448 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.629464 Acc@1: 0.532316 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.598765 Acc@1: 0.541217 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.621453 Acc@1: 0.550902 
	Train Epoch: 25 	Loss: 1.618643 Acc@1: 0.537313 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.560252 Acc@1: 0.543304 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.595731 Acc@1: 0.536329 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.618547 Acc@1: 0.556220 
Base private model test accuracy:  0.5559302657902258
              precision    recall  f1-score   support

         0.0       0.25      0.22      0.23       508
         1.0       0.23      0.20      0.22       482
         2.0       0.12      0.06      0.08       510
         3.0       0.06      0.03      0.04       489
         4.0       0.19      0.18      0.19       466
         5.0       0.48      0.57      0.52      2972
         6.0       0.63      0.62      0.63      3080
         7.0       0.56      0.55      0.56      2961
         8.0       0.71      0.75      0.73      3024
         9.0       0.64      0.63      0.63      3003

    accuracy                           0.56     17495
   macro avg       0.39      0.38      0.38     17495
weighted avg       0.54      0.56      0.55     17495

Base private model train accuracy:  0.5392487208286534
              precision    recall  f1-score   support

         0.0       0.47      0.24      0.32       482
         1.0       0.56      0.26      0.35       450
         2.0       0.47      0.15      0.22       461
         3.0       0.22      0.07      0.10       470
         4.0       0.38      0.25      0.30       442
         5.0       0.43      0.61      0.50      1139
         6.0       0.57      0.67      0.62      1166
         7.0       0.53      0.60      0.57      1125
         8.0       0.66      0.79      0.72      1156
         9.0       0.61      0.72      0.66      1122

    accuracy                           0.54      8013
   macro avg       0.49      0.44      0.44      8013
weighted avg       0.52      0.54      0.51      8013

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.4580629056415377
test acc: 0.673289183222958
min train acc: 0.4530612244897959
maj train acc: 0.4671558350803634
min test acc: 0.6776145203111495
maj test acc: 0.6709897610921502
total acc: 0.5666213039712978
total min acc: 0.5621326616288833
total maj acc: 0.5702693370165746
precision, recall: (0.5794126934006947, 0.4580629056415377)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.4, 50.24151667068924, 0.5559302657902258, 0.5392487208286534, 0.5666213039712978, 0.5621326616288833, 0.5702693370165746, '              precision    recall  f1-score   support\n\n         0.0       0.25      0.22      0.23       508\n         1.0       0.23      0.20      0.22       482\n         2.0       0.12      0.06      0.08       510\n         3.0       0.06      0.03      0.04       489\n         4.0       0.19      0.18      0.19       466\n         5.0       0.48      0.57      0.52      2972\n         6.0       0.63      0.62      0.63      3080\n         7.0       0.56      0.55      0.56      2961\n         8.0       0.71      0.75      0.73      3024\n         9.0       0.64      0.63      0.63      3003\n\n    accuracy                           0.56     17495\n   macro avg       0.39      0.38      0.38     17495\nweighted avg       0.54      0.56      0.55     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.47      0.24      0.32       482\n         1.0       0.56      0.26      0.35       450\n         2.0       0.47      0.15      0.22       461\n         3.0       0.22      0.07      0.10       470\n         4.0       0.38      0.25      0.30       442\n         5.0       0.43      0.61      0.50      1139\n         6.0       0.57      0.67      0.62      1166\n         7.0       0.53      0.60      0.57      1125\n         8.0       0.66      0.79      0.72      1156\n         9.0       0.61      0.72      0.66      1122\n\n    accuracy                           0.54      8013\n   macro avg       0.49      0.44      0.44      8013\nweighted avg       0.52      0.54      0.51      8013\n']
experiment_number: 18
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-18.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.6
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 776, 6.0: 776, 7.0: 776, 8.0: 776, 9.0: 776}
resampled train counts:  tensor([498, 455, 445, 464, 515, 741, 760, 834, 781, 735])
resampled test counts:  tensor([466, 466, 466, 466, 466, 776, 776, 776, 776, 776])
training set size:  (6228, 3, 32, 32)
test set size:  (6210, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.438193 Acc@1: 0.063291 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.297451 Acc@1: 0.146887 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.323561 Acc@1: 0.148602 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.136165 Acc@1: 0.176358 
	Train Epoch: 2 	Loss: 2.216536 Acc@1: 0.160338 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.307055 Acc@1: 0.147992 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.339154 Acc@1: 0.159044 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.073116 Acc@1: 0.240537 
	Train Epoch: 3 	Loss: 2.255459 Acc@1: 0.137795 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.630795 Acc@1: 0.184371 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.548019 Acc@1: 0.178588 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.115444 Acc@1: 0.228485 
	Train Epoch: 4 	Loss: 2.207763 Acc@1: 0.186603 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.323048 Acc@1: 0.138863 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.308829 Acc@1: 0.155166 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.083410 Acc@1: 0.274332 
	Train Epoch: 5 	Loss: 2.219081 Acc@1: 0.198444 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.300005 Acc@1: 0.215975 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.358788 Acc@1: 0.215930 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.362720 Acc@1: 0.260995 
	Train Epoch: 6 	Loss: 2.552024 Acc@1: 0.221774 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.414880 Acc@1: 0.195819 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.362115 Acc@1: 0.185605 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.114210 Acc@1: 0.279653 
	Train Epoch: 7 	Loss: 2.246906 Acc@1: 0.191667 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.326579 Acc@1: 0.198712 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.413084 Acc@1: 0.166464 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.154478 Acc@1: 0.185636 
	Train Epoch: 8 	Loss: 2.293210 Acc@1: 0.119403 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.277019 Acc@1: 0.135854 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.368127 Acc@1: 0.153449 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.072865 Acc@1: 0.254005 
	Train Epoch: 9 	Loss: 2.293105 Acc@1: 0.192000 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.324354 Acc@1: 0.193726 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.368468 Acc@1: 0.195510 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.147497 Acc@1: 0.215798 
	Train Epoch: 10 	Loss: 2.332871 Acc@1: 0.197581 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.311805 Acc@1: 0.224460 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.431919 Acc@1: 0.225984 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.161279 Acc@1: 0.301269 
	Train Epoch: 11 	Loss: 2.253211 Acc@1: 0.322581 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.388664 Acc@1: 0.183843 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.384863 Acc@1: 0.218751 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.306601 Acc@1: 0.296121 
	Train Epoch: 12 	Loss: 2.390074 Acc@1: 0.234848 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.264792 Acc@1: 0.250780 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.257779 Acc@1: 0.250142 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.113153 Acc@1: 0.312356 
	Train Epoch: 13 	Loss: 2.215082 Acc@1: 0.246094 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.215378 Acc@1: 0.213201 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.212439 Acc@1: 0.217277 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.011764 Acc@1: 0.313664 
	Train Epoch: 14 	Loss: 2.075119 Acc@1: 0.233871 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.159813 Acc@1: 0.227086 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.218770 Acc@1: 0.228861 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.007567 Acc@1: 0.315843 
	Train Epoch: 15 	Loss: 2.106738 Acc@1: 0.261364 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.216902 Acc@1: 0.237824 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.264038 Acc@1: 0.237027 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.127511 Acc@1: 0.318297 
	Train Epoch: 16 	Loss: 2.256162 Acc@1: 0.292308 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.290246 Acc@1: 0.247239 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.264522 Acc@1: 0.246977 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.140654 Acc@1: 0.298442 
	Train Epoch: 17 	Loss: 2.374261 Acc@1: 0.277567 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.262421 Acc@1: 0.251320 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.225485 Acc@1: 0.248459 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.138606 Acc@1: 0.345178 
	Train Epoch: 18 	Loss: 2.200463 Acc@1: 0.252000 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.251468 Acc@1: 0.238519 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.245877 Acc@1: 0.243144 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.225094 Acc@1: 0.317873 
	Train Epoch: 19 	Loss: 2.290398 Acc@1: 0.270073 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.243699 Acc@1: 0.268925 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.210462 Acc@1: 0.277604 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.080960 Acc@1: 0.327508 
	Train Epoch: 20 	Loss: 2.181018 Acc@1: 0.275109 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.163279 Acc@1: 0.293998 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.151528 Acc@1: 0.283909 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.067955 Acc@1: 0.352097 
	Train Epoch: 21 	Loss: 2.234761 Acc@1: 0.255230 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.146567 Acc@1: 0.279622 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.170714 Acc@1: 0.284381 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.082797 Acc@1: 0.357972 
	Train Epoch: 22 	Loss: 2.352041 Acc@1: 0.265385 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.154183 Acc@1: 0.298379 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.153746 Acc@1: 0.301943 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.991192 Acc@1: 0.365172 
	Train Epoch: 23 	Loss: 2.127296 Acc@1: 0.279070 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.092195 Acc@1: 0.292558 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.077685 Acc@1: 0.305834 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.992957 Acc@1: 0.369518 
	Train Epoch: 24 	Loss: 2.183653 Acc@1: 0.332046 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.133397 Acc@1: 0.299253 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.137794 Acc@1: 0.293775 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.977194 Acc@1: 0.369964 
	Train Epoch: 25 	Loss: 2.132668 Acc@1: 0.295720 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.075563 Acc@1: 0.292028 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.055909 Acc@1: 0.300475 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.995141 Acc@1: 0.367473 
Base private model test accuracy:  0.36724778508145184
              precision    recall  f1-score   support

         0.0       0.06      0.07      0.06       508
         1.0       0.07      0.08      0.07       482
         2.0       0.08      0.03      0.04       510
         3.0       0.08      0.07      0.08       489
         4.0       0.08      0.10      0.09       466
         5.0       0.29      0.31      0.30      2972
         6.0       0.39      0.33      0.36      3080
         7.0       0.38      0.45      0.41      2961
         8.0       0.58      0.60      0.59      3024
         9.0       0.43      0.39      0.41      3003

    accuracy                           0.37     17495
   macro avg       0.24      0.24      0.24     17495
weighted avg       0.37      0.37      0.36     17495

Base private model train accuracy:  0.30218368657675015
              precision    recall  f1-score   support

         0.0       0.25      0.12      0.16       498
         1.0       0.26      0.12      0.17       455
         2.0       0.15      0.02      0.03       445
         3.0       0.23      0.08      0.12       464
         4.0       0.19      0.09      0.12       515
         5.0       0.20      0.33      0.25       741
         6.0       0.32      0.37      0.34       760
         7.0       0.33      0.46      0.38       834
         8.0       0.43      0.60      0.50       781
         9.0       0.33      0.41      0.36       735

    accuracy                           0.30      6228
   macro avg       0.27      0.26      0.24      6228
weighted avg       0.28      0.30      0.27      6228

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5806037251123957
test acc: 0.5172302737520129
min train acc: 0.5616
maj train acc: 0.5957104557640751
min test acc: 0.5387234042553192
maj test acc: 0.5036082474226804
total acc: 0.5489628557645924
total min acc: 0.5505154639175258
total maj acc: 0.5487516425755585
precision, recall: (0.5467190807378288, 0.5806037251123957)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.6, 50.24151667068924, 0.36724778508145184, 0.30218368657675015, 0.5489628557645924, 0.5505154639175258, 0.5487516425755585, '              precision    recall  f1-score   support\n\n         0.0       0.06      0.07      0.06       508\n         1.0       0.07      0.08      0.07       482\n         2.0       0.08      0.03      0.04       510\n         3.0       0.08      0.07      0.08       489\n         4.0       0.08      0.10      0.09       466\n         5.0       0.29      0.31      0.30      2972\n         6.0       0.39      0.33      0.36      3080\n         7.0       0.38      0.45      0.41      2961\n         8.0       0.58      0.60      0.59      3024\n         9.0       0.43      0.39      0.41      3003\n\n    accuracy                           0.37     17495\n   macro avg       0.24      0.24      0.24     17495\nweighted avg       0.37      0.37      0.36     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.25      0.12      0.16       498\n         1.0       0.26      0.12      0.17       455\n         2.0       0.15      0.02      0.03       445\n         3.0       0.23      0.08      0.12       464\n         4.0       0.19      0.09      0.12       515\n         5.0       0.20      0.33      0.25       741\n         6.0       0.32      0.37      0.34       760\n         7.0       0.33      0.46      0.38       834\n         8.0       0.43      0.60      0.50       781\n         9.0       0.33      0.41      0.36       735\n\n    accuracy                           0.30      6228\n   macro avg       0.27      0.26      0.24      6228\nweighted avg       0.28      0.30      0.27      6228\n']
experiment_number: 19
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-19.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.8
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 582, 6.0: 582, 7.0: 582, 8.0: 582, 9.0: 582}
resampled train counts:  tensor([487, 493, 458, 465, 456, 603, 572, 623, 577, 594])
resampled test counts:  tensor([466, 466, 466, 466, 466, 582, 582, 582, 582, 582])
training set size:  (5328, 3, 32, 32)
test set size:  (5240, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.680689 Acc@1: 0.070652 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.559575 Acc@1: 0.097449 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.495398 Acc@1: 0.116061 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.240075 Acc@1: 0.176132 
	Train Epoch: 2 	Loss: 2.289622 Acc@1: 0.105000 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.290045 Acc@1: 0.130897 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.285370 Acc@1: 0.152389 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.294840 Acc@1: 0.254014 
	Train Epoch: 3 	Loss: 2.431546 Acc@1: 0.172249 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.461077 Acc@1: 0.146688 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.392265 Acc@1: 0.140663 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.250697 Acc@1: 0.173591 
	Train Epoch: 4 	Loss: 2.406713 Acc@1: 0.121076 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.339130 Acc@1: 0.118383 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.329764 Acc@1: 0.139097 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.496335 Acc@1: 0.185636 
	Train Epoch: 5 	Loss: 2.329454 Acc@1: 0.140097 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.392891 Acc@1: 0.140643 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.422398 Acc@1: 0.161208 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.493313 Acc@1: 0.243601 
	Train Epoch: 6 	Loss: 2.418311 Acc@1: 0.233333 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.424467 Acc@1: 0.189098 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.575562 Acc@1: 0.168931 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.258424 Acc@1: 0.236731 
	Train Epoch: 7 	Loss: 2.346454 Acc@1: 0.168950 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.719924 Acc@1: 0.130532 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.542742 Acc@1: 0.125420 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.278031 Acc@1: 0.097284 
	Train Epoch: 8 	Loss: 2.372828 Acc@1: 0.133641 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.295589 Acc@1: 0.140231 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.296201 Acc@1: 0.161146 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.242694 Acc@1: 0.247761 
	Train Epoch: 9 	Loss: 2.304327 Acc@1: 0.222222 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.364754 Acc@1: 0.187925 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.340093 Acc@1: 0.202245 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.151101 Acc@1: 0.324694 
	Train Epoch: 10 	Loss: 2.283364 Acc@1: 0.252101 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.328726 Acc@1: 0.214967 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.319018 Acc@1: 0.216126 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.181504 Acc@1: 0.319196 
	Train Epoch: 11 	Loss: 2.582542 Acc@1: 0.170103 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.271670 Acc@1: 0.208709 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.285299 Acc@1: 0.222119 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.045492 Acc@1: 0.352301 
	Train Epoch: 12 	Loss: 2.040736 Acc@1: 0.282723 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.195911 Acc@1: 0.272226 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.202001 Acc@1: 0.258949 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.144229 Acc@1: 0.325703 
	Train Epoch: 13 	Loss: 2.115401 Acc@1: 0.268657 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.176845 Acc@1: 0.240152 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.195388 Acc@1: 0.233480 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.230814 Acc@1: 0.281052 
	Train Epoch: 14 	Loss: 2.206608 Acc@1: 0.244240 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.286780 Acc@1: 0.237072 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.307729 Acc@1: 0.240262 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.218444 Acc@1: 0.319586 
	Train Epoch: 15 	Loss: 2.338446 Acc@1: 0.284974 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.224992 Acc@1: 0.253179 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.211423 Acc@1: 0.250976 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.337307 Acc@1: 0.270912 
	Train Epoch: 16 	Loss: 2.203047 Acc@1: 0.244131 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.234584 Acc@1: 0.267120 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.221296 Acc@1: 0.268291 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.177485 Acc@1: 0.279448 
	Train Epoch: 17 	Loss: 2.314594 Acc@1: 0.265625 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.152786 Acc@1: 0.274877 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.184340 Acc@1: 0.269567 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.166262 Acc@1: 0.331887 
	Train Epoch: 18 	Loss: 2.204298 Acc@1: 0.281690 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.187093 Acc@1: 0.273638 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.160576 Acc@1: 0.278167 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.049994 Acc@1: 0.380114 
	Train Epoch: 19 	Loss: 2.174721 Acc@1: 0.336449 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.158781 Acc@1: 0.297235 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.165881 Acc@1: 0.295648 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.132700 Acc@1: 0.368352 
	Train Epoch: 20 	Loss: 2.137001 Acc@1: 0.265896 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.157034 Acc@1: 0.286595 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.154057 Acc@1: 0.290986 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.138103 Acc@1: 0.343073 
	Train Epoch: 21 	Loss: 2.288393 Acc@1: 0.252577 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.158007 Acc@1: 0.276055 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.166058 Acc@1: 0.284740 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.139718 Acc@1: 0.345884 
	Train Epoch: 22 	Loss: 2.129805 Acc@1: 0.282178 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.158969 Acc@1: 0.286028 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.113058 Acc@1: 0.293386 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.122317 Acc@1: 0.345957 
	Train Epoch: 23 	Loss: 2.107959 Acc@1: 0.296651 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.054305 Acc@1: 0.302988 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.091641 Acc@1: 0.306723 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.108562 Acc@1: 0.359454 
	Train Epoch: 24 	Loss: 1.869952 Acc@1: 0.361809 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.084179 Acc@1: 0.287449 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.091673 Acc@1: 0.289028 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.147830 Acc@1: 0.347412 
	Train Epoch: 25 	Loss: 2.156604 Acc@1: 0.313433 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.146802 Acc@1: 0.288816 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.102754 Acc@1: 0.298707 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.140241 Acc@1: 0.352757 
Base private model test accuracy:  0.35250071448985426
              precision    recall  f1-score   support

         0.0       0.09      0.13      0.11       508
         1.0       0.08      0.16      0.11       482
         2.0       0.06      0.02      0.03       510
         3.0       0.07      0.07      0.07       489
         4.0       0.09      0.21      0.12       466
         5.0       0.31      0.31      0.31      2972
         6.0       0.38      0.35      0.37      3080
         7.0       0.41      0.37      0.39      2961
         8.0       0.58      0.58      0.58      3024
         9.0       0.40      0.34      0.37      3003

    accuracy                           0.35     17495
   macro avg       0.25      0.25      0.25     17495
weighted avg       0.37      0.35      0.36     17495

Base private model train accuracy:  0.3044294294294294
              precision    recall  f1-score   support

         0.0       0.36      0.16      0.22       487
         1.0       0.37      0.22      0.27       493
         2.0       0.22      0.02      0.03       458
         3.0       0.29      0.09      0.14       465
         4.0       0.23      0.19      0.21       456
         5.0       0.24      0.37      0.29       603
         6.0       0.25      0.36      0.29       572
         7.0       0.31      0.41      0.35       623
         8.0       0.41      0.61      0.49       577
         9.0       0.32      0.44      0.37       594

    accuracy                           0.30      5328
   macro avg       0.30      0.29      0.27      5328
weighted avg       0.30      0.30      0.28      5328

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5
test acc: 0.5931297709923664
min train acc: 0.489778534923339
maj train acc: 0.5096153846153846
min test acc: 0.5839041095890412
maj test acc: 0.6005471956224351
total acc: 0.5461771385314156
total min acc: 0.5367207514944492
total maj acc: 0.5551747772446881
precision, recall: (0.5554628857381151, 0.5)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.8, 50.24151667068924, 0.35250071448985426, 0.3044294294294294, 0.5461771385314156, 0.5367207514944492, 0.5551747772446881, '              precision    recall  f1-score   support\n\n         0.0       0.09      0.13      0.11       508\n         1.0       0.08      0.16      0.11       482\n         2.0       0.06      0.02      0.03       510\n         3.0       0.07      0.07      0.07       489\n         4.0       0.09      0.21      0.12       466\n         5.0       0.31      0.31      0.31      2972\n         6.0       0.38      0.35      0.37      3080\n         7.0       0.41      0.37      0.39      2961\n         8.0       0.58      0.58      0.58      3024\n         9.0       0.40      0.34      0.37      3003\n\n    accuracy                           0.35     17495\n   macro avg       0.25      0.25      0.25     17495\nweighted avg       0.37      0.35      0.36     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.36      0.16      0.22       487\n         1.0       0.37      0.22      0.27       493\n         2.0       0.22      0.02      0.03       458\n         3.0       0.29      0.09      0.14       465\n         4.0       0.23      0.19      0.21       456\n         5.0       0.24      0.37      0.29       603\n         6.0       0.25      0.36      0.29       572\n         7.0       0.31      0.41      0.35       623\n         8.0       0.41      0.61      0.49       577\n         9.0       0.32      0.44      0.37       594\n\n    accuracy                           0.30      5328\n   macro avg       0.30      0.29      0.27      5328\nweighted avg       0.30      0.30      0.28      5328\n']
experiment_number: 20
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-20.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  1.0
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 466, 6.0: 466, 7.0: 466, 8.0: 466, 9.0: 466}
resampled train counts:  tensor([444, 464, 481, 440, 481, 461, 445, 489, 477, 484])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4666, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.243272 Acc@1: 0.108696 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.934964 Acc@1: 0.113068 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.796897 Acc@1: 0.118979 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.411413 Acc@1: 0.124521 
	Train Epoch: 2 	Loss: 2.494991 Acc@1: 0.063492 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.329735 Acc@1: 0.103944 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.316226 Acc@1: 0.116870 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.431521 Acc@1: 0.118011 
	Train Epoch: 3 	Loss: 2.416671 Acc@1: 0.177419 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.394240 Acc@1: 0.138658 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.369751 Acc@1: 0.143359 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.404385 Acc@1: 0.169392 
	Train Epoch: 4 	Loss: 2.442243 Acc@1: 0.122581 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.300581 Acc@1: 0.190819 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.292431 Acc@1: 0.186649 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.276058 Acc@1: 0.214103 
	Train Epoch: 5 	Loss: 2.278474 Acc@1: 0.165829 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.371792 Acc@1: 0.187833 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.392084 Acc@1: 0.178657 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 3.049965 Acc@1: 0.099115 
	Train Epoch: 6 	Loss: 2.677895 Acc@1: 0.107345 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.557297 Acc@1: 0.168191 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.442846 Acc@1: 0.176471 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.300312 Acc@1: 0.125141 
	Train Epoch: 7 	Loss: 2.387671 Acc@1: 0.170330 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.276256 Acc@1: 0.181780 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.292670 Acc@1: 0.173403 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.483356 Acc@1: 0.096611 
	Train Epoch: 8 	Loss: 2.460821 Acc@1: 0.175758 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.308598 Acc@1: 0.193265 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.301384 Acc@1: 0.180347 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.211736 Acc@1: 0.263849 
	Train Epoch: 9 	Loss: 2.330410 Acc@1: 0.197861 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.379225 Acc@1: 0.182994 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.337875 Acc@1: 0.184326 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.821768 Acc@1: 0.127801 
	Train Epoch: 10 	Loss: 2.544870 Acc@1: 0.222798 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.446435 Acc@1: 0.171987 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.439125 Acc@1: 0.157942 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.287302 Acc@1: 0.103295 
	Train Epoch: 11 	Loss: 2.270540 Acc@1: 0.176166 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.290571 Acc@1: 0.165412 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 2.327609 Acc@1: 0.181555 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.336260 Acc@1: 0.188524 
	Train Epoch: 12 	Loss: 2.427807 Acc@1: 0.206522 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.343196 Acc@1: 0.198021 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 2.355832 Acc@1: 0.195601 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.176337 Acc@1: 0.267105 
	Train Epoch: 13 	Loss: 2.286391 Acc@1: 0.154206 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.316208 Acc@1: 0.177922 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 2.313533 Acc@1: 0.190079 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.284147 Acc@1: 0.126027 
	Train Epoch: 14 	Loss: 2.096326 Acc@1: 0.220513 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.252640 Acc@1: 0.211582 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 2.268449 Acc@1: 0.206345 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.430588 Acc@1: 0.175912 
	Train Epoch: 15 	Loss: 2.395271 Acc@1: 0.215000 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.449398 Acc@1: 0.207647 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 2.366709 Acc@1: 0.205244 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.400067 Acc@1: 0.205963 
	Train Epoch: 16 	Loss: 2.328410 Acc@1: 0.167568 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.219685 Acc@1: 0.215101 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 2.207140 Acc@1: 0.224158 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.163906 Acc@1: 0.189253 
	Train Epoch: 17 	Loss: 2.101975 Acc@1: 0.255102 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.126064 Acc@1: 0.237800 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 2.147060 Acc@1: 0.240235 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.210098 Acc@1: 0.222358 
	Train Epoch: 18 	Loss: 2.084468 Acc@1: 0.292308 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.198857 Acc@1: 0.254685 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 2.176331 Acc@1: 0.252029 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.247929 Acc@1: 0.229991 
	Train Epoch: 19 	Loss: 2.016037 Acc@1: 0.231579 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.139744 Acc@1: 0.244758 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 2.131099 Acc@1: 0.255399 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.275342 Acc@1: 0.248117 
	Train Epoch: 20 	Loss: 1.974687 Acc@1: 0.284211 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.090249 Acc@1: 0.271108 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 2.124943 Acc@1: 0.260011 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.162094 Acc@1: 0.242462 
	Train Epoch: 21 	Loss: 2.102762 Acc@1: 0.244019 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.163086 Acc@1: 0.254402 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 2.132185 Acc@1: 0.258697 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.166703 Acc@1: 0.297483 
	Train Epoch: 22 	Loss: 2.063982 Acc@1: 0.270718 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.083947 Acc@1: 0.266070 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 2.066968 Acc@1: 0.272359 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.174053 Acc@1: 0.266906 
	Train Epoch: 23 	Loss: 2.072325 Acc@1: 0.291005 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.060738 Acc@1: 0.274075 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 2.057454 Acc@1: 0.282928 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.129593 Acc@1: 0.267229 
	Train Epoch: 24 	Loss: 2.166447 Acc@1: 0.210811 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.096801 Acc@1: 0.262504 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 2.065071 Acc@1: 0.274498 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.159168 Acc@1: 0.267425 
	Train Epoch: 25 	Loss: 2.007488 Acc@1: 0.287425 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.029021 Acc@1: 0.295089 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 2.053456 Acc@1: 0.287885 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 2.140096 Acc@1: 0.264145 
Base private model test accuracy:  0.26447556444698483
              precision    recall  f1-score   support

         0.0       0.10      0.27      0.15       508
         1.0       0.10      0.24      0.14       482
         2.0       0.06      0.06      0.06       510
         3.0       0.06      0.10      0.07       489
         4.0       0.07      0.51      0.12       466
         5.0       0.37      0.15      0.21      2972
         6.0       0.40      0.20      0.26      3080
         7.0       0.29      0.21      0.25      2961
         8.0       0.45      0.43      0.44      3024
         9.0       0.50      0.36      0.42      3003

    accuracy                           0.26     17495
   macro avg       0.24      0.25      0.21     17495
weighted avg       0.36      0.26      0.29     17495

Base private model train accuracy:  0.28911273039005575
              precision    recall  f1-score   support

         0.0       0.37      0.34      0.35       444
         1.0       0.45      0.35      0.39       464
         2.0       0.19      0.07      0.10       481
         3.0       0.18      0.11      0.13       440
         4.0       0.24      0.54      0.34       481
         5.0       0.21      0.15      0.17       461
         6.0       0.25      0.22      0.23       445
         7.0       0.23      0.25      0.24       489
         8.0       0.34      0.47      0.40       477
         9.0       0.39      0.37      0.38       484

    accuracy                           0.29      4666
   macro avg       0.28      0.29      0.27      4666
weighted avg       0.29      0.29      0.27      4666

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5649378482640377
test acc: 0.5347639484978541
min train acc: 0.532617671345995
maj train acc: 0.5987599645704162
min test acc: 0.5882352941176471
maj test acc: 0.48
total acc: 0.5498606047608835
total min acc: 0.5601832569762599
total maj acc: 0.5388328214129003
precision, recall: (0.5487094088259784, 0.5649378482640377)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 1.0, 50.24151667068924, 0.26447556444698483, 0.28911273039005575, 0.5498606047608835, 0.5601832569762599, 0.5388328214129003, '              precision    recall  f1-score   support\n\n         0.0       0.10      0.27      0.15       508\n         1.0       0.10      0.24      0.14       482\n         2.0       0.06      0.06      0.06       510\n         3.0       0.06      0.10      0.07       489\n         4.0       0.07      0.51      0.12       466\n         5.0       0.37      0.15      0.21      2972\n         6.0       0.40      0.20      0.26      3080\n         7.0       0.29      0.21      0.25      2961\n         8.0       0.45      0.43      0.44      3024\n         9.0       0.50      0.36      0.42      3003\n\n    accuracy                           0.26     17495\n   macro avg       0.24      0.25      0.21     17495\nweighted avg       0.36      0.26      0.29     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.37      0.34      0.35       444\n         1.0       0.45      0.35      0.39       464\n         2.0       0.19      0.07      0.10       481\n         3.0       0.18      0.11      0.13       440\n         4.0       0.24      0.54      0.34       481\n         5.0       0.21      0.15      0.17       461\n         6.0       0.25      0.22      0.23       445\n         7.0       0.23      0.25      0.24       489\n         8.0       0.34      0.47      0.40       477\n         9.0       0.39      0.37      0.38       484\n\n    accuracy                           0.29      4666\n   macro avg       0.28      0.29      0.27      4666\nweighted avg       0.29      0.29      0.27      4666\n']
experiment_number: 22
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-22.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1268, 1229, 1208, 1294, 1286, 3082, 3145, 3017, 3070, 3088])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21687, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 4.814927 Acc@1: 0.146399 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.949882 Acc@1: 0.153434 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.622581 Acc@1: 0.158607 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.266630 Acc@1: 0.178940 
	Train Epoch: 2 	Loss: 2.381065 Acc@1: 0.122619 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.299030 Acc@1: 0.144010 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.260339 Acc@1: 0.151312 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.116776 Acc@1: 0.171813 
	Train Epoch: 3 	Loss: 2.205097 Acc@1: 0.137376 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.236996 Acc@1: 0.156110 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.224736 Acc@1: 0.154282 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.067813 Acc@1: 0.178560 
	Train Epoch: 4 	Loss: 2.209088 Acc@1: 0.146789 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.207113 Acc@1: 0.172399 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.171485 Acc@1: 0.200952 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.076785 Acc@1: 0.208052 
	Train Epoch: 5 	Loss: 2.198511 Acc@1: 0.183815 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.240758 Acc@1: 0.170927 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.218493 Acc@1: 0.175007 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.974681 Acc@1: 0.301020 
	Train Epoch: 6 	Loss: 2.104078 Acc@1: 0.239257 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.107361 Acc@1: 0.266213 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.308276 Acc@1: 0.225835 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.053212 Acc@1: 0.217959 
	Train Epoch: 7 	Loss: 2.096419 Acc@1: 0.195946 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.156379 Acc@1: 0.236712 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.136706 Acc@1: 0.268669 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.989043 Acc@1: 0.361552 
	Train Epoch: 8 	Loss: 2.229748 Acc@1: 0.311815 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.115283 Acc@1: 0.341135 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.124233 Acc@1: 0.341144 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.716905 Acc@1: 0.438678 
	Train Epoch: 9 	Loss: 1.989795 Acc@1: 0.366359 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.999936 Acc@1: 0.367982 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.972983 Acc@1: 0.380696 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.836234 Acc@1: 0.464710 
	Train Epoch: 10 	Loss: 1.902628 Acc@1: 0.435359 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.832488 Acc@1: 0.429137 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.819663 Acc@1: 0.430634 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.564976 Acc@1: 0.506864 
	Train Epoch: 11 	Loss: 1.646320 Acc@1: 0.457627 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.799121 Acc@1: 0.441001 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.750913 Acc@1: 0.456951 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.590249 Acc@1: 0.529622 
	Train Epoch: 12 	Loss: 1.786736 Acc@1: 0.456180 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.672239 Acc@1: 0.491926 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.667446 Acc@1: 0.498488 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.565761 Acc@1: 0.550408 
	Train Epoch: 13 	Loss: 1.770603 Acc@1: 0.469751 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.666845 Acc@1: 0.497658 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.683553 Acc@1: 0.496745 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.476136 Acc@1: 0.561275 
	Train Epoch: 14 	Loss: 1.615237 Acc@1: 0.487833 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.632206 Acc@1: 0.510847 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.600489 Acc@1: 0.518674 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.448246 Acc@1: 0.568731 
	Train Epoch: 15 	Loss: 1.626610 Acc@1: 0.512761 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.597956 Acc@1: 0.536483 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.570796 Acc@1: 0.540275 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.564298 Acc@1: 0.587627 
	Train Epoch: 16 	Loss: 1.744446 Acc@1: 0.523864 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.603413 Acc@1: 0.532851 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.555509 Acc@1: 0.546829 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.523128 Acc@1: 0.596741 
	Train Epoch: 17 	Loss: 1.711701 Acc@1: 0.567691 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.535848 Acc@1: 0.560256 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.508648 Acc@1: 0.565527 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.455625 Acc@1: 0.611231 
	Train Epoch: 18 	Loss: 1.479979 Acc@1: 0.587319 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.505794 Acc@1: 0.578130 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.503672 Acc@1: 0.574684 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.366883 Acc@1: 0.615357 
	Train Epoch: 19 	Loss: 1.392304 Acc@1: 0.584580 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.482286 Acc@1: 0.570419 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.478101 Acc@1: 0.578901 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.444074 Acc@1: 0.617738 
	Train Epoch: 20 	Loss: 1.467884 Acc@1: 0.573072 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.479032 Acc@1: 0.582605 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.466788 Acc@1: 0.583984 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.358820 Acc@1: 0.627532 
	Train Epoch: 21 	Loss: 1.431289 Acc@1: 0.589510 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.443625 Acc@1: 0.597422 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.445302 Acc@1: 0.596143 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.375563 Acc@1: 0.632168 
	Train Epoch: 22 	Loss: 1.561473 Acc@1: 0.590963 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.442309 Acc@1: 0.594267 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.454364 Acc@1: 0.592610 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.357235 Acc@1: 0.631658 
	Train Epoch: 23 	Loss: 1.597974 Acc@1: 0.579812 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.435983 Acc@1: 0.598299 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.433904 Acc@1: 0.600042 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.377666 Acc@1: 0.634269 
	Train Epoch: 24 	Loss: 1.405708 Acc@1: 0.614646 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.467736 Acc@1: 0.600326 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.458347 Acc@1: 0.599433 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.373865 Acc@1: 0.632634 
	Train Epoch: 25 	Loss: 1.485597 Acc@1: 0.604265 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.466877 Acc@1: 0.596678 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.463256 Acc@1: 0.597563 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.370746 Acc@1: 0.632457 
Base private model test accuracy:  0.6322377822234925
              precision    recall  f1-score   support

         0.0       0.36      0.24      0.29       508
         1.0       0.32      0.17      0.22       482
         2.0       0.25      0.15      0.19       510
         3.0       0.05      0.02      0.02       489
         4.0       0.21      0.09      0.13       466
         5.0       0.57      0.66      0.61      2972
         6.0       0.69      0.75      0.72      3080
         7.0       0.63      0.64      0.63      2961
         8.0       0.73      0.80      0.76      3024
         9.0       0.68      0.72      0.70      3003

    accuracy                           0.63     17495
   macro avg       0.45      0.42      0.43     17495
weighted avg       0.60      0.63      0.61     17495

Base private model train accuracy:  0.5916447641444184
              precision    recall  f1-score   support

         0.0       0.55      0.37      0.44      1268
         1.0       0.46      0.42      0.44      1229
         2.0       0.40      0.27      0.32      1208
         3.0       0.39      0.19      0.26      1294
         4.0       0.42      0.23      0.30      1286
         5.0       0.55      0.65      0.59      3082
         6.0       0.63      0.74      0.68      3145
         7.0       0.62      0.66      0.64      3017
         8.0       0.69      0.80      0.74      3070
         9.0       0.65      0.72      0.68      3088

    accuracy                           0.59     21687
   macro avg       0.53      0.50      0.51     21687
weighted avg       0.57      0.59      0.57     21687

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.679424513511021
test acc: 0.44990723562152135
min train acc: 0.7301849405548216
maj train acc: 0.6602679721721206
min test acc: 0.44995172191824917
maj test acc: 0.4496941298971756
total acc: 0.5650002312352588
total min acc: 0.5882640586797065
total maj acc: 0.5555195856264163
precision, recall: (0.554034744679251, 0.679424513511021)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.4, 50.24151667068924, 0.6322377822234925, 0.5916447641444184, 0.5650002312352588, 0.5882640586797065, 0.5555195856264163, '              precision    recall  f1-score   support\n\n         0.0       0.36      0.24      0.29       508\n         1.0       0.32      0.17      0.22       482\n         2.0       0.25      0.15      0.19       510\n         3.0       0.05      0.02      0.02       489\n         4.0       0.21      0.09      0.13       466\n         5.0       0.57      0.66      0.61      2972\n         6.0       0.69      0.75      0.72      3080\n         7.0       0.63      0.64      0.63      2961\n         8.0       0.73      0.80      0.76      3024\n         9.0       0.68      0.72      0.70      3003\n\n    accuracy                           0.63     17495\n   macro avg       0.45      0.42      0.43     17495\nweighted avg       0.60      0.63      0.61     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.55      0.37      0.44      1268\n         1.0       0.46      0.42      0.44      1229\n         2.0       0.40      0.27      0.32      1208\n         3.0       0.39      0.19      0.26      1294\n         4.0       0.42      0.23      0.30      1286\n         5.0       0.55      0.65      0.59      3082\n         6.0       0.63      0.74      0.68      3145\n         7.0       0.62      0.66      0.64      3017\n         8.0       0.69      0.80      0.74      3070\n         9.0       0.65      0.72      0.68      3088\n\n    accuracy                           0.59     21687\n   macro avg       0.53      0.50      0.51     21687\nweighted avg       0.57      0.59      0.57     21687\n']
experiment_number: 18
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-18.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1934, 1905, 1867, 1871, 1873, 3193, 3100, 3076, 3066, 3159])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (25044, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.107344 Acc@1: 0.118006 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.545546 Acc@1: 0.133171 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.439943 Acc@1: 0.129109 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.193509 Acc@1: 0.170877 
	Train Epoch: 2 	Loss: 2.268361 Acc@1: 0.113340 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.259763 Acc@1: 0.138832 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.266920 Acc@1: 0.146866 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.102025 Acc@1: 0.227643 
	Train Epoch: 3 	Loss: 2.190235 Acc@1: 0.176063 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.477113 Acc@1: 0.160412 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.394225 Acc@1: 0.150423 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.110466 Acc@1: 0.197408 
	Train Epoch: 4 	Loss: 2.210965 Acc@1: 0.160569 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.224025 Acc@1: 0.195645 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.258459 Acc@1: 0.170006 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.370815 Acc@1: 0.234886 
	Train Epoch: 5 	Loss: 2.398237 Acc@1: 0.199191 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.184076 Acc@1: 0.223450 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.158921 Acc@1: 0.239418 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.926623 Acc@1: 0.263625 
	Train Epoch: 6 	Loss: 2.063725 Acc@1: 0.239067 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.055675 Acc@1: 0.272148 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.017907 Acc@1: 0.289966 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.823877 Acc@1: 0.408384 
	Train Epoch: 7 	Loss: 1.947627 Acc@1: 0.365477 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.939246 Acc@1: 0.354000 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 1.942814 Acc@1: 0.364770 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.762319 Acc@1: 0.437962 
	Train Epoch: 8 	Loss: 2.058936 Acc@1: 0.370902 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.903187 Acc@1: 0.404358 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 1.898792 Acc@1: 0.401131 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.508628 Acc@1: 0.501292 
	Train Epoch: 9 	Loss: 1.740785 Acc@1: 0.427861 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.756406 Acc@1: 0.441928 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.781132 Acc@1: 0.447575 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.570138 Acc@1: 0.513117 
	Train Epoch: 10 	Loss: 1.720566 Acc@1: 0.442872 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.744539 Acc@1: 0.459347 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.745350 Acc@1: 0.462411 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.511739 Acc@1: 0.550952 
	Train Epoch: 11 	Loss: 1.802480 Acc@1: 0.474820 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.669175 Acc@1: 0.489051 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.687178 Acc@1: 0.484020 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.460903 Acc@1: 0.566147 
	Train Epoch: 12 	Loss: 1.666569 Acc@1: 0.505051 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.722146 Acc@1: 0.508782 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.663943 Acc@1: 0.510052 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.482933 Acc@1: 0.558818 
	Train Epoch: 13 	Loss: 1.612255 Acc@1: 0.525263 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.588898 Acc@1: 0.529683 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.589027 Acc@1: 0.529226 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.455816 Acc@1: 0.576257 
	Train Epoch: 14 	Loss: 1.510546 Acc@1: 0.545455 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.550502 Acc@1: 0.551357 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.545847 Acc@1: 0.548146 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.421766 Acc@1: 0.602449 
	Train Epoch: 15 	Loss: 1.626422 Acc@1: 0.522495 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.557011 Acc@1: 0.553296 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.534840 Acc@1: 0.558920 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.424190 Acc@1: 0.597814 
	Train Epoch: 16 	Loss: 1.541717 Acc@1: 0.570722 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.527125 Acc@1: 0.559308 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.507934 Acc@1: 0.567965 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.421977 Acc@1: 0.616326 
	Train Epoch: 17 	Loss: 1.621790 Acc@1: 0.535441 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.510770 Acc@1: 0.567063 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.506252 Acc@1: 0.571795 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.421047 Acc@1: 0.601244 
	Train Epoch: 18 	Loss: 1.600667 Acc@1: 0.571429 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.486478 Acc@1: 0.574436 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.486584 Acc@1: 0.576152 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.392655 Acc@1: 0.608340 
	Train Epoch: 19 	Loss: 1.396215 Acc@1: 0.592233 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.460797 Acc@1: 0.592692 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.477037 Acc@1: 0.587752 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.374942 Acc@1: 0.620135 
	Train Epoch: 20 	Loss: 1.545312 Acc@1: 0.550505 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.457980 Acc@1: 0.589052 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.443542 Acc@1: 0.593117 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.413832 Acc@1: 0.610231 
	Train Epoch: 21 	Loss: 1.446613 Acc@1: 0.585487 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.511308 Acc@1: 0.582884 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.473721 Acc@1: 0.591135 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.358493 Acc@1: 0.624055 
	Train Epoch: 22 	Loss: 1.570495 Acc@1: 0.583942 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.494981 Acc@1: 0.584673 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.481217 Acc@1: 0.586025 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.347895 Acc@1: 0.632011 
	Train Epoch: 23 	Loss: 1.431831 Acc@1: 0.598309 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.420676 Acc@1: 0.599107 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.436254 Acc@1: 0.601083 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.358689 Acc@1: 0.631611 
	Train Epoch: 24 	Loss: 1.505966 Acc@1: 0.596273 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.467661 Acc@1: 0.600196 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.464880 Acc@1: 0.600537 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.361344 Acc@1: 0.626985 
	Train Epoch: 25 	Loss: 1.352833 Acc@1: 0.609293 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.461841 Acc@1: 0.593558 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.453408 Acc@1: 0.597175 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.349075 Acc@1: 0.632627 
Base private model test accuracy:  0.632409259788511
              precision    recall  f1-score   support

         0.0       0.33      0.32      0.33       508
         1.0       0.33      0.30      0.31       482
         2.0       0.29      0.21      0.24       510
         3.0       0.10      0.05      0.07       489
         4.0       0.24      0.16      0.19       466
         5.0       0.59      0.65      0.62      2972
         6.0       0.71      0.76      0.74      3080
         7.0       0.67      0.65      0.66      2961
         8.0       0.75      0.76      0.76      3024
         9.0       0.65      0.67      0.66      3003

    accuracy                           0.63     17495
   macro avg       0.47      0.45      0.46     17495
weighted avg       0.62      0.63      0.62     17495

Base private model train accuracy:  0.6004232550710749
              precision    recall  f1-score   support

         0.0       0.62      0.54      0.58      1934
         1.0       0.61      0.60      0.60      1905
         2.0       0.47      0.32      0.38      1867
         3.0       0.42      0.31      0.36      1871
         4.0       0.48      0.38      0.43      1873
         5.0       0.57      0.66      0.61      3193
         6.0       0.59      0.73      0.65      3100
         7.0       0.65      0.67      0.66      3076
         8.0       0.71      0.77      0.74      3066
         9.0       0.65      0.69      0.67      3159

    accuracy                           0.60     25044
   macro avg       0.58      0.57      0.57     25044
weighted avg       0.59      0.60      0.59     25044

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6259383485066283
test acc: 0.5228084415584415
min train acc: 0.6397365532381998
maj train acc: 0.617363344051447
min test acc: 0.5538896132116471
maj test acc: 0.5041407867494825
total acc: 0.574792689799533
total min acc: 0.596592770558043
total maj acc: 0.5609236921886086
precision, recall: (0.5714077422176861, 0.6259383485066283)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.6, 50.24151667068924, 0.632409259788511, 0.6004232550710749, 0.574792689799533, 0.596592770558043, 0.5609236921886086, '              precision    recall  f1-score   support\n\n         0.0       0.33      0.32      0.33       508\n         1.0       0.33      0.30      0.31       482\n         2.0       0.29      0.21      0.24       510\n         3.0       0.10      0.05      0.07       489\n         4.0       0.24      0.16      0.19       466\n         5.0       0.59      0.65      0.62      2972\n         6.0       0.71      0.76      0.74      3080\n         7.0       0.67      0.65      0.66      2961\n         8.0       0.75      0.76      0.76      3024\n         9.0       0.65      0.67      0.66      3003\n\n    accuracy                           0.63     17495\n   macro avg       0.47      0.45      0.46     17495\nweighted avg       0.62      0.63      0.62     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.62      0.54      0.58      1934\n         1.0       0.61      0.60      0.60      1905\n         2.0       0.47      0.32      0.38      1867\n         3.0       0.42      0.31      0.36      1871\n         4.0       0.48      0.38      0.43      1873\n         5.0       0.57      0.66      0.61      3193\n         6.0       0.59      0.73      0.65      3100\n         7.0       0.65      0.67      0.66      3076\n         8.0       0.71      0.77      0.74      3066\n         9.0       0.65      0.69      0.67      3159\n\n    accuracy                           0.60     25044\n   macro avg       0.58      0.57      0.57     25044\nweighted avg       0.59      0.60      0.59     25044\n']
experiment_number: 19
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-19.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2599, 2445, 2501, 2503, 2491, 3036, 3172, 3143, 3073, 3082])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (28045, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.861398 Acc@1: 0.107414 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.409814 Acc@1: 0.114473 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.487623 Acc@1: 0.122567 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.296068 Acc@1: 0.168892 
	Train Epoch: 2 	Loss: 2.300445 Acc@1: 0.100437 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.293179 Acc@1: 0.123633 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.294318 Acc@1: 0.137763 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 18.110898 Acc@1: 0.025799 
	Train Epoch: 3 	Loss: 11.488405 Acc@1: 0.093948 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 5.154916 Acc@1: 0.140922 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 3.817669 Acc@1: 0.121379 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.166961 Acc@1: 0.246325 
	Train Epoch: 4 	Loss: 2.230551 Acc@1: 0.168739 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.238556 Acc@1: 0.176872 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.227758 Acc@1: 0.174530 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.195393 Acc@1: 0.224290 
	Train Epoch: 5 	Loss: 2.249269 Acc@1: 0.208022 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.619617 Acc@1: 0.164584 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.419769 Acc@1: 0.177395 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.055520 Acc@1: 0.230803 
	Train Epoch: 6 	Loss: 2.120209 Acc@1: 0.192377 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.109787 Acc@1: 0.221869 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.156803 Acc@1: 0.206109 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.035630 Acc@1: 0.264188 
	Train Epoch: 7 	Loss: 2.104351 Acc@1: 0.234982 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.081268 Acc@1: 0.246022 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.049371 Acc@1: 0.260729 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.877502 Acc@1: 0.356560 
	Train Epoch: 8 	Loss: 2.026418 Acc@1: 0.310282 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.196582 Acc@1: 0.258673 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.080160 Acc@1: 0.281486 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.910372 Acc@1: 0.341611 
	Train Epoch: 9 	Loss: 2.034941 Acc@1: 0.321872 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 1.990604 Acc@1: 0.342059 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.030949 Acc@1: 0.337663 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.963546 Acc@1: 0.336629 
	Train Epoch: 10 	Loss: 1.890358 Acc@1: 0.322409 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.902341 Acc@1: 0.340866 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.892728 Acc@1: 0.348112 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.793099 Acc@1: 0.417585 
	Train Epoch: 11 	Loss: 1.786451 Acc@1: 0.392954 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.792171 Acc@1: 0.403876 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.815711 Acc@1: 0.409595 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.564524 Acc@1: 0.500999 
	Train Epoch: 12 	Loss: 1.766416 Acc@1: 0.441204 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.769276 Acc@1: 0.431961 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.806504 Acc@1: 0.431858 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.524753 Acc@1: 0.517746 
	Train Epoch: 13 	Loss: 1.777529 Acc@1: 0.427397 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.754144 Acc@1: 0.457456 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.753630 Acc@1: 0.457800 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.536274 Acc@1: 0.539033 
	Train Epoch: 14 	Loss: 1.631194 Acc@1: 0.462847 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.705153 Acc@1: 0.469719 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.726898 Acc@1: 0.475146 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.468824 Acc@1: 0.557409 
	Train Epoch: 15 	Loss: 1.737553 Acc@1: 0.476449 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.692017 Acc@1: 0.485471 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.684937 Acc@1: 0.490462 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.450054 Acc@1: 0.574496 
	Train Epoch: 16 	Loss: 1.698131 Acc@1: 0.503863 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.704294 Acc@1: 0.491170 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.692368 Acc@1: 0.499883 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.425313 Acc@1: 0.577489 
	Train Epoch: 17 	Loss: 1.742532 Acc@1: 0.484959 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.671419 Acc@1: 0.508492 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.678481 Acc@1: 0.509826 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.419261 Acc@1: 0.588589 
	Train Epoch: 18 	Loss: 1.588444 Acc@1: 0.523297 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.630450 Acc@1: 0.527773 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.631743 Acc@1: 0.527129 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.428669 Acc@1: 0.598656 
	Train Epoch: 19 	Loss: 1.711361 Acc@1: 0.509259 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.638084 Acc@1: 0.528957 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.635697 Acc@1: 0.531896 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.443044 Acc@1: 0.580489 
	Train Epoch: 20 	Loss: 1.624545 Acc@1: 0.531972 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.679369 Acc@1: 0.530863 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.645643 Acc@1: 0.533339 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.426626 Acc@1: 0.591436 
	Train Epoch: 21 	Loss: 1.597485 Acc@1: 0.545538 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.611630 Acc@1: 0.542300 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.623450 Acc@1: 0.539627 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.403734 Acc@1: 0.607941 
	Train Epoch: 22 	Loss: 1.675980 Acc@1: 0.537122 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.629750 Acc@1: 0.542785 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.630641 Acc@1: 0.544340 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.436506 Acc@1: 0.604457 
	Train Epoch: 23 	Loss: 1.548967 Acc@1: 0.548444 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.611631 Acc@1: 0.549003 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.639041 Acc@1: 0.545316 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.415793 Acc@1: 0.607514 
	Train Epoch: 24 	Loss: 1.713644 Acc@1: 0.541885 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.632917 Acc@1: 0.542880 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.646435 Acc@1: 0.544497 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.411853 Acc@1: 0.608023 
	Train Epoch: 25 	Loss: 1.602489 Acc@1: 0.554291 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.630641 Acc@1: 0.546973 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.627913 Acc@1: 0.545632 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.404576 Acc@1: 0.610259 
Base private model test accuracy:  0.6096027436410403
              precision    recall  f1-score   support

         0.0       0.34      0.26      0.29       508
         1.0       0.26      0.18      0.21       482
         2.0       0.20      0.15      0.17       510
         3.0       0.08      0.04      0.06       489
         4.0       0.17      0.07      0.10       466
         5.0       0.56      0.65      0.60      2972
         6.0       0.69      0.73      0.71      3080
         7.0       0.62      0.61      0.62      2961
         8.0       0.72      0.74      0.73      3024
         9.0       0.66      0.69      0.67      3003

    accuracy                           0.61     17495
   macro avg       0.43      0.41      0.42     17495
weighted avg       0.59      0.61      0.60     17495

Base private model train accuracy:  0.548796576929934
              precision    recall  f1-score   support

         0.0       0.61      0.46      0.52      2599
         1.0       0.55      0.54      0.54      2445
         2.0       0.41      0.31      0.36      2501
         3.0       0.44      0.31      0.36      2503
         4.0       0.44      0.28      0.34      2491
         5.0       0.51      0.66      0.58      3036
         6.0       0.54      0.72      0.62      3172
         7.0       0.58      0.61      0.59      3143
         8.0       0.64      0.73      0.68      3073
         9.0       0.63      0.71      0.67      3082

    accuracy                           0.55     28045
   macro avg       0.53      0.53      0.53     28045
weighted avg       0.54      0.55      0.54     28045

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5765226073313364
test acc: 0.5687590187590188
min train acc: 0.544293297942933
maj train acc: 0.6013771996939556
min test acc: 0.6429266709928618
maj test acc: 0.5093433688035297
total acc: 0.5726633670468403
total min acc: 0.5941601049868768
total maj acc: 0.5557627990738359
precision, recall: (0.5749235474006116, 0.5765226073313364)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.8, 50.24151667068924, 0.6096027436410403, 0.548796576929934, 0.5726633670468403, 0.5941601049868768, 0.5557627990738359, '              precision    recall  f1-score   support\n\n         0.0       0.34      0.26      0.29       508\n         1.0       0.26      0.18      0.21       482\n         2.0       0.20      0.15      0.17       510\n         3.0       0.08      0.04      0.06       489\n         4.0       0.17      0.07      0.10       466\n         5.0       0.56      0.65      0.60      2972\n         6.0       0.69      0.73      0.71      3080\n         7.0       0.62      0.61      0.62      2961\n         8.0       0.72      0.74      0.73      3024\n         9.0       0.66      0.69      0.67      3003\n\n    accuracy                           0.61     17495\n   macro avg       0.43      0.41      0.42     17495\nweighted avg       0.59      0.61      0.60     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.61      0.46      0.52      2599\n         1.0       0.55      0.54      0.54      2445\n         2.0       0.41      0.31      0.36      2501\n         3.0       0.44      0.31      0.36      2503\n         4.0       0.44      0.28      0.34      2491\n         5.0       0.51      0.66      0.58      3036\n         6.0       0.54      0.72      0.62      3172\n         7.0       0.58      0.61      0.59      3143\n         8.0       0.64      0.73      0.68      3073\n         9.0       0.63      0.71      0.67      3082\n\n    accuracy                           0.55     28045\n   macro avg       0.53      0.53      0.53     28045\nweighted avg       0.54      0.55      0.54     28045\n']
experiment_number: 21
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-21.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 50.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2988, 3083, 3156, 3060, 3040, 3054, 3050, 3036, 3043, 3195])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30705, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.268362 Acc@1: 0.109698 (ε = 7.77, δ = 1e-05) for α = 3.0
	Train Epoch: 1 	Loss: 2.490305 Acc@1: 0.129728 (ε = 12.38, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.401569 Acc@1: 0.116166 (ε = 14.38, δ = 1e-05) for α = 2.1
	Test set:Loss: 2.284388 Acc@1: 0.175559 
	Train Epoch: 2 	Loss: 2.220135 Acc@1: 0.163800 (ε = 15.15, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.266894 Acc@1: 0.147959 (ε = 16.54, δ = 1e-05) for α = 2.0
	Train Epoch: 2 	Loss: 2.293742 Acc@1: 0.148893 (ε = 17.71, δ = 1e-05) for α = 1.9
	Test set:Loss: 2.199644 Acc@1: 0.198821 
	Train Epoch: 3 	Loss: 2.215575 Acc@1: 0.165485 (ε = 18.24, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.364374 Acc@1: 0.157189 (ε = 19.31, δ = 1e-05) for α = 1.9
	Train Epoch: 3 	Loss: 2.749343 Acc@1: 0.150827 (ε = 20.30, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.372685 Acc@1: 0.080008 
	Train Epoch: 4 	Loss: 2.366140 Acc@1: 0.124795 (ε = 20.72, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.404355 Acc@1: 0.122955 (ε = 21.55, δ = 1e-05) for α = 1.8
	Train Epoch: 4 	Loss: 2.367279 Acc@1: 0.144875 (ε = 22.39, δ = 1e-05) for α = 1.8
	Test set:Loss: 2.248762 Acc@1: 0.168090 
	Train Epoch: 5 	Loss: 2.179341 Acc@1: 0.148268 (ε = 22.80, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.174923 Acc@1: 0.178039 (ε = 23.63, δ = 1e-05) for α = 1.8
	Train Epoch: 5 	Loss: 2.167621 Acc@1: 0.200055 (ε = 24.45, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.591426 Acc@1: 0.203906 
	Train Epoch: 6 	Loss: 2.288072 Acc@1: 0.217709 (ε = 24.78, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.186099 Acc@1: 0.239448 (ε = 25.44, δ = 1e-05) for α = 1.7
	Train Epoch: 6 	Loss: 2.157541 Acc@1: 0.252837 (ε = 26.10, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.234752 Acc@1: 0.267538 
	Train Epoch: 7 	Loss: 2.161631 Acc@1: 0.233523 (ε = 26.43, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.052308 Acc@1: 0.297507 (ε = 27.09, δ = 1e-05) for α = 1.7
	Train Epoch: 7 	Loss: 2.068613 Acc@1: 0.308152 (ε = 27.75, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.889165 Acc@1: 0.383651 
	Train Epoch: 8 	Loss: 2.027515 Acc@1: 0.304094 (ε = 28.08, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.040247 Acc@1: 0.322659 (ε = 28.74, δ = 1e-05) for α = 1.7
	Train Epoch: 8 	Loss: 2.034130 Acc@1: 0.321223 (ε = 29.41, δ = 1e-05) for α = 1.7
	Test set:Loss: 2.249062 Acc@1: 0.330971 
	Train Epoch: 9 	Loss: 2.458975 Acc@1: 0.306020 (ε = 29.74, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.040478 Acc@1: 0.319931 (ε = 30.40, δ = 1e-05) for α = 1.7
	Train Epoch: 9 	Loss: 2.006302 Acc@1: 0.337305 (ε = 30.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.748937 Acc@1: 0.433730 
	Train Epoch: 10 	Loss: 1.894752 Acc@1: 0.386719 (ε = 31.24, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 2.035052 Acc@1: 0.353599 (ε = 31.77, δ = 1e-05) for α = 1.6
	Train Epoch: 10 	Loss: 1.954739 Acc@1: 0.377320 (ε = 32.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 2.034482 Acc@1: 0.354575 
	Train Epoch: 11 	Loss: 2.088625 Acc@1: 0.343524 (ε = 32.57, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.865332 Acc@1: 0.384628 (ε = 33.10, δ = 1e-05) for α = 1.6
	Train Epoch: 11 	Loss: 1.852914 Acc@1: 0.397175 (ε = 33.64, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.611364 Acc@1: 0.522206 
	Train Epoch: 12 	Loss: 1.975056 Acc@1: 0.414369 (ε = 33.90, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.805648 Acc@1: 0.433427 (ε = 34.44, δ = 1e-05) for α = 1.6
	Train Epoch: 12 	Loss: 1.828907 Acc@1: 0.439928 (ε = 34.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.560791 Acc@1: 0.544008 
	Train Epoch: 13 	Loss: 1.929927 Acc@1: 0.441390 (ε = 35.24, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.805273 Acc@1: 0.453121 (ε = 35.77, δ = 1e-05) for α = 1.6
	Train Epoch: 13 	Loss: 1.800828 Acc@1: 0.451343 (ε = 36.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.569907 Acc@1: 0.539183 
	Train Epoch: 14 	Loss: 1.756353 Acc@1: 0.435004 (ε = 36.57, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.747326 Acc@1: 0.452582 (ε = 37.10, δ = 1e-05) for α = 1.6
	Train Epoch: 14 	Loss: 1.742619 Acc@1: 0.457895 (ε = 37.63, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.530121 Acc@1: 0.544401 
	Train Epoch: 15 	Loss: 1.653288 Acc@1: 0.470916 (ε = 37.90, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.695612 Acc@1: 0.480184 (ε = 38.43, δ = 1e-05) for α = 1.6
	Train Epoch: 15 	Loss: 1.700294 Acc@1: 0.483745 (ε = 38.97, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.511286 Acc@1: 0.555620 
	Train Epoch: 16 	Loss: 1.611838 Acc@1: 0.518003 (ε = 39.23, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.723179 Acc@1: 0.489339 (ε = 39.77, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.704726 Acc@1: 0.489789 (ε = 40.27, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.509749 Acc@1: 0.565131 
	Train Epoch: 17 	Loss: 1.594229 Acc@1: 0.497939 (ε = 40.49, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.674992 Acc@1: 0.497187 (ε = 40.92, δ = 1e-05) for α = 1.5
	Train Epoch: 17 	Loss: 1.669515 Acc@1: 0.498366 (ε = 41.36, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.593853 Acc@1: 0.551128 
	Train Epoch: 18 	Loss: 1.666827 Acc@1: 0.503882 (ε = 41.58, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.638366 Acc@1: 0.510508 (ε = 42.01, δ = 1e-05) for α = 1.5
	Train Epoch: 18 	Loss: 1.660207 Acc@1: 0.505988 (ε = 42.45, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.522583 Acc@1: 0.568232 
	Train Epoch: 19 	Loss: 1.601489 Acc@1: 0.495784 (ε = 42.66, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.614939 Acc@1: 0.515906 (ε = 43.10, δ = 1e-05) for α = 1.5
	Train Epoch: 19 	Loss: 1.622336 Acc@1: 0.517999 (ε = 43.54, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.524383 Acc@1: 0.566606 
	Train Epoch: 20 	Loss: 1.711499 Acc@1: 0.508340 (ε = 43.75, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.649124 Acc@1: 0.519969 (ε = 44.19, δ = 1e-05) for α = 1.5
	Train Epoch: 20 	Loss: 1.651717 Acc@1: 0.517601 (ε = 44.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.488414 Acc@1: 0.584932 
	Train Epoch: 21 	Loss: 1.728424 Acc@1: 0.509819 (ε = 44.84, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.662253 Acc@1: 0.522460 (ε = 45.28, δ = 1e-05) for α = 1.5
	Train Epoch: 21 	Loss: 1.652863 Acc@1: 0.522248 (ε = 45.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.482313 Acc@1: 0.579678 
	Train Epoch: 22 	Loss: 1.562036 Acc@1: 0.557929 (ε = 45.93, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.657844 Acc@1: 0.520056 (ε = 46.37, δ = 1e-05) for α = 1.5
	Train Epoch: 22 	Loss: 1.657768 Acc@1: 0.520788 (ε = 46.80, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.503320 Acc@1: 0.576953 
	Train Epoch: 23 	Loss: 1.664277 Acc@1: 0.533058 (ε = 47.02, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.642092 Acc@1: 0.524606 (ε = 47.45, δ = 1e-05) for α = 1.5
	Train Epoch: 23 	Loss: 1.634756 Acc@1: 0.527082 (ε = 47.89, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.476445 Acc@1: 0.579831 
	Train Epoch: 24 	Loss: 1.727792 Acc@1: 0.517007 (ε = 48.11, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.633602 Acc@1: 0.528016 (ε = 48.54, δ = 1e-05) for α = 1.5
	Train Epoch: 24 	Loss: 1.633882 Acc@1: 0.527471 (ε = 48.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.482867 Acc@1: 0.582711 
	Train Epoch: 25 	Loss: 1.666182 Acc@1: 0.534979 (ε = 49.20, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.634361 Acc@1: 0.523913 (ε = 49.63, δ = 1e-05) for α = 1.5
	Train Epoch: 25 	Loss: 1.621256 Acc@1: 0.525821 (ε = 50.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.482209 Acc@1: 0.582611 
Base private model test accuracy:  0.5829094026864818
              precision    recall  f1-score   support

         0.0       0.28      0.26      0.27       508
         1.0       0.24      0.24      0.24       482
         2.0       0.21      0.20      0.21       510
         3.0       0.08      0.05      0.06       489
         4.0       0.15      0.09      0.11       466
         5.0       0.55      0.61      0.58      2972
         6.0       0.68      0.70      0.69      3080
         7.0       0.59      0.56      0.58      2961
         8.0       0.70      0.75      0.73      3024
         9.0       0.64      0.62      0.63      3003

    accuracy                           0.58     17495
   macro avg       0.41      0.41      0.41     17495
weighted avg       0.57      0.58      0.58     17495

Base private model train accuracy:  0.532453997720241
              precision    recall  f1-score   support

         0.0       0.57      0.50      0.53      2988
         1.0       0.58      0.58      0.58      3083
         2.0       0.45      0.35      0.39      3156
         3.0       0.43      0.33      0.37      3060
         4.0       0.44      0.31      0.36      3040
         5.0       0.50      0.61      0.55      3054
         6.0       0.51      0.69      0.59      3050
         7.0       0.54      0.58      0.56      3036
         8.0       0.63      0.76      0.69      3043
         9.0       0.61      0.62      0.61      3195

    accuracy                           0.53     30705
   macro avg       0.53      0.53      0.52     30705
weighted avg       0.53      0.53      0.52     30705

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5417535174570088
test acc: 0.6127922077922078
min train acc: 0.5814386384789256
maj train acc: 0.5053872480669286
min test acc: 0.6191034662496742
maj test acc: 0.6066442605997932
total acc: 0.5773283038501561
total min acc: 0.6004606778545574
total maj acc: 0.55552
precision, recall: (0.5824229691876751, 0.5417535174570088)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 1.0, 50.24151667068924, 0.5829094026864818, 0.532453997720241, 0.5773283038501561, 0.6004606778545574, 0.55552, '              precision    recall  f1-score   support\n\n         0.0       0.28      0.26      0.27       508\n         1.0       0.24      0.24      0.24       482\n         2.0       0.21      0.20      0.21       510\n         3.0       0.08      0.05      0.06       489\n         4.0       0.15      0.09      0.11       466\n         5.0       0.55      0.61      0.58      2972\n         6.0       0.68      0.70      0.69      3080\n         7.0       0.59      0.56      0.58      2961\n         8.0       0.70      0.75      0.73      3024\n         9.0       0.64      0.62      0.63      3003\n\n    accuracy                           0.58     17495\n   macro avg       0.41      0.41      0.41     17495\nweighted avg       0.57      0.58      0.58     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.50      0.53      2988\n         1.0       0.58      0.58      0.58      3083\n         2.0       0.45      0.35      0.39      3156\n         3.0       0.43      0.33      0.37      3060\n         4.0       0.44      0.31      0.36      3040\n         5.0       0.50      0.61      0.55      3054\n         6.0       0.51      0.69      0.59      3050\n         7.0       0.54      0.58      0.56      3036\n         8.0       0.63      0.76      0.69      3043\n         9.0       0.61      0.62      0.61      3195\n\n    accuracy                           0.53     30705\n   macro avg       0.53      0.53      0.52     30705\nweighted avg       0.53      0.53      0.52     30705\n']
experiment_number: 23
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-23.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
resampled train counts:  tensor([ 519,  504,  522,  497,  527, 3019, 3009, 3011, 2942, 3107])
resampled test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
training set size:  (17657, 3, 32, 32)
test set size:  (17495, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.053256 Acc@1: 0.017266 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.616039 Acc@1: 0.161121 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 3.697663 Acc@1: 0.172075 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 78.741557 Acc@1: 0.175686 
	Train Epoch: 2 	Loss: 84.621162 Acc@1: 0.161473 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 13.596157 Acc@1: 0.164676 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 8.110859 Acc@1: 0.172403 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.027234 Acc@1: 0.173094 
	Train Epoch: 3 	Loss: 2.066847 Acc@1: 0.197349 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.148822 Acc@1: 0.164744 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.769452 Acc@1: 0.163682 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.050221 Acc@1: 0.168643 
	Train Epoch: 4 	Loss: 2.081846 Acc@1: 0.173134 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.084543 Acc@1: 0.171924 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.109246 Acc@1: 0.174116 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.036383 Acc@1: 0.169382 
	Train Epoch: 5 	Loss: 1.976288 Acc@1: 0.170243 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.038978 Acc@1: 0.174455 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.049461 Acc@1: 0.172273 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.032657 Acc@1: 0.173955 
	Train Epoch: 6 	Loss: 2.007681 Acc@1: 0.175074 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.051323 Acc@1: 0.170128 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.167062 Acc@1: 0.172013 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.039213 Acc@1: 0.172739 
	Train Epoch: 7 	Loss: 2.061064 Acc@1: 0.166168 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.050221 Acc@1: 0.170371 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.078764 Acc@1: 0.175563 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.026930 Acc@1: 0.172279 
	Train Epoch: 8 	Loss: 2.063516 Acc@1: 0.163324 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.042874 Acc@1: 0.178291 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.042867 Acc@1: 0.175017 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.032796 Acc@1: 0.170738 
	Train Epoch: 9 	Loss: 2.061734 Acc@1: 0.161850 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.039164 Acc@1: 0.170320 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 2.051651 Acc@1: 0.170317 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 2.033655 Acc@1: 0.171889 
	Train Epoch: 10 	Loss: 2.056478 Acc@1: 0.157965 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 2.047572 Acc@1: 0.175027 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.139572 Acc@1: 0.178176 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.036785 Acc@1: 0.175349 
	Train Epoch: 11 	Loss: 2.041772 Acc@1: 0.172028 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.055909 Acc@1: 0.172707 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.062649 Acc@1: 0.174137 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.029407 Acc@1: 0.169741 
	Train Epoch: 12 	Loss: 2.069819 Acc@1: 0.166421 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.044523 Acc@1: 0.169059 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.040800 Acc@1: 0.170011 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 2.038130 Acc@1: 0.168662 
	Train Epoch: 13 	Loss: 2.002240 Acc@1: 0.185596 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.048611 Acc@1: 0.175330 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.053710 Acc@1: 0.175910 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.031697 Acc@1: 0.169288 
	Train Epoch: 14 	Loss: 2.010676 Acc@1: 0.196221 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.028593 Acc@1: 0.169860 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.038509 Acc@1: 0.175070 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.032280 Acc@1: 0.169901 
	Train Epoch: 15 	Loss: 2.075584 Acc@1: 0.171184 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.054229 Acc@1: 0.163682 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.048847 Acc@1: 0.169584 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.032790 Acc@1: 0.175423 
	Train Epoch: 16 	Loss: 2.060461 Acc@1: 0.166906 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.059278 Acc@1: 0.178184 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.058135 Acc@1: 0.176061 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.023460 Acc@1: 0.170358 
	Train Epoch: 17 	Loss: 2.044559 Acc@1: 0.182069 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.035193 Acc@1: 0.170088 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.042056 Acc@1: 0.172245 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.026021 Acc@1: 0.169745 
	Train Epoch: 18 	Loss: 2.018743 Acc@1: 0.182094 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.027955 Acc@1: 0.180165 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.032304 Acc@1: 0.174211 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.024197 Acc@1: 0.172735 
	Train Epoch: 19 	Loss: 2.006606 Acc@1: 0.207773 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.029610 Acc@1: 0.176762 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.030497 Acc@1: 0.172701 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.023620 Acc@1: 0.168895 
	Train Epoch: 20 	Loss: 2.033822 Acc@1: 0.163758 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 2.028657 Acc@1: 0.174333 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 2.032961 Acc@1: 0.173903 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.024495 Acc@1: 0.169502 
	Train Epoch: 21 	Loss: 2.075663 Acc@1: 0.157664 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.048081 Acc@1: 0.170152 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.038726 Acc@1: 0.170117 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.022311 Acc@1: 0.172525 
	Train Epoch: 22 	Loss: 2.087659 Acc@1: 0.162393 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.035347 Acc@1: 0.167161 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.034193 Acc@1: 0.170393 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.020510 Acc@1: 0.174151 
	Train Epoch: 23 	Loss: 2.027573 Acc@1: 0.183731 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 2.044167 Acc@1: 0.172060 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 2.038275 Acc@1: 0.171627 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.022038 Acc@1: 0.169908 
	Train Epoch: 24 	Loss: 2.054521 Acc@1: 0.181180 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.032272 Acc@1: 0.179130 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.032189 Acc@1: 0.177601 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.021019 Acc@1: 0.170351 
	Train Epoch: 25 	Loss: 2.032979 Acc@1: 0.171946 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.040438 Acc@1: 0.171060 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.036049 Acc@1: 0.175532 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.021300 Acc@1: 0.169801 
Base private model test accuracy:  0.1702200628751072
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.00      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.00      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.17      0.99      0.29      2972
         6.0       0.21      0.00      0.00      3080
         7.0       0.26      0.01      0.02      2961
         8.0       0.00      0.00      0.00      3024
         9.0       0.20      0.00      0.00      3003

    accuracy                           0.17     17495
   macro avg       0.08      0.10      0.03     17495
weighted avg       0.14      0.17      0.05     17495

Base private model train accuracy:  0.17171659964886446
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       519
         1.0       0.00      0.00      0.00       504
         2.0       0.00      0.00      0.00       522
         3.0       0.00      0.00      0.00       497
         4.0       0.00      0.00      0.00       527
         5.0       0.17      0.99      0.29      3019
         6.0       0.56      0.00      0.01      3009
         7.0       0.33      0.01      0.02      3011
         8.0       0.38      0.00      0.00      2942
         9.0       0.00      0.00      0.00      3107

    accuracy                           0.17     17657
   macro avg       0.14      0.10      0.03     17657
weighted avg       0.24      0.17      0.05     17657

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6264159492523788
test acc: 0.3780724819938265
min train acc: 0.7820015515903801
maj train acc: 0.5990894483128013
min test acc: 0.21681780708985987
maj test acc: 0.403897136797455
total acc: 0.5028165007112375
total min acc: 0.5079936051159073
total maj acc: 0.5009992006394884
precision, recall: (0.504102096627165, 0.6264159492523788)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['none', 0.5, 10.013886331234898, 0.1702200628751072, 0.17171659964886446, 0.5028165007112375, 0.5079936051159073, 0.5009992006394884, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.00      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.00      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.17      0.99      0.29      2972\n         6.0       0.21      0.00      0.00      3080\n         7.0       0.26      0.01      0.02      2961\n         8.0       0.00      0.00      0.00      3024\n         9.0       0.20      0.00      0.00      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.08      0.10      0.03     17495\nweighted avg       0.14      0.17      0.05     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       519\n         1.0       0.00      0.00      0.00       504\n         2.0       0.00      0.00      0.00       522\n         3.0       0.00      0.00      0.00       497\n         4.0       0.00      0.00      0.00       527\n         5.0       0.17      0.99      0.29      3019\n         6.0       0.56      0.00      0.01      3009\n         7.0       0.33      0.01      0.02      3011\n         8.0       0.38      0.00      0.00      2942\n         9.0       0.00      0.00      0.00      3107\n\n    accuracy                           0.17     17657\n   macro avg       0.14      0.10      0.03     17657\nweighted avg       0.24      0.17      0.05     17657\n']
experiment_number: 179
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-179.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1223, 1181, 1220, 1260, 1207, 3051, 3125, 3068, 3120, 3126])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21581, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.599192 Acc@1: 0.136580 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.580515 Acc@1: 0.154844 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.643102 Acc@1: 0.157916 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 1.995672 Acc@1: 0.303618 
	Train Epoch: 2 	Loss: 2.321849 Acc@1: 0.243875 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.341258 Acc@1: 0.202187 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.245674 Acc@1: 0.224260 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.989248 Acc@1: 0.275807 
	Train Epoch: 3 	Loss: 2.105066 Acc@1: 0.228750 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.136707 Acc@1: 0.240169 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.111869 Acc@1: 0.247711 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.076285 Acc@1: 0.222051 
	Train Epoch: 4 	Loss: 2.174312 Acc@1: 0.199324 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.115273 Acc@1: 0.257848 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.065205 Acc@1: 0.284940 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 1.947027 Acc@1: 0.346659 
	Train Epoch: 5 	Loss: 2.018932 Acc@1: 0.310427 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.088053 Acc@1: 0.303750 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.024464 Acc@1: 0.322251 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.752834 Acc@1: 0.418578 
	Train Epoch: 6 	Loss: 1.800019 Acc@1: 0.380895 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 1.896073 Acc@1: 0.386449 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 1.944385 Acc@1: 0.385303 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.606686 Acc@1: 0.467481 
	Train Epoch: 7 	Loss: 1.757102 Acc@1: 0.399524 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.755507 Acc@1: 0.415004 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.782857 Acc@1: 0.428858 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.618874 Acc@1: 0.494967 
	Train Epoch: 8 	Loss: 1.846017 Acc@1: 0.429952 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.837551 Acc@1: 0.436230 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.818565 Acc@1: 0.435699 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.580613 Acc@1: 0.534308 
	Train Epoch: 9 	Loss: 1.823010 Acc@1: 0.455830 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 1.737048 Acc@1: 0.457804 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.698018 Acc@1: 0.475155 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.501780 Acc@1: 0.557422 
	Train Epoch: 10 	Loss: 1.749456 Acc@1: 0.472540 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.669495 Acc@1: 0.494089 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.648331 Acc@1: 0.501946 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.459172 Acc@1: 0.558407 
	Train Epoch: 11 	Loss: 1.582500 Acc@1: 0.514863 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.600996 Acc@1: 0.523550 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.605467 Acc@1: 0.524991 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.556823 Acc@1: 0.557905 
	Train Epoch: 12 	Loss: 1.617065 Acc@1: 0.541073 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.630719 Acc@1: 0.527591 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.631368 Acc@1: 0.527683 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.464551 Acc@1: 0.584929 
	Train Epoch: 13 	Loss: 1.540374 Acc@1: 0.548652 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.642647 Acc@1: 0.528902 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.639128 Acc@1: 0.526464 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.451399 Acc@1: 0.578838 
	Train Epoch: 14 	Loss: 1.517244 Acc@1: 0.554102 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.600030 Acc@1: 0.545341 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.605340 Acc@1: 0.545537 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.476460 Acc@1: 0.591333 
	Train Epoch: 15 	Loss: 1.553985 Acc@1: 0.545894 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.548012 Acc@1: 0.558206 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.571035 Acc@1: 0.555979 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.527153 Acc@1: 0.581809 
	Train Epoch: 16 	Loss: 1.480619 Acc@1: 0.565510 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.602740 Acc@1: 0.554488 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.554561 Acc@1: 0.559129 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.476772 Acc@1: 0.600450 
	Train Epoch: 17 	Loss: 1.624025 Acc@1: 0.537990 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.539085 Acc@1: 0.558013 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.528518 Acc@1: 0.566966 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.435621 Acc@1: 0.608243 
	Train Epoch: 18 	Loss: 1.497606 Acc@1: 0.573883 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.492247 Acc@1: 0.580191 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.505083 Acc@1: 0.579853 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.437965 Acc@1: 0.609832 
	Train Epoch: 19 	Loss: 1.559227 Acc@1: 0.604550 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.454353 Acc@1: 0.585853 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.456461 Acc@1: 0.586751 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.487893 Acc@1: 0.599129 
	Train Epoch: 20 	Loss: 1.697740 Acc@1: 0.565169 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.538163 Acc@1: 0.575147 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.512787 Acc@1: 0.576961 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.411378 Acc@1: 0.614338 
	Train Epoch: 21 	Loss: 1.361357 Acc@1: 0.610855 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.463454 Acc@1: 0.590792 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.437429 Acc@1: 0.594602 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.422828 Acc@1: 0.616832 
	Train Epoch: 22 	Loss: 1.445356 Acc@1: 0.566102 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.447246 Acc@1: 0.587668 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.444416 Acc@1: 0.594585 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.418580 Acc@1: 0.618144 
	Train Epoch: 23 	Loss: 1.390636 Acc@1: 0.615295 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.436299 Acc@1: 0.590408 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.431354 Acc@1: 0.593784 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.427494 Acc@1: 0.616795 
	Train Epoch: 24 	Loss: 1.430367 Acc@1: 0.608952 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.412714 Acc@1: 0.603551 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.433947 Acc@1: 0.598688 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.424409 Acc@1: 0.616988 
	Train Epoch: 25 	Loss: 1.363113 Acc@1: 0.604308 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.448113 Acc@1: 0.596047 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.452603 Acc@1: 0.595965 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.424440 Acc@1: 0.617874 
Base private model test accuracy:  0.6182909402686482
              precision    recall  f1-score   support

         0.0       0.34      0.30      0.32       508
         1.0       0.28      0.37      0.32       482
         2.0       0.26      0.23      0.24       510
         3.0       0.10      0.06      0.08       489
         4.0       0.20      0.20      0.20       466
         5.0       0.58      0.62      0.60      2972
         6.0       0.71      0.72      0.72      3080
         7.0       0.66      0.62      0.64      2961
         8.0       0.74      0.74      0.74      3024
         9.0       0.69      0.70      0.70      3003

    accuracy                           0.62     17495
   macro avg       0.45      0.46      0.45     17495
weighted avg       0.61      0.62      0.62     17495

Base private model train accuracy:  0.5986284231499931
              precision    recall  f1-score   support

         0.0       0.57      0.41      0.47      1223
         1.0       0.54      0.48      0.51      1181
         2.0       0.47      0.29      0.36      1220
         3.0       0.37      0.15      0.21      1260
         4.0       0.47      0.30      0.36      1207
         5.0       0.52      0.65      0.58      3051
         6.0       0.64      0.74      0.69      3125
         7.0       0.62      0.66      0.64      3068
         8.0       0.67      0.75      0.71      3120
         9.0       0.67      0.72      0.70      3126

    accuracy                           0.60     21581
   macro avg       0.55      0.52      0.52     21581
weighted avg       0.58      0.60      0.58     21581

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.556533827618165
test acc: 0.7010204081632654
min train acc: 0.7067114093959731
maj train acc: 0.499359795134443
min test acc: 0.840843720038351
maj test acc: 0.6439107166166297
total acc: 0.628743625405656
total min acc: 0.7754133246030447
total maj acc: 0.5709391765238188
precision, recall: (0.6507368877329865, 0.556533827618165)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.4, 10.013886331234898, 0.6182909402686482, 0.5986284231499931, 0.628743625405656, 0.7754133246030447, 0.5709391765238188, '              precision    recall  f1-score   support\n\n         0.0       0.34      0.30      0.32       508\n         1.0       0.28      0.37      0.32       482\n         2.0       0.26      0.23      0.24       510\n         3.0       0.10      0.06      0.08       489\n         4.0       0.20      0.20      0.20       466\n         5.0       0.58      0.62      0.60      2972\n         6.0       0.71      0.72      0.72      3080\n         7.0       0.66      0.62      0.64      2961\n         8.0       0.74      0.74      0.74      3024\n         9.0       0.69      0.70      0.70      3003\n\n    accuracy                           0.62     17495\n   macro avg       0.45      0.46      0.45     17495\nweighted avg       0.61      0.62      0.62     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.41      0.47      1223\n         1.0       0.54      0.48      0.51      1181\n         2.0       0.47      0.29      0.36      1220\n         3.0       0.37      0.15      0.21      1260\n         4.0       0.47      0.30      0.36      1207\n         5.0       0.52      0.65      0.58      3051\n         6.0       0.64      0.74      0.69      3125\n         7.0       0.62      0.66      0.64      3068\n         8.0       0.67      0.75      0.71      3120\n         9.0       0.67      0.72      0.70      3126\n\n    accuracy                           0.60     21581\n   macro avg       0.55      0.52      0.52     21581\nweighted avg       0.58      0.60      0.58     21581\n']
experiment_number: 31
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-31.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1850, 1884, 1834, 1785, 1841, 3055, 3180, 3131, 3067, 3089])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (24716, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.677713 Acc@1: 0.082035 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.462300 Acc@1: 0.133890 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.394508 Acc@1: 0.133322 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.101702 Acc@1: 0.164200 
	Train Epoch: 2 	Loss: 2.265197 Acc@1: 0.102459 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.265215 Acc@1: 0.146137 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.346425 Acc@1: 0.150407 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.068524 Acc@1: 0.290613 
	Train Epoch: 3 	Loss: 2.231550 Acc@1: 0.199390 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.314111 Acc@1: 0.179017 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.286562 Acc@1: 0.189442 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.084415 Acc@1: 0.360746 
	Train Epoch: 4 	Loss: 2.174638 Acc@1: 0.289446 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.307250 Acc@1: 0.205035 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.223798 Acc@1: 0.233333 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 1.911991 Acc@1: 0.368076 
	Train Epoch: 5 	Loss: 2.043241 Acc@1: 0.294002 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.180022 Acc@1: 0.284764 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.123767 Acc@1: 0.293816 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.020890 Acc@1: 0.411817 
	Train Epoch: 6 	Loss: 2.142210 Acc@1: 0.338525 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.016168 Acc@1: 0.346023 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 1.993808 Acc@1: 0.353486 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.751071 Acc@1: 0.446025 
	Train Epoch: 7 	Loss: 1.863963 Acc@1: 0.402210 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.019973 Acc@1: 0.358468 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.003980 Acc@1: 0.352117 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.847691 Acc@1: 0.432608 
	Train Epoch: 8 	Loss: 1.881822 Acc@1: 0.376387 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.885764 Acc@1: 0.400178 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.950813 Acc@1: 0.386385 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.649860 Acc@1: 0.461833 
	Train Epoch: 9 	Loss: 1.860853 Acc@1: 0.349057 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 1.851614 Acc@1: 0.404126 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.857186 Acc@1: 0.415822 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.596245 Acc@1: 0.508148 
	Train Epoch: 10 	Loss: 1.676018 Acc@1: 0.472410 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.769470 Acc@1: 0.441903 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.787573 Acc@1: 0.442910 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.497256 Acc@1: 0.544045 
	Train Epoch: 11 	Loss: 1.627474 Acc@1: 0.465000 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.744772 Acc@1: 0.460183 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.713688 Acc@1: 0.465147 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.576761 Acc@1: 0.536469 
	Train Epoch: 12 	Loss: 1.681848 Acc@1: 0.476143 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.692845 Acc@1: 0.492842 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.677155 Acc@1: 0.496080 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.681003 Acc@1: 0.531530 
	Train Epoch: 13 	Loss: 1.784983 Acc@1: 0.484472 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.667634 Acc@1: 0.501139 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.683718 Acc@1: 0.507270 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.599536 Acc@1: 0.546582 
	Train Epoch: 14 	Loss: 1.649026 Acc@1: 0.485714 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.644275 Acc@1: 0.505621 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.653085 Acc@1: 0.507794 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.657370 Acc@1: 0.538120 
	Train Epoch: 15 	Loss: 1.597335 Acc@1: 0.553408 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.595364 Acc@1: 0.532886 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.607016 Acc@1: 0.531218 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.550862 Acc@1: 0.584566 
	Train Epoch: 16 	Loss: 1.579404 Acc@1: 0.554645 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.591635 Acc@1: 0.540317 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.590988 Acc@1: 0.542271 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.717294 Acc@1: 0.537853 
	Train Epoch: 17 	Loss: 1.568996 Acc@1: 0.518711 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.584922 Acc@1: 0.541067 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.553279 Acc@1: 0.550415 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.707890 Acc@1: 0.544021 
	Train Epoch: 18 	Loss: 1.596456 Acc@1: 0.551148 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.583513 Acc@1: 0.552782 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.559919 Acc@1: 0.553951 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.609825 Acc@1: 0.566590 
	Train Epoch: 19 	Loss: 1.615892 Acc@1: 0.542424 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.565003 Acc@1: 0.562821 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.560123 Acc@1: 0.563843 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.611988 Acc@1: 0.570446 
	Train Epoch: 20 	Loss: 1.468505 Acc@1: 0.593909 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.518262 Acc@1: 0.569071 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.520260 Acc@1: 0.566756 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.626882 Acc@1: 0.571172 
	Train Epoch: 21 	Loss: 1.418114 Acc@1: 0.597180 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.507443 Acc@1: 0.583075 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.528629 Acc@1: 0.574920 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.603834 Acc@1: 0.577679 
	Train Epoch: 22 	Loss: 1.432357 Acc@1: 0.606464 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.502189 Acc@1: 0.573931 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.515417 Acc@1: 0.573905 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.598391 Acc@1: 0.580746 
	Train Epoch: 23 	Loss: 1.552268 Acc@1: 0.596234 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.502670 Acc@1: 0.579510 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.481562 Acc@1: 0.583193 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.605770 Acc@1: 0.579604 
	Train Epoch: 24 	Loss: 1.608463 Acc@1: 0.577621 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.507548 Acc@1: 0.584596 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.520629 Acc@1: 0.579927 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.599467 Acc@1: 0.581056 
	Train Epoch: 25 	Loss: 1.597888 Acc@1: 0.562688 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.511628 Acc@1: 0.576058 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.505627 Acc@1: 0.576764 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.598798 Acc@1: 0.583098 
Base private model test accuracy:  0.5826236067447842
              precision    recall  f1-score   support

         0.0       0.29      0.41      0.34       508
         1.0       0.21      0.41      0.28       482
         2.0       0.21      0.32      0.26       510
         3.0       0.11      0.17      0.13       489
         4.0       0.20      0.32      0.24       466
         5.0       0.60      0.54      0.57      2972
         6.0       0.76      0.70      0.73      3080
         7.0       0.71      0.62      0.66      2961
         8.0       0.72      0.64      0.68      3024
         9.0       0.66      0.61      0.64      3003

    accuracy                           0.58     17495
   macro avg       0.45      0.47      0.45     17495
weighted avg       0.62      0.58      0.60     17495

Base private model train accuracy:  0.5784107460754168
              precision    recall  f1-score   support

         0.0       0.62      0.55      0.58      1850
         1.0       0.60      0.58      0.59      1884
         2.0       0.43      0.39      0.41      1834
         3.0       0.40      0.28      0.33      1785
         4.0       0.52      0.42      0.47      1841
         5.0       0.50      0.56      0.53      3055
         6.0       0.66      0.73      0.69      3180
         7.0       0.62      0.63      0.63      3131
         8.0       0.63      0.70      0.66      3067
         9.0       0.61      0.66      0.64      3089

    accuracy                           0.58     24716
   macro avg       0.56      0.55      0.55     24716
weighted avg       0.57      0.58      0.57     24716

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7582133031234828
test acc: 0.6018668831168832
min train acc: 0.8865264100268576
maj train acc: 0.6845586364792674
min test acc: 0.8277801817395067
maj test acc: 0.4666580176440063
total acc: 0.6801604668125456
total min acc: 0.8566556655665567
total maj acc: 0.5766859344894028
precision, recall: (0.6563922942206655, 0.7582133031234828)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.6, 10.013886331234898, 0.5826236067447842, 0.5784107460754168, 0.6801604668125456, 0.8566556655665567, 0.5766859344894028, '              precision    recall  f1-score   support\n\n         0.0       0.29      0.41      0.34       508\n         1.0       0.21      0.41      0.28       482\n         2.0       0.21      0.32      0.26       510\n         3.0       0.11      0.17      0.13       489\n         4.0       0.20      0.32      0.24       466\n         5.0       0.60      0.54      0.57      2972\n         6.0       0.76      0.70      0.73      3080\n         7.0       0.71      0.62      0.66      2961\n         8.0       0.72      0.64      0.68      3024\n         9.0       0.66      0.61      0.64      3003\n\n    accuracy                           0.58     17495\n   macro avg       0.45      0.47      0.45     17495\nweighted avg       0.62      0.58      0.60     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.62      0.55      0.58      1850\n         1.0       0.60      0.58      0.59      1884\n         2.0       0.43      0.39      0.41      1834\n         3.0       0.40      0.28      0.33      1785\n         4.0       0.52      0.42      0.47      1841\n         5.0       0.50      0.56      0.53      3055\n         6.0       0.66      0.73      0.69      3180\n         7.0       0.62      0.63      0.63      3131\n         8.0       0.63      0.70      0.66      3067\n         9.0       0.61      0.66      0.64      3089\n\n    accuracy                           0.58     24716\n   macro avg       0.56      0.55      0.55     24716\nweighted avg       0.57      0.58      0.57     24716\n']
experiment_number: 32
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-32.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2470, 2420, 2417, 2405, 2404, 3165, 3104, 3144, 3083, 3037])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (27649, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.157262 Acc@1: 0.092081 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.530401 Acc@1: 0.116301 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.445515 Acc@1: 0.124164 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.250590 Acc@1: 0.171990 
	Train Epoch: 2 	Loss: 2.286023 Acc@1: 0.108499 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.306318 Acc@1: 0.137129 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.362879 Acc@1: 0.128015 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.128650 Acc@1: 0.232581 
	Train Epoch: 3 	Loss: 2.254213 Acc@1: 0.151737 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.403015 Acc@1: 0.153885 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.388144 Acc@1: 0.138126 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.151479 Acc@1: 0.222528 
	Train Epoch: 4 	Loss: 2.256034 Acc@1: 0.150709 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.252538 Acc@1: 0.168300 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 3.057559 Acc@1: 0.142534 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.272248 Acc@1: 0.200922 
	Train Epoch: 5 	Loss: 2.313368 Acc@1: 0.134394 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.365708 Acc@1: 0.119851 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.334324 Acc@1: 0.114977 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.235722 Acc@1: 0.170527 
	Train Epoch: 6 	Loss: 2.295876 Acc@1: 0.117813 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.297494 Acc@1: 0.110720 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.298809 Acc@1: 0.112840 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.473448 Acc@1: 0.233414 
	Train Epoch: 7 	Loss: 2.402512 Acc@1: 0.157943 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.347871 Acc@1: 0.132003 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.296733 Acc@1: 0.146686 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.237523 Acc@1: 0.237154 
	Train Epoch: 8 	Loss: 2.268298 Acc@1: 0.173599 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.205748 Acc@1: 0.211218 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.262214 Acc@1: 0.207067 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.036703 Acc@1: 0.325310 
	Train Epoch: 9 	Loss: 2.151727 Acc@1: 0.229401 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.152307 Acc@1: 0.225550 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 2.155353 Acc@1: 0.248725 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.810664 Acc@1: 0.416512 
	Train Epoch: 10 	Loss: 2.045235 Acc@1: 0.317360 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 2.018418 Acc@1: 0.324853 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.020740 Acc@1: 0.338287 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.913765 Acc@1: 0.412014 
	Train Epoch: 11 	Loss: 1.942758 Acc@1: 0.390925 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.984260 Acc@1: 0.364798 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.953042 Acc@1: 0.369624 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.752273 Acc@1: 0.455212 
	Train Epoch: 12 	Loss: 1.967517 Acc@1: 0.375410 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.904712 Acc@1: 0.385707 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.908401 Acc@1: 0.389602 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.749712 Acc@1: 0.457008 
	Train Epoch: 13 	Loss: 2.008214 Acc@1: 0.370403 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.840694 Acc@1: 0.407074 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.817663 Acc@1: 0.415330 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.755135 Acc@1: 0.473658 
	Train Epoch: 14 	Loss: 1.927852 Acc@1: 0.424842 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.823781 Acc@1: 0.430569 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.792459 Acc@1: 0.437954 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.728032 Acc@1: 0.469966 
	Train Epoch: 15 	Loss: 1.713952 Acc@1: 0.453721 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.740290 Acc@1: 0.450538 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.752485 Acc@1: 0.450660 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.665319 Acc@1: 0.484711 
	Train Epoch: 16 	Loss: 1.749023 Acc@1: 0.443733 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.752713 Acc@1: 0.452571 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.748707 Acc@1: 0.453207 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.793191 Acc@1: 0.454190 
	Train Epoch: 17 	Loss: 1.635005 Acc@1: 0.477312 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.712380 Acc@1: 0.461411 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.721218 Acc@1: 0.458551 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.695252 Acc@1: 0.490179 
	Train Epoch: 18 	Loss: 1.711150 Acc@1: 0.463346 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.693812 Acc@1: 0.467366 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.701460 Acc@1: 0.472357 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.683568 Acc@1: 0.493346 
	Train Epoch: 19 	Loss: 1.624534 Acc@1: 0.489401 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.659084 Acc@1: 0.480268 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.654525 Acc@1: 0.482242 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.737682 Acc@1: 0.487079 
	Train Epoch: 20 	Loss: 1.641077 Acc@1: 0.504178 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.682983 Acc@1: 0.484028 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.660389 Acc@1: 0.487235 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.691683 Acc@1: 0.495105 
	Train Epoch: 21 	Loss: 1.643143 Acc@1: 0.479711 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.656874 Acc@1: 0.488111 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.659404 Acc@1: 0.486867 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.663408 Acc@1: 0.510430 
	Train Epoch: 22 	Loss: 1.633199 Acc@1: 0.502313 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.619981 Acc@1: 0.495364 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.618737 Acc@1: 0.496841 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.690143 Acc@1: 0.503753 
	Train Epoch: 23 	Loss: 1.659894 Acc@1: 0.492390 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.636516 Acc@1: 0.499071 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.639870 Acc@1: 0.497253 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.651625 Acc@1: 0.512412 
	Train Epoch: 24 	Loss: 1.619351 Acc@1: 0.515209 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.613329 Acc@1: 0.500959 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.618567 Acc@1: 0.501059 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.663491 Acc@1: 0.509538 
	Train Epoch: 25 	Loss: 1.554941 Acc@1: 0.496625 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.611548 Acc@1: 0.503194 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.619597 Acc@1: 0.497190 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.675634 Acc@1: 0.506534 
Base private model test accuracy:  0.5064304086881967
              precision    recall  f1-score   support

         0.0       0.22      0.41      0.29       508
         1.0       0.24      0.57      0.33       482
         2.0       0.16      0.28      0.20       510
         3.0       0.08      0.15      0.11       489
         4.0       0.13      0.30      0.19       466
         5.0       0.53      0.41      0.46      2972
         6.0       0.70      0.55      0.62      3080
         7.0       0.61      0.53      0.57      2961
         8.0       0.72      0.62      0.66      3024
         9.0       0.62      0.55      0.58      3003

    accuracy                           0.51     17495
   macro avg       0.40      0.44      0.40     17495
weighted avg       0.57      0.51      0.53     17495

Base private model train accuracy:  0.49470143585663134
              precision    recall  f1-score   support

         0.0       0.57      0.51      0.54      2470
         1.0       0.58      0.60      0.59      2420
         2.0       0.44      0.37      0.40      2417
         3.0       0.36      0.28      0.32      2405
         4.0       0.42      0.35      0.38      2404
         5.0       0.41      0.44      0.42      3165
         6.0       0.49      0.55      0.52      3104
         7.0       0.55      0.55      0.55      3144
         8.0       0.57      0.65      0.60      3083
         9.0       0.50      0.57      0.53      3037

    accuracy                           0.49     27649
   macro avg       0.49      0.49      0.49     27649
weighted avg       0.49      0.49      0.49     27649

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6931423611111112
test acc: 0.7585137085137085
min train acc: 0.8714839144348998
maj train acc: 0.5596873818227657
min test acc: 0.9437912707360283
maj test acc: 0.6081451507636079
total acc: 0.7258705389394596
total min acc: 0.9084472254240079
total maj acc: 0.5834936514043862
precision, recall: (0.7411246036043004, 0.6931423611111112)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 0.8, 10.013886331234898, 0.5064304086881967, 0.49470143585663134, 0.7258705389394596, 0.9084472254240079, 0.5834936514043862, '              precision    recall  f1-score   support\n\n         0.0       0.22      0.41      0.29       508\n         1.0       0.24      0.57      0.33       482\n         2.0       0.16      0.28      0.20       510\n         3.0       0.08      0.15      0.11       489\n         4.0       0.13      0.30      0.19       466\n         5.0       0.53      0.41      0.46      2972\n         6.0       0.70      0.55      0.62      3080\n         7.0       0.61      0.53      0.57      2961\n         8.0       0.72      0.62      0.66      3024\n         9.0       0.62      0.55      0.58      3003\n\n    accuracy                           0.51     17495\n   macro avg       0.40      0.44      0.40     17495\nweighted avg       0.57      0.51      0.53     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.57      0.51      0.54      2470\n         1.0       0.58      0.60      0.59      2420\n         2.0       0.44      0.37      0.40      2417\n         3.0       0.36      0.28      0.32      2405\n         4.0       0.42      0.35      0.38      2404\n         5.0       0.41      0.44      0.42      3165\n         6.0       0.49      0.55      0.52      3104\n         7.0       0.55      0.55      0.55      3144\n         8.0       0.57      0.65      0.60      3083\n         9.0       0.50      0.57      0.53      3037\n\n    accuracy                           0.49     27649\n   macro avg       0.49      0.49      0.49     27649\nweighted avg       0.49      0.49      0.49     27649\n']
experiment_number: 33
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-33.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'over', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing oversampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([3072, 3101, 3149, 3130, 3017, 3068, 3090, 3165, 3085, 3099])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (30976, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.298296 Acc@1: 0.109908 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.501110 Acc@1: 0.105767 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.436740 Acc@1: 0.108264 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.407230 Acc@1: 0.028863 
	Train Epoch: 2 	Loss: 2.379069 Acc@1: 0.119391 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 4.162623 Acc@1: 0.139854 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 3.280968 Acc@1: 0.119069 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.290927 Acc@1: 0.198707 
	Train Epoch: 3 	Loss: 2.309698 Acc@1: 0.135696 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.494887 Acc@1: 0.117665 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.419670 Acc@1: 0.119346 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.233620 Acc@1: 0.169715 
	Train Epoch: 4 	Loss: 2.273197 Acc@1: 0.130616 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.318331 Acc@1: 0.142626 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.314812 Acc@1: 0.159570 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.159223 Acc@1: 0.216254 
	Train Epoch: 5 	Loss: 2.216210 Acc@1: 0.204781 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.229220 Acc@1: 0.233264 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.284909 Acc@1: 0.242270 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.190805 Acc@1: 0.252825 
	Train Epoch: 6 	Loss: 2.291645 Acc@1: 0.222689 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.388396 Acc@1: 0.195865 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.392685 Acc@1: 0.189200 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.129866 Acc@1: 0.203160 
	Train Epoch: 7 	Loss: 2.179181 Acc@1: 0.276349 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.168245 Acc@1: 0.259538 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.146917 Acc@1: 0.272389 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.895796 Acc@1: 0.353873 
	Train Epoch: 8 	Loss: 2.046343 Acc@1: 0.328063 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.008765 Acc@1: 0.335112 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.968682 Acc@1: 0.348031 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.911682 Acc@1: 0.353110 
	Train Epoch: 9 	Loss: 1.934381 Acc@1: 0.358650 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 1.897080 Acc@1: 0.374619 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.887573 Acc@1: 0.392127 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.858215 Acc@1: 0.378922 
	Train Epoch: 10 	Loss: 1.791465 Acc@1: 0.380524 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.821929 Acc@1: 0.414891 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.818141 Acc@1: 0.420160 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.751156 Acc@1: 0.475117 
	Train Epoch: 11 	Loss: 1.800829 Acc@1: 0.441589 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.745913 Acc@1: 0.457785 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.739610 Acc@1: 0.467645 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.731313 Acc@1: 0.503939 
	Train Epoch: 12 	Loss: 1.671497 Acc@1: 0.496825 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.687461 Acc@1: 0.494492 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.680655 Acc@1: 0.495872 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.939926 Acc@1: 0.454310 
	Train Epoch: 13 	Loss: 1.714622 Acc@1: 0.499578 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.701576 Acc@1: 0.489933 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.700103 Acc@1: 0.495984 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.643446 Acc@1: 0.536855 
	Train Epoch: 14 	Loss: 1.678354 Acc@1: 0.517077 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.586473 Acc@1: 0.530993 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.601216 Acc@1: 0.534362 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.655384 Acc@1: 0.545703 
	Train Epoch: 15 	Loss: 1.592154 Acc@1: 0.551807 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.579762 Acc@1: 0.545280 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.595512 Acc@1: 0.544555 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.716898 Acc@1: 0.527273 
	Train Epoch: 16 	Loss: 1.580257 Acc@1: 0.542248 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.553863 Acc@1: 0.552712 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.538023 Acc@1: 0.560991 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.768218 Acc@1: 0.536359 
	Train Epoch: 17 	Loss: 1.559881 Acc@1: 0.576893 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.551293 Acc@1: 0.571039 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.527750 Acc@1: 0.573438 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.752577 Acc@1: 0.535160 
	Train Epoch: 18 	Loss: 1.464761 Acc@1: 0.574934 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.484096 Acc@1: 0.582864 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.487502 Acc@1: 0.586639 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.739159 Acc@1: 0.549852 
	Train Epoch: 19 	Loss: 1.541978 Acc@1: 0.572785 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.511909 Acc@1: 0.584898 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.498856 Acc@1: 0.587733 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.708869 Acc@1: 0.554054 
	Train Epoch: 20 	Loss: 1.483498 Acc@1: 0.586151 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.485592 Acc@1: 0.590587 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.466470 Acc@1: 0.594875 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.709806 Acc@1: 0.561275 
	Train Epoch: 21 	Loss: 1.502365 Acc@1: 0.593828 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.480032 Acc@1: 0.598356 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.481697 Acc@1: 0.595356 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.680316 Acc@1: 0.569115 
	Train Epoch: 22 	Loss: 1.401425 Acc@1: 0.619651 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.445665 Acc@1: 0.606201 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.449347 Acc@1: 0.603410 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.709505 Acc@1: 0.561341 
	Train Epoch: 23 	Loss: 1.418570 Acc@1: 0.632838 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.430372 Acc@1: 0.602678 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.422665 Acc@1: 0.603620 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.715325 Acc@1: 0.561038 
	Train Epoch: 24 	Loss: 1.415802 Acc@1: 0.608661 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.436859 Acc@1: 0.598883 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.442861 Acc@1: 0.596377 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.725323 Acc@1: 0.558680 
	Train Epoch: 25 	Loss: 1.531290 Acc@1: 0.586319 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.442557 Acc@1: 0.608512 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.433783 Acc@1: 0.609633 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.700443 Acc@1: 0.565757 
Base private model test accuracy:  0.5664475564446985
              precision    recall  f1-score   support

         0.0       0.26      0.51      0.34       508
         1.0       0.24      0.59      0.34       482
         2.0       0.20      0.36      0.26       510
         3.0       0.10      0.25      0.15       489
         4.0       0.18      0.49      0.26       466
         5.0       0.64      0.48      0.55      2972
         6.0       0.80      0.64      0.71      3080
         7.0       0.72      0.58      0.65      2961
         8.0       0.80      0.63      0.70      3024
         9.0       0.73      0.59      0.65      3003

    accuracy                           0.57     17495
   macro avg       0.47      0.51      0.46     17495
weighted avg       0.66      0.57      0.60     17495

Base private model train accuracy:  0.6105694731404959
              precision    recall  f1-score   support

         0.0       0.70      0.72      0.71      3072
         1.0       0.69      0.72      0.71      3101
         2.0       0.58      0.53      0.56      3149
         3.0       0.53      0.45      0.48      3130
         4.0       0.55      0.60      0.57      3017
         5.0       0.51      0.52      0.51      3068
         6.0       0.62      0.66      0.64      3090
         7.0       0.62      0.61      0.62      3165
         8.0       0.69      0.66      0.68      3085
         9.0       0.61      0.63      0.62      3099

    accuracy                           0.61     30976
   macro avg       0.61      0.61      0.61     30976
weighted avg       0.61      0.61      0.61     30976

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.7721461776859504
test acc: 0.7681168831168831
min train acc: 0.9264627659574468
maj train acc: 0.6276299112801014
min test acc: 0.9604024248677931
maj test acc: 0.5734621914587958
total acc: 0.7701372701372702
total min acc: 0.9436914816997316
total maj acc: 0.6009519521451083
precision, recall: (0.7700579523502897, 0.7721461776859504)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['over', 1.0, 10.013886331234898, 0.5664475564446985, 0.6105694731404959, 0.7701372701372702, 0.9436914816997316, 0.6009519521451083, '              precision    recall  f1-score   support\n\n         0.0       0.26      0.51      0.34       508\n         1.0       0.24      0.59      0.34       482\n         2.0       0.20      0.36      0.26       510\n         3.0       0.10      0.25      0.15       489\n         4.0       0.18      0.49      0.26       466\n         5.0       0.64      0.48      0.55      2972\n         6.0       0.80      0.64      0.71      3080\n         7.0       0.72      0.58      0.65      2961\n         8.0       0.80      0.63      0.70      3024\n         9.0       0.73      0.59      0.65      3003\n\n    accuracy                           0.57     17495\n   macro avg       0.47      0.51      0.46     17495\nweighted avg       0.66      0.57      0.60     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.70      0.72      0.71      3072\n         1.0       0.69      0.72      0.71      3101\n         2.0       0.58      0.53      0.56      3149\n         3.0       0.53      0.45      0.48      3130\n         4.0       0.55      0.60      0.57      3017\n         5.0       0.51      0.52      0.51      3068\n         6.0       0.62      0.66      0.64      3090\n         7.0       0.62      0.61      0.62      3165\n         8.0       0.69      0.66      0.68      3085\n         9.0       0.61      0.63      0.62      3099\n\n    accuracy                           0.61     30976\n   macro avg       0.61      0.61      0.61     30976\nweighted avg       0.61      0.61      0.61     30976\n']
experiment_number: 34
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/over/test_results-34.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.4
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 1165, 6.0: 1165, 7.0: 1165, 8.0: 1165, 9.0: 1165}
resampled train counts:  tensor([ 488,  469,  467,  446,  472, 1228, 1200, 1187, 1218, 1195])
resampled test counts:  tensor([ 466,  466,  466,  466,  466, 1165, 1165, 1165, 1165, 1165])
training set size:  (8370, 3, 32, 32)
test set size:  (8155, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.159015 Acc@1: 0.044025 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 3.084007 Acc@1: 0.150035 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.793072 Acc@1: 0.158624 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 1.913182 Acc@1: 0.328810 
	Train Epoch: 2 	Loss: 2.274580 Acc@1: 0.272973 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.368279 Acc@1: 0.216225 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.347087 Acc@1: 0.223757 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.352654 Acc@1: 0.194052 
	Train Epoch: 3 	Loss: 2.513455 Acc@1: 0.164134 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.443343 Acc@1: 0.169365 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.407233 Acc@1: 0.177679 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.081069 Acc@1: 0.271255 
	Train Epoch: 4 	Loss: 2.290987 Acc@1: 0.247024 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.323783 Acc@1: 0.247819 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.366226 Acc@1: 0.264727 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.146562 Acc@1: 0.271344 
	Train Epoch: 5 	Loss: 3.078365 Acc@1: 0.193642 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.397275 Acc@1: 0.242758 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.415828 Acc@1: 0.242014 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.263663 Acc@1: 0.291938 
	Train Epoch: 6 	Loss: 2.533571 Acc@1: 0.189274 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.473092 Acc@1: 0.233178 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.368102 Acc@1: 0.214726 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.093633 Acc@1: 0.280603 
	Train Epoch: 7 	Loss: 2.268560 Acc@1: 0.246914 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.195333 Acc@1: 0.217515 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.222118 Acc@1: 0.216113 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.989075 Acc@1: 0.259832 
	Train Epoch: 8 	Loss: 2.127710 Acc@1: 0.168142 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.257347 Acc@1: 0.223876 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.231080 Acc@1: 0.221777 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.038134 Acc@1: 0.286993 
	Train Epoch: 9 	Loss: 2.200841 Acc@1: 0.185535 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.194510 Acc@1: 0.220800 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 2.186399 Acc@1: 0.219341 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 2.022720 Acc@1: 0.271435 
	Train Epoch: 10 	Loss: 2.124902 Acc@1: 0.242525 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 2.153752 Acc@1: 0.233180 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.157322 Acc@1: 0.229513 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.039470 Acc@1: 0.240464 
	Train Epoch: 11 	Loss: 2.243365 Acc@1: 0.224852 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.168694 Acc@1: 0.225099 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.150065 Acc@1: 0.232460 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.009334 Acc@1: 0.285764 
	Train Epoch: 12 	Loss: 2.064177 Acc@1: 0.291667 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.131915 Acc@1: 0.251369 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.156481 Acc@1: 0.257777 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.997544 Acc@1: 0.289751 
	Train Epoch: 13 	Loss: 2.218140 Acc@1: 0.212963 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.249084 Acc@1: 0.262957 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.217565 Acc@1: 0.273763 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.998608 Acc@1: 0.314863 
	Train Epoch: 14 	Loss: 2.164926 Acc@1: 0.230769 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.090921 Acc@1: 0.291428 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.108712 Acc@1: 0.286095 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.989316 Acc@1: 0.347518 
	Train Epoch: 15 	Loss: 2.140870 Acc@1: 0.278736 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.125617 Acc@1: 0.294089 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.128926 Acc@1: 0.296973 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.945921 Acc@1: 0.339866 
	Train Epoch: 16 	Loss: 2.070104 Acc@1: 0.284345 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.156000 Acc@1: 0.292765 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.145074 Acc@1: 0.293089 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.018165 Acc@1: 0.350179 
	Train Epoch: 17 	Loss: 2.057826 Acc@1: 0.354167 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.100509 Acc@1: 0.292687 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.105283 Acc@1: 0.295379 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.088337 Acc@1: 0.344861 
	Train Epoch: 18 	Loss: 2.201349 Acc@1: 0.251429 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.115158 Acc@1: 0.293234 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.091157 Acc@1: 0.302273 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.927265 Acc@1: 0.353000 
	Train Epoch: 19 	Loss: 2.118237 Acc@1: 0.283582 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.039616 Acc@1: 0.303102 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.048532 Acc@1: 0.302059 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.904013 Acc@1: 0.356050 
	Train Epoch: 20 	Loss: 2.000460 Acc@1: 0.292011 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 2.091444 Acc@1: 0.296219 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 2.081249 Acc@1: 0.308288 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.916802 Acc@1: 0.359434 
	Train Epoch: 21 	Loss: 2.050882 Acc@1: 0.319403 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.068329 Acc@1: 0.296519 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.037897 Acc@1: 0.307172 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.936502 Acc@1: 0.356723 
	Train Epoch: 22 	Loss: 2.022176 Acc@1: 0.316109 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.060425 Acc@1: 0.304333 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.069424 Acc@1: 0.306625 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.876451 Acc@1: 0.360973 
	Train Epoch: 23 	Loss: 2.010767 Acc@1: 0.310241 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 2.030328 Acc@1: 0.306353 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 2.054392 Acc@1: 0.306438 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.902073 Acc@1: 0.355937 
	Train Epoch: 24 	Loss: 2.064545 Acc@1: 0.302632 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.064636 Acc@1: 0.305743 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.029602 Acc@1: 0.307662 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.909588 Acc@1: 0.357283 
	Train Epoch: 25 	Loss: 2.070099 Acc@1: 0.280120 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.989800 Acc@1: 0.325865 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.019197 Acc@1: 0.314027 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.886769 Acc@1: 0.357500 
Base private model test accuracy:  0.3568448128036582
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.10      0.01      0.01       482
         2.0       0.00      0.00      0.00       510
         3.0       0.00      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.28      0.21      0.24      2972
         6.0       0.33      0.61      0.43      3080
         7.0       0.30      0.32      0.31      2961
         8.0       0.47      0.60      0.52      3024
         9.0       0.39      0.33      0.36      3003

    accuracy                           0.36     17495
   macro avg       0.19      0.21      0.19     17495
weighted avg       0.31      0.36      0.32     17495

Base private model train accuracy:  0.3090800477897252
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       488
         1.0       0.14      0.00      0.01       469
         2.0       0.00      0.00      0.00       467
         3.0       0.00      0.00      0.00       446
         4.0       0.00      0.00      0.00       472
         5.0       0.25      0.22      0.23      1228
         6.0       0.27      0.61      0.37      1200
         7.0       0.27      0.35      0.30      1187
         8.0       0.40      0.60      0.48      1218
         9.0       0.37      0.36      0.36      1195

    accuracy                           0.31      8370
   macro avg       0.17      0.21      0.18      8370
weighted avg       0.23      0.31      0.25      8370

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.46714456391875747
test acc: 0.5337257787588914
min train acc: 0.2244062244062244
maj train acc: 0.5711793440334961
min test acc: 0.7982532751091703
maj test acc: 0.43167912984364376
total acc: 0.5
total min acc: 0.5021132713440406
total maj acc: 0.5005165289256198
precision, recall: (0.5070020746887967, 0.46714456391875747)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.4, 10.013886331234898, 0.3568448128036582, 0.3090800477897252, 0.5, 0.5021132713440406, 0.5005165289256198, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.10      0.01      0.01       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.00      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.28      0.21      0.24      2972\n         6.0       0.33      0.61      0.43      3080\n         7.0       0.30      0.32      0.31      2961\n         8.0       0.47      0.60      0.52      3024\n         9.0       0.39      0.33      0.36      3003\n\n    accuracy                           0.36     17495\n   macro avg       0.19      0.21      0.19     17495\nweighted avg       0.31      0.36      0.32     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       488\n         1.0       0.14      0.00      0.01       469\n         2.0       0.00      0.00      0.00       467\n         3.0       0.00      0.00      0.00       446\n         4.0       0.00      0.00      0.00       472\n         5.0       0.25      0.22      0.23      1228\n         6.0       0.27      0.61      0.37      1200\n         7.0       0.27      0.35      0.30      1187\n         8.0       0.40      0.60      0.48      1218\n         9.0       0.37      0.36      0.36      1195\n\n    accuracy                           0.31      8370\n   macro avg       0.17      0.21      0.18      8370\nweighted avg       0.23      0.31      0.25      8370\n']
experiment_number: 25
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-25.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.6
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 776, 6.0: 776, 7.0: 776, 8.0: 776, 9.0: 776}
resampled train counts:  tensor([492, 415, 472, 489, 471, 752, 783, 755, 735, 773])
resampled test counts:  tensor([466, 466, 466, 466, 466, 776, 776, 776, 776, 776])
training set size:  (6137, 3, 32, 32)
test set size:  (6210, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.077603 Acc@1: 0.110132 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.486929 Acc@1: 0.120269 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.475808 Acc@1: 0.148328 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.488439 Acc@1: 0.192996 
	Train Epoch: 2 	Loss: 2.734522 Acc@1: 0.143519 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.458702 Acc@1: 0.132427 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.472687 Acc@1: 0.144377 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.333754 Acc@1: 0.167744 
	Train Epoch: 3 	Loss: 2.409480 Acc@1: 0.138577 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.410874 Acc@1: 0.157587 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.475175 Acc@1: 0.154287 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.219913 Acc@1: 0.176292 
	Train Epoch: 4 	Loss: 2.238325 Acc@1: 0.142308 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.424712 Acc@1: 0.114822 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.396835 Acc@1: 0.121849 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.455392 Acc@1: 0.199736 
	Train Epoch: 5 	Loss: 3.257059 Acc@1: 0.192825 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.797803 Acc@1: 0.146040 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.643174 Acc@1: 0.136704 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.416366 Acc@1: 0.175323 
	Train Epoch: 6 	Loss: 2.361444 Acc@1: 0.133858 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.452974 Acc@1: 0.141675 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.434722 Acc@1: 0.137231 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.293047 Acc@1: 0.175839 
	Train Epoch: 7 	Loss: 2.473302 Acc@1: 0.115226 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.516459 Acc@1: 0.130361 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.510016 Acc@1: 0.131191 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.525454 Acc@1: 0.180777 
	Train Epoch: 8 	Loss: 2.858732 Acc@1: 0.125954 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.616803 Acc@1: 0.139780 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.558338 Acc@1: 0.153550 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.334622 Acc@1: 0.234096 
	Train Epoch: 9 	Loss: 2.868391 Acc@1: 0.165323 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.470546 Acc@1: 0.138621 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 2.462274 Acc@1: 0.139349 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 2.325060 Acc@1: 0.188614 
	Train Epoch: 10 	Loss: 2.575762 Acc@1: 0.190265 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 2.528508 Acc@1: 0.144462 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.501487 Acc@1: 0.148057 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.464235 Acc@1: 0.237327 
	Train Epoch: 11 	Loss: 2.501297 Acc@1: 0.201550 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.492884 Acc@1: 0.162056 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.538529 Acc@1: 0.149325 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.256058 Acc@1: 0.211738 
	Train Epoch: 12 	Loss: 2.370955 Acc@1: 0.139013 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.506292 Acc@1: 0.171319 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.515297 Acc@1: 0.167934 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 2.336421 Acc@1: 0.173198 
	Train Epoch: 13 	Loss: 2.695836 Acc@1: 0.143426 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.403797 Acc@1: 0.122964 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.378822 Acc@1: 0.125504 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.218424 Acc@1: 0.174094 
	Train Epoch: 14 	Loss: 2.289276 Acc@1: 0.126984 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.344747 Acc@1: 0.124614 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.359422 Acc@1: 0.122412 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.297876 Acc@1: 0.172442 
	Train Epoch: 15 	Loss: 2.356251 Acc@1: 0.114754 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.351282 Acc@1: 0.120649 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.382973 Acc@1: 0.121825 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.237462 Acc@1: 0.183958 
	Train Epoch: 16 	Loss: 2.383422 Acc@1: 0.118577 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.333530 Acc@1: 0.117333 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.319483 Acc@1: 0.122230 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.195137 Acc@1: 0.174720 
	Train Epoch: 17 	Loss: 2.297126 Acc@1: 0.082988 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.320676 Acc@1: 0.123533 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.326330 Acc@1: 0.130655 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.247546 Acc@1: 0.178054 
	Train Epoch: 18 	Loss: 2.309095 Acc@1: 0.130597 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.383836 Acc@1: 0.128447 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.356981 Acc@1: 0.133044 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.217697 Acc@1: 0.185004 
	Train Epoch: 19 	Loss: 2.274996 Acc@1: 0.149635 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.301742 Acc@1: 0.135984 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.292777 Acc@1: 0.135717 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.211704 Acc@1: 0.186435 
	Train Epoch: 20 	Loss: 2.293437 Acc@1: 0.138340 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 2.305387 Acc@1: 0.154312 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 2.297452 Acc@1: 0.152508 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.236753 Acc@1: 0.195128 
	Train Epoch: 21 	Loss: 2.293656 Acc@1: 0.149425 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.336322 Acc@1: 0.145328 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.325429 Acc@1: 0.138945 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.222227 Acc@1: 0.190219 
	Train Epoch: 22 	Loss: 2.294894 Acc@1: 0.156627 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.300991 Acc@1: 0.133657 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.297663 Acc@1: 0.137763 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.229759 Acc@1: 0.190046 
	Train Epoch: 23 	Loss: 2.306562 Acc@1: 0.135021 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 2.312667 Acc@1: 0.144284 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 2.311201 Acc@1: 0.147690 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.222012 Acc@1: 0.182709 
	Train Epoch: 24 	Loss: 2.306237 Acc@1: 0.125926 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.282120 Acc@1: 0.146664 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.284712 Acc@1: 0.139865 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.219846 Acc@1: 0.183828 
	Train Epoch: 25 	Loss: 2.251782 Acc@1: 0.148148 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.275832 Acc@1: 0.142830 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.289829 Acc@1: 0.147946 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.222244 Acc@1: 0.184768 
Base private model test accuracy:  0.1841097456416119
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.06      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.06      0.00      0.00       489
         4.0       0.00      0.00      0.00       466
         5.0       0.19      0.01      0.02      2972
         6.0       0.40      0.13      0.19      3080
         7.0       0.17      0.94      0.29      2961
         8.0       0.10      0.00      0.00      3024
         9.0       0.12      0.00      0.00      3003

    accuracy                           0.18     17495
   macro avg       0.11      0.11      0.05     17495
weighted avg       0.18      0.18      0.09     17495

Base private model train accuracy:  0.14013361577317907
              precision    recall  f1-score   support

         0.0       0.17      0.00      0.01       492
         1.0       0.33      0.00      0.01       415
         2.0       0.00      0.00      0.00       472
         3.0       0.38      0.01      0.01       489
         4.0       0.38      0.01      0.02       471
         5.0       0.20      0.01      0.02       752
         6.0       0.32      0.15      0.20       783
         7.0       0.13      0.96      0.22       755
         8.0       0.17      0.00      0.00       735
         9.0       0.14      0.00      0.01       773

    accuracy                           0.14      6137
   macro avg       0.22      0.11      0.05      6137
weighted avg       0.21      0.14      0.06      6137

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.5860495436766623
test acc: 0.4016103059581321
min train acc: 0.6038961038961039
maj train acc: 0.5661178969729156
min test acc: 0.4059322033898305
maj test acc: 0.39896640826873386
total acc: 0.4932771747934554
total min acc: 0.5070480928689884
total maj acc: 0.4814038763750655
precision, recall: (0.49179431072210067, 0.5860495436766623)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.6, 10.013886331234898, 0.1841097456416119, 0.14013361577317907, 0.4932771747934554, 0.5070480928689884, 0.4814038763750655, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.06      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.06      0.00      0.00       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.19      0.01      0.02      2972\n         6.0       0.40      0.13      0.19      3080\n         7.0       0.17      0.94      0.29      2961\n         8.0       0.10      0.00      0.00      3024\n         9.0       0.12      0.00      0.00      3003\n\n    accuracy                           0.18     17495\n   macro avg       0.11      0.11      0.05     17495\nweighted avg       0.18      0.18      0.09     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.17      0.00      0.01       492\n         1.0       0.33      0.00      0.01       415\n         2.0       0.00      0.00      0.00       472\n         3.0       0.38      0.01      0.01       489\n         4.0       0.38      0.01      0.02       471\n         5.0       0.20      0.01      0.02       752\n         6.0       0.32      0.15      0.20       783\n         7.0       0.13      0.96      0.22       755\n         8.0       0.17      0.00      0.00       735\n         9.0       0.14      0.00      0.01       773\n\n    accuracy                           0.14      6137\n   macro avg       0.22      0.11      0.05      6137\nweighted avg       0.21      0.14      0.06      6137\n']
experiment_number: 26
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-26.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  0.8
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 582, 6.0: 582, 7.0: 582, 8.0: 582, 9.0: 582}
resampled train counts:  tensor([472, 497, 452, 495, 453, 585, 622, 620, 584, 544])
resampled test counts:  tensor([466, 466, 466, 466, 466, 582, 582, 582, 582, 582])
training set size:  (5324, 3, 32, 32)
test set size:  (5240, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.116793 Acc@1: 0.154185 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 3.357119 Acc@1: 0.122516 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 3.030078 Acc@1: 0.115945 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.087141 Acc@1: 0.271611 
	Train Epoch: 2 	Loss: 2.238955 Acc@1: 0.180000 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.423700 Acc@1: 0.168747 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.431658 Acc@1: 0.149403 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.123007 Acc@1: 0.275371 
	Train Epoch: 3 	Loss: 2.885248 Acc@1: 0.180000 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.652177 Acc@1: 0.145161 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.787527 Acc@1: 0.126703 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.402997 Acc@1: 0.171653 
	Train Epoch: 4 	Loss: 2.363847 Acc@1: 0.141463 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.551515 Acc@1: 0.114301 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.479350 Acc@1: 0.113860 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.422226 Acc@1: 0.177478 
	Train Epoch: 5 	Loss: 2.594301 Acc@1: 0.131313 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.596756 Acc@1: 0.099144 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.685879 Acc@1: 0.100163 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 3.040897 Acc@1: 0.028633 
	Train Epoch: 6 	Loss: 2.713099 Acc@1: 0.088235 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.472936 Acc@1: 0.112970 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.488027 Acc@1: 0.107202 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.490328 Acc@1: 0.173785 
	Train Epoch: 7 	Loss: 2.324502 Acc@1: 0.135135 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.406098 Acc@1: 0.126440 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.459376 Acc@1: 0.116715 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.374495 Acc@1: 0.168253 
	Train Epoch: 8 	Loss: 2.374576 Acc@1: 0.101322 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.493562 Acc@1: 0.105338 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.774639 Acc@1: 0.109219 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.481270 Acc@1: 0.166511 
	Train Epoch: 9 	Loss: 2.355374 Acc@1: 0.124444 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 3.241547 Acc@1: 0.094992 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 2.898603 Acc@1: 0.107234 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 3.098113 Acc@1: 0.028816 
	Train Epoch: 10 	Loss: 2.433925 Acc@1: 0.080214 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 2.488844 Acc@1: 0.111913 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.754596 Acc@1: 0.104003 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.464876 Acc@1: 0.172829 
	Train Epoch: 11 	Loss: 2.318095 Acc@1: 0.125604 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.802153 Acc@1: 0.119368 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.668780 Acc@1: 0.116319 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.576172 Acc@1: 0.171216 
	Train Epoch: 12 	Loss: 3.336835 Acc@1: 0.126168 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.479982 Acc@1: 0.107569 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 2.491322 Acc@1: 0.109756 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 2.578494 Acc@1: 0.028416 
	Train Epoch: 13 	Loss: 2.384585 Acc@1: 0.104348 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.505025 Acc@1: 0.104502 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.475654 Acc@1: 0.110588 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.666085 Acc@1: 0.172675 
	Train Epoch: 14 	Loss: 2.294227 Acc@1: 0.122642 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.493455 Acc@1: 0.100875 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.509123 Acc@1: 0.101605 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.455603 Acc@1: 0.167587 
	Train Epoch: 15 	Loss: 2.711612 Acc@1: 0.103960 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.462075 Acc@1: 0.113879 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.427769 Acc@1: 0.115940 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.434618 Acc@1: 0.166637 
	Train Epoch: 16 	Loss: 2.391525 Acc@1: 0.086735 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.378176 Acc@1: 0.109322 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.366999 Acc@1: 0.110768 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 2.354918 Acc@1: 0.168556 
	Train Epoch: 17 	Loss: 2.302807 Acc@1: 0.113861 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.357790 Acc@1: 0.108622 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.413006 Acc@1: 0.112420 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.369372 Acc@1: 0.168630 
	Train Epoch: 18 	Loss: 2.596992 Acc@1: 0.105528 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.386365 Acc@1: 0.110443 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.380466 Acc@1: 0.117558 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.379036 Acc@1: 0.167930 
	Train Epoch: 19 	Loss: 2.447756 Acc@1: 0.093596 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.491753 Acc@1: 0.104880 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.525410 Acc@1: 0.105754 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.307522 Acc@1: 0.173468 
	Train Epoch: 20 	Loss: 2.611932 Acc@1: 0.118721 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 2.565056 Acc@1: 0.103224 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 2.549784 Acc@1: 0.113315 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.333582 Acc@1: 0.172968 
	Train Epoch: 21 	Loss: 2.545666 Acc@1: 0.077320 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.567303 Acc@1: 0.104082 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.454385 Acc@1: 0.100463 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.340513 Acc@1: 0.174264 
	Train Epoch: 22 	Loss: 3.335243 Acc@1: 0.117647 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.430585 Acc@1: 0.115400 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.461253 Acc@1: 0.112797 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.325859 Acc@1: 0.171270 
	Train Epoch: 23 	Loss: 2.300493 Acc@1: 0.104348 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 2.331882 Acc@1: 0.114721 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 2.330741 Acc@1: 0.115860 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.317750 Acc@1: 0.167640 
	Train Epoch: 24 	Loss: 2.283008 Acc@1: 0.090452 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.368219 Acc@1: 0.109969 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.345848 Acc@1: 0.114050 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.322891 Acc@1: 0.168166 
	Train Epoch: 25 	Loss: 2.293016 Acc@1: 0.104762 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.327564 Acc@1: 0.115651 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.328983 Acc@1: 0.110805 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.322573 Acc@1: 0.169765 
Base private model test accuracy:  0.16896256073163762
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.20      0.00      0.00       482
         2.0       0.00      0.00      0.00       510
         3.0       0.06      0.01      0.02       489
         4.0       0.00      0.00      0.00       466
         5.0       0.24      0.01      0.02      2972
         6.0       0.25      0.00      0.00      3080
         7.0       0.17      0.98      0.29      2961
         8.0       0.00      0.00      0.00      3024
         9.0       0.16      0.01      0.01      3003

    accuracy                           0.17     17495
   macro avg       0.11      0.10      0.03     17495
weighted avg       0.15      0.17      0.06     17495

Base private model train accuracy:  0.11870773854244929
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       472
         1.0       0.00      0.00      0.00       497
         2.0       0.00      0.00      0.00       452
         3.0       0.11      0.00      0.01       495
         4.0       0.18      0.00      0.01       453
         5.0       0.17      0.01      0.02       585
         6.0       0.14      0.00      0.00       622
         7.0       0.12      0.99      0.21       620
         8.0       0.00      0.00      0.00       584
         9.0       0.11      0.01      0.02       544

    accuracy                           0.12      5324
   macro avg       0.08      0.10      0.03      5324
weighted avg       0.09      0.12      0.03      5324

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6254695717505635
test acc: 0.34160305343511455
min train acc: 0.228
maj train acc: 0.9927536231884058
min test acc: 0.7793468667255075
maj test acc: 0.010688042752171056
total acc: 0.48466489965922
total min acc: 0.4901384809064205
total maj acc: 0.48175182481751827
precision, recall: (0.4911504424778761, 0.6254695717505635)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 0.8, 10.013886331234898, 0.16896256073163762, 0.11870773854244929, 0.48466489965922, 0.4901384809064205, 0.48175182481751827, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.20      0.00      0.00       482\n         2.0       0.00      0.00      0.00       510\n         3.0       0.06      0.01      0.02       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.24      0.01      0.02      2972\n         6.0       0.25      0.00      0.00      3080\n         7.0       0.17      0.98      0.29      2961\n         8.0       0.00      0.00      0.00      3024\n         9.0       0.16      0.01      0.01      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.11      0.10      0.03     17495\nweighted avg       0.15      0.17      0.06     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       472\n         1.0       0.00      0.00      0.00       497\n         2.0       0.00      0.00      0.00       452\n         3.0       0.11      0.00      0.01       495\n         4.0       0.18      0.00      0.01       453\n         5.0       0.17      0.01      0.02       585\n         6.0       0.14      0.00      0.00       622\n         7.0       0.12      0.99      0.21       620\n         8.0       0.00      0.00      0.00       584\n         9.0       0.11      0.01      0.02       544\n\n    accuracy                           0.12      5324\n   macro avg       0.08      0.10      0.03      5324\nweighted avg       0.09      0.12      0.03      5324\n']
experiment_number: 27
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-27.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'under', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing undersampling at  1.0
{0.0: 466, 1.0: 466, 2.0: 466, 3.0: 466, 4.0: 466, 5.0: 466, 6.0: 466, 7.0: 466, 8.0: 466, 9.0: 466}
resampled train counts:  tensor([490, 466, 494, 447, 483, 473, 474, 472, 453, 455])
resampled test counts:  tensor([466, 466, 466, 466, 466, 466, 466, 466, 466, 466])
training set size:  (4707, 3, 32, 32)
test set size:  (4660, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.932811 Acc@1: 0.119171 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.549878 Acc@1: 0.101083 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.467779 Acc@1: 0.113025 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.270309 Acc@1: 0.191178 
	Train Epoch: 2 	Loss: 2.452963 Acc@1: 0.105000 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.616229 Acc@1: 0.132487 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.574411 Acc@1: 0.120919 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.533434 Acc@1: 0.169948 
	Train Epoch: 3 	Loss: 2.938783 Acc@1: 0.119565 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.816533 Acc@1: 0.114801 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.675769 Acc@1: 0.110485 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.660006 Acc@1: 0.034527 
	Train Epoch: 4 	Loss: 2.389205 Acc@1: 0.101695 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.719593 Acc@1: 0.102109 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.745984 Acc@1: 0.106539 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.875517 Acc@1: 0.033671 
	Train Epoch: 5 	Loss: 2.481706 Acc@1: 0.117647 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.905107 Acc@1: 0.095493 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.838296 Acc@1: 0.102524 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.814219 Acc@1: 0.031250 
	Train Epoch: 6 	Loss: 2.361895 Acc@1: 0.109827 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 3.063208 Acc@1: 0.110122 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 3.215427 Acc@1: 0.105404 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 3.620073 Acc@1: 0.175989 
	Train Epoch: 7 	Loss: 3.944864 Acc@1: 0.078125 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 3.914617 Acc@1: 0.093760 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 3.783058 Acc@1: 0.090863 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.925057 Acc@1: 0.167653 
	Train Epoch: 8 	Loss: 2.678838 Acc@1: 0.102151 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.960319 Acc@1: 0.101244 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.827655 Acc@1: 0.094163 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 3.665391 Acc@1: 0.175106 
	Train Epoch: 9 	Loss: 2.909196 Acc@1: 0.107692 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 3.461343 Acc@1: 0.090135 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 3.218511 Acc@1: 0.102057 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 2.936061 Acc@1: 0.029039 
	Train Epoch: 10 	Loss: 3.714451 Acc@1: 0.155000 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 3.027083 Acc@1: 0.114700 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.811278 Acc@1: 0.109426 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.956880 Acc@1: 0.031360 
	Train Epoch: 11 	Loss: 2.371241 Acc@1: 0.125000 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.977470 Acc@1: 0.109608 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 2.919934 Acc@1: 0.106134 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 2.881326 Acc@1: 0.164916 
	Train Epoch: 12 	Loss: 2.428380 Acc@1: 0.074627 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 3.336506 Acc@1: 0.110194 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 3.314759 Acc@1: 0.101464 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 2.850223 Acc@1: 0.029259 
	Train Epoch: 13 	Loss: 6.753071 Acc@1: 0.109091 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 2.990202 Acc@1: 0.103303 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 3.199319 Acc@1: 0.107909 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.954913 Acc@1: 0.162658 
	Train Epoch: 14 	Loss: 5.109412 Acc@1: 0.122905 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.877279 Acc@1: 0.097343 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 2.737024 Acc@1: 0.101075 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 2.927441 Acc@1: 0.164457 
	Train Epoch: 15 	Loss: 2.631701 Acc@1: 0.093264 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.783015 Acc@1: 0.107581 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 2.684011 Acc@1: 0.103492 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 3.073728 Acc@1: 0.027734 
	Train Epoch: 16 	Loss: 2.834982 Acc@1: 0.088398 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.537866 Acc@1: 0.105938 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 2.497705 Acc@1: 0.098526 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 3.009191 Acc@1: 0.030778 
	Train Epoch: 17 	Loss: 2.297307 Acc@1: 0.090426 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.742555 Acc@1: 0.096262 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 2.621830 Acc@1: 0.098016 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.845502 Acc@1: 0.169791 
	Train Epoch: 18 	Loss: 2.355786 Acc@1: 0.056995 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.479381 Acc@1: 0.115148 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 2.578240 Acc@1: 0.112019 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.904078 Acc@1: 0.028803 
	Train Epoch: 19 	Loss: 2.409178 Acc@1: 0.099010 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.676835 Acc@1: 0.097487 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 2.593341 Acc@1: 0.098769 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 2.907588 Acc@1: 0.029529 
	Train Epoch: 20 	Loss: 2.308675 Acc@1: 0.093168 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 2.588905 Acc@1: 0.105501 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 2.514835 Acc@1: 0.107724 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.950490 Acc@1: 0.028303 
	Train Epoch: 21 	Loss: 2.533660 Acc@1: 0.124294 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.419109 Acc@1: 0.108667 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 2.477897 Acc@1: 0.109200 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.862889 Acc@1: 0.030841 
	Train Epoch: 22 	Loss: 3.319951 Acc@1: 0.104972 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.690148 Acc@1: 0.103865 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 2.548823 Acc@1: 0.107550 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 2.858537 Acc@1: 0.028363 
	Train Epoch: 23 	Loss: 2.909731 Acc@1: 0.131148 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 2.556803 Acc@1: 0.106755 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 2.531337 Acc@1: 0.108030 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.840560 Acc@1: 0.170481 
	Train Epoch: 24 	Loss: 2.283306 Acc@1: 0.114943 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.462073 Acc@1: 0.112437 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 2.531133 Acc@1: 0.101906 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.854921 Acc@1: 0.170621 
	Train Epoch: 25 	Loss: 2.497151 Acc@1: 0.079755 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.665822 Acc@1: 0.096520 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 2.555974 Acc@1: 0.100005 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 2.853173 Acc@1: 0.170254 
Base private model test accuracy:  0.1706773363818234
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       508
         1.0       0.05      0.01      0.02       482
         2.0       0.04      0.00      0.00       510
         3.0       0.03      0.01      0.02       489
         4.0       0.00      0.00      0.00       466
         5.0       0.17      0.00      0.00      2972
         6.0       0.18      0.00      0.01      3080
         7.0       0.19      0.01      0.01      2961
         8.0       0.21      0.00      0.00      3024
         9.0       0.17      0.98      0.30      3003

    accuracy                           0.17     17495
   macro avg       0.10      0.10      0.04     17495
weighted avg       0.16      0.17      0.06     17495

Base private model train accuracy:  0.10558742298704057
              precision    recall  f1-score   support

         0.0       0.08      0.00      0.00       490
         1.0       0.54      0.03      0.06       466
         2.0       0.00      0.00      0.00       494
         3.0       0.33      0.04      0.08       447
         4.0       0.57      0.01      0.02       483
         5.0       0.00      0.00      0.00       473
         6.0       0.24      0.02      0.03       474
         7.0       0.17      0.01      0.02       472
         8.0       0.00      0.00      0.00       453
         9.0       0.10      0.98      0.18       455

    accuracy                           0.11      4707
   macro avg       0.20      0.11      0.04      4707
weighted avg       0.20      0.11      0.04      4707

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.49468763280917977
test acc: 0.5004291845493563
min train acc: 0.3993260320134794
maj train acc: 0.590633130962706
min test acc: 0.5974358974358974
maj test acc: 0.40341880341880343
total acc: 0.497544309203502
total min acc: 0.49766652524395416
total maj acc: 0.49634093844167027
precision, recall: (0.5, 0.49468763280917977)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['under', 1.0, 10.013886331234898, 0.1706773363818234, 0.10558742298704057, 0.497544309203502, 0.49766652524395416, 0.49634093844167027, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       508\n         1.0       0.05      0.01      0.02       482\n         2.0       0.04      0.00      0.00       510\n         3.0       0.03      0.01      0.02       489\n         4.0       0.00      0.00      0.00       466\n         5.0       0.17      0.00      0.00      2972\n         6.0       0.18      0.00      0.01      3080\n         7.0       0.19      0.01      0.01      2961\n         8.0       0.21      0.00      0.00      3024\n         9.0       0.17      0.98      0.30      3003\n\n    accuracy                           0.17     17495\n   macro avg       0.10      0.10      0.04     17495\nweighted avg       0.16      0.17      0.06     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.08      0.00      0.00       490\n         1.0       0.54      0.03      0.06       466\n         2.0       0.00      0.00      0.00       494\n         3.0       0.33      0.04      0.08       447\n         4.0       0.57      0.01      0.02       483\n         5.0       0.00      0.00      0.00       473\n         6.0       0.24      0.02      0.03       474\n         7.0       0.17      0.01      0.02       472\n         8.0       0.00      0.00      0.00       453\n         9.0       0.10      0.98      0.18       455\n\n    accuracy                           0.11      4707\n   macro avg       0.20      0.11      0.04      4707\nweighted avg       0.20      0.11      0.04      4707\n']
experiment_number: 28
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/under/test_results-28.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.4}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.4
{0.0: 1232, 1.0: 1232, 2.0: 1232, 3.0: 1232, 4.0: 1232, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1209, 1263, 1239, 1222, 1256, 3098, 3183, 3112, 3108, 3060])
resampled test counts:  tensor([1232, 1232, 1232, 1232, 1232, 3080, 3080, 3080, 3080, 3080])
training set size:  (21750, 3, 32, 32)
test set size:  (21560, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.200698 Acc@1: 0.128028 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.517618 Acc@1: 0.144133 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.502301 Acc@1: 0.145660 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 5.125541 Acc@1: 0.172192 
	Train Epoch: 2 	Loss: 5.898235 Acc@1: 0.144912 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.947628 Acc@1: 0.151832 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.585656 Acc@1: 0.174858 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.871955 Acc@1: 0.373211 
	Train Epoch: 3 	Loss: 2.175459 Acc@1: 0.316990 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.484435 Acc@1: 0.261696 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.371378 Acc@1: 0.214966 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.073324 Acc@1: 0.191115 
	Train Epoch: 4 	Loss: 2.186677 Acc@1: 0.177725 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.210729 Acc@1: 0.182351 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.184740 Acc@1: 0.196812 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 1.991811 Acc@1: 0.247784 
	Train Epoch: 5 	Loss: 2.192173 Acc@1: 0.228507 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.295021 Acc@1: 0.248049 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.235941 Acc@1: 0.223856 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.999232 Acc@1: 0.260568 
	Train Epoch: 6 	Loss: 2.137171 Acc@1: 0.222632 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.160147 Acc@1: 0.265015 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.164921 Acc@1: 0.282291 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.787019 Acc@1: 0.397877 
	Train Epoch: 7 	Loss: 1.954319 Acc@1: 0.334868 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.974428 Acc@1: 0.367410 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.996144 Acc@1: 0.366404 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.722515 Acc@1: 0.443591 
	Train Epoch: 8 	Loss: 1.940756 Acc@1: 0.384230 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.906583 Acc@1: 0.401280 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.896774 Acc@1: 0.409087 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.595268 Acc@1: 0.486270 
	Train Epoch: 9 	Loss: 1.801803 Acc@1: 0.418919 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 1.865571 Acc@1: 0.427118 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.826255 Acc@1: 0.441001 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.551020 Acc@1: 0.533839 
	Train Epoch: 10 	Loss: 1.790998 Acc@1: 0.444169 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.784458 Acc@1: 0.481683 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.769151 Acc@1: 0.485757 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.549283 Acc@1: 0.545810 
	Train Epoch: 11 	Loss: 1.777263 Acc@1: 0.479769 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.756329 Acc@1: 0.485277 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.727314 Acc@1: 0.492645 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.684744 Acc@1: 0.545460 
	Train Epoch: 12 	Loss: 2.098825 Acc@1: 0.452915 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.767216 Acc@1: 0.498098 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.727794 Acc@1: 0.505439 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.577924 Acc@1: 0.542470 
	Train Epoch: 13 	Loss: 1.850271 Acc@1: 0.455899 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.702280 Acc@1: 0.497151 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.690579 Acc@1: 0.509816 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.536662 Acc@1: 0.553050 
	Train Epoch: 14 	Loss: 1.602893 Acc@1: 0.507264 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.661908 Acc@1: 0.536143 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.633017 Acc@1: 0.537966 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.561484 Acc@1: 0.575242 
	Train Epoch: 15 	Loss: 1.644538 Acc@1: 0.544509 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.564338 Acc@1: 0.548640 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.562503 Acc@1: 0.556159 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.500973 Acc@1: 0.597810 
	Train Epoch: 16 	Loss: 1.587415 Acc@1: 0.552424 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.590564 Acc@1: 0.564696 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.580144 Acc@1: 0.561575 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.471866 Acc@1: 0.599998 
	Train Epoch: 17 	Loss: 1.530948 Acc@1: 0.582278 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.559549 Acc@1: 0.571642 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.558342 Acc@1: 0.572703 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.464679 Acc@1: 0.611980 
	Train Epoch: 18 	Loss: 1.469414 Acc@1: 0.598434 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.536066 Acc@1: 0.582099 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.544792 Acc@1: 0.579502 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.476123 Acc@1: 0.616873 
	Train Epoch: 19 	Loss: 1.704635 Acc@1: 0.534699 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.572816 Acc@1: 0.567881 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.585789 Acc@1: 0.569863 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.466379 Acc@1: 0.612316 
	Train Epoch: 20 	Loss: 1.514723 Acc@1: 0.593088 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.564461 Acc@1: 0.579608 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.548920 Acc@1: 0.582828 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.452730 Acc@1: 0.612446 
	Train Epoch: 21 	Loss: 1.529098 Acc@1: 0.576471 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.551193 Acc@1: 0.585106 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.530932 Acc@1: 0.588318 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.457121 Acc@1: 0.623482 
	Train Epoch: 22 	Loss: 1.497403 Acc@1: 0.586931 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.538494 Acc@1: 0.590446 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.529760 Acc@1: 0.588959 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.440182 Acc@1: 0.624784 
	Train Epoch: 23 	Loss: 1.508746 Acc@1: 0.600470 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.502449 Acc@1: 0.603271 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.507738 Acc@1: 0.602971 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.438685 Acc@1: 0.623336 
	Train Epoch: 24 	Loss: 1.539793 Acc@1: 0.582139 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.502454 Acc@1: 0.598234 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.519873 Acc@1: 0.597783 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.433283 Acc@1: 0.623755 
	Train Epoch: 25 	Loss: 1.484469 Acc@1: 0.582949 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.508927 Acc@1: 0.591680 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.506081 Acc@1: 0.595535 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.436305 Acc@1: 0.624894 
Base private model test accuracy:  0.6253786796227494
              precision    recall  f1-score   support

         0.0       0.30      0.21      0.25       508
         1.0       0.24      0.09      0.13       482
         2.0       0.22      0.10      0.13       510
         3.0       0.07      0.03      0.04       489
         4.0       0.21      0.12      0.15       466
         5.0       0.58      0.64      0.61      2972
         6.0       0.70      0.74      0.72      3080
         7.0       0.62      0.66      0.64      2961
         8.0       0.72      0.77      0.74      3024
         9.0       0.66      0.74      0.70      3003

    accuracy                           0.63     17495
   macro avg       0.43      0.41      0.41     17495
weighted avg       0.59      0.63      0.61     17495

Base private model train accuracy:  0.6015172413793104
              precision    recall  f1-score   support

         0.0       0.55      0.44      0.49      1209
         1.0       0.53      0.39      0.45      1263
         2.0       0.39      0.25      0.30      1239
         3.0       0.37      0.21      0.27      1222
         4.0       0.43      0.23      0.30      1256
         5.0       0.57      0.66      0.61      3098
         6.0       0.64      0.74      0.68      3183
         7.0       0.62      0.68      0.65      3112
         8.0       0.71      0.78      0.75      3108
         9.0       0.63      0.74      0.68      3060

    accuracy                           0.60     21750
   macro avg       0.54      0.51      0.52     21750
weighted avg       0.58      0.60      0.59     21750

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6336551724137931
test acc: 0.5119666048237477
min train acc: 0.6802675585284281
maj train acc: 0.6155128205128205
min test acc: 0.5266558966074313
maj test acc: 0.5059129304743339
total acc: 0.5730778111290695
total min acc: 0.6021364009860313
total maj acc: 0.5610842207163601
precision, recall: (0.5670671494404214, 0.6336551724137931)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.4, 10.013886331234898, 0.6253786796227494, 0.6015172413793104, 0.5730778111290695, 0.6021364009860313, 0.5610842207163601, '              precision    recall  f1-score   support\n\n         0.0       0.30      0.21      0.25       508\n         1.0       0.24      0.09      0.13       482\n         2.0       0.22      0.10      0.13       510\n         3.0       0.07      0.03      0.04       489\n         4.0       0.21      0.12      0.15       466\n         5.0       0.58      0.64      0.61      2972\n         6.0       0.70      0.74      0.72      3080\n         7.0       0.62      0.66      0.64      2961\n         8.0       0.72      0.77      0.74      3024\n         9.0       0.66      0.74      0.70      3003\n\n    accuracy                           0.63     17495\n   macro avg       0.43      0.41      0.41     17495\nweighted avg       0.59      0.63      0.61     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.55      0.44      0.49      1209\n         1.0       0.53      0.39      0.45      1263\n         2.0       0.39      0.25      0.30      1239\n         3.0       0.37      0.21      0.27      1222\n         4.0       0.43      0.23      0.30      1256\n         5.0       0.57      0.66      0.61      3098\n         6.0       0.64      0.74      0.68      3183\n         7.0       0.62      0.68      0.65      3112\n         8.0       0.71      0.78      0.75      3108\n         9.0       0.63      0.74      0.68      3060\n\n    accuracy                           0.60     21750\n   macro avg       0.54      0.51      0.52     21750\nweighted avg       0.58      0.60      0.59     21750\n']
experiment_number: 24
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-24.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.6}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.6
{0.0: 1848, 1.0: 1848, 2.0: 1848, 3.0: 1848, 4.0: 1848, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([1874, 1823, 1859, 1813, 1883, 3098, 2993, 3067, 2988, 3080])
resampled test counts:  tensor([1848, 1848, 1848, 1848, 1848, 3080, 3080, 3080, 3080, 3080])
training set size:  (24478, 3, 32, 32)
test set size:  (24640, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.413834 Acc@1: 0.129884 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.410705 Acc@1: 0.123291 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.488064 Acc@1: 0.135755 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.232512 Acc@1: 0.168936 
	Train Epoch: 2 	Loss: 2.289688 Acc@1: 0.109019 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.556571 Acc@1: 0.150312 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.883000 Acc@1: 0.142132 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.210906 Acc@1: 0.224742 
	Train Epoch: 3 	Loss: 2.219930 Acc@1: 0.171198 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.189575 Acc@1: 0.187996 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.343373 Acc@1: 0.187737 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.064689 Acc@1: 0.248673 
	Train Epoch: 4 	Loss: 2.314682 Acc@1: 0.242769 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.250736 Acc@1: 0.224049 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.187086 Acc@1: 0.233513 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 1.907453 Acc@1: 0.322516 
	Train Epoch: 5 	Loss: 2.114531 Acc@1: 0.284024 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.057956 Acc@1: 0.300874 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.043643 Acc@1: 0.303840 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.887105 Acc@1: 0.384324 
	Train Epoch: 6 	Loss: 2.017767 Acc@1: 0.368583 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.042836 Acc@1: 0.310452 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 1.985760 Acc@1: 0.330894 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.998379 Acc@1: 0.335217 
	Train Epoch: 7 	Loss: 2.073754 Acc@1: 0.345804 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.986014 Acc@1: 0.352442 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.939566 Acc@1: 0.369081 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.570126 Acc@1: 0.493749 
	Train Epoch: 8 	Loss: 1.716193 Acc@1: 0.454902 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.961928 Acc@1: 0.399010 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.881521 Acc@1: 0.410440 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.729844 Acc@1: 0.492227 
	Train Epoch: 9 	Loss: 2.016327 Acc@1: 0.449889 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.088929 Acc@1: 0.388664 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.935423 Acc@1: 0.404627 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.594836 Acc@1: 0.495894 
	Train Epoch: 10 	Loss: 1.742520 Acc@1: 0.436620 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.777427 Acc@1: 0.450476 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.744577 Acc@1: 0.458634 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.519116 Acc@1: 0.556453 
	Train Epoch: 11 	Loss: 1.806848 Acc@1: 0.475495 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.691871 Acc@1: 0.490883 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.708849 Acc@1: 0.490279 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.533080 Acc@1: 0.537211 
	Train Epoch: 12 	Loss: 1.524782 Acc@1: 0.522044 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.619742 Acc@1: 0.507450 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.637341 Acc@1: 0.512608 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.483362 Acc@1: 0.575465 
	Train Epoch: 13 	Loss: 1.659664 Acc@1: 0.537745 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.605692 Acc@1: 0.536509 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.608570 Acc@1: 0.540059 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.530563 Acc@1: 0.587017 
	Train Epoch: 14 	Loss: 1.738042 Acc@1: 0.503435 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.619233 Acc@1: 0.532546 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.603609 Acc@1: 0.539248 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.476082 Acc@1: 0.593671 
	Train Epoch: 15 	Loss: 1.714934 Acc@1: 0.530060 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.627573 Acc@1: 0.547452 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.623278 Acc@1: 0.549302 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.454983 Acc@1: 0.595755 
	Train Epoch: 16 	Loss: 1.520671 Acc@1: 0.556133 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.592858 Acc@1: 0.559724 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.590744 Acc@1: 0.562199 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.440054 Acc@1: 0.608853 
	Train Epoch: 17 	Loss: 1.713018 Acc@1: 0.541082 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.587930 Acc@1: 0.567863 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.602424 Acc@1: 0.563771 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.478981 Acc@1: 0.597487 
	Train Epoch: 18 	Loss: 1.604522 Acc@1: 0.572589 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.572301 Acc@1: 0.574916 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.582985 Acc@1: 0.576263 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.435719 Acc@1: 0.615270 
	Train Epoch: 19 	Loss: 1.592959 Acc@1: 0.575695 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.527122 Acc@1: 0.583264 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.557013 Acc@1: 0.576781 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.423459 Acc@1: 0.621164 
	Train Epoch: 20 	Loss: 1.514706 Acc@1: 0.581976 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.503593 Acc@1: 0.595394 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.496445 Acc@1: 0.596467 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.457476 Acc@1: 0.616739 
	Train Epoch: 21 	Loss: 1.601925 Acc@1: 0.586345 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.562671 Acc@1: 0.589930 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.545336 Acc@1: 0.593674 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.446655 Acc@1: 0.626829 
	Train Epoch: 22 	Loss: 1.521346 Acc@1: 0.610376 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.532071 Acc@1: 0.595772 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.516554 Acc@1: 0.594466 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.441112 Acc@1: 0.629177 
	Train Epoch: 23 	Loss: 1.487543 Acc@1: 0.621118 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.548366 Acc@1: 0.597013 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.530910 Acc@1: 0.599597 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.443568 Acc@1: 0.627105 
	Train Epoch: 24 	Loss: 1.378683 Acc@1: 0.616384 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.538505 Acc@1: 0.598231 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.540808 Acc@1: 0.598512 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.435452 Acc@1: 0.628997 
	Train Epoch: 25 	Loss: 1.579133 Acc@1: 0.595588 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.536896 Acc@1: 0.598597 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.534700 Acc@1: 0.599797 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.436935 Acc@1: 0.626819 
Base private model test accuracy:  0.6273220920262932
              precision    recall  f1-score   support

         0.0       0.35      0.30      0.33       508
         1.0       0.30      0.22      0.25       482
         2.0       0.20      0.16      0.18       510
         3.0       0.06      0.03      0.04       489
         4.0       0.24      0.12      0.16       466
         5.0       0.59      0.63      0.61      2972
         6.0       0.69      0.75      0.72      3080
         7.0       0.64      0.64      0.64      2961
         8.0       0.75      0.76      0.76      3024
         9.0       0.66      0.72      0.69      3003

    accuracy                           0.63     17495
   macro avg       0.45      0.43      0.44     17495
weighted avg       0.61      0.63      0.62     17495

Base private model train accuracy:  0.598088079091429
              precision    recall  f1-score   support

         0.0       0.61      0.47      0.53      1874
         1.0       0.57      0.53      0.55      1823
         2.0       0.46      0.34      0.39      1859
         3.0       0.44      0.35      0.39      1813
         4.0       0.49      0.37      0.42      1883
         5.0       0.59      0.66      0.62      3098
         6.0       0.62      0.75      0.68      2993
         7.0       0.61      0.66      0.64      3067
         8.0       0.71      0.75      0.73      2988
         9.0       0.64      0.73      0.68      3080

    accuracy                           0.60     24478
   macro avg       0.57      0.56      0.56     24478
weighted avg       0.59      0.60      0.59     24478

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6911512378462292
test acc: 0.4676948051948052
min train acc: 0.725720620842572
maj train acc: 0.6736572890025575
min test acc: 0.47075208913649025
maj test acc: 0.46561398929923004
total acc: 0.5790545217639155
total min acc: 0.5960553557807562
total maj acc: 0.5706904346702836
precision, recall: (0.5632949324099354, 0.6911512378462292)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.6, 10.013886331234898, 0.6273220920262932, 0.598088079091429, 0.5790545217639155, 0.5960553557807562, 0.5706904346702836, '              precision    recall  f1-score   support\n\n         0.0       0.35      0.30      0.33       508\n         1.0       0.30      0.22      0.25       482\n         2.0       0.20      0.16      0.18       510\n         3.0       0.06      0.03      0.04       489\n         4.0       0.24      0.12      0.16       466\n         5.0       0.59      0.63      0.61      2972\n         6.0       0.69      0.75      0.72      3080\n         7.0       0.64      0.64      0.64      2961\n         8.0       0.75      0.76      0.76      3024\n         9.0       0.66      0.72      0.69      3003\n\n    accuracy                           0.63     17495\n   macro avg       0.45      0.43      0.44     17495\nweighted avg       0.61      0.63      0.62     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.61      0.47      0.53      1874\n         1.0       0.57      0.53      0.55      1823\n         2.0       0.46      0.34      0.39      1859\n         3.0       0.44      0.35      0.39      1813\n         4.0       0.49      0.37      0.42      1883\n         5.0       0.59      0.66      0.62      3098\n         6.0       0.62      0.75      0.68      2993\n         7.0       0.61      0.66      0.64      3067\n         8.0       0.71      0.75      0.73      2988\n         9.0       0.64      0.73      0.68      3080\n\n    accuracy                           0.60     24478\n   macro avg       0.57      0.56      0.56     24478\nweighted avg       0.59      0.60      0.59     24478\n']
experiment_number: 25
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-25.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 0.8}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  0.8
{0.0: 2464, 1.0: 2464, 2.0: 2464, 3.0: 2464, 4.0: 2464, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([2424, 2577, 2491, 2429, 2424, 3138, 3118, 3059, 3122, 3086])
resampled test counts:  tensor([2464, 2464, 2464, 2464, 2464, 3080, 3080, 3080, 3080, 3080])
training set size:  (27868, 3, 32, 32)
test set size:  (27720, 3, 32, 32)
	Train Epoch: 1 	Loss: 3.325067 Acc@1: 0.086496 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.434642 Acc@1: 0.120120 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.424727 Acc@1: 0.125806 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.354484 Acc@1: 0.078892 
	Train Epoch: 2 	Loss: 2.418304 Acc@1: 0.099284 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.357852 Acc@1: 0.121544 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.320613 Acc@1: 0.142711 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.175111 Acc@1: 0.285901 
	Train Epoch: 3 	Loss: 2.240693 Acc@1: 0.222520 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.259643 Acc@1: 0.191377 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.285695 Acc@1: 0.172294 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.258347 Acc@1: 0.217279 
	Train Epoch: 4 	Loss: 2.319130 Acc@1: 0.175614 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.377715 Acc@1: 0.206655 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.258105 Acc@1: 0.218973 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.140798 Acc@1: 0.281701 
	Train Epoch: 5 	Loss: 2.169677 Acc@1: 0.254268 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.029579 Acc@1: 0.279129 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 1.999307 Acc@1: 0.295771 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.878129 Acc@1: 0.366630 
	Train Epoch: 6 	Loss: 2.013381 Acc@1: 0.331851 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 1.990712 Acc@1: 0.349467 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.098753 Acc@1: 0.334109 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.882147 Acc@1: 0.301759 
	Train Epoch: 7 	Loss: 1.984085 Acc@1: 0.276056 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.957720 Acc@1: 0.321412 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 1.923935 Acc@1: 0.342768 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.674156 Acc@1: 0.460028 
	Train Epoch: 8 	Loss: 1.873638 Acc@1: 0.380822 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.877356 Acc@1: 0.391692 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 1.874915 Acc@1: 0.401113 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.600557 Acc@1: 0.488654 
	Train Epoch: 9 	Loss: 1.780196 Acc@1: 0.415231 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 1.789264 Acc@1: 0.427377 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.771274 Acc@1: 0.433477 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.680659 Acc@1: 0.493859 
	Train Epoch: 10 	Loss: 1.810106 Acc@1: 0.450579 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.757555 Acc@1: 0.451707 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 1.751314 Acc@1: 0.455044 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.528513 Acc@1: 0.539759 
	Train Epoch: 11 	Loss: 1.677603 Acc@1: 0.489247 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.774595 Acc@1: 0.462188 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.760152 Acc@1: 0.465567 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.551075 Acc@1: 0.543545 
	Train Epoch: 12 	Loss: 1.618694 Acc@1: 0.490317 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.710620 Acc@1: 0.477920 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.722457 Acc@1: 0.478412 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.497875 Acc@1: 0.564472 
	Train Epoch: 13 	Loss: 1.747924 Acc@1: 0.473310 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.686816 Acc@1: 0.503790 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.671897 Acc@1: 0.503241 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.542902 Acc@1: 0.554864 
	Train Epoch: 14 	Loss: 1.700289 Acc@1: 0.511215 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.650967 Acc@1: 0.512138 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.668091 Acc@1: 0.513209 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.497651 Acc@1: 0.574625 
	Train Epoch: 15 	Loss: 1.503431 Acc@1: 0.529735 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.620480 Acc@1: 0.529363 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.647508 Acc@1: 0.522217 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.558882 Acc@1: 0.573726 
	Train Epoch: 16 	Loss: 1.679980 Acc@1: 0.525000 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.623016 Acc@1: 0.534171 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.632090 Acc@1: 0.531014 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.424843 Acc@1: 0.592411 
	Train Epoch: 17 	Loss: 1.608370 Acc@1: 0.514134 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.592046 Acc@1: 0.537712 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.594155 Acc@1: 0.538764 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.525130 Acc@1: 0.579844 
	Train Epoch: 18 	Loss: 1.585282 Acc@1: 0.530797 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.597712 Acc@1: 0.546782 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.584742 Acc@1: 0.549789 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.509067 Acc@1: 0.589628 
	Train Epoch: 19 	Loss: 1.601948 Acc@1: 0.557491 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.595224 Acc@1: 0.556599 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.595902 Acc@1: 0.555199 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.432951 Acc@1: 0.611344 
	Train Epoch: 20 	Loss: 1.584325 Acc@1: 0.572327 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.546647 Acc@1: 0.568102 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.561895 Acc@1: 0.564766 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.451110 Acc@1: 0.611464 
	Train Epoch: 21 	Loss: 1.653295 Acc@1: 0.546035 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.578693 Acc@1: 0.560950 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.570782 Acc@1: 0.565488 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.444866 Acc@1: 0.612087 
	Train Epoch: 22 	Loss: 1.647572 Acc@1: 0.554738 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.551082 Acc@1: 0.571808 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.563738 Acc@1: 0.572165 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.454728 Acc@1: 0.615986 
	Train Epoch: 23 	Loss: 1.559125 Acc@1: 0.573433 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.562589 Acc@1: 0.572181 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.571827 Acc@1: 0.573579 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.456091 Acc@1: 0.612310 
	Train Epoch: 24 	Loss: 1.597424 Acc@1: 0.561261 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.572531 Acc@1: 0.579419 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.562779 Acc@1: 0.578955 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.446427 Acc@1: 0.616556 
	Train Epoch: 25 	Loss: 1.663757 Acc@1: 0.572072 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.536152 Acc@1: 0.581050 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.523567 Acc@1: 0.581358 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.441549 Acc@1: 0.616952 
Base private model test accuracy:  0.6168048013718205
              precision    recall  f1-score   support

         0.0       0.34      0.27      0.30       508
         1.0       0.31      0.32      0.31       482
         2.0       0.23      0.21      0.22       510
         3.0       0.11      0.07      0.09       489
         4.0       0.21      0.21      0.21       466
         5.0       0.57      0.63      0.60      2972
         6.0       0.74      0.72      0.73      3080
         7.0       0.62      0.61      0.61      2961
         8.0       0.74      0.75      0.75      3024
         9.0       0.67      0.70      0.69      3003

    accuracy                           0.62     17495
   macro avg       0.45      0.45      0.45     17495
weighted avg       0.61      0.62      0.61     17495

Base private model train accuracy:  0.5792665422707047
              precision    recall  f1-score   support

         0.0       0.64      0.54      0.59      2424
         1.0       0.60      0.64      0.62      2577
         2.0       0.44      0.35      0.39      2491
         3.0       0.44      0.35      0.39      2429
         4.0       0.44      0.34      0.38      2424
         5.0       0.56      0.64      0.59      3138
         6.0       0.59      0.69      0.64      3118
         7.0       0.60      0.62      0.61      3059
         8.0       0.69      0.75      0.72      3122
         9.0       0.64      0.71      0.68      3086

    accuracy                           0.58     27868
   macro avg       0.56      0.56      0.56     27868
weighted avg       0.57      0.58      0.57     27868

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6167647480981772
test acc: 0.5314574314574314
min train acc: 0.6407155025553662
maj train acc: 0.599375
min test acc: 0.5423258848474963
maj test acc: 0.52319421113839
total acc: 0.5742246528027631
total min acc: 0.5904507957670194
total maj acc: 0.5619162589745219
precision, recall: (0.569591728525981, 0.6167647480981772)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 0.8, 10.013886331234898, 0.6168048013718205, 0.5792665422707047, 0.5742246528027631, 0.5904507957670194, 0.5619162589745219, '              precision    recall  f1-score   support\n\n         0.0       0.34      0.27      0.30       508\n         1.0       0.31      0.32      0.31       482\n         2.0       0.23      0.21      0.22       510\n         3.0       0.11      0.07      0.09       489\n         4.0       0.21      0.21      0.21       466\n         5.0       0.57      0.63      0.60      2972\n         6.0       0.74      0.72      0.73      3080\n         7.0       0.62      0.61      0.61      2961\n         8.0       0.74      0.75      0.75      3024\n         9.0       0.67      0.70      0.69      3003\n\n    accuracy                           0.62     17495\n   macro avg       0.45      0.45      0.45     17495\nweighted avg       0.61      0.62      0.61     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.64      0.54      0.59      2424\n         1.0       0.60      0.64      0.62      2577\n         2.0       0.44      0.35      0.39      2491\n         3.0       0.44      0.35      0.39      2429\n         4.0       0.44      0.34      0.38      2424\n         5.0       0.56      0.64      0.59      3138\n         6.0       0.59      0.69      0.64      3118\n         7.0       0.60      0.62      0.61      3059\n         8.0       0.69      0.75      0.72      3122\n         9.0       0.64      0.71      0.68      3086\n\n    accuracy                           0.58     27868\n   macro avg       0.56      0.56      0.56     27868\nweighted avg       0.57      0.58      0.57     27868\n']
experiment_number: 26
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-26.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 25, 'noise_multiplier': 1.3, 'target_epsilon': 10.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'smote', 'attack_model': 'nn', 'sampling_ratio': 1.0}
cuda
Files already downloaded and verified
Files already downloaded and verified
(60000, 32, 32, 3)
original counts:  tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])
removed indices 25011
(34989, 32, 32, 3)
imbalanced counts:  tensor([1021,  981, 1032,  991,  964, 6000, 6000, 6000, 6000, 6000])
original train counts:  tensor([ 513,  499,  522,  502,  498, 3028, 2920, 3039, 2976, 2997])
original test counts:  tensor([ 508,  482,  510,  489,  466, 2972, 3080, 2961, 3024, 3003])
performing smote resampling at  1.0
{0.0: 3080, 1.0: 3080, 2.0: 3080, 3.0: 3080, 4.0: 3080, 5.0: 3080, 6.0: 3080, 7.0: 3080, 8.0: 3080, 9.0: 3080}
resampled train counts:  tensor([3141, 3077, 3025, 3118, 3091, 3133, 3054, 3132, 3172, 3176])
resampled test counts:  tensor([3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080, 3080])
training set size:  (31119, 3, 32, 32)
test set size:  (30800, 3, 32, 32)
	Train Epoch: 1 	Loss: 2.524488 Acc@1: 0.092126 (ε = 2.38, δ = 1e-05) for α = 6.3
	Train Epoch: 1 	Loss: 2.416679 Acc@1: 0.102812 (ε = 3.06, δ = 1e-05) for α = 5.4
	Train Epoch: 1 	Loss: 2.673686 Acc@1: 0.110637 (ε = 3.39, δ = 1e-05) for α = 5.1
	Test set:Loss: 2.315025 Acc@1: 0.177830 
	Train Epoch: 2 	Loss: 2.327915 Acc@1: 0.171504 (ε = 3.52, δ = 1e-05) for α = 5.0
	Train Epoch: 2 	Loss: 2.419411 Acc@1: 0.164865 (ε = 3.76, δ = 1e-05) for α = 4.9
	Train Epoch: 2 	Loss: 2.389286 Acc@1: 0.146977 (ε = 3.97, δ = 1e-05) for α = 4.8
	Test set:Loss: 2.190507 Acc@1: 0.175899 
	Train Epoch: 3 	Loss: 2.323664 Acc@1: 0.119451 (ε = 4.07, δ = 1e-05) for α = 4.7
	Train Epoch: 3 	Loss: 2.263557 Acc@1: 0.144975 (ε = 4.26, δ = 1e-05) for α = 4.6
	Train Epoch: 3 	Loss: 2.245375 Acc@1: 0.167377 (ε = 4.44, δ = 1e-05) for α = 4.6
	Test set:Loss: 2.236973 Acc@1: 0.175210 
	Train Epoch: 4 	Loss: 2.243435 Acc@1: 0.155093 (ε = 4.52, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.249571 Acc@1: 0.155487 (ε = 4.68, δ = 1e-05) for α = 4.5
	Train Epoch: 4 	Loss: 2.253603 Acc@1: 0.162179 (ε = 4.84, δ = 1e-05) for α = 4.4
	Test set:Loss: 2.083332 Acc@1: 0.181947 
	Train Epoch: 5 	Loss: 2.105695 Acc@1: 0.170370 (ε = 4.91, δ = 1e-05) for α = 4.4
	Train Epoch: 5 	Loss: 2.150257 Acc@1: 0.193673 (ε = 5.06, δ = 1e-05) for α = 4.3
	Train Epoch: 5 	Loss: 2.170769 Acc@1: 0.194077 (ε = 5.20, δ = 1e-05) for α = 4.3
	Test set:Loss: 2.189458 Acc@1: 0.153044 
	Train Epoch: 6 	Loss: 2.167064 Acc@1: 0.187062 (ε = 5.27, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.125725 Acc@1: 0.209027 (ε = 5.40, δ = 1e-05) for α = 4.2
	Train Epoch: 6 	Loss: 2.197208 Acc@1: 0.189334 (ε = 5.53, δ = 1e-05) for α = 4.2
	Test set:Loss: 2.157269 Acc@1: 0.154456 
	Train Epoch: 7 	Loss: 2.186759 Acc@1: 0.163622 (ε = 5.60, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.123253 Acc@1: 0.202094 (ε = 5.72, δ = 1e-05) for α = 4.1
	Train Epoch: 7 	Loss: 2.766826 Acc@1: 0.178346 (ε = 5.85, δ = 1e-05) for α = 4.1
	Test set:Loss: 2.161271 Acc@1: 0.174900 
	Train Epoch: 8 	Loss: 2.190282 Acc@1: 0.154452 (ε = 5.91, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.287268 Acc@1: 0.162347 (ε = 6.03, δ = 1e-05) for α = 4.0
	Train Epoch: 8 	Loss: 2.207638 Acc@1: 0.181347 (ε = 6.14, δ = 1e-05) for α = 4.0
	Test set:Loss: 2.096604 Acc@1: 0.192360 
	Train Epoch: 9 	Loss: 2.052573 Acc@1: 0.221860 (ε = 6.20, δ = 1e-05) for α = 4.0
	Train Epoch: 9 	Loss: 2.019422 Acc@1: 0.249923 (ε = 6.31, δ = 1e-05) for α = 3.9
	Train Epoch: 9 	Loss: 1.993162 Acc@1: 0.280183 (ε = 6.43, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.953001 Acc@1: 0.348002 
	Train Epoch: 10 	Loss: 1.952140 Acc@1: 0.333891 (ε = 6.48, δ = 1e-05) for α = 3.9
	Train Epoch: 10 	Loss: 1.998193 Acc@1: 0.328367 (ε = 6.59, δ = 1e-05) for α = 3.8
	Train Epoch: 10 	Loss: 2.008594 Acc@1: 0.331212 (ε = 6.70, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.921368 Acc@1: 0.396789 
	Train Epoch: 11 	Loss: 1.973632 Acc@1: 0.339472 (ε = 6.75, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.977773 Acc@1: 0.354592 (ε = 6.86, δ = 1e-05) for α = 3.8
	Train Epoch: 11 	Loss: 1.941967 Acc@1: 0.364973 (ε = 6.96, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.918055 Acc@1: 0.390451 
	Train Epoch: 12 	Loss: 1.921431 Acc@1: 0.356164 (ε = 7.01, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.935654 Acc@1: 0.374297 (ε = 7.11, δ = 1e-05) for α = 3.7
	Train Epoch: 12 	Loss: 1.910410 Acc@1: 0.380088 (ε = 7.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.667055 Acc@1: 0.461343 
	Train Epoch: 13 	Loss: 1.933089 Acc@1: 0.377241 (ε = 7.26, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.834290 Acc@1: 0.394745 (ε = 7.36, δ = 1e-05) for α = 3.7
	Train Epoch: 13 	Loss: 1.843746 Acc@1: 0.402655 (ε = 7.46, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.600529 Acc@1: 0.490100 
	Train Epoch: 14 	Loss: 1.764117 Acc@1: 0.431694 (ε = 7.50, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.808826 Acc@1: 0.420533 (ε = 7.60, δ = 1e-05) for α = 3.6
	Train Epoch: 14 	Loss: 1.789962 Acc@1: 0.427384 (ε = 7.69, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.552157 Acc@1: 0.524839 
	Train Epoch: 15 	Loss: 1.694067 Acc@1: 0.452066 (ε = 7.74, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.770041 Acc@1: 0.458273 (ε = 7.83, δ = 1e-05) for α = 3.6
	Train Epoch: 15 	Loss: 1.754306 Acc@1: 0.462438 (ε = 7.92, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.515489 Acc@1: 0.555364 
	Train Epoch: 16 	Loss: 1.770683 Acc@1: 0.458234 (ε = 7.97, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.739079 Acc@1: 0.474722 (ε = 8.06, δ = 1e-05) for α = 3.5
	Train Epoch: 16 	Loss: 1.724206 Acc@1: 0.477126 (ε = 8.15, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.552973 Acc@1: 0.529525 
	Train Epoch: 17 	Loss: 1.779841 Acc@1: 0.435070 (ε = 8.19, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.705329 Acc@1: 0.476131 (ε = 8.28, δ = 1e-05) for α = 3.5
	Train Epoch: 17 	Loss: 1.720396 Acc@1: 0.481789 (ε = 8.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.471255 Acc@1: 0.570257 
	Train Epoch: 18 	Loss: 1.668864 Acc@1: 0.502443 (ε = 8.41, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.687713 Acc@1: 0.499338 (ε = 8.50, δ = 1e-05) for α = 3.4
	Train Epoch: 18 	Loss: 1.692334 Acc@1: 0.497722 (ε = 8.58, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.526446 Acc@1: 0.553942 
	Train Epoch: 19 	Loss: 1.570993 Acc@1: 0.521562 (ε = 8.63, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.673865 Acc@1: 0.502593 (ε = 8.71, δ = 1e-05) for α = 3.4
	Train Epoch: 19 	Loss: 1.662072 Acc@1: 0.509188 (ε = 8.80, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.508238 Acc@1: 0.577943 
	Train Epoch: 20 	Loss: 1.695919 Acc@1: 0.493289 (ε = 8.84, δ = 1e-05) for α = 3.4
	Train Epoch: 20 	Loss: 1.671737 Acc@1: 0.520815 (ε = 8.92, δ = 1e-05) for α = 3.3
	Train Epoch: 20 	Loss: 1.664522 Acc@1: 0.515358 (ε = 9.00, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.501807 Acc@1: 0.580460 
	Train Epoch: 21 	Loss: 1.664214 Acc@1: 0.515918 (ε = 9.04, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.688205 Acc@1: 0.523719 (ε = 9.12, δ = 1e-05) for α = 3.3
	Train Epoch: 21 	Loss: 1.663223 Acc@1: 0.526472 (ε = 9.20, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.489932 Acc@1: 0.587683 
	Train Epoch: 22 	Loss: 1.649804 Acc@1: 0.535519 (ε = 9.24, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.626519 Acc@1: 0.528694 (ε = 9.32, δ = 1e-05) for α = 3.3
	Train Epoch: 22 	Loss: 1.627124 Acc@1: 0.530694 (ε = 9.41, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.507652 Acc@1: 0.585812 
	Train Epoch: 23 	Loss: 1.645114 Acc@1: 0.520131 (ε = 9.45, δ = 1e-05) for α = 3.3
	Train Epoch: 23 	Loss: 1.628185 Acc@1: 0.534083 (ε = 9.52, δ = 1e-05) for α = 3.2
	Train Epoch: 23 	Loss: 1.643547 Acc@1: 0.533102 (ε = 9.60, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.515984 Acc@1: 0.580083 
	Train Epoch: 24 	Loss: 1.576269 Acc@1: 0.536807 (ε = 9.64, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.661257 Acc@1: 0.528671 (ε = 9.72, δ = 1e-05) for α = 3.2
	Train Epoch: 24 	Loss: 1.652757 Acc@1: 0.532271 (ε = 9.79, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.509218 Acc@1: 0.586800 
	Train Epoch: 25 	Loss: 1.621003 Acc@1: 0.531897 (ε = 9.83, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.666418 Acc@1: 0.531600 (ε = 9.91, δ = 1e-05) for α = 3.2
	Train Epoch: 25 	Loss: 1.660650 Acc@1: 0.531433 (ε = 9.98, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.507190 Acc@1: 0.586847 
Base private model test accuracy:  0.5868533866819091
              precision    recall  f1-score   support

         0.0       0.27      0.29      0.28       508
         1.0       0.22      0.11      0.14       482
         2.0       0.22      0.19      0.20       510
         3.0       0.06      0.03      0.04       489
         4.0       0.17      0.13      0.15       466
         5.0       0.56      0.59      0.58      2972
         6.0       0.67      0.73      0.70      3080
         7.0       0.58      0.57      0.57      2961
         8.0       0.71      0.74      0.72      3024
         9.0       0.63      0.65      0.64      3003

    accuracy                           0.59     17495
   macro avg       0.41      0.40      0.40     17495
weighted avg       0.57      0.59      0.58     17495

Base private model train accuracy:  0.5351393039622095
              precision    recall  f1-score   support

         0.0       0.58      0.54      0.56      3141
         1.0       0.56      0.54      0.55      3077
         2.0       0.43      0.33      0.38      3025
         3.0       0.43      0.32      0.36      3118
         4.0       0.44      0.33      0.38      3091
         5.0       0.53      0.61      0.57      3133
         6.0       0.48      0.71      0.58      3054
         7.0       0.56      0.57      0.56      3132
         8.0       0.66      0.72      0.69      3172
         9.0       0.60      0.66      0.63      3176

    accuracy                           0.54     31119
   macro avg       0.53      0.53      0.53     31119
weighted avg       0.53      0.54      0.53     31119

{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0}
{5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}
NN model attack results: 
train acc: 0.6359020502602996
test acc: 0.5097402597402597
min train acc: 0.704816852274252
maj train acc: 0.5706924720372
min test acc: 0.48437906795105445
maj test acc: 0.5349378881987578
total acc: 0.5731451274265965
total min acc: 0.5929302940204824
total maj acc: 0.5530761874402296
precision, recall: (0.5671864251318505, 0.6359020502602996)
sampling type, sampling ratio, epsilon, acc, train acc, mia, min mia, maj mia, report, train report
['smote', 1.0, 10.013886331234898, 0.5868533866819091, 0.5351393039622095, 0.5731451274265965, 0.5929302940204824, 0.5530761874402296, '              precision    recall  f1-score   support\n\n         0.0       0.27      0.29      0.28       508\n         1.0       0.22      0.11      0.14       482\n         2.0       0.22      0.19      0.20       510\n         3.0       0.06      0.03      0.04       489\n         4.0       0.17      0.13      0.15       466\n         5.0       0.56      0.59      0.58      2972\n         6.0       0.67      0.73      0.70      3080\n         7.0       0.58      0.57      0.57      2961\n         8.0       0.71      0.74      0.72      3024\n         9.0       0.63      0.65      0.64      3003\n\n    accuracy                           0.59     17495\n   macro avg       0.41      0.40      0.40     17495\nweighted avg       0.57      0.59      0.58     17495\n', '              precision    recall  f1-score   support\n\n         0.0       0.58      0.54      0.56      3141\n         1.0       0.56      0.54      0.55      3077\n         2.0       0.43      0.33      0.38      3025\n         3.0       0.43      0.32      0.36      3118\n         4.0       0.44      0.33      0.38      3091\n         5.0       0.53      0.61      0.57      3133\n         6.0       0.48      0.71      0.58      3054\n         7.0       0.56      0.57      0.56      3132\n         8.0       0.66      0.72      0.69      3172\n         9.0       0.60      0.66      0.63      3176\n\n    accuracy                           0.54     31119\n   macro avg       0.53      0.53      0.53     31119\nweighted avg       0.53      0.54      0.53     31119\n']
experiment_number: 27
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/smote/test_results-27.json
Wed Jun  9 21:52:36 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:0C.0 Off |                    0 |
| N/A   55C    P0    36W /  70W |      0MiB / 15109MiB |     89%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 21:52:36 up  5:31,  2 users,  load average: 15.24, 15.07, 14.72
