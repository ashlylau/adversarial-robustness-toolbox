Python 2.7.18
Python 3.8.5
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 1, 'noise_multiplier': 1e-05, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[6. 5. 8. ... 2. 1. 0.]
[6. 5. 6. ... 8. 5. 7.]
(17255, 3, 32, 32)
(17500, 3, 32, 32)
(17255, 3, 32, 32)
(17255,)
	Train Epoch: 1 	Loss: 2.305616 Acc@1: 0.034384 (ε = 5500000079.72, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.251689 Acc@1: 0.152749 (ε = 60499999725.65, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.159239 Acc@1: 0.161874 (ε = 115499999371.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 2.008553 Acc@1: 0.188832 
test results
Base private model accuracy:  0.18897142857142857
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       502
         1.0       0.00      0.00      0.00       502
         2.0       0.00      0.00      0.00       508
         3.0       0.00      0.00      0.00       492
         4.0       0.00      0.00      0.00       499
         5.0       0.00      0.00      0.00      2992
         6.0       0.67      0.10      0.17      3082
         7.0       0.00      0.00      0.00      2973
         8.0       0.18      1.00      0.30      3007
         9.0       0.06      0.00      0.01      2943

    accuracy                           0.19     17500
   macro avg       0.09      0.11      0.05     17500
weighted avg       0.16      0.19      0.08     17500

train results
Base private model accuracy:  0.18093306288032454
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       473
         1.0       0.00      0.00      0.00       489
         2.0       0.00      0.00      0.00       467
         3.0       0.00      0.00      0.00       484
         4.0       0.00      0.00      0.00       503
         5.0       0.00      0.00      0.00      2990
         6.0       0.66      0.09      0.17      2938
         7.0       0.00      0.00      0.00      2969
         8.0       0.17      1.00      0.29      2838
         9.0       0.08      0.01      0.01      3104

    accuracy                           0.18     17255
   macro avg       0.09      0.11      0.05     17255
weighted avg       0.15      0.18      0.08     17255

NN model attack results: 
train acc: 0.5928716314111852
test acc: 0.4197142857142857
total acc: 0.5056826355920011
precision, recall: (0.5018395879323032, 0.5928716314111852)
epsilon, acc, train acc, mia, report, train report
[137499999229.9384, 0.18897142857142857, 0.18093306288032454, 0.5056826355920011, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       502\n         1.0       0.00      0.00      0.00       502\n         2.0       0.00      0.00      0.00       508\n         3.0       0.00      0.00      0.00       492\n         4.0       0.00      0.00      0.00       499\n         5.0       0.00      0.00      0.00      2992\n         6.0       0.67      0.10      0.17      3082\n         7.0       0.00      0.00      0.00      2973\n         8.0       0.18      1.00      0.30      3007\n         9.0       0.06      0.00      0.01      2943\n\n    accuracy                           0.19     17500\n   macro avg       0.09      0.11      0.05     17500\nweighted avg       0.16      0.19      0.08     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       473\n         1.0       0.00      0.00      0.00       489\n         2.0       0.00      0.00      0.00       467\n         3.0       0.00      0.00      0.00       484\n         4.0       0.00      0.00      0.00       503\n         5.0       0.00      0.00      0.00      2990\n         6.0       0.66      0.09      0.17      2938\n         7.0       0.00      0.00      0.00      2969\n         8.0       0.17      1.00      0.29      2838\n         9.0       0.08      0.01      0.01      3104\n\n    accuracy                           0.18     17255\n   macro avg       0.09      0.11      0.05     17255\nweighted avg       0.15      0.18      0.08     17255\n']
experiment_number: 109
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-109.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.05, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[7. 6. 8. ... 7. 8. 6.]
[7. 9. 6. ... 2. 6. 6.]
(17340, 3, 32, 32)
(17500, 3, 32, 32)
(17340, 3, 32, 32)
(17340,)
	Train Epoch: 1 	Loss: 2.285881 Acc@1: 0.161429 (ε = 278.25, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.179007 Acc@1: 0.171230 (ε = 2145.65, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.109342 Acc@1: 0.187370 (ε = 3991.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.944626 Acc@1: 0.285973 
	Train Epoch: 2 	Loss: 1.954199 Acc@1: 0.285922 (ε = 4914.53, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.880217 Acc@1: 0.326537 (ε = 6760.45, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.841855 Acc@1: 0.349096 (ε = 8606.38, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.710226 Acc@1: 0.418016 
	Train Epoch: 3 	Loss: 1.684741 Acc@1: 0.437936 (ε = 9529.34, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.703434 Acc@1: 0.421770 (ε = 11375.26, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.659176 Acc@1: 0.429998 (ε = 13221.19, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.665684 Acc@1: 0.456450 
	Train Epoch: 4 	Loss: 1.545059 Acc@1: 0.492938 (ε = 14144.15, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.612215 Acc@1: 0.467548 (ε = 15990.07, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.595028 Acc@1: 0.472212 (ε = 17836.00, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.538147 Acc@1: 0.506688 
	Train Epoch: 5 	Loss: 1.508521 Acc@1: 0.526989 (ε = 18758.96, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.511797 Acc@1: 0.498904 (ε = 20604.88, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.503866 Acc@1: 0.505713 (ε = 22450.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.675920 Acc@1: 0.506949 
	Train Epoch: 6 	Loss: 1.733226 Acc@1: 0.483380 (ε = 23373.77, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.521404 Acc@1: 0.508979 (ε = 25219.69, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.455811 Acc@1: 0.524718 (ε = 27065.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.326504 Acc@1: 0.569227 
	Train Epoch: 7 	Loss: 1.374699 Acc@1: 0.566334 (ε = 27988.58, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.372218 Acc@1: 0.570283 (ε = 29834.50, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.350328 Acc@1: 0.576512 (ε = 31680.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.339565 Acc@1: 0.581726 
	Train Epoch: 8 	Loss: 1.448239 Acc@1: 0.546805 (ε = 32603.39, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.329721 Acc@1: 0.571860 (ε = 34449.31, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.320884 Acc@1: 0.579679 (ε = 36295.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.226395 Acc@1: 0.605119 
	Train Epoch: 9 	Loss: 1.215328 Acc@1: 0.618632 (ε = 37218.19, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.245553 Acc@1: 0.606922 (ε = 39064.12, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.257702 Acc@1: 0.605108 (ε = 40910.04, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.249664 Acc@1: 0.612179 
	Train Epoch: 10 	Loss: 1.232856 Acc@1: 0.611983 (ε = 41833.00, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.250762 Acc@1: 0.613053 (ε = 43678.93, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.252638 Acc@1: 0.612769 (ε = 45524.85, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.213316 Acc@1: 0.621953 
	Train Epoch: 11 	Loss: 1.252843 Acc@1: 0.615611 (ε = 46447.81, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.241826 Acc@1: 0.607662 (ε = 48293.74, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.240434 Acc@1: 0.613425 (ε = 50139.66, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.296853 Acc@1: 0.608270 
	Train Epoch: 12 	Loss: 1.233767 Acc@1: 0.633238 (ε = 51062.62, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.209979 Acc@1: 0.630367 (ε = 52908.55, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.215253 Acc@1: 0.628246 (ε = 54754.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.223983 Acc@1: 0.632301 
	Train Epoch: 13 	Loss: 1.141205 Acc@1: 0.657670 (ε = 55677.43, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.234041 Acc@1: 0.628822 (ε = 57523.36, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.215877 Acc@1: 0.632251 (ε = 59369.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.159671 Acc@1: 0.641863 
	Train Epoch: 14 	Loss: 1.238438 Acc@1: 0.627507 (ε = 60292.24, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.173511 Acc@1: 0.646090 (ε = 62138.16, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.168398 Acc@1: 0.649272 (ε = 63984.09, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.153810 Acc@1: 0.654537 
	Train Epoch: 15 	Loss: 1.023898 Acc@1: 0.682203 (ε = 64907.05, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.123988 Acc@1: 0.662449 (ε = 66752.97, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.135162 Acc@1: 0.659299 (ε = 68598.90, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.099847 Acc@1: 0.670137 
	Train Epoch: 16 	Loss: 1.054907 Acc@1: 0.687853 (ε = 69521.86, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.117556 Acc@1: 0.664879 (ε = 71367.78, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.110962 Acc@1: 0.670703 (ε = 73213.71, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.088092 Acc@1: 0.674213 
	Train Epoch: 17 	Loss: 1.056973 Acc@1: 0.682336 (ε = 74136.67, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.053793 Acc@1: 0.678737 (ε = 75982.59, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.077543 Acc@1: 0.677250 (ε = 77828.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.099611 Acc@1: 0.677989 
	Train Epoch: 18 	Loss: 1.052590 Acc@1: 0.685841 (ε = 78751.48, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.100078 Acc@1: 0.675404 (ε = 80597.40, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.098323 Acc@1: 0.678788 (ε = 82443.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.077480 Acc@1: 0.679700 
	Train Epoch: 19 	Loss: 1.079139 Acc@1: 0.684507 (ε = 83366.29, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.069081 Acc@1: 0.689626 (ε = 85212.21, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.074152 Acc@1: 0.688783 (ε = 87058.13, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.038230 Acc@1: 0.692159 
	Train Epoch: 20 	Loss: 0.974329 Acc@1: 0.677843 (ε = 87981.10, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.060322 Acc@1: 0.685813 (ε = 89827.02, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.050071 Acc@1: 0.689798 (ε = 91672.94, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.076954 Acc@1: 0.689297 
	Train Epoch: 21 	Loss: 0.982991 Acc@1: 0.711326 (ε = 92595.90, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.015577 Acc@1: 0.708234 (ε = 94441.83, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.015635 Acc@1: 0.706050 (ε = 96287.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.070739 Acc@1: 0.690990 
	Train Epoch: 22 	Loss: 1.151002 Acc@1: 0.676380 (ε = 97210.71, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.042461 Acc@1: 0.696325 (ε = 99056.64, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.024918 Acc@1: 0.699487 (ε = 100902.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.080136 Acc@1: 0.692179 
	Train Epoch: 23 	Loss: 0.994068 Acc@1: 0.712100 (ε = 101825.52, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.038123 Acc@1: 0.698071 (ε = 103671.45, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 1.015466 Acc@1: 0.703113 (ε = 105517.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.034446 Acc@1: 0.698694 
	Train Epoch: 24 	Loss: 1.014146 Acc@1: 0.695898 (ε = 106440.33, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.997080 Acc@1: 0.708511 (ε = 108286.26, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.014627 Acc@1: 0.706948 (ε = 110132.18, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.004052 Acc@1: 0.706770 
	Train Epoch: 25 	Loss: 0.934087 Acc@1: 0.735119 (ε = 111055.14, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 1.007764 Acc@1: 0.715259 (ε = 112901.06, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.998296 Acc@1: 0.714598 (ε = 114746.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.990530 Acc@1: 0.710529 
	Train Epoch: 26 	Loss: 0.923152 Acc@1: 0.716876 (ε = 115669.95, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.945723 Acc@1: 0.721870 (ε = 117515.87, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.944061 Acc@1: 0.726521 (ε = 119361.80, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.019273 Acc@1: 0.713943 
	Train Epoch: 27 	Loss: 0.950347 Acc@1: 0.742358 (ε = 120284.76, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.953268 Acc@1: 0.728299 (ε = 122130.68, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.954425 Acc@1: 0.727872 (ε = 123976.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.977305 Acc@1: 0.723441 
	Train Epoch: 28 	Loss: 0.926238 Acc@1: 0.737805 (ε = 124899.57, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.962651 Acc@1: 0.726818 (ε = 126745.49, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.949287 Acc@1: 0.725946 (ε = 128591.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.982703 Acc@1: 0.724544 
	Train Epoch: 29 	Loss: 0.834353 Acc@1: 0.755917 (ε = 129514.38, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.902356 Acc@1: 0.741152 (ε = 131360.30, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.914872 Acc@1: 0.735181 (ε = 133206.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.968540 Acc@1: 0.723518 
	Train Epoch: 30 	Loss: 0.786888 Acc@1: 0.776999 (ε = 134129.19, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.907021 Acc@1: 0.741325 (ε = 135975.11, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.915587 Acc@1: 0.737641 (ε = 137821.03, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.979316 Acc@1: 0.726235 
	Train Epoch: 31 	Loss: 0.993183 Acc@1: 0.709722 (ε = 138744.00, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.900631 Acc@1: 0.735727 (ε = 140589.92, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.903417 Acc@1: 0.735203 (ε = 142435.84, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.948877 Acc@1: 0.733514 
	Train Epoch: 32 	Loss: 0.867495 Acc@1: 0.738129 (ε = 143358.81, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.904833 Acc@1: 0.736462 (ε = 145204.73, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.910792 Acc@1: 0.737361 (ε = 147050.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.946668 Acc@1: 0.735810 
	Train Epoch: 33 	Loss: 0.832059 Acc@1: 0.761151 (ε = 147973.61, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.900705 Acc@1: 0.745857 (ε = 149819.54, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.892555 Acc@1: 0.751780 (ε = 151665.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.932400 Acc@1: 0.737641 
	Train Epoch: 34 	Loss: 0.976954 Acc@1: 0.724040 (ε = 152588.42, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.890021 Acc@1: 0.752273 (ε = 154434.35, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.900539 Acc@1: 0.747462 (ε = 156280.27, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.032329 Acc@1: 0.726437 
	Train Epoch: 35 	Loss: 1.019281 Acc@1: 0.735714 (ε = 157203.23, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.962380 Acc@1: 0.732663 (ε = 159049.16, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.938508 Acc@1: 0.738669 (ε = 160895.08, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.982298 Acc@1: 0.732312 
	Train Epoch: 36 	Loss: 0.925425 Acc@1: 0.746799 (ε = 161818.04, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.901964 Acc@1: 0.745877 (ε = 163663.97, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.891806 Acc@1: 0.750850 (ε = 165509.89, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.956073 Acc@1: 0.739194 
	Train Epoch: 37 	Loss: 0.876533 Acc@1: 0.741655 (ε = 166432.85, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.870532 Acc@1: 0.750295 (ε = 168278.77, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.876278 Acc@1: 0.752587 (ε = 170124.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.951281 Acc@1: 0.741673 
	Train Epoch: 38 	Loss: 1.011117 Acc@1: 0.726457 (ε = 171047.66, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.888669 Acc@1: 0.740158 (ε = 172893.58, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.884784 Acc@1: 0.746656 (ε = 174739.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.958495 Acc@1: 0.740186 
	Train Epoch: 39 	Loss: 0.824531 Acc@1: 0.768794 (ε = 175662.47, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.881092 Acc@1: 0.756388 (ε = 177508.39, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.885230 Acc@1: 0.752007 (ε = 179354.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.931604 Acc@1: 0.745156 
	Train Epoch: 40 	Loss: 0.798542 Acc@1: 0.766342 (ε = 180277.28, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.866997 Acc@1: 0.751248 (ε = 182123.20, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.869408 Acc@1: 0.754728 (ε = 183969.13, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.938805 Acc@1: 0.741484 
	Train Epoch: 41 	Loss: 0.788602 Acc@1: 0.767143 (ε = 184892.09, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.893387 Acc@1: 0.754085 (ε = 186738.01, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.888285 Acc@1: 0.752767 (ε = 188583.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.975806 Acc@1: 0.737540 
	Train Epoch: 42 	Loss: 0.793552 Acc@1: 0.773050 (ε = 189506.90, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.878122 Acc@1: 0.755031 (ε = 191352.82, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.868371 Acc@1: 0.757406 (ε = 193198.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.950744 Acc@1: 0.744282 
	Train Epoch: 43 	Loss: 0.840813 Acc@1: 0.754213 (ε = 194121.71, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.878876 Acc@1: 0.749429 (ε = 195967.63, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.882236 Acc@1: 0.751519 (ε = 197813.55, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.935993 Acc@1: 0.743344 
	Train Epoch: 44 	Loss: 1.005559 Acc@1: 0.735823 (ε = 198736.52, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.871398 Acc@1: 0.751695 (ε = 200582.44, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.854420 Acc@1: 0.755959 (ε = 202428.36, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944020 Acc@1: 0.747093 
	Train Epoch: 45 	Loss: 0.834483 Acc@1: 0.756338 (ε = 203351.32, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.843011 Acc@1: 0.764444 (ε = 205197.25, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.838453 Acc@1: 0.766095 (ε = 207043.17, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.960626 Acc@1: 0.746013 
	Train Epoch: 46 	Loss: 0.837169 Acc@1: 0.753030 (ε = 207966.13, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.875042 Acc@1: 0.761472 (ε = 209812.06, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.870498 Acc@1: 0.759081 (ε = 211657.98, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.927795 Acc@1: 0.746849 
	Train Epoch: 47 	Loss: 0.778596 Acc@1: 0.782123 (ε = 212580.94, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.838530 Acc@1: 0.766731 (ε = 214426.87, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.861198 Acc@1: 0.762787 (ε = 216272.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.947262 Acc@1: 0.743955 
	Train Epoch: 48 	Loss: 0.886638 Acc@1: 0.758427 (ε = 217195.75, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.885148 Acc@1: 0.753000 (ε = 219041.68, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.856648 Acc@1: 0.760428 (ε = 220887.60, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943705 Acc@1: 0.745038 
	Train Epoch: 49 	Loss: 0.835652 Acc@1: 0.758179 (ε = 221810.56, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.886522 Acc@1: 0.754893 (ε = 223656.48, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.872337 Acc@1: 0.758140 (ε = 225502.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.938833 Acc@1: 0.748395 
	Train Epoch: 50 	Loss: 0.944281 Acc@1: 0.734577 (ε = 226425.37, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.849211 Acc@1: 0.766318 (ε = 228271.29, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.831530 Acc@1: 0.769254 (ε = 230117.22, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.929506 Acc@1: 0.749390 
	Train Epoch: 51 	Loss: 0.927535 Acc@1: 0.738752 (ε = 231040.18, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.863976 Acc@1: 0.762586 (ε = 232886.10, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.828676 Acc@1: 0.768370 (ε = 234732.03, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925009 Acc@1: 0.749417 
	Train Epoch: 52 	Loss: 0.733687 Acc@1: 0.794483 (ε = 235654.99, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.832615 Acc@1: 0.767088 (ε = 237500.91, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.832506 Acc@1: 0.767800 (ε = 239346.84, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.933151 Acc@1: 0.751543 
	Train Epoch: 53 	Loss: 0.987766 Acc@1: 0.705795 (ε = 240269.80, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.858574 Acc@1: 0.757896 (ε = 242115.72, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.846000 Acc@1: 0.762549 (ε = 243961.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.940839 Acc@1: 0.748550 
	Train Epoch: 54 	Loss: 0.904189 Acc@1: 0.766049 (ε = 244884.61, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.880847 Acc@1: 0.763794 (ε = 246730.53, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.860860 Acc@1: 0.765388 (ε = 248576.45, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.934041 Acc@1: 0.750704 
	Train Epoch: 55 	Loss: 0.866773 Acc@1: 0.752266 (ε = 249499.42, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.853683 Acc@1: 0.767573 (ε = 251345.34, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.856446 Acc@1: 0.763772 (ε = 253191.26, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.920826 Acc@1: 0.750628 
	Train Epoch: 56 	Loss: 0.900052 Acc@1: 0.732938 (ε = 254114.22, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.809677 Acc@1: 0.770842 (ε = 255960.15, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.813085 Acc@1: 0.770289 (ε = 257806.07, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.924234 Acc@1: 0.752442 
	Train Epoch: 57 	Loss: 0.891477 Acc@1: 0.754386 (ε = 258729.03, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.855379 Acc@1: 0.764459 (ε = 260574.96, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.840856 Acc@1: 0.770627 (ε = 262420.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.928637 Acc@1: 0.751541 
	Train Epoch: 58 	Loss: 0.835850 Acc@1: 0.765432 (ε = 263343.84, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.823976 Acc@1: 0.767264 (ε = 265189.77, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.836287 Acc@1: 0.765358 (ε = 267035.69, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925401 Acc@1: 0.751748 
	Train Epoch: 59 	Loss: 0.869333 Acc@1: 0.756681 (ε = 267958.65, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.838825 Acc@1: 0.764243 (ε = 269804.58, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.847487 Acc@1: 0.766643 (ε = 271650.50, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925158 Acc@1: 0.752373 
	Train Epoch: 60 	Loss: 0.874565 Acc@1: 0.760962 (ε = 272573.46, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.832347 Acc@1: 0.764163 (ε = 274419.39, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.818679 Acc@1: 0.768223 (ε = 276265.31, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.928058 Acc@1: 0.751117 
test results
Base private model accuracy:  0.7519428571428571
              precision    recall  f1-score   support

         0.0       0.56      0.37      0.44       502
         1.0       0.56      0.35      0.43       502
         2.0       0.39      0.13      0.19       508
         3.0       0.22      0.01      0.02       492
         4.0       0.44      0.18      0.26       499
         5.0       0.65      0.81      0.72      2992
         6.0       0.80      0.86      0.83      3082
         7.0       0.78      0.77      0.78      2973
         8.0       0.83      0.88      0.86      3007
         9.0       0.80      0.88      0.84      2943

    accuracy                           0.75     17500
   macro avg       0.60      0.53      0.54     17500
weighted avg       0.72      0.75      0.73     17500

train results
Base private model accuracy:  0.7633794694348327
              precision    recall  f1-score   support

         0.0       0.59      0.40      0.48       497
         1.0       0.62      0.36      0.45       538
         2.0       0.41      0.15      0.22       512
         3.0       0.33      0.01      0.03       499
         4.0       0.59      0.26      0.36       493
         5.0       0.66      0.83      0.73      2941
         6.0       0.81      0.87      0.84      2871
         7.0       0.80      0.79      0.80      2977
         8.0       0.82      0.90      0.86      2951
         9.0       0.81      0.88      0.84      3061

    accuracy                           0.76     17340
   macro avg       0.64      0.54      0.56     17340
weighted avg       0.74      0.76      0.74     17340

NN model attack results: 
train acc: 0.6038062283737025
test acc: 0.5117142857142858
total acc: 0.557548794489093
precision, recall: (0.5506179332106232, 0.6038062283737025)
epsilon, acc, train acc, mia, report, train report
[277003.67828231346, 0.7519428571428571, 0.7633794694348327, 0.557548794489093, '              precision    recall  f1-score   support\n\n         0.0       0.56      0.37      0.44       502\n         1.0       0.56      0.35      0.43       502\n         2.0       0.39      0.13      0.19       508\n         3.0       0.22      0.01      0.02       492\n         4.0       0.44      0.18      0.26       499\n         5.0       0.65      0.81      0.72      2992\n         6.0       0.80      0.86      0.83      3082\n         7.0       0.78      0.77      0.78      2973\n         8.0       0.83      0.88      0.86      3007\n         9.0       0.80      0.88      0.84      2943\n\n    accuracy                           0.75     17500\n   macro avg       0.60      0.53      0.54     17500\nweighted avg       0.72      0.75      0.73     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.59      0.40      0.48       497\n         1.0       0.62      0.36      0.45       538\n         2.0       0.41      0.15      0.22       512\n         3.0       0.33      0.01      0.03       499\n         4.0       0.59      0.26      0.36       493\n         5.0       0.66      0.83      0.73      2941\n         6.0       0.81      0.87      0.84      2871\n         7.0       0.80      0.79      0.80      2977\n         8.0       0.82      0.90      0.86      2951\n         9.0       0.81      0.88      0.84      3061\n\n    accuracy                           0.76     17340\n   macro avg       0.64      0.54      0.56     17340\nweighted avg       0.74      0.76      0.74     17340\n']
experiment_number: 112
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-112.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.1, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[5. 8. 5. ... 8. 9. 3.]
[8. 5. 7. ... 7. 8. 9.]
(17361, 3, 32, 32)
(17500, 3, 32, 32)
(17361, 3, 32, 32)
(17361,)
	Train Epoch: 1 	Loss: 2.354267 Acc@1: 0.022727 (ε = 87.52, δ = 1e-05) for α = 1.4
	Train Epoch: 1 	Loss: 2.227211 Acc@1: 0.149001 (ε = 344.55, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.125462 Acc@1: 0.193295 (ε = 553.12, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.893090 Acc@1: 0.330712 
	Train Epoch: 2 	Loss: 1.888563 Acc@1: 0.311377 (ε = 657.40, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.826623 Acc@1: 0.352505 (ε = 865.97, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.797404 Acc@1: 0.364953 (ε = 1074.54, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.702672 Acc@1: 0.419470 
	Train Epoch: 3 	Loss: 1.745866 Acc@1: 0.404380 (ε = 1178.82, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.688921 Acc@1: 0.424591 (ε = 1387.39, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.643187 Acc@1: 0.441998 (ε = 1595.96, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.577902 Acc@1: 0.467182 
	Train Epoch: 4 	Loss: 1.534991 Acc@1: 0.488722 (ε = 1700.24, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.557152 Acc@1: 0.475667 (ε = 1908.81, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.558697 Acc@1: 0.476256 (ε = 2117.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.490112 Acc@1: 0.505068 
	Train Epoch: 5 	Loss: 1.433958 Acc@1: 0.540146 (ε = 2221.66, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.452091 Acc@1: 0.524185 (ε = 2430.23, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.486491 Acc@1: 0.516906 (ε = 2638.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.481610 Acc@1: 0.519790 
	Train Epoch: 6 	Loss: 1.503727 Acc@1: 0.540197 (ε = 2743.08, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.436839 Acc@1: 0.531624 (ε = 2951.64, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.421746 Acc@1: 0.535994 (ε = 3160.21, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.358668 Acc@1: 0.570069 
	Train Epoch: 7 	Loss: 1.297756 Acc@1: 0.594477 (ε = 3264.49, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.362493 Acc@1: 0.576786 (ε = 3473.06, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.348211 Acc@1: 0.570824 (ε = 3681.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.293548 Acc@1: 0.586425 
	Train Epoch: 8 	Loss: 1.308943 Acc@1: 0.584435 (ε = 3785.91, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.323177 Acc@1: 0.576149 (ε = 3994.48, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.319523 Acc@1: 0.574262 (ε = 4203.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.248359 Acc@1: 0.601759 
	Train Epoch: 9 	Loss: 1.203478 Acc@1: 0.594595 (ε = 4307.33, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.281447 Acc@1: 0.589985 (ε = 4515.90, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.260657 Acc@1: 0.594324 (ε = 4724.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.238682 Acc@1: 0.614844 
	Train Epoch: 10 	Loss: 1.259067 Acc@1: 0.622507 (ε = 4828.75, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.231641 Acc@1: 0.613329 (ε = 5037.31, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.246981 Acc@1: 0.612069 (ε = 5245.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.221488 Acc@1: 0.625864 
	Train Epoch: 11 	Loss: 1.264961 Acc@1: 0.611983 (ε = 5350.17, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.237263 Acc@1: 0.623525 (ε = 5558.73, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.236015 Acc@1: 0.619840 (ε = 5767.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.208686 Acc@1: 0.630998 
	Train Epoch: 12 	Loss: 1.135331 Acc@1: 0.653955 (ε = 5871.58, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.168939 Acc@1: 0.638421 (ε = 6080.15, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.180273 Acc@1: 0.638879 (ε = 6288.72, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.177116 Acc@1: 0.647126 
	Train Epoch: 13 	Loss: 1.238455 Acc@1: 0.645862 (ε = 6393.00, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.180428 Acc@1: 0.642875 (ε = 6601.57, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.165230 Acc@1: 0.653097 (ε = 6810.14, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.120789 Acc@1: 0.665389 
	Train Epoch: 14 	Loss: 1.129087 Acc@1: 0.667120 (ε = 6914.42, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.089915 Acc@1: 0.671273 (ε = 7122.99, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.120373 Acc@1: 0.666020 (ε = 7331.55, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.138968 Acc@1: 0.667243 
	Train Epoch: 15 	Loss: 1.131639 Acc@1: 0.658156 (ε = 7435.84, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.127806 Acc@1: 0.664978 (ε = 7644.40, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.142165 Acc@1: 0.664573 (ε = 7852.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.239538 Acc@1: 0.644452 
	Train Epoch: 16 	Loss: 1.242203 Acc@1: 0.637410 (ε = 7957.26, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.092931 Acc@1: 0.675600 (ε = 8165.82, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.090543 Acc@1: 0.676475 (ε = 8374.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.124644 Acc@1: 0.680259 
	Train Epoch: 17 	Loss: 1.114480 Acc@1: 0.671348 (ε = 8478.67, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.069041 Acc@1: 0.684270 (ε = 8687.24, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.069983 Acc@1: 0.678405 (ε = 8895.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.163125 Acc@1: 0.665640 
	Train Epoch: 18 	Loss: 1.143362 Acc@1: 0.660485 (ε = 9000.09, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.084855 Acc@1: 0.685422 (ε = 9208.66, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.093661 Acc@1: 0.682301 (ε = 9417.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.061009 Acc@1: 0.684731 
	Train Epoch: 19 	Loss: 1.105332 Acc@1: 0.677761 (ε = 9521.51, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.092272 Acc@1: 0.679544 (ε = 9730.08, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.074485 Acc@1: 0.685389 (ε = 9938.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.088038 Acc@1: 0.685679 
	Train Epoch: 20 	Loss: 1.078311 Acc@1: 0.688650 (ε = 10042.93, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.082595 Acc@1: 0.686718 (ε = 10251.49, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.081224 Acc@1: 0.684749 (ε = 10460.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.098240 Acc@1: 0.681681 
	Train Epoch: 21 	Loss: 1.098824 Acc@1: 0.691445 (ε = 10564.35, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.070566 Acc@1: 0.684584 (ε = 10772.91, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.053198 Acc@1: 0.686992 (ε = 10981.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.035992 Acc@1: 0.694485 
	Train Epoch: 22 	Loss: 1.155904 Acc@1: 0.686217 (ε = 11085.76, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.063379 Acc@1: 0.693078 (ε = 11294.33, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.052992 Acc@1: 0.696644 (ε = 11502.90, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.019316 Acc@1: 0.703790 
	Train Epoch: 23 	Loss: 1.021488 Acc@1: 0.703264 (ε = 11607.18, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.994906 Acc@1: 0.708406 (ε = 11815.75, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.996881 Acc@1: 0.711357 (ε = 12024.32, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.016481 Acc@1: 0.703733 
	Train Epoch: 24 	Loss: 1.037521 Acc@1: 0.685393 (ε = 12128.60, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.026425 Acc@1: 0.704551 (ε = 12337.17, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 1.012827 Acc@1: 0.704030 (ε = 12545.73, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.011243 Acc@1: 0.709564 
	Train Epoch: 25 	Loss: 0.967488 Acc@1: 0.720930 (ε = 12650.02, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.941387 Acc@1: 0.720843 (ε = 12858.58, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.974029 Acc@1: 0.715627 (ε = 13067.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.019215 Acc@1: 0.714125 
	Train Epoch: 26 	Loss: 0.943410 Acc@1: 0.733846 (ε = 13171.44, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.975283 Acc@1: 0.713943 (ε = 13380.00, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.981893 Acc@1: 0.715958 (ε = 13588.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.013242 Acc@1: 0.712486 
	Train Epoch: 27 	Loss: 0.920054 Acc@1: 0.736600 (ε = 13692.85, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.957317 Acc@1: 0.724498 (ε = 13901.42, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.955373 Acc@1: 0.723195 (ε = 14109.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.039534 Acc@1: 0.708899 
	Train Epoch: 28 	Loss: 0.974895 Acc@1: 0.706447 (ε = 14214.27, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.952063 Acc@1: 0.721862 (ε = 14422.84, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.964372 Acc@1: 0.722514 (ε = 14631.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.987492 Acc@1: 0.717477 
	Train Epoch: 29 	Loss: 0.951630 Acc@1: 0.728716 (ε = 14735.69, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.992497 Acc@1: 0.719420 (ε = 14944.26, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.962311 Acc@1: 0.725958 (ε = 15152.82, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.008231 Acc@1: 0.712183 
	Train Epoch: 30 	Loss: 0.875471 Acc@1: 0.735119 (ε = 15257.11, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.945207 Acc@1: 0.724072 (ε = 15465.67, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.936160 Acc@1: 0.728499 (ε = 15674.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.974442 Acc@1: 0.727658 
	Train Epoch: 31 	Loss: 0.896068 Acc@1: 0.750353 (ε = 15778.53, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.921748 Acc@1: 0.743390 (ε = 15987.09, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.906728 Acc@1: 0.744370 (ε = 16195.66, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.941960 Acc@1: 0.729211 
	Train Epoch: 32 	Loss: 0.854947 Acc@1: 0.754658 (ε = 16299.94, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.921691 Acc@1: 0.740532 (ε = 16508.51, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.922871 Acc@1: 0.741384 (ε = 16717.08, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.987251 Acc@1: 0.730215 
	Train Epoch: 33 	Loss: 0.977275 Acc@1: 0.745626 (ε = 16821.36, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.923924 Acc@1: 0.741338 (ε = 17029.93, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.911498 Acc@1: 0.749450 (ε = 17238.50, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.962367 Acc@1: 0.731375 
	Train Epoch: 34 	Loss: 0.784738 Acc@1: 0.761015 (ε = 17342.78, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.930235 Acc@1: 0.737943 (ε = 17551.35, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.917777 Acc@1: 0.742067 (ε = 17759.91, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.990786 Acc@1: 0.730306 
	Train Epoch: 35 	Loss: 0.804253 Acc@1: 0.750720 (ε = 17864.20, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.882365 Acc@1: 0.750247 (ε = 18072.76, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.887282 Acc@1: 0.748850 (ε = 18281.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.968575 Acc@1: 0.732714 
	Train Epoch: 36 	Loss: 0.867338 Acc@1: 0.745602 (ε = 18385.62, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.921394 Acc@1: 0.741492 (ε = 18594.18, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.912241 Acc@1: 0.743502 (ε = 18802.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.952156 Acc@1: 0.735872 
	Train Epoch: 37 	Loss: 0.919935 Acc@1: 0.748212 (ε = 18907.03, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.888621 Acc@1: 0.749238 (ε = 19115.60, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.891525 Acc@1: 0.749357 (ε = 19324.17, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.970016 Acc@1: 0.738897 
	Train Epoch: 38 	Loss: 0.865238 Acc@1: 0.765924 (ε = 19428.45, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.841985 Acc@1: 0.762305 (ε = 19637.02, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.858357 Acc@1: 0.758764 (ε = 19845.59, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.030643 Acc@1: 0.735111 
	Train Epoch: 39 	Loss: 1.008927 Acc@1: 0.722552 (ε = 19949.87, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.888807 Acc@1: 0.755454 (ε = 20158.44, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.888948 Acc@1: 0.755682 (ε = 20367.00, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.954931 Acc@1: 0.739445 
	Train Epoch: 40 	Loss: 0.814779 Acc@1: 0.765152 (ε = 20471.29, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.881252 Acc@1: 0.762157 (ε = 20679.85, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.882479 Acc@1: 0.759332 (ε = 20888.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.000001 Acc@1: 0.733833 
	Train Epoch: 41 	Loss: 0.881004 Acc@1: 0.776989 (ε = 20992.71, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.895666 Acc@1: 0.758954 (ε = 21201.27, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.886494 Acc@1: 0.754261 (ε = 21409.84, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.971671 Acc@1: 0.738483 
	Train Epoch: 42 	Loss: 0.938491 Acc@1: 0.741980 (ε = 21514.12, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.854504 Acc@1: 0.759430 (ε = 21722.69, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.866913 Acc@1: 0.757546 (ε = 21931.26, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943789 Acc@1: 0.743699 
	Train Epoch: 43 	Loss: 0.903162 Acc@1: 0.734859 (ε = 22035.54, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.852642 Acc@1: 0.758777 (ε = 22244.11, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.855440 Acc@1: 0.760943 (ε = 22452.68, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.962466 Acc@1: 0.742611 
	Train Epoch: 44 	Loss: 0.780487 Acc@1: 0.774524 (ε = 22556.96, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.856480 Acc@1: 0.756832 (ε = 22765.53, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.853355 Acc@1: 0.761501 (ε = 22974.09, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.951052 Acc@1: 0.740081 
	Train Epoch: 45 	Loss: 0.919485 Acc@1: 0.760745 (ε = 23078.38, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.866321 Acc@1: 0.764872 (ε = 23286.94, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.855726 Acc@1: 0.765207 (ε = 23495.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.941391 Acc@1: 0.745496 
	Train Epoch: 46 	Loss: 0.892669 Acc@1: 0.758321 (ε = 23599.79, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.879335 Acc@1: 0.755992 (ε = 23808.36, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.869437 Acc@1: 0.758856 (ε = 24016.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.960201 Acc@1: 0.742212 
	Train Epoch: 47 	Loss: 0.782017 Acc@1: 0.780338 (ε = 24121.21, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.853498 Acc@1: 0.764575 (ε = 24329.78, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.840885 Acc@1: 0.764925 (ε = 24538.35, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.934313 Acc@1: 0.747416 
	Train Epoch: 48 	Loss: 0.795629 Acc@1: 0.758569 (ε = 24642.63, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.857206 Acc@1: 0.760236 (ε = 24851.20, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.854264 Acc@1: 0.760155 (ε = 25059.77, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944233 Acc@1: 0.744998 
	Train Epoch: 49 	Loss: 0.748981 Acc@1: 0.780488 (ε = 25164.05, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.843675 Acc@1: 0.768396 (ε = 25372.62, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.849209 Acc@1: 0.766569 (ε = 25581.18, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.947253 Acc@1: 0.745764 
	Train Epoch: 50 	Loss: 0.735920 Acc@1: 0.791304 (ε = 25685.47, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.806816 Acc@1: 0.772339 (ε = 25894.03, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.819082 Acc@1: 0.769813 (ε = 26102.60, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944186 Acc@1: 0.745565 
	Train Epoch: 51 	Loss: 0.729971 Acc@1: 0.786704 (ε = 26206.88, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.820786 Acc@1: 0.772077 (ε = 26415.45, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.840095 Acc@1: 0.770176 (ε = 26624.02, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.950638 Acc@1: 0.746992 
	Train Epoch: 52 	Loss: 0.824657 Acc@1: 0.769655 (ε = 26728.30, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.850870 Acc@1: 0.767313 (ε = 26936.87, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.840597 Acc@1: 0.772417 (ε = 27145.44, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.956360 Acc@1: 0.747561 
	Train Epoch: 53 	Loss: 0.829131 Acc@1: 0.780236 (ε = 27249.72, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.851898 Acc@1: 0.766081 (ε = 27458.29, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.861974 Acc@1: 0.766368 (ε = 27666.86, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937630 Acc@1: 0.748169 
	Train Epoch: 54 	Loss: 0.833144 Acc@1: 0.765625 (ε = 27771.14, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.821081 Acc@1: 0.768115 (ε = 27979.71, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.814990 Acc@1: 0.771829 (ε = 28188.27, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.935746 Acc@1: 0.747836 
	Train Epoch: 55 	Loss: 0.799354 Acc@1: 0.758876 (ε = 28292.56, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.846179 Acc@1: 0.767601 (ε = 28501.12, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.838505 Acc@1: 0.769917 (ε = 28709.69, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.939822 Acc@1: 0.748028 
	Train Epoch: 56 	Loss: 0.893338 Acc@1: 0.764791 (ε = 28813.97, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.833259 Acc@1: 0.772729 (ε = 29022.54, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.821420 Acc@1: 0.776473 (ε = 29231.11, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937150 Acc@1: 0.747413 
	Train Epoch: 57 	Loss: 0.803199 Acc@1: 0.763948 (ε = 29335.39, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.778581 Acc@1: 0.785328 (ε = 29543.96, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.814658 Acc@1: 0.777377 (ε = 29752.53, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937716 Acc@1: 0.748673 
	Train Epoch: 58 	Loss: 0.853782 Acc@1: 0.766756 (ε = 29856.81, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.820263 Acc@1: 0.773291 (ε = 30065.38, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.799960 Acc@1: 0.777311 (ε = 30273.95, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.940573 Acc@1: 0.748730 
	Train Epoch: 59 	Loss: 0.883205 Acc@1: 0.770718 (ε = 30378.23, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.834689 Acc@1: 0.769965 (ε = 30586.80, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.836256 Acc@1: 0.771585 (ε = 30795.36, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937859 Acc@1: 0.748508 
	Train Epoch: 60 	Loss: 0.843577 Acc@1: 0.757781 (ε = 30899.65, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.841659 Acc@1: 0.772582 (ε = 31108.21, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.835393 Acc@1: 0.771163 (ε = 31316.78, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.936596 Acc@1: 0.749126 
test results
Base private model accuracy:  0.7489142857142858
              precision    recall  f1-score   support

         0.0       0.52      0.35      0.42       502
         1.0       0.56      0.36      0.44       502
         2.0       0.41      0.14      0.21       508
         3.0       0.21      0.01      0.02       492
         4.0       0.41      0.18      0.25       499
         5.0       0.64      0.82      0.72      2992
         6.0       0.81      0.85      0.83      3082
         7.0       0.78      0.78      0.78      2973
         8.0       0.81      0.88      0.85      3007
         9.0       0.81      0.86      0.84      2943

    accuracy                           0.75     17500
   macro avg       0.60      0.52      0.54     17500
weighted avg       0.72      0.75      0.73     17500

train results
Base private model accuracy:  0.7682737169517885
              precision    recall  f1-score   support

         0.0       0.59      0.40      0.47       481
         1.0       0.68      0.39      0.50       501
         2.0       0.48      0.22      0.31       486
         3.0       0.44      0.03      0.05       521
         4.0       0.58      0.25      0.35       503
         5.0       0.66      0.83      0.74      3080
         6.0       0.82      0.87      0.84      2881
         7.0       0.80      0.80      0.80      2982
         8.0       0.83      0.90      0.86      2912
         9.0       0.82      0.87      0.85      3014

    accuracy                           0.77     17361
   macro avg       0.67      0.56      0.58     17361
weighted avg       0.75      0.77      0.75     17361

NN model attack results: 
train acc: 0.5942988770515405
test acc: 0.5457142857142857
total acc: 0.5699125197189158
precision, recall: (0.5648604269293924, 0.5942988770515405)
epsilon, acc, train acc, mia, report, train report
[31400.207952180506, 0.7489142857142858, 0.7682737169517885, 0.5699125197189158, '              precision    recall  f1-score   support\n\n         0.0       0.52      0.35      0.42       502\n         1.0       0.56      0.36      0.44       502\n         2.0       0.41      0.14      0.21       508\n         3.0       0.21      0.01      0.02       492\n         4.0       0.41      0.18      0.25       499\n         5.0       0.64      0.82      0.72      2992\n         6.0       0.81      0.85      0.83      3082\n         7.0       0.78      0.78      0.78      2973\n         8.0       0.81      0.88      0.85      3007\n         9.0       0.81      0.86      0.84      2943\n\n    accuracy                           0.75     17500\n   macro avg       0.60      0.52      0.54     17500\nweighted avg       0.72      0.75      0.73     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.59      0.40      0.47       481\n         1.0       0.68      0.39      0.50       501\n         2.0       0.48      0.22      0.31       486\n         3.0       0.44      0.03      0.05       521\n         4.0       0.58      0.25      0.35       503\n         5.0       0.66      0.83      0.74      3080\n         6.0       0.82      0.87      0.84      2881\n         7.0       0.80      0.80      0.80      2982\n         8.0       0.83      0.90      0.86      2912\n         9.0       0.82      0.87      0.85      3014\n\n    accuracy                           0.77     17361\n   macro avg       0.67      0.56      0.58     17361\nweighted avg       0.75      0.77      0.75     17361\n']
experiment_number: 113
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-113.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.15, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[7. 5. 8. ... 8. 0. 1.]
[3. 7. 6. ... 6. 8. 7.]
(17504, 3, 32, 32)
(17500, 3, 32, 32)
(17504, 3, 32, 32)
(17504,)
	Train Epoch: 1 	Loss: 2.325190 Acc@1: 0.025937 (ε = 46.16, δ = 1e-05) for α = 1.6
	Train Epoch: 1 	Loss: 2.223272 Acc@1: 0.131174 (ε = 143.16, δ = 1e-05) for α = 1.1
	Train Epoch: 1 	Loss: 2.127081 Acc@1: 0.174437 (ε = 168.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.919758 Acc@1: 0.310979 
	Train Epoch: 2 	Loss: 1.940321 Acc@1: 0.284916 (ε = 181.38, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.857529 Acc@1: 0.334815 (ε = 206.87, δ = 1e-05) for α = 1.1
	Train Epoch: 2 	Loss: 1.813658 Acc@1: 0.356723 (ε = 232.35, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.691108 Acc@1: 0.422284 
	Train Epoch: 3 	Loss: 1.687525 Acc@1: 0.424419 (ε = 245.09, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.705349 Acc@1: 0.409338 (ε = 270.57, δ = 1e-05) for α = 1.1
	Train Epoch: 3 	Loss: 1.667066 Acc@1: 0.423686 (ε = 296.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.603965 Acc@1: 0.456711 
	Train Epoch: 4 	Loss: 1.707517 Acc@1: 0.433908 (ε = 308.79, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.567032 Acc@1: 0.464774 (ε = 334.28, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.543775 Acc@1: 0.479589 (ε = 359.76, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.617087 Acc@1: 0.483388 
	Train Epoch: 5 	Loss: 1.651144 Acc@1: 0.469741 (ε = 372.50, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.499291 Acc@1: 0.504557 (ε = 397.98, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.488715 Acc@1: 0.510517 (ε = 423.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.348465 Acc@1: 0.551722 
	Train Epoch: 6 	Loss: 1.295525 Acc@1: 0.566529 (ε = 436.21, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.398258 Acc@1: 0.540976 (ε = 461.69, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.389012 Acc@1: 0.547611 (ε = 487.17, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.371110 Acc@1: 0.570214 
	Train Epoch: 7 	Loss: 1.321163 Acc@1: 0.581498 (ε = 499.91, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.307073 Acc@1: 0.579047 (ε = 525.39, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.330106 Acc@1: 0.577675 (ε = 550.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.420916 Acc@1: 0.541241 
	Train Epoch: 8 	Loss: 1.412830 Acc@1: 0.532967 (ε = 563.62, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.339282 Acc@1: 0.570484 (ε = 589.10, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.347669 Acc@1: 0.568633 (ε = 614.58, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.287548 Acc@1: 0.594474 
	Train Epoch: 9 	Loss: 1.241912 Acc@1: 0.602582 (ε = 627.32, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.298869 Acc@1: 0.582592 (ε = 652.81, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.281440 Acc@1: 0.593550 (ε = 678.29, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.204112 Acc@1: 0.620469 
	Train Epoch: 10 	Loss: 1.227528 Acc@1: 0.613605 (ε = 691.03, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.224863 Acc@1: 0.614329 (ε = 716.51, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.219282 Acc@1: 0.617559 (ε = 741.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.208855 Acc@1: 0.639325 
	Train Epoch: 11 	Loss: 1.162036 Acc@1: 0.652949 (ε = 754.73, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.214027 Acc@1: 0.634265 (ε = 780.22, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.200977 Acc@1: 0.636675 (ε = 805.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.226307 Acc@1: 0.631136 
	Train Epoch: 12 	Loss: 1.223883 Acc@1: 0.649770 (ε = 818.44, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.146892 Acc@1: 0.652338 (ε = 843.92, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.149399 Acc@1: 0.652332 (ε = 869.40, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.202151 Acc@1: 0.654938 
	Train Epoch: 13 	Loss: 1.219797 Acc@1: 0.659973 (ε = 882.15, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.136569 Acc@1: 0.665579 (ε = 907.63, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.133651 Acc@1: 0.663287 (ε = 933.11, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.237794 Acc@1: 0.640935 
	Train Epoch: 14 	Loss: 1.081421 Acc@1: 0.695779 (ε = 945.85, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.135585 Acc@1: 0.660985 (ε = 971.33, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.110943 Acc@1: 0.669239 (ε = 996.82, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.076393 Acc@1: 0.674174 
	Train Epoch: 15 	Loss: 1.118746 Acc@1: 0.666667 (ε = 1009.56, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.068013 Acc@1: 0.679917 (ε = 1035.04, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.072920 Acc@1: 0.680603 (ε = 1060.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.124658 Acc@1: 0.678784 
	Train Epoch: 16 	Loss: 1.091916 Acc@1: 0.677374 (ε = 1073.26, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.082828 Acc@1: 0.682683 (ε = 1098.75, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.106951 Acc@1: 0.676740 (ε = 1124.23, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.060272 Acc@1: 0.681553 
	Train Epoch: 17 	Loss: 0.930936 Acc@1: 0.701429 (ε = 1136.97, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.041336 Acc@1: 0.690585 (ε = 1162.45, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.051838 Acc@1: 0.692327 (ε = 1187.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.082047 Acc@1: 0.685487 
	Train Epoch: 18 	Loss: 1.050125 Acc@1: 0.690265 (ε = 1200.67, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.079292 Acc@1: 0.689621 (ε = 1226.16, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.090271 Acc@1: 0.683253 (ε = 1251.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.108804 Acc@1: 0.683517 
	Train Epoch: 19 	Loss: 1.009667 Acc@1: 0.706965 (ε = 1264.38, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.017568 Acc@1: 0.699798 (ε = 1289.86, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.040328 Acc@1: 0.697939 (ε = 1315.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.089111 Acc@1: 0.687404 
	Train Epoch: 20 	Loss: 1.048503 Acc@1: 0.689415 (ε = 1328.09, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.032967 Acc@1: 0.689839 (ε = 1353.57, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.024094 Acc@1: 0.697633 (ε = 1379.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.125914 Acc@1: 0.688133 
	Train Epoch: 21 	Loss: 1.124400 Acc@1: 0.683333 (ε = 1391.79, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.046603 Acc@1: 0.698292 (ε = 1417.27, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.027145 Acc@1: 0.699965 (ε = 1442.76, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.019384 Acc@1: 0.703344 
	Train Epoch: 22 	Loss: 0.889743 Acc@1: 0.718887 (ε = 1455.50, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 0.963836 Acc@1: 0.717899 (ε = 1480.98, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 0.968459 Acc@1: 0.717465 (ε = 1506.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.014999 Acc@1: 0.715875 
	Train Epoch: 23 	Loss: 0.935137 Acc@1: 0.720478 (ε = 1519.20, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.941223 Acc@1: 0.728393 (ε = 1544.69, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.965490 Acc@1: 0.727654 (ε = 1570.17, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.004946 Acc@1: 0.714667 
	Train Epoch: 24 	Loss: 0.772808 Acc@1: 0.756914 (ε = 1582.91, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.938582 Acc@1: 0.728857 (ε = 1608.39, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.940374 Acc@1: 0.727262 (ε = 1633.87, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.987238 Acc@1: 0.721480 
	Train Epoch: 25 	Loss: 0.889085 Acc@1: 0.737300 (ε = 1646.61, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.946012 Acc@1: 0.723653 (ε = 1672.10, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.933502 Acc@1: 0.729374 (ε = 1697.58, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.980366 Acc@1: 0.724448 
	Train Epoch: 26 	Loss: 0.854897 Acc@1: 0.728933 (ε = 1710.32, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.916991 Acc@1: 0.736355 (ε = 1735.80, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.931951 Acc@1: 0.732966 (ε = 1761.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.971565 Acc@1: 0.727392 
	Train Epoch: 27 	Loss: 0.776925 Acc@1: 0.776812 (ε = 1774.03, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.896918 Acc@1: 0.737729 (ε = 1799.51, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.894424 Acc@1: 0.739388 (ε = 1824.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.003930 Acc@1: 0.726720 
	Train Epoch: 28 	Loss: 1.051180 Acc@1: 0.730159 (ε = 1837.73, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.930993 Acc@1: 0.739510 (ε = 1863.21, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.935329 Acc@1: 0.735530 (ε = 1888.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.964719 Acc@1: 0.722346 
	Train Epoch: 29 	Loss: 0.873657 Acc@1: 0.732558 (ε = 1901.44, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.900454 Acc@1: 0.734986 (ε = 1926.92, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.899499 Acc@1: 0.737509 (ε = 1952.40, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.929109 Acc@1: 0.735168 
	Train Epoch: 30 	Loss: 0.907753 Acc@1: 0.722701 (ε = 1965.14, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.885795 Acc@1: 0.745993 (ε = 1990.63, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.880663 Acc@1: 0.749566 (ε = 2016.11, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944320 Acc@1: 0.733949 
	Train Epoch: 31 	Loss: 0.869017 Acc@1: 0.743741 (ε = 2028.85, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.883962 Acc@1: 0.743753 (ε = 2054.33, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.873082 Acc@1: 0.748939 (ε = 2079.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.916575 Acc@1: 0.738732 
	Train Epoch: 32 	Loss: 0.757649 Acc@1: 0.787413 (ε = 2092.55, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.858421 Acc@1: 0.751910 (ε = 2118.04, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.863570 Acc@1: 0.750796 (ε = 2143.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.950265 Acc@1: 0.740255 
	Train Epoch: 33 	Loss: 0.915438 Acc@1: 0.747899 (ε = 2156.26, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.893889 Acc@1: 0.749655 (ε = 2181.74, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.879153 Acc@1: 0.751115 (ε = 2207.22, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944037 Acc@1: 0.740465 
	Train Epoch: 34 	Loss: 0.912830 Acc@1: 0.743590 (ε = 2219.97, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.878598 Acc@1: 0.750934 (ε = 2245.45, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.884295 Acc@1: 0.752557 (ε = 2270.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.888920 Acc@1: 0.744464 
	Train Epoch: 35 	Loss: 0.808490 Acc@1: 0.741844 (ε = 2283.67, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.876591 Acc@1: 0.747919 (ε = 2309.15, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.878856 Acc@1: 0.747903 (ε = 2334.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.926768 Acc@1: 0.740157 
	Train Epoch: 36 	Loss: 0.877910 Acc@1: 0.734088 (ε = 2347.38, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.865017 Acc@1: 0.756825 (ε = 2372.86, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.858721 Acc@1: 0.756965 (ε = 2398.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.962863 Acc@1: 0.739401 
	Train Epoch: 37 	Loss: 0.863518 Acc@1: 0.755848 (ε = 2411.08, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.858248 Acc@1: 0.759987 (ε = 2436.57, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.874699 Acc@1: 0.755593 (ε = 2462.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.999409 Acc@1: 0.736256 
	Train Epoch: 38 	Loss: 0.988643 Acc@1: 0.718887 (ε = 2474.79, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.854429 Acc@1: 0.758897 (ε = 2500.27, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.861797 Acc@1: 0.760740 (ε = 2525.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.901807 Acc@1: 0.751435 
	Train Epoch: 39 	Loss: 0.875590 Acc@1: 0.742081 (ε = 2538.49, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.841563 Acc@1: 0.764261 (ε = 2563.98, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.845646 Acc@1: 0.762646 (ε = 2589.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.932275 Acc@1: 0.744629 
	Train Epoch: 40 	Loss: 0.837553 Acc@1: 0.748603 (ε = 2602.20, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.815424 Acc@1: 0.764981 (ε = 2627.68, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.834026 Acc@1: 0.766471 (ε = 2653.16, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.918085 Acc@1: 0.746360 
	Train Epoch: 41 	Loss: 0.982822 Acc@1: 0.733813 (ε = 2665.91, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.818009 Acc@1: 0.767505 (ε = 2691.39, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.854856 Acc@1: 0.760273 (ε = 2716.87, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.920138 Acc@1: 0.749668 
	Train Epoch: 42 	Loss: 0.771604 Acc@1: 0.775385 (ε = 2729.61, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.841211 Acc@1: 0.762275 (ε = 2755.09, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.837943 Acc@1: 0.763273 (ε = 2780.58, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925422 Acc@1: 0.748804 
	Train Epoch: 43 	Loss: 0.833707 Acc@1: 0.775540 (ε = 2793.32, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.841654 Acc@1: 0.767906 (ε = 2818.80, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.836758 Acc@1: 0.769010 (ε = 2844.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.899813 Acc@1: 0.754088 
	Train Epoch: 44 	Loss: 0.891007 Acc@1: 0.761702 (ε = 2857.02, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.813429 Acc@1: 0.769388 (ε = 2882.51, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.832902 Acc@1: 0.767239 (ε = 2907.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.921204 Acc@1: 0.754241 
	Train Epoch: 45 	Loss: 0.913412 Acc@1: 0.744711 (ε = 2920.73, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.819156 Acc@1: 0.764007 (ε = 2946.21, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.813096 Acc@1: 0.770141 (ε = 2971.69, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.934832 Acc@1: 0.749321 
	Train Epoch: 46 	Loss: 0.833355 Acc@1: 0.770349 (ε = 2984.43, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.815709 Acc@1: 0.767580 (ε = 3009.92, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.812369 Acc@1: 0.772799 (ε = 3035.40, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.903001 Acc@1: 0.752132 
	Train Epoch: 47 	Loss: 0.846946 Acc@1: 0.766289 (ε = 3048.14, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.833637 Acc@1: 0.765284 (ε = 3073.62, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.817769 Acc@1: 0.770054 (ε = 3099.10, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.927436 Acc@1: 0.752560 
	Train Epoch: 48 	Loss: 0.810508 Acc@1: 0.762997 (ε = 3111.85, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.824189 Acc@1: 0.773484 (ε = 3137.33, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.818413 Acc@1: 0.772312 (ε = 3162.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.899591 Acc@1: 0.753850 
	Train Epoch: 49 	Loss: 0.811620 Acc@1: 0.782913 (ε = 3175.55, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.800194 Acc@1: 0.777561 (ε = 3201.03, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.805760 Acc@1: 0.776814 (ε = 3226.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.916967 Acc@1: 0.756018 
	Train Epoch: 50 	Loss: 0.841414 Acc@1: 0.763984 (ε = 3239.26, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.794697 Acc@1: 0.777365 (ε = 3264.74, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.819801 Acc@1: 0.771535 (ε = 3290.22, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.907580 Acc@1: 0.755770 
	Train Epoch: 51 	Loss: 0.915693 Acc@1: 0.754717 (ε = 3302.96, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.787722 Acc@1: 0.778852 (ε = 3328.45, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.799507 Acc@1: 0.778088 (ε = 3353.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.913818 Acc@1: 0.754514 
	Train Epoch: 52 	Loss: 0.861134 Acc@1: 0.769231 (ε = 3366.67, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.813195 Acc@1: 0.776023 (ε = 3392.15, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.814926 Acc@1: 0.773938 (ε = 3417.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.913386 Acc@1: 0.756779 
	Train Epoch: 53 	Loss: 0.831888 Acc@1: 0.757703 (ε = 3430.37, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.825690 Acc@1: 0.774373 (ε = 3455.86, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.817048 Acc@1: 0.778380 (ε = 3481.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.905019 Acc@1: 0.757638 
	Train Epoch: 54 	Loss: 0.799606 Acc@1: 0.794798 (ε = 3494.08, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.817548 Acc@1: 0.773676 (ε = 3519.56, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.831522 Acc@1: 0.772513 (ε = 3545.04, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.899155 Acc@1: 0.757694 
	Train Epoch: 55 	Loss: 0.678518 Acc@1: 0.798867 (ε = 3557.79, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.796334 Acc@1: 0.783465 (ε = 3583.27, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.791954 Acc@1: 0.781792 (ε = 3608.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.904661 Acc@1: 0.756409 
	Train Epoch: 56 	Loss: 0.867195 Acc@1: 0.792319 (ε = 3621.49, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.821984 Acc@1: 0.777419 (ε = 3646.97, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.826175 Acc@1: 0.774660 (ε = 3672.46, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.909785 Acc@1: 0.756693 
	Train Epoch: 57 	Loss: 0.868654 Acc@1: 0.772989 (ε = 3685.20, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.796934 Acc@1: 0.777878 (ε = 3710.68, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.781549 Acc@1: 0.781077 (ε = 3736.16, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.907114 Acc@1: 0.757222 
	Train Epoch: 58 	Loss: 0.833309 Acc@1: 0.758571 (ε = 3748.90, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.821887 Acc@1: 0.772172 (ε = 3774.39, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.814881 Acc@1: 0.772854 (ε = 3799.87, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.902443 Acc@1: 0.757581 
	Train Epoch: 59 	Loss: 0.766212 Acc@1: 0.786337 (ε = 3812.61, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.791733 Acc@1: 0.783211 (ε = 3838.09, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.808263 Acc@1: 0.778158 (ε = 3863.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.903032 Acc@1: 0.757461 
	Train Epoch: 60 	Loss: 0.716109 Acc@1: 0.783286 (ε = 3876.31, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.801670 Acc@1: 0.778615 (ε = 3901.80, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.806536 Acc@1: 0.776846 (ε = 3927.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.904668 Acc@1: 0.757485 
test results
Base private model accuracy:  0.7576571428571428
              precision    recall  f1-score   support

         0.0       0.56      0.37      0.45       502
         1.0       0.60      0.38      0.46       502
         2.0       0.45      0.17      0.25       508
         3.0       0.29      0.03      0.05       492
         4.0       0.40      0.19      0.25       499
         5.0       0.65      0.81      0.73      2992
         6.0       0.82      0.87      0.84      3082
         7.0       0.79      0.78      0.79      2973
         8.0       0.82      0.89      0.85      3007
         9.0       0.81      0.88      0.84      2943

    accuracy                           0.76     17500
   macro avg       0.62      0.54      0.55     17500
weighted avg       0.73      0.76      0.74     17500

train results
Base private model accuracy:  0.7819355575868373
              precision    recall  f1-score   support

         0.0       0.64      0.44      0.52       513
         1.0       0.69      0.42      0.52       506
         2.0       0.56      0.23      0.32       452
         3.0       0.31      0.04      0.07       488
         4.0       0.53      0.26      0.35       502
         5.0       0.70      0.85      0.77      3109
         6.0       0.82      0.89      0.85      2842
         7.0       0.82      0.80      0.81      2995
         8.0       0.83      0.89      0.86      3047
         9.0       0.83      0.89      0.86      3050

    accuracy                           0.78     17504
   macro avg       0.67      0.57      0.59     17504
weighted avg       0.76      0.78      0.76     17504

NN model attack results: 
train acc: 0.5598400457012283
test acc: 0.5954285714285714
total acc: 0.5776317668904443
precision, recall: (0.580568720379147, 0.5598400457012283)
epsilon, acc, train acc, mia, report, train report
[3937.4719562830587, 0.7576571428571428, 0.7819355575868373, 0.5776317668904443, '              precision    recall  f1-score   support\n\n         0.0       0.56      0.37      0.45       502\n         1.0       0.60      0.38      0.46       502\n         2.0       0.45      0.17      0.25       508\n         3.0       0.29      0.03      0.05       492\n         4.0       0.40      0.19      0.25       499\n         5.0       0.65      0.81      0.73      2992\n         6.0       0.82      0.87      0.84      3082\n         7.0       0.79      0.78      0.79      2973\n         8.0       0.82      0.89      0.85      3007\n         9.0       0.81      0.88      0.84      2943\n\n    accuracy                           0.76     17500\n   macro avg       0.62      0.54      0.55     17500\nweighted avg       0.73      0.76      0.74     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.64      0.44      0.52       513\n         1.0       0.69      0.42      0.52       506\n         2.0       0.56      0.23      0.32       452\n         3.0       0.31      0.04      0.07       488\n         4.0       0.53      0.26      0.35       502\n         5.0       0.70      0.85      0.77      3109\n         6.0       0.82      0.89      0.85      2842\n         7.0       0.82      0.80      0.81      2995\n         8.0       0.83      0.89      0.86      3047\n         9.0       0.83      0.89      0.86      3050\n\n    accuracy                           0.78     17504\n   macro avg       0.67      0.57      0.59     17504\nweighted avg       0.76      0.78      0.76     17504\n']
experiment_number: 114
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-114.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.2, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[9. 6. 6. ... 7. 9. 3.]
[8. 9. 6. ... 6. 0. 6.]
(17768, 3, 32, 32)
(17500, 3, 32, 32)
(17768, 3, 32, 32)
(17768,)
	Train Epoch: 1 	Loss: 2.329283 Acc@1: 0.027457 (ε = 29.65, δ = 1e-05) for α = 1.8
	Train Epoch: 1 	Loss: 2.206631 Acc@1: 0.144729 (ε = 75.10, δ = 1e-05) for α = 1.2
	Train Epoch: 1 	Loss: 2.115194 Acc@1: 0.196370 (ε = 91.04, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.851146 Acc@1: 0.333651 
	Train Epoch: 2 	Loss: 1.853212 Acc@1: 0.297337 (ε = 99.01, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 1.812893 Acc@1: 0.357050 (ε = 114.94, δ = 1e-05) for α = 1.2
	Train Epoch: 2 	Loss: 1.772734 Acc@1: 0.376048 (ε = 130.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.736608 Acc@1: 0.421722 
	Train Epoch: 3 	Loss: 1.755750 Acc@1: 0.424677 (ε = 138.85, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 1.681826 Acc@1: 0.429161 (ε = 154.79, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 1.651077 Acc@1: 0.438058 (ε = 164.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.595410 Acc@1: 0.457652 
	Train Epoch: 4 	Loss: 1.605057 Acc@1: 0.435277 (ε = 167.50, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.587101 Acc@1: 0.475556 (ε = 174.39, δ = 1e-05) for α = 1.1
	Train Epoch: 4 	Loss: 1.552136 Acc@1: 0.487269 (ε = 181.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.463078 Acc@1: 0.511318 
	Train Epoch: 5 	Loss: 1.484348 Acc@1: 0.500000 (ε = 184.73, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.492262 Acc@1: 0.504597 (ε = 191.62, δ = 1e-05) for α = 1.1
	Train Epoch: 5 	Loss: 1.469428 Acc@1: 0.511874 (ε = 198.51, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.402462 Acc@1: 0.545090 
	Train Epoch: 6 	Loss: 1.429787 Acc@1: 0.532394 (ε = 201.96, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.426732 Acc@1: 0.542762 (ε = 208.85, δ = 1e-05) for α = 1.1
	Train Epoch: 6 	Loss: 1.416585 Acc@1: 0.547429 (ε = 215.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.364274 Acc@1: 0.569535 
	Train Epoch: 7 	Loss: 1.451581 Acc@1: 0.545455 (ε = 219.18, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.377191 Acc@1: 0.560066 (ε = 226.07, δ = 1e-05) for α = 1.1
	Train Epoch: 7 	Loss: 1.370393 Acc@1: 0.565663 (ε = 232.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.366690 Acc@1: 0.573480 
	Train Epoch: 8 	Loss: 1.334319 Acc@1: 0.575800 (ε = 236.41, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.321746 Acc@1: 0.576739 (ε = 243.30, δ = 1e-05) for α = 1.1
	Train Epoch: 8 	Loss: 1.309302 Acc@1: 0.583027 (ε = 250.19, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.261067 Acc@1: 0.599079 
	Train Epoch: 9 	Loss: 1.199454 Acc@1: 0.603471 (ε = 253.64, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.256491 Acc@1: 0.605960 (ε = 260.53, δ = 1e-05) for α = 1.1
	Train Epoch: 9 	Loss: 1.239027 Acc@1: 0.612538 (ε = 267.42, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.248613 Acc@1: 0.622787 
	Train Epoch: 10 	Loss: 1.323737 Acc@1: 0.591896 (ε = 270.87, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.277159 Acc@1: 0.612639 (ε = 277.76, δ = 1e-05) for α = 1.1
	Train Epoch: 10 	Loss: 1.300545 Acc@1: 0.605330 (ε = 284.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.167602 Acc@1: 0.628973 
	Train Epoch: 11 	Loss: 1.104908 Acc@1: 0.631136 (ε = 288.09, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.224317 Acc@1: 0.614266 (ε = 294.98, δ = 1e-05) for α = 1.1
	Train Epoch: 11 	Loss: 1.208181 Acc@1: 0.623310 (ε = 301.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.220433 Acc@1: 0.635269 
	Train Epoch: 12 	Loss: 1.313508 Acc@1: 0.622507 (ε = 305.32, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.176048 Acc@1: 0.638549 (ε = 312.21, δ = 1e-05) for α = 1.1
	Train Epoch: 12 	Loss: 1.185975 Acc@1: 0.641678 (ε = 319.10, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.114872 Acc@1: 0.653139 
	Train Epoch: 13 	Loss: 1.119918 Acc@1: 0.636099 (ε = 322.55, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.170384 Acc@1: 0.639749 (ε = 329.44, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.174646 Acc@1: 0.643933 (ε = 336.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.186272 Acc@1: 0.644103 
	Train Epoch: 14 	Loss: 1.198157 Acc@1: 0.642559 (ε = 339.78, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.115481 Acc@1: 0.649674 (ε = 346.67, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.128655 Acc@1: 0.649903 (ε = 353.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.118325 Acc@1: 0.671420 
	Train Epoch: 15 	Loss: 1.070706 Acc@1: 0.687500 (ε = 357.00, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.110128 Acc@1: 0.666201 (ε = 363.90, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.118834 Acc@1: 0.664219 (ε = 370.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.126786 Acc@1: 0.668892 
	Train Epoch: 16 	Loss: 1.030216 Acc@1: 0.690509 (ε = 374.23, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.109271 Acc@1: 0.666957 (ε = 381.12, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.096533 Acc@1: 0.674315 (ε = 388.01, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.080262 Acc@1: 0.686016 
	Train Epoch: 17 	Loss: 0.997256 Acc@1: 0.706724 (ε = 391.46, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.033608 Acc@1: 0.691811 (ε = 398.35, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.060121 Acc@1: 0.688471 (ε = 405.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.054332 Acc@1: 0.686976 
	Train Epoch: 18 	Loss: 1.081723 Acc@1: 0.691884 (ε = 408.69, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.079208 Acc@1: 0.683755 (ε = 415.58, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.059484 Acc@1: 0.686578 (ε = 422.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.049204 Acc@1: 0.694298 
	Train Epoch: 19 	Loss: 0.959913 Acc@1: 0.717949 (ε = 425.91, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.021361 Acc@1: 0.700329 (ε = 432.81, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.051972 Acc@1: 0.693120 (ε = 439.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.039132 Acc@1: 0.694869 
	Train Epoch: 20 	Loss: 1.087563 Acc@1: 0.672439 (ε = 443.14, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.094090 Acc@1: 0.675504 (ε = 450.03, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.080827 Acc@1: 0.681149 (ε = 456.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.041050 Acc@1: 0.695066 
	Train Epoch: 21 	Loss: 0.982751 Acc@1: 0.685363 (ε = 460.37, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 0.971556 Acc@1: 0.709019 (ε = 467.26, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 0.988463 Acc@1: 0.710212 (ε = 474.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.988269 Acc@1: 0.714974 
	Train Epoch: 22 	Loss: 1.097021 Acc@1: 0.701201 (ε = 477.60, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 0.977926 Acc@1: 0.717124 (ε = 484.49, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 0.978941 Acc@1: 0.718486 (ε = 491.38, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.086717 Acc@1: 0.698155 
	Train Epoch: 23 	Loss: 0.926004 Acc@1: 0.732877 (ε = 494.82, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.997720 Acc@1: 0.715414 (ε = 501.72, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.982039 Acc@1: 0.719127 (ε = 508.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.974413 Acc@1: 0.720663 
	Train Epoch: 24 	Loss: 0.963256 Acc@1: 0.723647 (ε = 512.05, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.931768 Acc@1: 0.728051 (ε = 518.94, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.948708 Acc@1: 0.726845 (ε = 525.83, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.994981 Acc@1: 0.719956 
	Train Epoch: 25 	Loss: 0.849979 Acc@1: 0.751085 (ε = 529.28, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.953698 Acc@1: 0.725565 (ε = 536.17, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.972737 Acc@1: 0.721732 (ε = 543.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.022963 Acc@1: 0.714918 
	Train Epoch: 26 	Loss: 0.866878 Acc@1: 0.728278 (ε = 546.51, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.976447 Acc@1: 0.723499 (ε = 553.40, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.957815 Acc@1: 0.727028 (ε = 560.29, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.010720 Acc@1: 0.720768 
	Train Epoch: 27 	Loss: 1.031597 Acc@1: 0.703196 (ε = 563.73, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.921039 Acc@1: 0.736164 (ε = 570.63, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.911664 Acc@1: 0.739564 (ε = 577.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.001303 Acc@1: 0.723464 
	Train Epoch: 28 	Loss: 0.949421 Acc@1: 0.733146 (ε = 580.96, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.953005 Acc@1: 0.735863 (ε = 587.85, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.940921 Acc@1: 0.733755 (ε = 594.74, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.956811 Acc@1: 0.728994 
	Train Epoch: 29 	Loss: 0.907658 Acc@1: 0.731944 (ε = 598.19, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.918140 Acc@1: 0.737621 (ε = 605.08, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.914304 Acc@1: 0.742192 (ε = 611.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.939824 Acc@1: 0.733713 
	Train Epoch: 30 	Loss: 0.943921 Acc@1: 0.726639 (ε = 615.42, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.891255 Acc@1: 0.736722 (ε = 622.31, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.913831 Acc@1: 0.737907 (ε = 629.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.979686 Acc@1: 0.730149 
	Train Epoch: 31 	Loss: 0.995948 Acc@1: 0.728341 (ε = 632.64, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.912097 Acc@1: 0.742865 (ε = 639.54, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.894822 Acc@1: 0.744567 (ε = 646.43, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.963400 Acc@1: 0.735847 
	Train Epoch: 32 	Loss: 0.900794 Acc@1: 0.739972 (ε = 649.87, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.889335 Acc@1: 0.750095 (ε = 656.76, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.892831 Acc@1: 0.753961 (ε = 663.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943499 Acc@1: 0.742709 
	Train Epoch: 33 	Loss: 0.888272 Acc@1: 0.737500 (ε = 667.10, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.894446 Acc@1: 0.747414 (ε = 673.99, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.885537 Acc@1: 0.751435 (ε = 680.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.939704 Acc@1: 0.743583 
	Train Epoch: 34 	Loss: 0.840737 Acc@1: 0.766949 (ε = 684.33, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.864540 Acc@1: 0.759645 (ε = 691.22, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.861996 Acc@1: 0.756263 (ε = 698.11, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.930069 Acc@1: 0.746207 
	Train Epoch: 35 	Loss: 0.822860 Acc@1: 0.748571 (ε = 701.56, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.875704 Acc@1: 0.752560 (ε = 708.45, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.860019 Acc@1: 0.756650 (ε = 715.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.988461 Acc@1: 0.737255 
	Train Epoch: 36 	Loss: 1.019345 Acc@1: 0.724476 (ε = 718.78, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.850108 Acc@1: 0.762780 (ε = 725.67, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.863194 Acc@1: 0.758960 (ε = 732.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.970093 Acc@1: 0.740477 
	Train Epoch: 37 	Loss: 0.776617 Acc@1: 0.792818 (ε = 736.01, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.849114 Acc@1: 0.767229 (ε = 742.90, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.855180 Acc@1: 0.763287 (ε = 749.79, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.946114 Acc@1: 0.745035 
	Train Epoch: 38 	Loss: 0.831564 Acc@1: 0.757971 (ε = 753.24, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.851807 Acc@1: 0.764420 (ε = 760.13, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.842453 Acc@1: 0.768541 (ε = 767.02, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.953047 Acc@1: 0.747334 
	Train Epoch: 39 	Loss: 0.956513 Acc@1: 0.740525 (ε = 770.47, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.854355 Acc@1: 0.763857 (ε = 777.36, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.856151 Acc@1: 0.764188 (ε = 784.25, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.948558 Acc@1: 0.746150 
	Train Epoch: 40 	Loss: 0.805386 Acc@1: 0.772206 (ε = 787.69, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.818775 Acc@1: 0.770744 (ε = 794.58, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.840024 Acc@1: 0.767809 (ε = 801.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.930825 Acc@1: 0.751314 
	Train Epoch: 41 	Loss: 0.802110 Acc@1: 0.774550 (ε = 804.92, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.817858 Acc@1: 0.778764 (ε = 811.81, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.838537 Acc@1: 0.771435 (ε = 818.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.977733 Acc@1: 0.745461 
	Train Epoch: 42 	Loss: 0.881438 Acc@1: 0.750696 (ε = 822.15, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.868926 Acc@1: 0.761010 (ε = 829.04, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.847190 Acc@1: 0.766890 (ε = 835.93, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.953428 Acc@1: 0.751625 
	Train Epoch: 43 	Loss: 0.975364 Acc@1: 0.737127 (ε = 839.38, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.810708 Acc@1: 0.772043 (ε = 846.27, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.822391 Acc@1: 0.773075 (ε = 853.16, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.929029 Acc@1: 0.754007 
	Train Epoch: 44 	Loss: 0.894693 Acc@1: 0.782034 (ε = 856.60, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.835827 Acc@1: 0.773187 (ε = 863.49, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.841820 Acc@1: 0.770964 (ε = 870.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943774 Acc@1: 0.750837 
	Train Epoch: 45 	Loss: 0.873352 Acc@1: 0.766714 (ε = 873.83, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.825987 Acc@1: 0.774911 (ε = 880.72, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.818168 Acc@1: 0.775221 (ε = 887.61, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.927850 Acc@1: 0.752648 
	Train Epoch: 46 	Loss: 0.760347 Acc@1: 0.797671 (ε = 891.06, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.828866 Acc@1: 0.779473 (ε = 897.95, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.822636 Acc@1: 0.777516 (ε = 904.84, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.915110 Acc@1: 0.756107 
	Train Epoch: 47 	Loss: 0.896830 Acc@1: 0.758904 (ε = 908.29, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.809231 Acc@1: 0.776017 (ε = 915.18, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.791057 Acc@1: 0.777662 (ε = 922.07, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.923895 Acc@1: 0.754211 
	Train Epoch: 48 	Loss: 0.875056 Acc@1: 0.773040 (ε = 925.51, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.846697 Acc@1: 0.770620 (ε = 932.40, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.834157 Acc@1: 0.773311 (ε = 939.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937827 Acc@1: 0.754522 
	Train Epoch: 49 	Loss: 0.899025 Acc@1: 0.750000 (ε = 942.74, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.798853 Acc@1: 0.778677 (ε = 949.63, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.791142 Acc@1: 0.778534 (ε = 956.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.935432 Acc@1: 0.757145 
	Train Epoch: 50 	Loss: 0.918785 Acc@1: 0.745505 (ε = 959.97, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.815521 Acc@1: 0.775590 (ε = 966.86, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.815548 Acc@1: 0.776737 (ε = 973.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.926779 Acc@1: 0.756240 
	Train Epoch: 51 	Loss: 0.843130 Acc@1: 0.753934 (ε = 977.20, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.803447 Acc@1: 0.780970 (ε = 984.09, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.811371 Acc@1: 0.778282 (ε = 990.98, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.926991 Acc@1: 0.755533 
	Train Epoch: 52 	Loss: 0.698620 Acc@1: 0.795082 (ε = 994.42, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.814855 Acc@1: 0.778782 (ε = 1001.31, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.833673 Acc@1: 0.773412 (ε = 1008.21, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.913735 Acc@1: 0.756597 
	Train Epoch: 53 	Loss: 0.719512 Acc@1: 0.794076 (ε = 1011.65, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.776573 Acc@1: 0.783662 (ε = 1018.54, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.798000 Acc@1: 0.781769 (ε = 1025.43, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.919294 Acc@1: 0.758787 
	Train Epoch: 54 	Loss: 0.810744 Acc@1: 0.769874 (ε = 1028.88, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.794086 Acc@1: 0.780947 (ε = 1035.77, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.806612 Acc@1: 0.777141 (ε = 1042.66, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.923036 Acc@1: 0.757165 
	Train Epoch: 55 	Loss: 0.862560 Acc@1: 0.763812 (ε = 1046.11, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.831555 Acc@1: 0.776093 (ε = 1053.00, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.828245 Acc@1: 0.776157 (ε = 1059.89, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.917113 Acc@1: 0.756498 
	Train Epoch: 56 	Loss: 0.936670 Acc@1: 0.741803 (ε = 1063.33, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.805953 Acc@1: 0.782951 (ε = 1070.22, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.806553 Acc@1: 0.780592 (ε = 1077.12, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.920263 Acc@1: 0.756722 
	Train Epoch: 57 	Loss: 0.862251 Acc@1: 0.779539 (ε = 1080.56, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.838901 Acc@1: 0.768298 (ε = 1087.45, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.819747 Acc@1: 0.774411 (ε = 1094.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.916927 Acc@1: 0.757680 
	Train Epoch: 58 	Loss: 0.810259 Acc@1: 0.794944 (ε = 1097.79, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.801399 Acc@1: 0.786034 (ε = 1104.68, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.777417 Acc@1: 0.786741 (ε = 1111.57, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.915990 Acc@1: 0.758512 
	Train Epoch: 59 	Loss: 0.860789 Acc@1: 0.765739 (ε = 1115.02, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.801006 Acc@1: 0.782282 (ε = 1121.91, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.797999 Acc@1: 0.782300 (ε = 1128.80, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.920224 Acc@1: 0.757943 
	Train Epoch: 60 	Loss: 0.870336 Acc@1: 0.765051 (ε = 1132.24, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.801033 Acc@1: 0.782558 (ε = 1139.13, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.813221 Acc@1: 0.780365 (ε = 1146.03, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.913221 Acc@1: 0.759558 
test results
Base private model accuracy:  0.7586285714285714
              precision    recall  f1-score   support

         0.0       0.57      0.35      0.44       502
         1.0       0.57      0.37      0.45       502
         2.0       0.41      0.14      0.20       508
         3.0       0.31      0.02      0.04       492
         4.0       0.43      0.22      0.29       499
         5.0       0.66      0.82      0.73      2992
         6.0       0.81      0.87      0.84      3082
         7.0       0.78      0.79      0.79      2973
         8.0       0.83      0.89      0.85      3007
         9.0       0.82      0.88      0.85      2943

    accuracy                           0.76     17500
   macro avg       0.62      0.53      0.55     17500
weighted avg       0.73      0.76      0.74     17500

train results
Base private model accuracy:  0.7756641152633948
              precision    recall  f1-score   support

         0.0       0.58      0.37      0.45       518
         1.0       0.67      0.41      0.51       504
         2.0       0.56      0.23      0.33       504
         3.0       0.37      0.03      0.06       534
         4.0       0.56      0.28      0.37       551
         5.0       0.68      0.84      0.75      3048
         6.0       0.82      0.89      0.85      2957
         7.0       0.80      0.81      0.81      3072
         8.0       0.84      0.90      0.87      3032
         9.0       0.82      0.88      0.85      3048

    accuracy                           0.78     17768
   macro avg       0.67      0.56      0.59     17768
weighted avg       0.76      0.78      0.75     17768

NN model attack results: 
train acc: 0.5773776027011818
test acc: 0.5871428571428572
total acc: 0.582222852282393
precision, recall: (0.5867886760080069, 0.5773776027011818)
epsilon, acc, train acc, mia, report, train report
[1148.7821972797774, 0.7586285714285714, 0.7756641152633948, 0.582222852282393, '              precision    recall  f1-score   support\n\n         0.0       0.57      0.35      0.44       502\n         1.0       0.57      0.37      0.45       502\n         2.0       0.41      0.14      0.20       508\n         3.0       0.31      0.02      0.04       492\n         4.0       0.43      0.22      0.29       499\n         5.0       0.66      0.82      0.73      2992\n         6.0       0.81      0.87      0.84      3082\n         7.0       0.78      0.79      0.79      2973\n         8.0       0.83      0.89      0.85      3007\n         9.0       0.82      0.88      0.85      2943\n\n    accuracy                           0.76     17500\n   macro avg       0.62      0.53      0.55     17500\nweighted avg       0.73      0.76      0.74     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.58      0.37      0.45       518\n         1.0       0.67      0.41      0.51       504\n         2.0       0.56      0.23      0.33       504\n         3.0       0.37      0.03      0.06       534\n         4.0       0.56      0.28      0.37       551\n         5.0       0.68      0.84      0.75      3048\n         6.0       0.82      0.89      0.85      2957\n         7.0       0.80      0.81      0.81      3072\n         8.0       0.84      0.90      0.87      3032\n         9.0       0.82      0.88      0.85      3048\n\n    accuracy                           0.78     17768\n   macro avg       0.67      0.56      0.59     17768\nweighted avg       0.76      0.78      0.75     17768\n']
experiment_number: 115
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-115.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.25, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[6. 5. 9. ... 5. 2. 7.]
[5. 9. 1. ... 9. 4. 8.]
(17429, 3, 32, 32)
(17500, 3, 32, 32)
(17429, 3, 32, 32)
(17429,)
	Train Epoch: 1 	Loss: 2.304942 Acc@1: 0.034582 (ε = 21.08, δ = 1e-05) for α = 2.0
	Train Epoch: 1 	Loss: 2.195958 Acc@1: 0.149481 (ε = 46.82, δ = 1e-05) for α = 1.4
	Train Epoch: 1 	Loss: 2.119918 Acc@1: 0.166786 (ε = 56.70, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.978053 Acc@1: 0.256370 
	Train Epoch: 2 	Loss: 2.010547 Acc@1: 0.230205 (ε = 61.06, δ = 1e-05) for α = 1.3
	Train Epoch: 2 	Loss: 1.869392 Acc@1: 0.325628 (ε = 69.79, δ = 1e-05) for α = 1.3
	Train Epoch: 2 	Loss: 1.830582 Acc@1: 0.347704 (ε = 78.51, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.673697 Acc@1: 0.428848 
	Train Epoch: 3 	Loss: 1.647723 Acc@1: 0.422256 (ε = 81.73, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 1.654588 Acc@1: 0.415406 (ε = 86.47, δ = 1e-05) for α = 1.2
	Train Epoch: 3 	Loss: 1.659070 Acc@1: 0.421741 (ε = 91.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.588264 Acc@1: 0.464662 
	Train Epoch: 4 	Loss: 1.586191 Acc@1: 0.450284 (ε = 93.58, δ = 1e-05) for α = 1.2
	Train Epoch: 4 	Loss: 1.596946 Acc@1: 0.449693 (ε = 98.32, δ = 1e-05) for α = 1.2
	Train Epoch: 4 	Loss: 1.554962 Acc@1: 0.463915 (ε = 103.06, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.446382 Acc@1: 0.503761 
	Train Epoch: 5 	Loss: 1.448770 Acc@1: 0.500000 (ε = 105.43, δ = 1e-05) for α = 1.2
	Train Epoch: 5 	Loss: 1.474068 Acc@1: 0.510780 (ε = 110.16, δ = 1e-05) for α = 1.2
	Train Epoch: 5 	Loss: 1.451747 Acc@1: 0.519671 (ε = 114.90, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.469549 Acc@1: 0.535575 
	Train Epoch: 6 	Loss: 1.367062 Acc@1: 0.571629 (ε = 117.27, δ = 1e-05) for α = 1.2
	Train Epoch: 6 	Loss: 1.387298 Acc@1: 0.548391 (ε = 122.01, δ = 1e-05) for α = 1.2
	Train Epoch: 6 	Loss: 1.370846 Acc@1: 0.553580 (ε = 126.75, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.389690 Acc@1: 0.569636 
	Train Epoch: 7 	Loss: 1.367137 Acc@1: 0.562594 (ε = 129.12, δ = 1e-05) for α = 1.2
	Train Epoch: 7 	Loss: 1.297761 Acc@1: 0.588257 (ε = 133.86, δ = 1e-05) for α = 1.2
	Train Epoch: 7 	Loss: 1.305104 Acc@1: 0.588183 (ε = 138.60, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.286324 Acc@1: 0.600002 
	Train Epoch: 8 	Loss: 1.263150 Acc@1: 0.599702 (ε = 140.97, δ = 1e-05) for α = 1.2
	Train Epoch: 8 	Loss: 1.251974 Acc@1: 0.612609 (ε = 145.71, δ = 1e-05) for α = 1.2
	Train Epoch: 8 	Loss: 1.257879 Acc@1: 0.612258 (ε = 150.44, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.391366 Acc@1: 0.588229 
	Train Epoch: 9 	Loss: 1.439698 Acc@1: 0.567227 (ε = 152.81, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.257755 Acc@1: 0.614347 (ε = 157.55, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.234547 Acc@1: 0.619287 (ε = 162.29, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.187919 Acc@1: 0.637937 
	Train Epoch: 10 	Loss: 1.146757 Acc@1: 0.666154 (ε = 164.66, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.195085 Acc@1: 0.637420 (ε = 169.40, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.187227 Acc@1: 0.639137 (ε = 174.14, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.371818 Acc@1: 0.616365 
	Train Epoch: 11 	Loss: 1.442029 Acc@1: 0.594101 (ε = 176.51, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.196504 Acc@1: 0.640703 (ε = 181.25, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.185165 Acc@1: 0.645020 (ε = 185.98, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.196988 Acc@1: 0.652435 
	Train Epoch: 12 	Loss: 1.116785 Acc@1: 0.665224 (ε = 188.35, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.166134 Acc@1: 0.655064 (ε = 193.09, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.213089 Acc@1: 0.640822 (ε = 196.67, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.086396 Acc@1: 0.664702 
	Train Epoch: 13 	Loss: 1.036797 Acc@1: 0.670940 (ε = 198.05, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.163853 Acc@1: 0.645013 (ε = 200.80, δ = 1e-05) for α = 1.1
	Train Epoch: 13 	Loss: 1.158246 Acc@1: 0.649164 (ε = 203.56, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.202971 Acc@1: 0.649737 
	Train Epoch: 14 	Loss: 1.054525 Acc@1: 0.682270 (ε = 204.93, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.136066 Acc@1: 0.660840 (ε = 207.69, δ = 1e-05) for α = 1.1
	Train Epoch: 14 	Loss: 1.114519 Acc@1: 0.667859 (ε = 210.44, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.132570 Acc@1: 0.670740 
	Train Epoch: 15 	Loss: 1.036485 Acc@1: 0.701245 (ε = 211.82, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.063570 Acc@1: 0.689925 (ε = 214.58, δ = 1e-05) for α = 1.1
	Train Epoch: 15 	Loss: 1.091660 Acc@1: 0.683433 (ε = 217.33, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.093788 Acc@1: 0.678400 
	Train Epoch: 16 	Loss: 1.087265 Acc@1: 0.670868 (ε = 218.71, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.070987 Acc@1: 0.684919 (ε = 221.46, δ = 1e-05) for α = 1.1
	Train Epoch: 16 	Loss: 1.065130 Acc@1: 0.685490 (ε = 224.22, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.086460 Acc@1: 0.679621 
	Train Epoch: 17 	Loss: 1.119824 Acc@1: 0.676596 (ε = 225.60, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.008349 Acc@1: 0.702686 (ε = 228.35, δ = 1e-05) for α = 1.1
	Train Epoch: 17 	Loss: 1.013129 Acc@1: 0.702140 (ε = 231.11, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.115452 Acc@1: 0.683215 
	Train Epoch: 18 	Loss: 1.171333 Acc@1: 0.685796 (ε = 232.48, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.058328 Acc@1: 0.696711 (ε = 235.24, δ = 1e-05) for α = 1.1
	Train Epoch: 18 	Loss: 1.030050 Acc@1: 0.702090 (ε = 237.99, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.086444 Acc@1: 0.693991 
	Train Epoch: 19 	Loss: 0.939988 Acc@1: 0.729226 (ε = 239.37, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.038035 Acc@1: 0.711006 (ε = 242.12, δ = 1e-05) for α = 1.1
	Train Epoch: 19 	Loss: 1.062841 Acc@1: 0.705838 (ε = 244.88, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.187431 Acc@1: 0.674659 
	Train Epoch: 20 	Loss: 1.179415 Acc@1: 0.687870 (ε = 246.26, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.052072 Acc@1: 0.695954 (ε = 249.01, δ = 1e-05) for α = 1.1
	Train Epoch: 20 	Loss: 1.026967 Acc@1: 0.696961 (ε = 251.77, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.018100 Acc@1: 0.704708 
	Train Epoch: 21 	Loss: 0.949971 Acc@1: 0.718750 (ε = 253.14, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.008232 Acc@1: 0.710071 (ε = 255.90, δ = 1e-05) for α = 1.1
	Train Epoch: 21 	Loss: 1.020549 Acc@1: 0.708010 (ε = 258.65, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.028403 Acc@1: 0.696366 
	Train Epoch: 22 	Loss: 1.055342 Acc@1: 0.698225 (ε = 260.03, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 1.010981 Acc@1: 0.701664 (ε = 262.79, δ = 1e-05) for α = 1.1
	Train Epoch: 22 	Loss: 0.991618 Acc@1: 0.710909 (ε = 265.54, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.998392 Acc@1: 0.710780 
	Train Epoch: 23 	Loss: 0.886973 Acc@1: 0.731405 (ε = 266.92, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.949282 Acc@1: 0.731287 (ε = 269.67, δ = 1e-05) for α = 1.1
	Train Epoch: 23 	Loss: 0.953756 Acc@1: 0.730311 (ε = 272.43, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.990097 Acc@1: 0.713271 
	Train Epoch: 24 	Loss: 1.021637 Acc@1: 0.693820 (ε = 273.80, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.993522 Acc@1: 0.714084 (ε = 276.56, δ = 1e-05) for α = 1.1
	Train Epoch: 24 	Loss: 0.983403 Acc@1: 0.719955 (ε = 279.31, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.999441 Acc@1: 0.719358 
	Train Epoch: 25 	Loss: 0.910567 Acc@1: 0.714667 (ε = 280.69, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.987809 Acc@1: 0.720883 (ε = 283.45, δ = 1e-05) for α = 1.1
	Train Epoch: 25 	Loss: 0.974132 Acc@1: 0.723630 (ε = 286.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.951891 Acc@1: 0.726425 
	Train Epoch: 26 	Loss: 0.832553 Acc@1: 0.765043 (ε = 287.58, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.941935 Acc@1: 0.729340 (ε = 290.33, δ = 1e-05) for α = 1.1
	Train Epoch: 26 	Loss: 0.951299 Acc@1: 0.731141 (ε = 293.09, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.989006 Acc@1: 0.723604 
	Train Epoch: 27 	Loss: 0.821940 Acc@1: 0.753762 (ε = 294.47, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.905702 Acc@1: 0.742975 (ε = 297.22, δ = 1e-05) for α = 1.1
	Train Epoch: 27 	Loss: 0.904139 Acc@1: 0.745807 (ε = 299.97, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.974711 Acc@1: 0.731653 
	Train Epoch: 28 	Loss: 0.770373 Acc@1: 0.778902 (ε = 301.35, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.909977 Acc@1: 0.748137 (ε = 304.11, δ = 1e-05) for α = 1.1
	Train Epoch: 28 	Loss: 0.915412 Acc@1: 0.744897 (ε = 306.86, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.082471 Acc@1: 0.711735 
	Train Epoch: 29 	Loss: 1.119451 Acc@1: 0.700000 (ε = 308.24, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.952049 Acc@1: 0.737062 (ε = 310.99, δ = 1e-05) for α = 1.1
	Train Epoch: 29 	Loss: 0.957662 Acc@1: 0.736815 (ε = 313.75, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.024287 Acc@1: 0.721679 
	Train Epoch: 30 	Loss: 0.888085 Acc@1: 0.758480 (ε = 315.13, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.936665 Acc@1: 0.738415 (ε = 317.88, δ = 1e-05) for α = 1.1
	Train Epoch: 30 	Loss: 0.900397 Acc@1: 0.746313 (ε = 320.64, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.984516 Acc@1: 0.728059 
	Train Epoch: 31 	Loss: 0.878510 Acc@1: 0.754930 (ε = 322.01, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.903759 Acc@1: 0.748550 (ε = 324.77, δ = 1e-05) for α = 1.1
	Train Epoch: 31 	Loss: 0.895193 Acc@1: 0.753938 (ε = 327.52, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.141055 Acc@1: 0.704245 
	Train Epoch: 32 	Loss: 0.998820 Acc@1: 0.721751 (ε = 328.90, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.980021 Acc@1: 0.735913 (ε = 331.65, δ = 1e-05) for α = 1.1
	Train Epoch: 32 	Loss: 0.960600 Acc@1: 0.737935 (ε = 334.41, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.929217 Acc@1: 0.735677 
	Train Epoch: 33 	Loss: 0.765563 Acc@1: 0.778249 (ε = 335.79, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.853241 Acc@1: 0.756320 (ε = 338.54, δ = 1e-05) for α = 1.1
	Train Epoch: 33 	Loss: 0.869507 Acc@1: 0.756906 (ε = 341.30, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.961552 Acc@1: 0.734577 
	Train Epoch: 34 	Loss: 0.792076 Acc@1: 0.760504 (ε = 342.67, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.848729 Acc@1: 0.764315 (ε = 345.43, δ = 1e-05) for α = 1.1
	Train Epoch: 34 	Loss: 0.851658 Acc@1: 0.762114 (ε = 348.18, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.964859 Acc@1: 0.738205 
	Train Epoch: 35 	Loss: 0.808522 Acc@1: 0.770950 (ε = 349.56, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.847998 Acc@1: 0.758692 (ε = 352.32, δ = 1e-05) for α = 1.1
	Train Epoch: 35 	Loss: 0.851233 Acc@1: 0.758664 (ε = 355.07, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.992052 Acc@1: 0.738621 
	Train Epoch: 36 	Loss: 0.921588 Acc@1: 0.750357 (ε = 356.45, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.877238 Acc@1: 0.758866 (ε = 359.20, δ = 1e-05) for α = 1.1
	Train Epoch: 36 	Loss: 0.856339 Acc@1: 0.763078 (ε = 361.96, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.965916 Acc@1: 0.743303 
	Train Epoch: 37 	Loss: 0.821294 Acc@1: 0.778417 (ε = 363.33, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.874928 Acc@1: 0.762159 (ε = 366.09, δ = 1e-05) for α = 1.1
	Train Epoch: 37 	Loss: 0.864079 Acc@1: 0.765159 (ε = 368.84, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.972286 Acc@1: 0.745112 
	Train Epoch: 38 	Loss: 0.800324 Acc@1: 0.788515 (ε = 370.22, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.864370 Acc@1: 0.763743 (ε = 372.98, δ = 1e-05) for α = 1.1
	Train Epoch: 38 	Loss: 0.861741 Acc@1: 0.766648 (ε = 375.73, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.946970 Acc@1: 0.744917 
	Train Epoch: 39 	Loss: 0.828444 Acc@1: 0.759891 (ε = 377.11, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.839717 Acc@1: 0.763946 (ε = 379.86, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.829532 Acc@1: 0.767703 (ε = 382.62, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.010025 Acc@1: 0.739135 
	Train Epoch: 40 	Loss: 0.876141 Acc@1: 0.763889 (ε = 384.00, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.830308 Acc@1: 0.768450 (ε = 386.75, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.831287 Acc@1: 0.771678 (ε = 389.50, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.957735 Acc@1: 0.749107 
	Train Epoch: 41 	Loss: 0.835127 Acc@1: 0.771137 (ε = 390.88, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.876180 Acc@1: 0.761865 (ε = 393.64, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.856465 Acc@1: 0.763992 (ε = 396.39, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.959356 Acc@1: 0.744747 
	Train Epoch: 42 	Loss: 0.792303 Acc@1: 0.787572 (ε = 397.77, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.828538 Acc@1: 0.778410 (ε = 400.52, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.802348 Acc@1: 0.779955 (ε = 403.28, δ = 1e-05) for α = 1.1
	Test set:Loss: 1.038300 Acc@1: 0.736428 
	Train Epoch: 43 	Loss: 0.963298 Acc@1: 0.754821 (ε = 404.66, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.893718 Acc@1: 0.764123 (ε = 407.41, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.870558 Acc@1: 0.765567 (ε = 410.17, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.931809 Acc@1: 0.750182 
	Train Epoch: 44 	Loss: 0.850256 Acc@1: 0.766575 (ε = 411.54, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.820615 Acc@1: 0.771547 (ε = 414.30, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.838067 Acc@1: 0.770574 (ε = 417.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.932385 Acc@1: 0.750825 
	Train Epoch: 45 	Loss: 0.947898 Acc@1: 0.755132 (ε = 418.43, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.826006 Acc@1: 0.778196 (ε = 421.18, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.821299 Acc@1: 0.778587 (ε = 423.94, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.966052 Acc@1: 0.749089 
	Train Epoch: 46 	Loss: 0.858526 Acc@1: 0.774286 (ε = 425.32, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.799454 Acc@1: 0.781028 (ε = 428.07, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.823180 Acc@1: 0.776336 (ε = 430.83, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.936516 Acc@1: 0.750893 
	Train Epoch: 47 	Loss: 0.752629 Acc@1: 0.804064 (ε = 432.20, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.843044 Acc@1: 0.773302 (ε = 434.96, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.827957 Acc@1: 0.774433 (ε = 437.71, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943092 Acc@1: 0.753687 
	Train Epoch: 48 	Loss: 0.853756 Acc@1: 0.773611 (ε = 439.09, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.813592 Acc@1: 0.782967 (ε = 441.85, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.816173 Acc@1: 0.779929 (ε = 444.60, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.968727 Acc@1: 0.749604 
	Train Epoch: 49 	Loss: 0.947440 Acc@1: 0.757489 (ε = 445.98, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.825663 Acc@1: 0.780319 (ε = 448.73, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.822936 Acc@1: 0.779639 (ε = 451.49, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.952706 Acc@1: 0.752151 
	Train Epoch: 50 	Loss: 0.806284 Acc@1: 0.793353 (ε = 452.86, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.810794 Acc@1: 0.786817 (ε = 455.62, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.814791 Acc@1: 0.784540 (ε = 458.37, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.949717 Acc@1: 0.752264 
	Train Epoch: 51 	Loss: 0.768237 Acc@1: 0.782486 (ε = 459.75, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.820848 Acc@1: 0.774914 (ε = 462.51, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.802016 Acc@1: 0.780077 (ε = 465.26, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.941221 Acc@1: 0.754832 
	Train Epoch: 52 	Loss: 0.803590 Acc@1: 0.777293 (ε = 466.64, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.805839 Acc@1: 0.780489 (ε = 469.39, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.803494 Acc@1: 0.781535 (ε = 472.15, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.940705 Acc@1: 0.752496 
	Train Epoch: 53 	Loss: 0.957482 Acc@1: 0.766906 (ε = 473.53, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.802165 Acc@1: 0.782452 (ε = 476.28, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.807391 Acc@1: 0.779225 (ε = 479.04, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.950966 Acc@1: 0.751181 
	Train Epoch: 54 	Loss: 0.778993 Acc@1: 0.775758 (ε = 480.41, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.821663 Acc@1: 0.778076 (ε = 483.17, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.818793 Acc@1: 0.779043 (ε = 485.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.942905 Acc@1: 0.753212 
	Train Epoch: 55 	Loss: 0.750312 Acc@1: 0.796196 (ε = 487.30, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.772476 Acc@1: 0.789323 (ε = 490.05, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.809661 Acc@1: 0.780397 (ε = 492.81, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.932927 Acc@1: 0.753882 
	Train Epoch: 56 	Loss: 0.841832 Acc@1: 0.773643 (ε = 494.19, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.805029 Acc@1: 0.784730 (ε = 496.94, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.818748 Acc@1: 0.782103 (ε = 499.70, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.939516 Acc@1: 0.754152 
	Train Epoch: 57 	Loss: 0.823559 Acc@1: 0.777126 (ε = 501.07, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.795754 Acc@1: 0.785059 (ε = 503.83, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.809410 Acc@1: 0.781710 (ε = 506.58, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.935441 Acc@1: 0.753158 
	Train Epoch: 58 	Loss: 0.803331 Acc@1: 0.777452 (ε = 507.96, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.785377 Acc@1: 0.792676 (ε = 510.72, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.797757 Acc@1: 0.784679 (ε = 513.47, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.943446 Acc@1: 0.754637 
	Train Epoch: 59 	Loss: 0.821401 Acc@1: 0.774194 (ε = 514.85, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.774320 Acc@1: 0.792143 (ε = 517.60, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.782453 Acc@1: 0.788429 (ε = 520.36, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.940419 Acc@1: 0.753138 
	Train Epoch: 60 	Loss: 0.827223 Acc@1: 0.800872 (ε = 521.73, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.789207 Acc@1: 0.782251 (ε = 524.49, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.788535 Acc@1: 0.782988 (ε = 527.24, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.941259 Acc@1: 0.753567 
test results
Base private model accuracy:  0.7536
              precision    recall  f1-score   support

         0.0       0.61      0.38      0.47       502
         1.0       0.57      0.34      0.43       502
         2.0       0.42      0.15      0.22       508
         3.0       0.15      0.01      0.02       492
         4.0       0.37      0.18      0.25       499
         5.0       0.65      0.81      0.72      2992
         6.0       0.81      0.86      0.83      3082
         7.0       0.79      0.79      0.79      2973
         8.0       0.83      0.89      0.86      3007
         9.0       0.80      0.88      0.84      2943

    accuracy                           0.75     17500
   macro avg       0.60      0.53      0.54     17500
weighted avg       0.72      0.75      0.73     17500

train results
Base private model accuracy:  0.7846692294451776
              precision    recall  f1-score   support

         0.0       0.69      0.41      0.51       457
         1.0       0.68      0.45      0.54       480
         2.0       0.49      0.18      0.26       456
         3.0       0.50      0.05      0.09       504
         4.0       0.55      0.25      0.34       491
         5.0       0.69      0.84      0.76      3086
         6.0       0.82      0.88      0.85      2943
         7.0       0.82      0.83      0.82      3037
         8.0       0.83      0.91      0.87      2962
         9.0       0.84      0.88      0.86      3013

    accuracy                           0.78     17429
   macro avg       0.69      0.57      0.59     17429
weighted avg       0.77      0.78      0.76     17429

NN model attack results: 
train acc: 0.6442914515203672
test acc: 0.502
total acc: 0.5730031491554538
precision, recall: (0.5630483830533969, 0.6442914515203672)
epsilon, acc, train acc, mia, report, train report
[528.3456061546365, 0.7536, 0.7846692294451776, 0.5730031491554538, '              precision    recall  f1-score   support\n\n         0.0       0.61      0.38      0.47       502\n         1.0       0.57      0.34      0.43       502\n         2.0       0.42      0.15      0.22       508\n         3.0       0.15      0.01      0.02       492\n         4.0       0.37      0.18      0.25       499\n         5.0       0.65      0.81      0.72      2992\n         6.0       0.81      0.86      0.83      3082\n         7.0       0.79      0.79      0.79      2973\n         8.0       0.83      0.89      0.86      3007\n         9.0       0.80      0.88      0.84      2943\n\n    accuracy                           0.75     17500\n   macro avg       0.60      0.53      0.54     17500\nweighted avg       0.72      0.75      0.73     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.69      0.41      0.51       457\n         1.0       0.68      0.45      0.54       480\n         2.0       0.49      0.18      0.26       456\n         3.0       0.50      0.05      0.09       504\n         4.0       0.55      0.25      0.34       491\n         5.0       0.69      0.84      0.76      3086\n         6.0       0.82      0.88      0.85      2943\n         7.0       0.82      0.83      0.82      3037\n         8.0       0.83      0.91      0.87      2962\n         9.0       0.84      0.88      0.86      3013\n\n    accuracy                           0.78     17429\n   macro avg       0.69      0.57      0.59     17429\nweighted avg       0.77      0.78      0.76     17429\n']
experiment_number: 116
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-116.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.3, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[7. 7. 6. ... 7. 0. 4.]
[8. 8. 4. ... 5. 5. 9.]
(17725, 3, 32, 32)
(17500, 3, 32, 32)
(17725, 3, 32, 32)
(17725,)
	Train Epoch: 1 	Loss: 2.303642 Acc@1: 0.177680 (ε = 15.92, δ = 1e-05) for α = 2.2
	Train Epoch: 1 	Loss: 2.217028 Acc@1: 0.171528 (ε = 31.59, δ = 1e-05) for α = 1.5
	Train Epoch: 1 	Loss: 2.127905 Acc@1: 0.194955 (ε = 38.67, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.911789 Acc@1: 0.333323 
	Train Epoch: 2 	Loss: 1.902386 Acc@1: 0.308802 (ε = 41.02, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 1.821775 Acc@1: 0.342078 (ε = 45.73, δ = 1e-05) for α = 1.4
	Train Epoch: 2 	Loss: 1.795675 Acc@1: 0.368827 (ε = 50.43, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.729211 Acc@1: 0.414631 
	Train Epoch: 3 	Loss: 1.619908 Acc@1: 0.465940 (ε = 52.79, δ = 1e-05) for α = 1.4
	Train Epoch: 3 	Loss: 1.652066 Acc@1: 0.431561 (ε = 56.32, δ = 1e-05) for α = 1.3
	Train Epoch: 3 	Loss: 1.641350 Acc@1: 0.440190 (ε = 59.26, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.586908 Acc@1: 0.475524 
	Train Epoch: 4 	Loss: 1.584553 Acc@1: 0.474198 (ε = 60.73, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 1.569273 Acc@1: 0.492714 (ε = 63.67, δ = 1e-05) for α = 1.3
	Train Epoch: 4 	Loss: 1.539848 Acc@1: 0.500529 (ε = 66.61, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.457241 Acc@1: 0.533497 
	Train Epoch: 5 	Loss: 1.383068 Acc@1: 0.549275 (ε = 68.08, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 1.471054 Acc@1: 0.529825 (ε = 71.02, δ = 1e-05) for α = 1.3
	Train Epoch: 5 	Loss: 1.483227 Acc@1: 0.530948 (ε = 73.96, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.390481 Acc@1: 0.559022 
	Train Epoch: 6 	Loss: 1.371547 Acc@1: 0.539007 (ε = 75.43, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 1.410332 Acc@1: 0.549102 (ε = 78.37, δ = 1e-05) for α = 1.3
	Train Epoch: 6 	Loss: 1.377406 Acc@1: 0.560059 (ε = 81.31, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.362664 Acc@1: 0.575240 
	Train Epoch: 7 	Loss: 1.284272 Acc@1: 0.604827 (ε = 82.78, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 1.325820 Acc@1: 0.587277 (ε = 85.73, δ = 1e-05) for α = 1.3
	Train Epoch: 7 	Loss: 1.328627 Acc@1: 0.588146 (ε = 88.67, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.245829 Acc@1: 0.605080 
	Train Epoch: 8 	Loss: 1.203720 Acc@1: 0.609195 (ε = 90.14, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 1.228408 Acc@1: 0.614436 (ε = 93.08, δ = 1e-05) for α = 1.3
	Train Epoch: 8 	Loss: 1.236344 Acc@1: 0.614380 (ε = 95.27, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.276226 Acc@1: 0.617158 
	Train Epoch: 9 	Loss: 1.220872 Acc@1: 0.626539 (ε = 96.23, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.273705 Acc@1: 0.621293 (ε = 98.15, δ = 1e-05) for α = 1.2
	Train Epoch: 9 	Loss: 1.257170 Acc@1: 0.621684 (ε = 100.07, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.292651 Acc@1: 0.615447 
	Train Epoch: 10 	Loss: 1.250794 Acc@1: 0.605375 (ε = 101.04, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.229301 Acc@1: 0.622235 (ε = 102.96, δ = 1e-05) for α = 1.2
	Train Epoch: 10 	Loss: 1.242203 Acc@1: 0.619176 (ε = 104.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.166747 Acc@1: 0.645472 
	Train Epoch: 11 	Loss: 1.242704 Acc@1: 0.645495 (ε = 105.85, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.232198 Acc@1: 0.630882 (ε = 107.77, δ = 1e-05) for α = 1.2
	Train Epoch: 11 	Loss: 1.228396 Acc@1: 0.629047 (ε = 109.69, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.173730 Acc@1: 0.647473 
	Train Epoch: 12 	Loss: 1.100034 Acc@1: 0.672805 (ε = 110.65, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.197368 Acc@1: 0.637899 (ε = 112.58, δ = 1e-05) for α = 1.2
	Train Epoch: 12 	Loss: 1.219413 Acc@1: 0.630781 (ε = 114.50, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.074086 Acc@1: 0.661256 
	Train Epoch: 13 	Loss: 1.089398 Acc@1: 0.653005 (ε = 115.46, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.114621 Acc@1: 0.655194 (ε = 117.39, δ = 1e-05) for α = 1.2
	Train Epoch: 13 	Loss: 1.119848 Acc@1: 0.658915 (ε = 119.31, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.137790 Acc@1: 0.662381 
	Train Epoch: 14 	Loss: 1.065553 Acc@1: 0.681429 (ε = 120.27, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.131225 Acc@1: 0.665796 (ε = 122.20, δ = 1e-05) for α = 1.2
	Train Epoch: 14 	Loss: 1.131540 Acc@1: 0.663612 (ε = 124.12, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.218058 Acc@1: 0.654182 
	Train Epoch: 15 	Loss: 1.213727 Acc@1: 0.648609 (ε = 125.08, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.099686 Acc@1: 0.676943 (ε = 127.00, δ = 1e-05) for α = 1.2
	Train Epoch: 15 	Loss: 1.095027 Acc@1: 0.676555 (ε = 128.93, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.105283 Acc@1: 0.679774 
	Train Epoch: 16 	Loss: 0.918156 Acc@1: 0.728022 (ε = 129.89, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.154274 Acc@1: 0.661818 (ε = 131.81, δ = 1e-05) for α = 1.2
	Train Epoch: 16 	Loss: 1.128406 Acc@1: 0.662520 (ε = 133.74, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.068391 Acc@1: 0.677302 
	Train Epoch: 17 	Loss: 0.940905 Acc@1: 0.712310 (ε = 134.70, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.062313 Acc@1: 0.684477 (ε = 136.62, δ = 1e-05) for α = 1.2
	Train Epoch: 17 	Loss: 1.075085 Acc@1: 0.679032 (ε = 138.55, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.136345 Acc@1: 0.671489 
	Train Epoch: 18 	Loss: 1.103435 Acc@1: 0.660606 (ε = 139.51, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.051404 Acc@1: 0.689116 (ε = 141.43, δ = 1e-05) for α = 1.2
	Train Epoch: 18 	Loss: 1.072028 Acc@1: 0.683225 (ε = 143.35, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.082851 Acc@1: 0.683793 
	Train Epoch: 19 	Loss: 0.981053 Acc@1: 0.709169 (ε = 144.32, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.029348 Acc@1: 0.692038 (ε = 146.24, δ = 1e-05) for α = 1.2
	Train Epoch: 19 	Loss: 1.038640 Acc@1: 0.692030 (ε = 148.16, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.113133 Acc@1: 0.680364 
	Train Epoch: 20 	Loss: 1.060396 Acc@1: 0.688293 (ε = 149.12, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.018953 Acc@1: 0.700910 (ε = 151.05, δ = 1e-05) for α = 1.2
	Train Epoch: 20 	Loss: 1.014055 Acc@1: 0.703165 (ε = 152.97, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.092103 Acc@1: 0.676554 
	Train Epoch: 21 	Loss: 0.957436 Acc@1: 0.714286 (ε = 153.93, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 1.038523 Acc@1: 0.699956 (ε = 155.86, δ = 1e-05) for α = 1.2
	Train Epoch: 21 	Loss: 0.998492 Acc@1: 0.705730 (ε = 157.78, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.047757 Acc@1: 0.702091 
	Train Epoch: 22 	Loss: 0.999089 Acc@1: 0.700573 (ε = 158.74, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 0.956814 Acc@1: 0.725113 (ε = 160.67, δ = 1e-05) for α = 1.2
	Train Epoch: 22 	Loss: 0.960770 Acc@1: 0.718775 (ε = 162.59, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.014254 Acc@1: 0.715011 
	Train Epoch: 23 	Loss: 0.865626 Acc@1: 0.731105 (ε = 163.55, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 0.979562 Acc@1: 0.716522 (ε = 165.47, δ = 1e-05) for α = 1.2
	Train Epoch: 23 	Loss: 0.979732 Acc@1: 0.721460 (ε = 167.40, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.009360 Acc@1: 0.711609 
	Train Epoch: 24 	Loss: 0.916067 Acc@1: 0.730942 (ε = 168.36, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 0.972620 Acc@1: 0.724873 (ε = 170.28, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 0.939465 Acc@1: 0.731321 (ε = 172.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.004837 Acc@1: 0.721662 
	Train Epoch: 25 	Loss: 0.901096 Acc@1: 0.735931 (ε = 173.17, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 0.971469 Acc@1: 0.726241 (ε = 175.09, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 0.960919 Acc@1: 0.726899 (ε = 177.02, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.975206 Acc@1: 0.724057 
	Train Epoch: 26 	Loss: 0.869077 Acc@1: 0.751397 (ε = 177.98, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 0.892891 Acc@1: 0.739845 (ε = 179.90, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 0.910657 Acc@1: 0.736078 (ε = 181.82, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.954732 Acc@1: 0.731055 
	Train Epoch: 27 	Loss: 0.856209 Acc@1: 0.753846 (ε = 182.79, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 0.899624 Acc@1: 0.740206 (ε = 184.71, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 0.901404 Acc@1: 0.743245 (ε = 186.63, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.023026 Acc@1: 0.724857 
	Train Epoch: 28 	Loss: 0.978753 Acc@1: 0.734286 (ε = 187.60, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 0.981734 Acc@1: 0.726286 (ε = 189.52, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 0.953564 Acc@1: 0.729032 (ε = 191.44, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.967584 Acc@1: 0.729285 
	Train Epoch: 29 	Loss: 0.868459 Acc@1: 0.756267 (ε = 192.40, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 0.900038 Acc@1: 0.745727 (ε = 194.33, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 0.889756 Acc@1: 0.748653 (ε = 196.25, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.015634 Acc@1: 0.729839 
	Train Epoch: 30 	Loss: 0.840612 Acc@1: 0.776099 (ε = 197.21, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 0.900885 Acc@1: 0.750409 (ε = 199.14, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 0.889674 Acc@1: 0.750865 (ε = 201.06, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.001814 Acc@1: 0.731475 
	Train Epoch: 31 	Loss: 0.899027 Acc@1: 0.767705 (ε = 202.02, δ = 1e-05) for α = 1.2
	Train Epoch: 31 	Loss: 0.924853 Acc@1: 0.748370 (ε = 203.95, δ = 1e-05) for α = 1.2
	Train Epoch: 31 	Loss: 0.912304 Acc@1: 0.748740 (ε = 205.87, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.954046 Acc@1: 0.736745 
	Train Epoch: 32 	Loss: 0.776526 Acc@1: 0.772277 (ε = 206.83, δ = 1e-05) for α = 1.2
	Train Epoch: 32 	Loss: 0.849765 Acc@1: 0.757033 (ε = 208.75, δ = 1e-05) for α = 1.2
	Train Epoch: 32 	Loss: 0.852750 Acc@1: 0.758732 (ε = 210.68, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.961043 Acc@1: 0.740583 
	Train Epoch: 33 	Loss: 0.969148 Acc@1: 0.719599 (ε = 211.64, δ = 1e-05) for α = 1.2
	Train Epoch: 33 	Loss: 0.862663 Acc@1: 0.753636 (ε = 213.56, δ = 1e-05) for α = 1.2
	Train Epoch: 33 	Loss: 0.863476 Acc@1: 0.754158 (ε = 215.49, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.969469 Acc@1: 0.737865 
	Train Epoch: 34 	Loss: 0.899474 Acc@1: 0.757440 (ε = 216.45, δ = 1e-05) for α = 1.2
	Train Epoch: 34 	Loss: 0.832333 Acc@1: 0.765422 (ε = 218.37, δ = 1e-05) for α = 1.2
	Train Epoch: 34 	Loss: 0.844138 Acc@1: 0.761540 (ε = 220.30, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.952186 Acc@1: 0.738636 
	Train Epoch: 35 	Loss: 0.935525 Acc@1: 0.727642 (ε = 221.26, δ = 1e-05) for α = 1.2
	Train Epoch: 35 	Loss: 0.846300 Acc@1: 0.767477 (ε = 223.18, δ = 1e-05) for α = 1.2
	Train Epoch: 35 	Loss: 0.846955 Acc@1: 0.767945 (ε = 225.10, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.958888 Acc@1: 0.740829 
	Train Epoch: 36 	Loss: 0.778029 Acc@1: 0.768012 (ε = 226.07, δ = 1e-05) for α = 1.2
	Train Epoch: 36 	Loss: 0.846598 Acc@1: 0.767068 (ε = 227.99, δ = 1e-05) for α = 1.2
	Train Epoch: 36 	Loss: 0.847624 Acc@1: 0.767591 (ε = 229.91, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.946901 Acc@1: 0.746635 
	Train Epoch: 37 	Loss: 0.765322 Acc@1: 0.774336 (ε = 230.87, δ = 1e-05) for α = 1.2
	Train Epoch: 37 	Loss: 0.843239 Acc@1: 0.761485 (ε = 232.80, δ = 1e-05) for α = 1.2
	Train Epoch: 37 	Loss: 0.816375 Acc@1: 0.769307 (ε = 234.72, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.954950 Acc@1: 0.748339 
	Train Epoch: 38 	Loss: 0.934286 Acc@1: 0.758410 (ε = 235.68, δ = 1e-05) for α = 1.2
	Train Epoch: 38 	Loss: 0.867630 Acc@1: 0.765750 (ε = 237.61, δ = 1e-05) for α = 1.2
	Train Epoch: 38 	Loss: 0.838225 Acc@1: 0.771752 (ε = 239.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.930591 Acc@1: 0.747664 
	Train Epoch: 39 	Loss: 0.923139 Acc@1: 0.750365 (ε = 240.14, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.840205 Acc@1: 0.764805 (ε = 241.45, δ = 1e-05) for α = 1.1
	Train Epoch: 39 	Loss: 0.836100 Acc@1: 0.766979 (ε = 242.77, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.967118 Acc@1: 0.751807 
	Train Epoch: 40 	Loss: 0.807112 Acc@1: 0.780822 (ε = 243.42, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.828562 Acc@1: 0.771538 (ε = 244.74, δ = 1e-05) for α = 1.1
	Train Epoch: 40 	Loss: 0.838589 Acc@1: 0.769153 (ε = 246.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.909978 Acc@1: 0.752612 
	Train Epoch: 41 	Loss: 0.838991 Acc@1: 0.772134 (ε = 246.71, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.799760 Acc@1: 0.782774 (ε = 248.02, δ = 1e-05) for α = 1.1
	Train Epoch: 41 	Loss: 0.817023 Acc@1: 0.776755 (ε = 249.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.944189 Acc@1: 0.753328 
	Train Epoch: 42 	Loss: 0.708359 Acc@1: 0.800310 (ε = 249.99, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.806346 Acc@1: 0.785267 (ε = 251.31, δ = 1e-05) for α = 1.1
	Train Epoch: 42 	Loss: 0.834064 Acc@1: 0.780733 (ε = 252.62, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.929853 Acc@1: 0.751499 
	Train Epoch: 43 	Loss: 0.830644 Acc@1: 0.766476 (ε = 253.28, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.817633 Acc@1: 0.777523 (ε = 254.60, δ = 1e-05) for α = 1.1
	Train Epoch: 43 	Loss: 0.812105 Acc@1: 0.779971 (ε = 255.91, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.940300 Acc@1: 0.755713 
	Train Epoch: 44 	Loss: 0.738627 Acc@1: 0.795918 (ε = 256.57, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.808789 Acc@1: 0.781231 (ε = 257.88, δ = 1e-05) for α = 1.1
	Train Epoch: 44 	Loss: 0.816910 Acc@1: 0.779485 (ε = 259.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.957220 Acc@1: 0.752471 
	Train Epoch: 45 	Loss: 0.819451 Acc@1: 0.761905 (ε = 259.85, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.796381 Acc@1: 0.779103 (ε = 261.17, δ = 1e-05) for α = 1.1
	Train Epoch: 45 	Loss: 0.818098 Acc@1: 0.779544 (ε = 262.48, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.947907 Acc@1: 0.752668 
	Train Epoch: 46 	Loss: 0.826463 Acc@1: 0.758953 (ε = 263.14, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.799351 Acc@1: 0.783061 (ε = 264.45, δ = 1e-05) for α = 1.1
	Train Epoch: 46 	Loss: 0.790084 Acc@1: 0.785185 (ε = 265.77, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.937091 Acc@1: 0.755925 
	Train Epoch: 47 	Loss: 0.860841 Acc@1: 0.742105 (ε = 266.43, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.798494 Acc@1: 0.774929 (ε = 267.74, δ = 1e-05) for α = 1.1
	Train Epoch: 47 	Loss: 0.793954 Acc@1: 0.779144 (ε = 269.05, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.951120 Acc@1: 0.753005 
	Train Epoch: 48 	Loss: 0.696581 Acc@1: 0.802276 (ε = 269.71, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.806098 Acc@1: 0.782410 (ε = 271.03, δ = 1e-05) for α = 1.1
	Train Epoch: 48 	Loss: 0.799369 Acc@1: 0.783136 (ε = 272.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.931613 Acc@1: 0.758241 
	Train Epoch: 49 	Loss: 0.747914 Acc@1: 0.806167 (ε = 273.00, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.750550 Acc@1: 0.790164 (ε = 274.31, δ = 1e-05) for α = 1.1
	Train Epoch: 49 	Loss: 0.770271 Acc@1: 0.789709 (ε = 275.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.947744 Acc@1: 0.757505 
	Train Epoch: 50 	Loss: 0.816377 Acc@1: 0.800000 (ε = 276.28, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.812762 Acc@1: 0.776241 (ε = 277.60, δ = 1e-05) for α = 1.1
	Train Epoch: 50 	Loss: 0.816996 Acc@1: 0.776602 (ε = 278.91, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.921006 Acc@1: 0.759279 
	Train Epoch: 51 	Loss: 0.706640 Acc@1: 0.800570 (ε = 279.57, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.751764 Acc@1: 0.791566 (ε = 280.89, δ = 1e-05) for α = 1.1
	Train Epoch: 51 	Loss: 0.769942 Acc@1: 0.784972 (ε = 282.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.922235 Acc@1: 0.757776 
	Train Epoch: 52 	Loss: 0.828790 Acc@1: 0.778102 (ε = 282.86, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.782594 Acc@1: 0.782712 (ε = 284.17, δ = 1e-05) for α = 1.1
	Train Epoch: 52 	Loss: 0.789835 Acc@1: 0.784080 (ε = 285.49, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925862 Acc@1: 0.760796 
	Train Epoch: 53 	Loss: 0.840606 Acc@1: 0.775964 (ε = 286.14, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.801732 Acc@1: 0.786352 (ε = 287.46, δ = 1e-05) for α = 1.1
	Train Epoch: 53 	Loss: 0.785228 Acc@1: 0.788736 (ε = 288.77, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.936506 Acc@1: 0.757227 
	Train Epoch: 54 	Loss: 0.712513 Acc@1: 0.788690 (ε = 289.43, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.803144 Acc@1: 0.784059 (ε = 290.74, δ = 1e-05) for α = 1.1
	Train Epoch: 54 	Loss: 0.812827 Acc@1: 0.780689 (ε = 292.06, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.925203 Acc@1: 0.760141 
	Train Epoch: 55 	Loss: 0.827416 Acc@1: 0.786517 (ε = 292.72, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.794634 Acc@1: 0.788385 (ε = 294.03, δ = 1e-05) for α = 1.1
	Train Epoch: 55 	Loss: 0.799970 Acc@1: 0.785039 (ε = 295.34, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.934658 Acc@1: 0.759100 
	Train Epoch: 56 	Loss: 0.664590 Acc@1: 0.816643 (ε = 296.00, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.793425 Acc@1: 0.784228 (ε = 297.32, δ = 1e-05) for α = 1.1
	Train Epoch: 56 	Loss: 0.786392 Acc@1: 0.788917 (ε = 298.63, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.930746 Acc@1: 0.759139 
	Train Epoch: 57 	Loss: 0.720079 Acc@1: 0.802436 (ε = 299.29, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.779460 Acc@1: 0.789346 (ε = 300.60, δ = 1e-05) for α = 1.1
	Train Epoch: 57 	Loss: 0.789699 Acc@1: 0.787966 (ε = 301.92, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.923422 Acc@1: 0.760299 
	Train Epoch: 58 	Loss: 0.812796 Acc@1: 0.777126 (ε = 302.57, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.774031 Acc@1: 0.784111 (ε = 303.89, δ = 1e-05) for α = 1.1
	Train Epoch: 58 	Loss: 0.771220 Acc@1: 0.786394 (ε = 305.20, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.922576 Acc@1: 0.760461 
	Train Epoch: 59 	Loss: 0.764004 Acc@1: 0.793605 (ε = 305.86, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.799449 Acc@1: 0.781032 (ε = 307.17, δ = 1e-05) for α = 1.1
	Train Epoch: 59 	Loss: 0.782008 Acc@1: 0.784527 (ε = 308.49, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.921769 Acc@1: 0.760355 
	Train Epoch: 60 	Loss: 0.800346 Acc@1: 0.781843 (ε = 309.15, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.777033 Acc@1: 0.786908 (ε = 310.46, δ = 1e-05) for α = 1.1
	Train Epoch: 60 	Loss: 0.770715 Acc@1: 0.791766 (ε = 311.78, δ = 1e-05) for α = 1.1
	Test set:Loss: 0.923430 Acc@1: 0.759479 
test results
Base private model accuracy:  0.7597714285714285
              precision    recall  f1-score   support

         0.0       0.59      0.38      0.46       502
         1.0       0.59      0.37      0.45       502
         2.0       0.41      0.17      0.24       508
         3.0       0.20      0.02      0.04       492
         4.0       0.42      0.22      0.29       499
         5.0       0.66      0.80      0.73      2992
         6.0       0.81      0.87      0.84      3082
         7.0       0.79      0.80      0.79      2973
         8.0       0.83      0.89      0.86      3007
         9.0       0.81      0.88      0.84      2943

    accuracy                           0.76     17500
   macro avg       0.61      0.54      0.55     17500
weighted avg       0.73      0.76      0.74     17500

train results
Base private model accuracy:  0.7869675599435825
              precision    recall  f1-score   support

         0.0       0.66      0.41      0.51       526
         1.0       0.72      0.47      0.57       496
         2.0       0.52      0.24      0.33       518
         3.0       0.36      0.04      0.07       513
         4.0       0.59      0.31      0.41       489
         5.0       0.69      0.84      0.76      3022
         6.0       0.82      0.89      0.86      2934
         7.0       0.81      0.82      0.82      3051
         8.0       0.84      0.91      0.87      2996
         9.0       0.84      0.89      0.86      3180

    accuracy                           0.79     17725
   macro avg       0.69      0.58      0.61     17725
weighted avg       0.77      0.79      0.77     17725

NN model attack results: 
train acc: 0.5342736248236953
test acc: 0.6591428571428571
total acc: 0.5963094393186658
precision, recall: (0.6135406543569809, 0.5342736248236953)
epsilon, acc, train acc, mia, report, train report
[312.3012072813382, 0.7597714285714285, 0.7869675599435825, 0.5963094393186658, '              precision    recall  f1-score   support\n\n         0.0       0.59      0.38      0.46       502\n         1.0       0.59      0.37      0.45       502\n         2.0       0.41      0.17      0.24       508\n         3.0       0.20      0.02      0.04       492\n         4.0       0.42      0.22      0.29       499\n         5.0       0.66      0.80      0.73      2992\n         6.0       0.81      0.87      0.84      3082\n         7.0       0.79      0.80      0.79      2973\n         8.0       0.83      0.89      0.86      3007\n         9.0       0.81      0.88      0.84      2943\n\n    accuracy                           0.76     17500\n   macro avg       0.61      0.54      0.55     17500\nweighted avg       0.73      0.76      0.74     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.66      0.41      0.51       526\n         1.0       0.72      0.47      0.57       496\n         2.0       0.52      0.24      0.33       518\n         3.0       0.36      0.04      0.07       513\n         4.0       0.59      0.31      0.41       489\n         5.0       0.69      0.84      0.76      3022\n         6.0       0.82      0.89      0.86      2934\n         7.0       0.81      0.82      0.82      3051\n         8.0       0.84      0.91      0.87      2996\n         9.0       0.84      0.89      0.86      3180\n\n    accuracy                           0.79     17725\n   macro avg       0.69      0.58      0.61     17725\nweighted avg       0.77      0.79      0.77     17725\n']
experiment_number: 117
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-117.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.35, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[9. 8. 7. ... 6. 1. 4.]
[9. 5. 9. ... 9. 9. 9.]
(17425, 3, 32, 32)
(17500, 3, 32, 32)
(17425, 3, 32, 32)
(17425,)
	Train Epoch: 1 	Loss: 2.306099 Acc@1: 0.031930 (ε = 12.50, δ = 1e-05) for α = 2.4
	Train Epoch: 1 	Loss: 2.190876 Acc@1: 0.177088 (ε = 22.96, δ = 1e-05) for α = 1.7
	Train Epoch: 1 	Loss: 2.110017 Acc@1: 0.201815 (ε = 27.31, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.885005 Acc@1: 0.325083 
	Train Epoch: 2 	Loss: 1.902734 Acc@1: 0.310595 (ε = 29.25, δ = 1e-05) for α = 1.6
	Train Epoch: 2 	Loss: 1.816407 Acc@1: 0.364869 (ε = 32.33, δ = 1e-05) for α = 1.5
	Train Epoch: 2 	Loss: 1.794344 Acc@1: 0.381606 (ε = 34.91, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.686620 Acc@1: 0.420590 
	Train Epoch: 3 	Loss: 1.721585 Acc@1: 0.435786 (ε = 36.21, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 1.646460 Acc@1: 0.443931 (ε = 38.79, δ = 1e-05) for α = 1.5
	Train Epoch: 3 	Loss: 1.618094 Acc@1: 0.451490 (ε = 41.37, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.559261 Acc@1: 0.485473 
	Train Epoch: 4 	Loss: 1.572461 Acc@1: 0.484627 (ε = 42.32, δ = 1e-05) for α = 1.4
	Train Epoch: 4 	Loss: 1.561288 Acc@1: 0.485650 (ε = 44.10, δ = 1e-05) for α = 1.4
	Train Epoch: 4 	Loss: 1.537799 Acc@1: 0.495047 (ε = 45.89, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.471981 Acc@1: 0.529000 
	Train Epoch: 5 	Loss: 1.460047 Acc@1: 0.513274 (ε = 46.78, δ = 1e-05) for α = 1.4
	Train Epoch: 5 	Loss: 1.445287 Acc@1: 0.543215 (ε = 48.56, δ = 1e-05) for α = 1.4
	Train Epoch: 5 	Loss: 1.465933 Acc@1: 0.547665 (ε = 50.34, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.405707 Acc@1: 0.543788 
	Train Epoch: 6 	Loss: 1.341608 Acc@1: 0.557664 (ε = 51.23, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.400704 Acc@1: 0.551900 (ε = 53.01, δ = 1e-05) for α = 1.4
	Train Epoch: 6 	Loss: 1.374582 Acc@1: 0.560074 (ε = 54.79, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.398971 Acc@1: 0.573618 
	Train Epoch: 7 	Loss: 1.293922 Acc@1: 0.592972 (ε = 55.68, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.351381 Acc@1: 0.584032 (ε = 57.47, δ = 1e-05) for α = 1.4
	Train Epoch: 7 	Loss: 1.324736 Acc@1: 0.585612 (ε = 59.25, δ = 1e-05) for α = 1.4
	Test set:Loss: 1.235295 Acc@1: 0.610970 
	Train Epoch: 8 	Loss: 1.237118 Acc@1: 0.627072 (ε = 60.14, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.282296 Acc@1: 0.609530 (ε = 61.92, δ = 1e-05) for α = 1.4
	Train Epoch: 8 	Loss: 1.275951 Acc@1: 0.607877 (ε = 63.25, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.205235 Acc@1: 0.627848 
	Train Epoch: 9 	Loss: 1.293530 Acc@1: 0.609649 (ε = 63.88, δ = 1e-05) for α = 1.3
	Train Epoch: 9 	Loss: 1.245067 Acc@1: 0.619634 (ε = 65.15, δ = 1e-05) for α = 1.3
	Train Epoch: 9 	Loss: 1.229504 Acc@1: 0.626025 (ε = 66.42, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.185221 Acc@1: 0.642050 
	Train Epoch: 10 	Loss: 1.268515 Acc@1: 0.609262 (ε = 67.06, δ = 1e-05) for α = 1.3
	Train Epoch: 10 	Loss: 1.244603 Acc@1: 0.625130 (ε = 68.32, δ = 1e-05) for α = 1.3
	Train Epoch: 10 	Loss: 1.229371 Acc@1: 0.626941 (ε = 69.59, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.174545 Acc@1: 0.647879 
	Train Epoch: 11 	Loss: 1.164324 Acc@1: 0.628959 (ε = 70.23, δ = 1e-05) for α = 1.3
	Train Epoch: 11 	Loss: 1.150439 Acc@1: 0.643921 (ε = 71.50, δ = 1e-05) for α = 1.3
	Train Epoch: 11 	Loss: 1.178617 Acc@1: 0.642252 (ε = 72.77, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.248872 Acc@1: 0.642611 
	Train Epoch: 12 	Loss: 1.353583 Acc@1: 0.621898 (ε = 73.40, δ = 1e-05) for α = 1.3
	Train Epoch: 12 	Loss: 1.227193 Acc@1: 0.635416 (ε = 74.67, δ = 1e-05) for α = 1.3
	Train Epoch: 12 	Loss: 1.205421 Acc@1: 0.639695 (ε = 75.94, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.136783 Acc@1: 0.659487 
	Train Epoch: 13 	Loss: 1.098692 Acc@1: 0.673913 (ε = 76.57, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.179121 Acc@1: 0.657824 (ε = 77.84, δ = 1e-05) for α = 1.3
	Train Epoch: 13 	Loss: 1.161834 Acc@1: 0.656568 (ε = 79.11, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.081473 Acc@1: 0.672680 
	Train Epoch: 14 	Loss: 1.274249 Acc@1: 0.637348 (ε = 79.75, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.163871 Acc@1: 0.650850 (ε = 81.01, δ = 1e-05) for α = 1.3
	Train Epoch: 14 	Loss: 1.138157 Acc@1: 0.659140 (ε = 82.28, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.189095 Acc@1: 0.652976 
	Train Epoch: 15 	Loss: 1.212862 Acc@1: 0.648607 (ε = 82.92, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.101698 Acc@1: 0.669423 (ε = 84.19, δ = 1e-05) for α = 1.3
	Train Epoch: 15 	Loss: 1.096609 Acc@1: 0.673812 (ε = 85.46, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.129493 Acc@1: 0.680672 
	Train Epoch: 16 	Loss: 1.079669 Acc@1: 0.690377 (ε = 86.09, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.050406 Acc@1: 0.686872 (ε = 87.36, δ = 1e-05) for α = 1.3
	Train Epoch: 16 	Loss: 1.065651 Acc@1: 0.683720 (ε = 88.63, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.269315 Acc@1: 0.649215 
	Train Epoch: 17 	Loss: 1.196173 Acc@1: 0.657632 (ε = 89.26, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.116319 Acc@1: 0.673143 (ε = 90.53, δ = 1e-05) for α = 1.3
	Train Epoch: 17 	Loss: 1.093637 Acc@1: 0.678613 (ε = 91.80, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.060316 Acc@1: 0.687857 
	Train Epoch: 18 	Loss: 1.052869 Acc@1: 0.673212 (ε = 92.44, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.024141 Acc@1: 0.697902 (ε = 93.70, δ = 1e-05) for α = 1.3
	Train Epoch: 18 	Loss: 1.023548 Acc@1: 0.701987 (ε = 94.97, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.108317 Acc@1: 0.694567 
	Train Epoch: 19 	Loss: 1.069074 Acc@1: 0.717877 (ε = 95.61, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.044428 Acc@1: 0.708731 (ε = 96.88, δ = 1e-05) for α = 1.3
	Train Epoch: 19 	Loss: 1.033094 Acc@1: 0.713071 (ε = 98.15, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.060364 Acc@1: 0.696098 
	Train Epoch: 20 	Loss: 0.895995 Acc@1: 0.720301 (ε = 98.78, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 0.978427 Acc@1: 0.720265 (ε = 100.05, δ = 1e-05) for α = 1.3
	Train Epoch: 20 	Loss: 1.003650 Acc@1: 0.712360 (ε = 101.32, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.041749 Acc@1: 0.709842 
	Train Epoch: 21 	Loss: 0.928576 Acc@1: 0.745324 (ε = 101.95, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.024116 Acc@1: 0.712409 (ε = 103.22, δ = 1e-05) for α = 1.3
	Train Epoch: 21 	Loss: 1.040370 Acc@1: 0.712103 (ε = 104.49, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.106218 Acc@1: 0.692996 
	Train Epoch: 22 	Loss: 1.022740 Acc@1: 0.717546 (ε = 105.12, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 0.985781 Acc@1: 0.718437 (ε = 106.39, δ = 1e-05) for α = 1.3
	Train Epoch: 22 	Loss: 0.994630 Acc@1: 0.716776 (ε = 107.66, δ = 1e-05) for α = 1.3
	Test set:Loss: 1.069608 Acc@1: 0.700331 
	Train Epoch: 23 	Loss: 1.014864 Acc@1: 0.683284 (ε = 108.30, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 0.957602 Acc@1: 0.722392 (ε = 109.57, δ = 1e-05) for α = 1.3
	Train Epoch: 23 	Loss: 0.947181 Acc@1: 0.724500 (ε = 110.69, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.011130 Acc@1: 0.715444 
	Train Epoch: 24 	Loss: 0.907564 Acc@1: 0.733038 (ε = 111.15, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 0.981560 Acc@1: 0.729717 (ε = 112.09, δ = 1e-05) for α = 1.2
	Train Epoch: 24 	Loss: 0.977629 Acc@1: 0.727148 (ε = 113.02, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.061226 Acc@1: 0.712552 
	Train Epoch: 25 	Loss: 1.031726 Acc@1: 0.722144 (ε = 113.48, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 0.984248 Acc@1: 0.723320 (ε = 114.41, δ = 1e-05) for α = 1.2
	Train Epoch: 25 	Loss: 0.972141 Acc@1: 0.728006 (ε = 115.34, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.999296 Acc@1: 0.714445 
	Train Epoch: 26 	Loss: 0.932219 Acc@1: 0.729771 (ε = 115.81, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 0.928648 Acc@1: 0.739203 (ε = 116.74, δ = 1e-05) for α = 1.2
	Train Epoch: 26 	Loss: 0.940380 Acc@1: 0.733270 (ε = 117.67, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.988888 Acc@1: 0.724204 
	Train Epoch: 27 	Loss: 1.007473 Acc@1: 0.714499 (ε = 118.13, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 0.972040 Acc@1: 0.727141 (ε = 119.06, δ = 1e-05) for α = 1.2
	Train Epoch: 27 	Loss: 0.959386 Acc@1: 0.730656 (ε = 119.99, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.102691 Acc@1: 0.719769 
	Train Epoch: 28 	Loss: 1.008638 Acc@1: 0.739884 (ε = 120.46, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 0.929168 Acc@1: 0.741232 (ε = 121.39, δ = 1e-05) for α = 1.2
	Train Epoch: 28 	Loss: 0.914760 Acc@1: 0.742255 (ε = 122.32, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.997741 Acc@1: 0.734798 
	Train Epoch: 29 	Loss: 0.752455 Acc@1: 0.778231 (ε = 122.78, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 0.916629 Acc@1: 0.749768 (ε = 123.72, δ = 1e-05) for α = 1.2
	Train Epoch: 29 	Loss: 0.923968 Acc@1: 0.747515 (ε = 124.65, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.973783 Acc@1: 0.735665 
	Train Epoch: 30 	Loss: 0.904817 Acc@1: 0.752624 (ε = 125.11, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 0.858130 Acc@1: 0.756875 (ε = 126.04, δ = 1e-05) for α = 1.2
	Train Epoch: 30 	Loss: 0.888665 Acc@1: 0.748974 (ε = 126.97, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.965877 Acc@1: 0.739859 
	Train Epoch: 31 	Loss: 0.910487 Acc@1: 0.760522 (ε = 127.44, δ = 1e-05) for α = 1.2
	Train Epoch: 31 	Loss: 0.865286 Acc@1: 0.761026 (ε = 128.37, δ = 1e-05) for α = 1.2
	Train Epoch: 31 	Loss: 0.872745 Acc@1: 0.757636 (ε = 129.30, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.970775 Acc@1: 0.738042 
	Train Epoch: 32 	Loss: 0.884099 Acc@1: 0.758982 (ε = 129.76, δ = 1e-05) for α = 1.2
	Train Epoch: 32 	Loss: 0.910451 Acc@1: 0.758293 (ε = 130.69, δ = 1e-05) for α = 1.2
	Train Epoch: 32 	Loss: 0.889461 Acc@1: 0.759770 (ε = 131.62, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.974397 Acc@1: 0.740698 
	Train Epoch: 33 	Loss: 0.869743 Acc@1: 0.769912 (ε = 132.09, δ = 1e-05) for α = 1.2
	Train Epoch: 33 	Loss: 0.903708 Acc@1: 0.757978 (ε = 133.02, δ = 1e-05) for α = 1.2
	Train Epoch: 33 	Loss: 0.887541 Acc@1: 0.758073 (ε = 133.95, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.976824 Acc@1: 0.742631 
	Train Epoch: 34 	Loss: 0.889974 Acc@1: 0.754167 (ε = 134.41, δ = 1e-05) for α = 1.2
	Train Epoch: 34 	Loss: 0.870700 Acc@1: 0.762697 (ε = 135.34, δ = 1e-05) for α = 1.2
	Train Epoch: 34 	Loss: 0.868843 Acc@1: 0.759718 (ε = 136.28, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.953912 Acc@1: 0.742933 
	Train Epoch: 35 	Loss: 0.734189 Acc@1: 0.781560 (ε = 136.74, δ = 1e-05) for α = 1.2
	Train Epoch: 35 	Loss: 0.856589 Acc@1: 0.764247 (ε = 137.67, δ = 1e-05) for α = 1.2
	Train Epoch: 35 	Loss: 0.870367 Acc@1: 0.765569 (ε = 138.60, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.008914 Acc@1: 0.736883 
	Train Epoch: 36 	Loss: 0.803356 Acc@1: 0.768437 (ε = 139.07, δ = 1e-05) for α = 1.2
	Train Epoch: 36 	Loss: 0.846180 Acc@1: 0.770162 (ε = 140.00, δ = 1e-05) for α = 1.2
	Train Epoch: 36 	Loss: 0.864518 Acc@1: 0.768396 (ε = 140.93, δ = 1e-05) for α = 1.2
	Test set:Loss: 1.008624 Acc@1: 0.742426 
	Train Epoch: 37 	Loss: 0.798765 Acc@1: 0.796215 (ε = 141.39, δ = 1e-05) for α = 1.2
	Train Epoch: 37 	Loss: 0.839322 Acc@1: 0.776108 (ε = 142.32, δ = 1e-05) for α = 1.2
	Train Epoch: 37 	Loss: 0.836081 Acc@1: 0.774749 (ε = 143.25, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.983179 Acc@1: 0.746013 
	Train Epoch: 38 	Loss: 0.833557 Acc@1: 0.768895 (ε = 143.72, δ = 1e-05) for α = 1.2
	Train Epoch: 38 	Loss: 0.891457 Acc@1: 0.761857 (ε = 144.65, δ = 1e-05) for α = 1.2
	Train Epoch: 38 	Loss: 0.870213 Acc@1: 0.765222 (ε = 145.58, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.959056 Acc@1: 0.750842 
	Train Epoch: 39 	Loss: 0.824580 Acc@1: 0.784993 (ε = 146.04, δ = 1e-05) for α = 1.2
	Train Epoch: 39 	Loss: 0.851606 Acc@1: 0.770417 (ε = 146.97, δ = 1e-05) for α = 1.2
	Train Epoch: 39 	Loss: 0.829906 Acc@1: 0.774089 (ε = 147.91, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.945595 Acc@1: 0.749906 
	Train Epoch: 40 	Loss: 0.829269 Acc@1: 0.764531 (ε = 148.37, δ = 1e-05) for α = 1.2
	Train Epoch: 40 	Loss: 0.820473 Acc@1: 0.779802 (ε = 149.30, δ = 1e-05) for α = 1.2
	Train Epoch: 40 	Loss: 0.831881 Acc@1: 0.778432 (ε = 150.23, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.951823 Acc@1: 0.749892 
	Train Epoch: 41 	Loss: 0.845421 Acc@1: 0.767606 (ε = 150.70, δ = 1e-05) for α = 1.2
	Train Epoch: 41 	Loss: 0.820468 Acc@1: 0.777940 (ε = 151.63, δ = 1e-05) for α = 1.2
	Train Epoch: 41 	Loss: 0.834428 Acc@1: 0.776976 (ε = 152.56, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.955770 Acc@1: 0.753013 
	Train Epoch: 42 	Loss: 0.782267 Acc@1: 0.784431 (ε = 153.02, δ = 1e-05) for α = 1.2
	Train Epoch: 42 	Loss: 0.829860 Acc@1: 0.779588 (ε = 153.95, δ = 1e-05) for α = 1.2
	Train Epoch: 42 	Loss: 0.841087 Acc@1: 0.775972 (ε = 154.88, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.953241 Acc@1: 0.751917 
	Train Epoch: 43 	Loss: 0.868308 Acc@1: 0.758133 (ε = 155.35, δ = 1e-05) for α = 1.2
	Train Epoch: 43 	Loss: 0.826626 Acc@1: 0.779916 (ε = 156.28, δ = 1e-05) for α = 1.2
	Train Epoch: 43 	Loss: 0.823035 Acc@1: 0.781370 (ε = 157.21, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.937843 Acc@1: 0.752939 
	Train Epoch: 44 	Loss: 0.831985 Acc@1: 0.779610 (ε = 157.67, δ = 1e-05) for α = 1.2
	Train Epoch: 44 	Loss: 0.825322 Acc@1: 0.775295 (ε = 158.60, δ = 1e-05) for α = 1.2
	Train Epoch: 44 	Loss: 0.821267 Acc@1: 0.777352 (ε = 159.53, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.973380 Acc@1: 0.753114 
	Train Epoch: 45 	Loss: 0.817079 Acc@1: 0.791553 (ε = 160.00, δ = 1e-05) for α = 1.2
	Train Epoch: 45 	Loss: 0.806180 Acc@1: 0.786221 (ε = 160.93, δ = 1e-05) for α = 1.2
	Train Epoch: 45 	Loss: 0.816887 Acc@1: 0.783670 (ε = 161.86, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.945076 Acc@1: 0.755747 
	Train Epoch: 46 	Loss: 0.785654 Acc@1: 0.787519 (ε = 162.33, δ = 1e-05) for α = 1.2
	Train Epoch: 46 	Loss: 0.810560 Acc@1: 0.778547 (ε = 163.26, δ = 1e-05) for α = 1.2
	Train Epoch: 46 	Loss: 0.798261 Acc@1: 0.783205 (ε = 164.19, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.935609 Acc@1: 0.757310 
	Train Epoch: 47 	Loss: 0.777581 Acc@1: 0.793007 (ε = 164.65, δ = 1e-05) for α = 1.2
	Train Epoch: 47 	Loss: 0.783868 Acc@1: 0.788249 (ε = 165.58, δ = 1e-05) for α = 1.2
	Train Epoch: 47 	Loss: 0.778039 Acc@1: 0.791355 (ε = 166.51, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.937219 Acc@1: 0.757441 
	Train Epoch: 48 	Loss: 0.836601 Acc@1: 0.768012 (ε = 166.98, δ = 1e-05) for α = 1.2
	Train Epoch: 48 	Loss: 0.817734 Acc@1: 0.782984 (ε = 167.91, δ = 1e-05) for α = 1.2
	Train Epoch: 48 	Loss: 0.802917 Acc@1: 0.786661 (ε = 168.84, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.963233 Acc@1: 0.757020 
	Train Epoch: 49 	Loss: 0.770697 Acc@1: 0.788752 (ε = 169.30, δ = 1e-05) for α = 1.2
	Train Epoch: 49 	Loss: 0.825659 Acc@1: 0.785080 (ε = 170.23, δ = 1e-05) for α = 1.2
	Train Epoch: 49 	Loss: 0.820472 Acc@1: 0.784489 (ε = 171.16, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.930773 Acc@1: 0.757485 
	Train Epoch: 50 	Loss: 0.820828 Acc@1: 0.770563 (ε = 171.63, δ = 1e-05) for α = 1.2
	Train Epoch: 50 	Loss: 0.825299 Acc@1: 0.784730 (ε = 172.56, δ = 1e-05) for α = 1.2
	Train Epoch: 50 	Loss: 0.793355 Acc@1: 0.786891 (ε = 173.49, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.949060 Acc@1: 0.758450 
	Train Epoch: 51 	Loss: 0.737596 Acc@1: 0.796407 (ε = 173.96, δ = 1e-05) for α = 1.2
	Train Epoch: 51 	Loss: 0.810696 Acc@1: 0.782319 (ε = 174.89, δ = 1e-05) for α = 1.2
	Train Epoch: 51 	Loss: 0.810458 Acc@1: 0.784714 (ε = 175.82, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.943435 Acc@1: 0.757714 
	Train Epoch: 52 	Loss: 0.852629 Acc@1: 0.775538 (ε = 176.28, δ = 1e-05) for α = 1.2
	Train Epoch: 52 	Loss: 0.793861 Acc@1: 0.785579 (ε = 177.21, δ = 1e-05) for α = 1.2
	Train Epoch: 52 	Loss: 0.808394 Acc@1: 0.784296 (ε = 178.14, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.919758 Acc@1: 0.760267 
	Train Epoch: 53 	Loss: 0.720229 Acc@1: 0.797059 (ε = 178.61, δ = 1e-05) for α = 1.2
	Train Epoch: 53 	Loss: 0.793361 Acc@1: 0.784617 (ε = 179.54, δ = 1e-05) for α = 1.2
	Train Epoch: 53 	Loss: 0.780793 Acc@1: 0.789606 (ε = 180.47, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.927659 Acc@1: 0.760198 
	Train Epoch: 54 	Loss: 0.645560 Acc@1: 0.817391 (ε = 180.93, δ = 1e-05) for α = 1.2
	Train Epoch: 54 	Loss: 0.752803 Acc@1: 0.790954 (ε = 181.86, δ = 1e-05) for α = 1.2
	Train Epoch: 54 	Loss: 0.768184 Acc@1: 0.791996 (ε = 182.79, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.939416 Acc@1: 0.760441 
	Train Epoch: 55 	Loss: 0.869807 Acc@1: 0.768531 (ε = 183.26, δ = 1e-05) for α = 1.2
	Train Epoch: 55 	Loss: 0.828479 Acc@1: 0.777181 (ε = 184.19, δ = 1e-05) for α = 1.2
	Train Epoch: 55 	Loss: 0.810432 Acc@1: 0.782298 (ε = 185.12, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.932781 Acc@1: 0.759705 
	Train Epoch: 56 	Loss: 0.810262 Acc@1: 0.769022 (ε = 185.59, δ = 1e-05) for α = 1.2
	Train Epoch: 56 	Loss: 0.795555 Acc@1: 0.785494 (ε = 186.52, δ = 1e-05) for α = 1.2
	Train Epoch: 56 	Loss: 0.793495 Acc@1: 0.787366 (ε = 187.45, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.930066 Acc@1: 0.759737 
	Train Epoch: 57 	Loss: 0.783097 Acc@1: 0.793872 (ε = 187.91, δ = 1e-05) for α = 1.2
	Train Epoch: 57 	Loss: 0.792681 Acc@1: 0.791234 (ε = 188.84, δ = 1e-05) for α = 1.2
	Train Epoch: 57 	Loss: 0.772375 Acc@1: 0.794629 (ε = 189.77, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.933333 Acc@1: 0.760207 
	Train Epoch: 58 	Loss: 0.807841 Acc@1: 0.785615 (ε = 190.24, δ = 1e-05) for α = 1.2
	Train Epoch: 58 	Loss: 0.790128 Acc@1: 0.786311 (ε = 191.17, δ = 1e-05) for α = 1.2
	Train Epoch: 58 	Loss: 0.782317 Acc@1: 0.789412 (ε = 192.10, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.922327 Acc@1: 0.761738 
	Train Epoch: 59 	Loss: 0.855842 Acc@1: 0.780347 (ε = 192.56, δ = 1e-05) for α = 1.2
	Train Epoch: 59 	Loss: 0.800289 Acc@1: 0.785584 (ε = 193.49, δ = 1e-05) for α = 1.2
	Train Epoch: 59 	Loss: 0.803944 Acc@1: 0.787551 (ε = 194.42, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.931883 Acc@1: 0.759836 
	Train Epoch: 60 	Loss: 0.851153 Acc@1: 0.762162 (ε = 194.89, δ = 1e-05) for α = 1.2
	Train Epoch: 60 	Loss: 0.840406 Acc@1: 0.775467 (ε = 195.82, δ = 1e-05) for α = 1.2
	Train Epoch: 60 	Loss: 0.808468 Acc@1: 0.784576 (ε = 196.75, δ = 1e-05) for α = 1.2
	Test set:Loss: 0.928162 Acc@1: 0.760498 
test results
Base private model accuracy:  0.7608
              precision    recall  f1-score   support

         0.0       0.60      0.42      0.49       502
         1.0       0.58      0.42      0.49       502
         2.0       0.40      0.19      0.26       508
         3.0       0.20      0.02      0.03       492
         4.0       0.38      0.19      0.25       499
         5.0       0.66      0.82      0.73      2992
         6.0       0.81      0.86      0.84      3082
         7.0       0.79      0.79      0.79      2973
         8.0       0.84      0.88      0.86      3007
         9.0       0.82      0.87      0.84      2943

    accuracy                           0.76     17500
   macro avg       0.61      0.55      0.56     17500
weighted avg       0.73      0.76      0.74     17500

train results
Base private model accuracy:  0.789038737446198
              precision    recall  f1-score   support

         0.0       0.67      0.50      0.57       496
         1.0       0.65      0.49      0.56       509
         2.0       0.53      0.26      0.35       515
         3.0       0.49      0.05      0.10       513
         4.0       0.56      0.31      0.40       488
         5.0       0.70      0.85      0.77      3011
         6.0       0.81      0.87      0.84      2847
         7.0       0.83      0.83      0.83      3000
         8.0       0.86      0.89      0.88      3002
         9.0       0.84      0.90      0.87      3044

    accuracy                           0.79     17425
   macro avg       0.69      0.60      0.62     17425
weighted avg       0.77      0.79      0.77     17425

NN model attack results: 
train acc: 0.6714490674318508
test acc: 0.5182857142857142
total acc: 0.5947029348604151
precision, recall: (0.5812220566318927, 0.6714490674318508)
epsilon, acc, train acc, mia, report, train report
[197.12244784641925, 0.7608, 0.789038737446198, 0.5947029348604151, '              precision    recall  f1-score   support\n\n         0.0       0.60      0.42      0.49       502\n         1.0       0.58      0.42      0.49       502\n         2.0       0.40      0.19      0.26       508\n         3.0       0.20      0.02      0.03       492\n         4.0       0.38      0.19      0.25       499\n         5.0       0.66      0.82      0.73      2992\n         6.0       0.81      0.86      0.84      3082\n         7.0       0.79      0.79      0.79      2973\n         8.0       0.84      0.88      0.86      3007\n         9.0       0.82      0.87      0.84      2943\n\n    accuracy                           0.76     17500\n   macro avg       0.61      0.55      0.56     17500\nweighted avg       0.73      0.76      0.74     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.67      0.50      0.57       496\n         1.0       0.65      0.49      0.56       509\n         2.0       0.53      0.26      0.35       515\n         3.0       0.49      0.05      0.10       513\n         4.0       0.56      0.31      0.40       488\n         5.0       0.70      0.85      0.77      3011\n         6.0       0.81      0.87      0.84      2847\n         7.0       0.83      0.83      0.83      3000\n         8.0       0.86      0.89      0.88      3002\n         9.0       0.84      0.90      0.87      3044\n\n    accuracy                           0.79     17425\n   macro avg       0.69      0.60      0.62     17425\nweighted avg       0.77      0.79      0.77     17425\n']
experiment_number: 118
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-118.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 0.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[5. 5. 6. ... 1. 8. 8.]
[8. 7. 6. ... 7. 6. 2.]
(17612, 3, 32, 32)
(17500, 3, 32, 32)
(17612, 3, 32, 32)
(17612,)
	Train Epoch: 1 	Loss: 2.311156 Acc@1: 0.035971 (ε = 6.96, δ = 1e-05) for α = 3.1
	Train Epoch: 1 	Loss: 2.198334 Acc@1: 0.171182 (ε = 10.82, δ = 1e-05) for α = 2.3
	Train Epoch: 1 	Loss: 2.108099 Acc@1: 0.210968 (ε = 12.43, δ = 1e-05) for α = 2.2
	Test set:Loss: 1.834493 Acc@1: 0.338448 
	Train Epoch: 2 	Loss: 1.826825 Acc@1: 0.325153 (ε = 13.11, δ = 1e-05) for α = 2.2
	Train Epoch: 2 	Loss: 1.793925 Acc@1: 0.372267 (ε = 14.23, δ = 1e-05) for α = 2.1
	Train Epoch: 2 	Loss: 1.770719 Acc@1: 0.381452 (ε = 15.27, δ = 1e-05) for α = 2.1
	Test set:Loss: 1.649240 Acc@1: 0.437116 
	Train Epoch: 3 	Loss: 1.622800 Acc@1: 0.437768 (ε = 15.71, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 1.621781 Acc@1: 0.453623 (ε = 16.53, δ = 1e-05) for α = 2.0
	Train Epoch: 3 	Loss: 1.589258 Acc@1: 0.470730 (ε = 17.35, δ = 1e-05) for α = 2.0
	Test set:Loss: 1.480425 Acc@1: 0.497694 
	Train Epoch: 4 	Loss: 1.485128 Acc@1: 0.482456 (ε = 17.77, δ = 1e-05) for α = 2.0
	Train Epoch: 4 	Loss: 1.483076 Acc@1: 0.513145 (ε = 18.46, δ = 1e-05) for α = 1.9
	Train Epoch: 4 	Loss: 1.476555 Acc@1: 0.519158 (ε = 19.12, δ = 1e-05) for α = 1.9
	Test set:Loss: 1.423361 Acc@1: 0.553412 
	Train Epoch: 5 	Loss: 1.391059 Acc@1: 0.576271 (ε = 19.45, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 1.413232 Acc@1: 0.558398 (ε = 20.11, δ = 1e-05) for α = 1.9
	Train Epoch: 5 	Loss: 1.389911 Acc@1: 0.563360 (ε = 20.77, δ = 1e-05) for α = 1.9
	Test set:Loss: 1.305914 Acc@1: 0.594840 
	Train Epoch: 6 	Loss: 1.195147 Acc@1: 0.602102 (ε = 21.10, δ = 1e-05) for α = 1.9
	Train Epoch: 6 	Loss: 1.351292 Acc@1: 0.583789 (ε = 21.69, δ = 1e-05) for α = 1.8
	Train Epoch: 6 	Loss: 1.347615 Acc@1: 0.580360 (ε = 22.22, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.266707 Acc@1: 0.596642 
	Train Epoch: 7 	Loss: 1.329635 Acc@1: 0.586801 (ε = 22.49, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 1.285636 Acc@1: 0.601862 (ε = 23.03, δ = 1e-05) for α = 1.8
	Train Epoch: 7 	Loss: 1.275256 Acc@1: 0.608177 (ε = 23.56, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.226115 Acc@1: 0.627412 
	Train Epoch: 8 	Loss: 1.305791 Acc@1: 0.613636 (ε = 23.83, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 1.270252 Acc@1: 0.624341 (ε = 24.37, δ = 1e-05) for α = 1.8
	Train Epoch: 8 	Loss: 1.269542 Acc@1: 0.619208 (ε = 24.90, δ = 1e-05) for α = 1.8
	Test set:Loss: 1.179803 Acc@1: 0.642781 
	Train Epoch: 9 	Loss: 1.187600 Acc@1: 0.652975 (ε = 25.17, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 1.252170 Acc@1: 0.620888 (ε = 25.71, δ = 1e-05) for α = 1.8
	Train Epoch: 9 	Loss: 1.248572 Acc@1: 0.625485 (ε = 26.22, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.151760 Acc@1: 0.636736 
	Train Epoch: 10 	Loss: 1.119459 Acc@1: 0.631579 (ε = 26.44, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 1.214715 Acc@1: 0.621079 (ε = 26.88, δ = 1e-05) for α = 1.7
	Train Epoch: 10 	Loss: 1.221660 Acc@1: 0.628636 (ε = 27.32, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.118533 Acc@1: 0.650468 
	Train Epoch: 11 	Loss: 1.103478 Acc@1: 0.659751 (ε = 27.54, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 1.157305 Acc@1: 0.650240 (ε = 27.99, δ = 1e-05) for α = 1.7
	Train Epoch: 11 	Loss: 1.151556 Acc@1: 0.652846 (ε = 28.43, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.175863 Acc@1: 0.650485 
	Train Epoch: 12 	Loss: 1.056396 Acc@1: 0.664411 (ε = 28.65, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 1.128889 Acc@1: 0.668688 (ε = 29.09, δ = 1e-05) for α = 1.7
	Train Epoch: 12 	Loss: 1.123863 Acc@1: 0.669507 (ε = 29.53, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.127387 Acc@1: 0.672552 
	Train Epoch: 13 	Loss: 1.062561 Acc@1: 0.686930 (ε = 29.75, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 1.122704 Acc@1: 0.677995 (ε = 30.20, δ = 1e-05) for α = 1.7
	Train Epoch: 13 	Loss: 1.133438 Acc@1: 0.674767 (ε = 30.64, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.166844 Acc@1: 0.663853 
	Train Epoch: 14 	Loss: 1.251563 Acc@1: 0.641457 (ε = 30.86, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.134314 Acc@1: 0.666631 (ε = 31.30, δ = 1e-05) for α = 1.7
	Train Epoch: 14 	Loss: 1.094628 Acc@1: 0.675359 (ε = 31.74, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.241234 Acc@1: 0.666551 
	Train Epoch: 15 	Loss: 1.149869 Acc@1: 0.700447 (ε = 31.96, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.144174 Acc@1: 0.675379 (ε = 32.41, δ = 1e-05) for α = 1.7
	Train Epoch: 15 	Loss: 1.142129 Acc@1: 0.673047 (ε = 32.85, δ = 1e-05) for α = 1.7
	Test set:Loss: 1.123674 Acc@1: 0.680736 
	Train Epoch: 16 	Loss: 1.098175 Acc@1: 0.678519 (ε = 33.04, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.075107 Acc@1: 0.691369 (ε = 33.41, δ = 1e-05) for α = 1.6
	Train Epoch: 16 	Loss: 1.051995 Acc@1: 0.695384 (ε = 33.77, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.097444 Acc@1: 0.693624 
	Train Epoch: 17 	Loss: 1.063114 Acc@1: 0.706845 (ε = 33.96, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.032724 Acc@1: 0.703046 (ε = 34.33, δ = 1e-05) for α = 1.6
	Train Epoch: 17 	Loss: 1.047283 Acc@1: 0.704135 (ε = 34.69, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.131701 Acc@1: 0.683611 
	Train Epoch: 18 	Loss: 1.156925 Acc@1: 0.692525 (ε = 34.88, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.075811 Acc@1: 0.699977 (ε = 35.25, δ = 1e-05) for α = 1.6
	Train Epoch: 18 	Loss: 1.073177 Acc@1: 0.698639 (ε = 35.62, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.189270 Acc@1: 0.679075 
	Train Epoch: 19 	Loss: 1.219388 Acc@1: 0.676096 (ε = 35.80, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.036751 Acc@1: 0.705791 (ε = 36.17, δ = 1e-05) for α = 1.6
	Train Epoch: 19 	Loss: 1.029774 Acc@1: 0.708432 (ε = 36.54, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.038032 Acc@1: 0.706773 
	Train Epoch: 20 	Loss: 0.947833 Acc@1: 0.719068 (ε = 36.72, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 0.986512 Acc@1: 0.725745 (ε = 37.09, δ = 1e-05) for α = 1.6
	Train Epoch: 20 	Loss: 0.984749 Acc@1: 0.724670 (ε = 37.46, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.101340 Acc@1: 0.698677 
	Train Epoch: 21 	Loss: 0.972974 Acc@1: 0.731118 (ε = 37.64, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 0.996758 Acc@1: 0.720828 (ε = 38.01, δ = 1e-05) for α = 1.6
	Train Epoch: 21 	Loss: 0.995791 Acc@1: 0.722655 (ε = 38.38, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.041130 Acc@1: 0.718949 
	Train Epoch: 22 	Loss: 1.078501 Acc@1: 0.721311 (ε = 38.56, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 0.981734 Acc@1: 0.730103 (ε = 38.93, δ = 1e-05) for α = 1.6
	Train Epoch: 22 	Loss: 1.004979 Acc@1: 0.725394 (ε = 39.30, δ = 1e-05) for α = 1.6
	Test set:Loss: 0.962922 Acc@1: 0.724857 
	Train Epoch: 23 	Loss: 0.848729 Acc@1: 0.744428 (ε = 39.48, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 0.920116 Acc@1: 0.738266 (ε = 39.85, δ = 1e-05) for α = 1.6
	Train Epoch: 23 	Loss: 0.936121 Acc@1: 0.736220 (ε = 40.22, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.027617 Acc@1: 0.721706 
	Train Epoch: 24 	Loss: 0.922186 Acc@1: 0.747761 (ε = 40.40, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 0.982432 Acc@1: 0.737793 (ε = 40.77, δ = 1e-05) for α = 1.6
	Train Epoch: 24 	Loss: 0.966105 Acc@1: 0.738012 (ε = 41.14, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.086980 Acc@1: 0.717650 
	Train Epoch: 25 	Loss: 0.843657 Acc@1: 0.750746 (ε = 41.32, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 0.940616 Acc@1: 0.745008 (ε = 41.69, δ = 1e-05) for α = 1.6
	Train Epoch: 25 	Loss: 0.949462 Acc@1: 0.747855 (ε = 42.06, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.102475 Acc@1: 0.721940 
	Train Epoch: 26 	Loss: 1.074160 Acc@1: 0.699847 (ε = 42.24, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 0.946496 Acc@1: 0.742755 (ε = 42.61, δ = 1e-05) for α = 1.6
	Train Epoch: 26 	Loss: 0.974695 Acc@1: 0.737075 (ε = 42.98, δ = 1e-05) for α = 1.6
	Test set:Loss: 1.042911 Acc@1: 0.723203 
	Train Epoch: 27 	Loss: 0.949347 Acc@1: 0.755767 (ε = 43.17, δ = 1e-05) for α = 1.6
	Train Epoch: 27 	Loss: 0.940326 Acc@1: 0.742807 (ε = 43.48, δ = 1e-05) for α = 1.5
	Train Epoch: 27 	Loss: 0.937621 Acc@1: 0.744790 (ε = 43.79, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.023236 Acc@1: 0.730304 
	Train Epoch: 28 	Loss: 0.818923 Acc@1: 0.770178 (ε = 43.94, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 0.926240 Acc@1: 0.749220 (ε = 44.25, δ = 1e-05) for α = 1.5
	Train Epoch: 28 	Loss: 0.935077 Acc@1: 0.747295 (ε = 44.56, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.039108 Acc@1: 0.731845 
	Train Epoch: 29 	Loss: 0.993201 Acc@1: 0.737537 (ε = 44.72, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 0.902373 Acc@1: 0.759776 (ε = 45.03, δ = 1e-05) for α = 1.5
	Train Epoch: 29 	Loss: 0.920765 Acc@1: 0.753576 (ε = 45.34, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.001036 Acc@1: 0.736607 
	Train Epoch: 30 	Loss: 0.817108 Acc@1: 0.780059 (ε = 45.49, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 0.897108 Acc@1: 0.760764 (ε = 45.80, δ = 1e-05) for α = 1.5
	Train Epoch: 30 	Loss: 0.911207 Acc@1: 0.757733 (ε = 46.11, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.007598 Acc@1: 0.739495 
	Train Epoch: 31 	Loss: 0.841936 Acc@1: 0.777457 (ε = 46.26, δ = 1e-05) for α = 1.5
	Train Epoch: 31 	Loss: 0.924037 Acc@1: 0.759714 (ε = 46.57, δ = 1e-05) for α = 1.5
	Train Epoch: 31 	Loss: 0.932705 Acc@1: 0.760085 (ε = 46.88, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.978146 Acc@1: 0.740937 
	Train Epoch: 32 	Loss: 0.783597 Acc@1: 0.783934 (ε = 47.04, δ = 1e-05) for α = 1.5
	Train Epoch: 32 	Loss: 0.882137 Acc@1: 0.758315 (ε = 47.35, δ = 1e-05) for α = 1.5
	Train Epoch: 32 	Loss: 0.890880 Acc@1: 0.759882 (ε = 47.66, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.006604 Acc@1: 0.738700 
	Train Epoch: 33 	Loss: 0.838069 Acc@1: 0.783476 (ε = 47.81, δ = 1e-05) for α = 1.5
	Train Epoch: 33 	Loss: 0.920000 Acc@1: 0.758544 (ε = 48.12, δ = 1e-05) for α = 1.5
	Train Epoch: 33 	Loss: 0.896346 Acc@1: 0.764093 (ε = 48.43, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.014095 Acc@1: 0.740585 
	Train Epoch: 34 	Loss: 0.752153 Acc@1: 0.802009 (ε = 48.58, δ = 1e-05) for α = 1.5
	Train Epoch: 34 	Loss: 0.873697 Acc@1: 0.772472 (ε = 48.89, δ = 1e-05) for α = 1.5
	Train Epoch: 34 	Loss: 0.896498 Acc@1: 0.764131 (ε = 49.20, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.074616 Acc@1: 0.738380 
	Train Epoch: 35 	Loss: 1.008288 Acc@1: 0.745242 (ε = 49.36, δ = 1e-05) for α = 1.5
	Train Epoch: 35 	Loss: 0.908337 Acc@1: 0.763856 (ε = 49.67, δ = 1e-05) for α = 1.5
	Train Epoch: 35 	Loss: 0.885258 Acc@1: 0.766227 (ε = 49.98, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.011031 Acc@1: 0.741407 
	Train Epoch: 36 	Loss: 0.949451 Acc@1: 0.758197 (ε = 50.13, δ = 1e-05) for α = 1.5
	Train Epoch: 36 	Loss: 0.883460 Acc@1: 0.767409 (ε = 50.44, δ = 1e-05) for α = 1.5
	Train Epoch: 36 	Loss: 0.869286 Acc@1: 0.767508 (ε = 50.75, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.022983 Acc@1: 0.740068 
	Train Epoch: 37 	Loss: 0.834749 Acc@1: 0.776627 (ε = 50.91, δ = 1e-05) for α = 1.5
	Train Epoch: 37 	Loss: 0.848254 Acc@1: 0.780036 (ε = 51.21, δ = 1e-05) for α = 1.5
	Train Epoch: 37 	Loss: 0.859865 Acc@1: 0.778320 (ε = 51.52, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.983593 Acc@1: 0.748277 
	Train Epoch: 38 	Loss: 0.750183 Acc@1: 0.805213 (ε = 51.68, δ = 1e-05) for α = 1.5
	Train Epoch: 38 	Loss: 0.859917 Acc@1: 0.781551 (ε = 51.99, δ = 1e-05) for α = 1.5
	Train Epoch: 38 	Loss: 0.860972 Acc@1: 0.779633 (ε = 52.30, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.025506 Acc@1: 0.739433 
	Train Epoch: 39 	Loss: 0.929885 Acc@1: 0.768717 (ε = 52.45, δ = 1e-05) for α = 1.5
	Train Epoch: 39 	Loss: 0.883044 Acc@1: 0.775440 (ε = 52.76, δ = 1e-05) for α = 1.5
	Train Epoch: 39 	Loss: 0.866374 Acc@1: 0.775775 (ε = 53.07, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.014265 Acc@1: 0.744152 
	Train Epoch: 40 	Loss: 0.794845 Acc@1: 0.788148 (ε = 53.23, δ = 1e-05) for α = 1.5
	Train Epoch: 40 	Loss: 0.847725 Acc@1: 0.777351 (ε = 53.54, δ = 1e-05) for α = 1.5
	Train Epoch: 40 	Loss: 0.838799 Acc@1: 0.776991 (ε = 53.84, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.013924 Acc@1: 0.745466 
	Train Epoch: 41 	Loss: 0.912310 Acc@1: 0.776243 (ε = 54.00, δ = 1e-05) for α = 1.5
	Train Epoch: 41 	Loss: 0.844286 Acc@1: 0.776830 (ε = 54.31, δ = 1e-05) for α = 1.5
	Train Epoch: 41 	Loss: 0.843322 Acc@1: 0.778199 (ε = 54.62, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.963906 Acc@1: 0.749567 
	Train Epoch: 42 	Loss: 0.725132 Acc@1: 0.795804 (ε = 54.77, δ = 1e-05) for α = 1.5
	Train Epoch: 42 	Loss: 0.797615 Acc@1: 0.787021 (ε = 55.08, δ = 1e-05) for α = 1.5
	Train Epoch: 42 	Loss: 0.811102 Acc@1: 0.788826 (ε = 55.39, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.007749 Acc@1: 0.748787 
	Train Epoch: 43 	Loss: 0.780627 Acc@1: 0.789706 (ε = 55.55, δ = 1e-05) for α = 1.5
	Train Epoch: 43 	Loss: 0.818242 Acc@1: 0.788182 (ε = 55.86, δ = 1e-05) for α = 1.5
	Train Epoch: 43 	Loss: 0.828159 Acc@1: 0.784946 (ε = 56.17, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.044121 Acc@1: 0.744974 
	Train Epoch: 44 	Loss: 0.940994 Acc@1: 0.768421 (ε = 56.32, δ = 1e-05) for α = 1.5
	Train Epoch: 44 	Loss: 0.824914 Acc@1: 0.781698 (ε = 56.63, δ = 1e-05) for α = 1.5
	Train Epoch: 44 	Loss: 0.840713 Acc@1: 0.782540 (ε = 56.94, δ = 1e-05) for α = 1.5
	Test set:Loss: 1.005535 Acc@1: 0.747388 
	Train Epoch: 45 	Loss: 0.833678 Acc@1: 0.772472 (ε = 57.09, δ = 1e-05) for α = 1.5
	Train Epoch: 45 	Loss: 0.841099 Acc@1: 0.782355 (ε = 57.40, δ = 1e-05) for α = 1.5
	Train Epoch: 45 	Loss: 0.828072 Acc@1: 0.784985 (ε = 57.71, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.992920 Acc@1: 0.749446 
	Train Epoch: 46 	Loss: 0.876891 Acc@1: 0.769655 (ε = 57.87, δ = 1e-05) for α = 1.5
	Train Epoch: 46 	Loss: 0.825211 Acc@1: 0.785886 (ε = 58.18, δ = 1e-05) for α = 1.5
	Train Epoch: 46 	Loss: 0.828610 Acc@1: 0.785457 (ε = 58.49, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.969795 Acc@1: 0.754517 
	Train Epoch: 47 	Loss: 0.720676 Acc@1: 0.797337 (ε = 58.64, δ = 1e-05) for α = 1.5
	Train Epoch: 47 	Loss: 0.807554 Acc@1: 0.793851 (ε = 58.95, δ = 1e-05) for α = 1.5
	Train Epoch: 47 	Loss: 0.801288 Acc@1: 0.790082 (ε = 59.26, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.987979 Acc@1: 0.754145 
	Train Epoch: 48 	Loss: 0.717947 Acc@1: 0.813154 (ε = 59.41, δ = 1e-05) for α = 1.5
	Train Epoch: 48 	Loss: 0.805564 Acc@1: 0.792708 (ε = 59.72, δ = 1e-05) for α = 1.5
	Train Epoch: 48 	Loss: 0.827727 Acc@1: 0.786629 (ε = 60.03, δ = 1e-05) for α = 1.5
	Test set:Loss: 0.981718 Acc@1: 0.753549 
	Train Epoch: 49 	Loss: 0.892531 Acc@1: 0.781740 (ε = 60.19, δ = 1e-05) for α = 1.5
	Train Epoch: 49 	Loss: 0.777009 Acc@1: 0.790666 (ε = 60.46, δ = 1e-05) for α = 1.4
	Train Epoch: 49 	Loss: 0.781353 Acc@1: 0.791450 (ε = 60.72, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.978070 Acc@1: 0.756134 
	Train Epoch: 50 	Loss: 0.919438 Acc@1: 0.768309 (ε = 60.85, δ = 1e-05) for α = 1.4
	Train Epoch: 50 	Loss: 0.815960 Acc@1: 0.791591 (ε = 61.11, δ = 1e-05) for α = 1.4
	Train Epoch: 50 	Loss: 0.815538 Acc@1: 0.789377 (ε = 61.37, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.977263 Acc@1: 0.755979 
	Train Epoch: 51 	Loss: 0.692365 Acc@1: 0.811398 (ε = 61.50, δ = 1e-05) for α = 1.4
	Train Epoch: 51 	Loss: 0.802773 Acc@1: 0.788870 (ε = 61.76, δ = 1e-05) for α = 1.4
	Train Epoch: 51 	Loss: 0.791279 Acc@1: 0.787978 (ε = 62.03, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.980198 Acc@1: 0.756670 
	Train Epoch: 52 	Loss: 0.716997 Acc@1: 0.809722 (ε = 62.16, δ = 1e-05) for α = 1.4
	Train Epoch: 52 	Loss: 0.838140 Acc@1: 0.786106 (ε = 62.42, δ = 1e-05) for α = 1.4
	Train Epoch: 52 	Loss: 0.806714 Acc@1: 0.789834 (ε = 62.68, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.989387 Acc@1: 0.756082 
	Train Epoch: 53 	Loss: 0.908238 Acc@1: 0.775000 (ε = 62.81, δ = 1e-05) for α = 1.4
	Train Epoch: 53 	Loss: 0.810942 Acc@1: 0.788543 (ε = 63.07, δ = 1e-05) for α = 1.4
	Train Epoch: 53 	Loss: 0.804771 Acc@1: 0.788523 (ε = 63.33, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.973539 Acc@1: 0.756481 
	Train Epoch: 54 	Loss: 0.628088 Acc@1: 0.821114 (ε = 63.46, δ = 1e-05) for α = 1.4
	Train Epoch: 54 	Loss: 0.767997 Acc@1: 0.798986 (ε = 63.73, δ = 1e-05) for α = 1.4
	Train Epoch: 54 	Loss: 0.798952 Acc@1: 0.792996 (ε = 63.99, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.980805 Acc@1: 0.754239 
	Train Epoch: 55 	Loss: 0.770329 Acc@1: 0.801802 (ε = 64.12, δ = 1e-05) for α = 1.4
	Train Epoch: 55 	Loss: 0.802444 Acc@1: 0.791348 (ε = 64.38, δ = 1e-05) for α = 1.4
	Train Epoch: 55 	Loss: 0.791928 Acc@1: 0.793833 (ε = 64.64, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.970563 Acc@1: 0.756530 
	Train Epoch: 56 	Loss: 0.694745 Acc@1: 0.818705 (ε = 64.77, δ = 1e-05) for α = 1.4
	Train Epoch: 56 	Loss: 0.767873 Acc@1: 0.797836 (ε = 65.03, δ = 1e-05) for α = 1.4
	Train Epoch: 56 	Loss: 0.786898 Acc@1: 0.796910 (ε = 65.30, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.977567 Acc@1: 0.757197 
	Train Epoch: 57 	Loss: 0.883974 Acc@1: 0.777778 (ε = 65.43, δ = 1e-05) for α = 1.4
	Train Epoch: 57 	Loss: 0.827594 Acc@1: 0.786468 (ε = 65.69, δ = 1e-05) for α = 1.4
	Train Epoch: 57 	Loss: 0.815827 Acc@1: 0.788744 (ε = 65.95, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.969025 Acc@1: 0.756818 
	Train Epoch: 58 	Loss: 0.929668 Acc@1: 0.747899 (ε = 66.08, δ = 1e-05) for α = 1.4
	Train Epoch: 58 	Loss: 0.791844 Acc@1: 0.793055 (ε = 66.34, δ = 1e-05) for α = 1.4
	Train Epoch: 58 	Loss: 0.780374 Acc@1: 0.793695 (ε = 66.60, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.968988 Acc@1: 0.757027 
	Train Epoch: 59 	Loss: 0.753861 Acc@1: 0.815115 (ε = 66.73, δ = 1e-05) for α = 1.4
	Train Epoch: 59 	Loss: 0.806723 Acc@1: 0.793312 (ε = 67.00, δ = 1e-05) for α = 1.4
	Train Epoch: 59 	Loss: 0.806622 Acc@1: 0.794590 (ε = 67.26, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.971401 Acc@1: 0.756579 
	Train Epoch: 60 	Loss: 0.819446 Acc@1: 0.791988 (ε = 67.39, δ = 1e-05) for α = 1.4
	Train Epoch: 60 	Loss: 0.771350 Acc@1: 0.796693 (ε = 67.65, δ = 1e-05) for α = 1.4
	Train Epoch: 60 	Loss: 0.796007 Acc@1: 0.792638 (ε = 67.91, δ = 1e-05) for α = 1.4
	Test set:Loss: 0.970762 Acc@1: 0.756862 
test results
Base private model accuracy:  0.7570285714285714
              precision    recall  f1-score   support

         0.0       0.53      0.36      0.43       502
         1.0       0.54      0.36      0.43       502
         2.0       0.37      0.16      0.22       508
         3.0       0.16      0.02      0.04       492
         4.0       0.41      0.22      0.29       499
         5.0       0.67      0.80      0.73      2992
         6.0       0.81      0.87      0.84      3082
         7.0       0.78      0.80      0.79      2973
         8.0       0.83      0.88      0.86      3007
         9.0       0.81      0.88      0.84      2943

    accuracy                           0.76     17500
   macro avg       0.59      0.54      0.55     17500
weighted avg       0.73      0.76      0.74     17500

train results
Base private model accuracy:  0.7913922325687032
              precision    recall  f1-score   support

         0.0       0.63      0.47      0.54       510
         1.0       0.69      0.44      0.54       532
         2.0       0.50      0.24      0.32       474
         3.0       0.44      0.06      0.11       514
         4.0       0.64      0.31      0.42       476
         5.0       0.71      0.84      0.77      2999
         6.0       0.82      0.89      0.85      2878
         7.0       0.83      0.84      0.83      3083
         8.0       0.85      0.89      0.87      3038
         9.0       0.83      0.90      0.86      3108

    accuracy                           0.79     17612
   macro avg       0.69      0.59      0.61     17612
weighted avg       0.78      0.79      0.77     17612

NN model attack results: 
train acc: 0.5816065852966222
test acc: 0.6154285714285714
total acc: 0.5984621956428876
precision, recall: (0.6035346097201767, 0.5816065852966222)
epsilon, acc, train acc, mia, report, train report
[68.01555816637924, 0.7570285714285714, 0.7913922325687032, 0.5984621956428876, '              precision    recall  f1-score   support\n\n         0.0       0.53      0.36      0.43       502\n         1.0       0.54      0.36      0.43       502\n         2.0       0.37      0.16      0.22       508\n         3.0       0.16      0.02      0.04       492\n         4.0       0.41      0.22      0.29       499\n         5.0       0.67      0.80      0.73      2992\n         6.0       0.81      0.87      0.84      3082\n         7.0       0.78      0.80      0.79      2973\n         8.0       0.83      0.88      0.86      3007\n         9.0       0.81      0.88      0.84      2943\n\n    accuracy                           0.76     17500\n   macro avg       0.59      0.54      0.55     17500\nweighted avg       0.73      0.76      0.74     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.63      0.47      0.54       510\n         1.0       0.69      0.44      0.54       532\n         2.0       0.50      0.24      0.32       474\n         3.0       0.44      0.06      0.11       514\n         4.0       0.64      0.31      0.42       476\n         5.0       0.71      0.84      0.77      2999\n         6.0       0.82      0.89      0.85      2878\n         7.0       0.83      0.84      0.83      3083\n         8.0       0.85      0.89      0.87      3038\n         9.0       0.83      0.90      0.86      3108\n\n    accuracy                           0.79     17612\n   macro avg       0.69      0.59      0.61     17612\nweighted avg       0.78      0.79      0.77     17612\n']
experiment_number: 119
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-119.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 1.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[7. 8. 5. ... 0. 1. 9.]
[5. 2. 0. ... 6. 6. 5.]
(17218, 3, 32, 32)
(17500, 3, 32, 32)
(17218, 3, 32, 32)
(17218,)
	Train Epoch: 1 	Loss: 2.304656 Acc@1: 0.068513 (ε = 1.93, δ = 1e-05) for α = 7.4
	Train Epoch: 1 	Loss: 2.180898 Acc@1: 0.163876 (ε = 2.42, δ = 1e-05) for α = 6.5
	Train Epoch: 1 	Loss: 2.113339 Acc@1: 0.210542 (ε = 2.68, δ = 1e-05) for α = 6.2
	Test set:Loss: 1.881820 Acc@1: 0.354098 
	Train Epoch: 2 	Loss: 1.920628 Acc@1: 0.354319 (ε = 2.78, δ = 1e-05) for α = 6.1
	Train Epoch: 2 	Loss: 1.818327 Acc@1: 0.381650 (ε = 2.97, δ = 1e-05) for α = 5.9
	Train Epoch: 2 	Loss: 1.795479 Acc@1: 0.391932 (ε = 3.14, δ = 1e-05) for α = 5.8
	Test set:Loss: 1.646868 Acc@1: 0.442822 
	Train Epoch: 3 	Loss: 1.689470 Acc@1: 0.420085 (ε = 3.22, δ = 1e-05) for α = 5.7
	Train Epoch: 3 	Loss: 1.650112 Acc@1: 0.449583 (ε = 3.37, δ = 1e-05) for α = 5.6
	Train Epoch: 3 	Loss: 1.592103 Acc@1: 0.473658 (ε = 3.51, δ = 1e-05) for α = 5.5
	Test set:Loss: 1.467396 Acc@1: 0.525301 
	Train Epoch: 4 	Loss: 1.428935 Acc@1: 0.539634 (ε = 3.58, δ = 1e-05) for α = 5.5
	Train Epoch: 4 	Loss: 1.549880 Acc@1: 0.522561 (ε = 3.71, δ = 1e-05) for α = 5.4
	Train Epoch: 4 	Loss: 1.520191 Acc@1: 0.531274 (ε = 3.84, δ = 1e-05) for α = 5.3
	Test set:Loss: 1.458170 Acc@1: 0.556721 
	Train Epoch: 5 	Loss: 1.497185 Acc@1: 0.535127 (ε = 3.90, δ = 1e-05) for α = 5.3
	Train Epoch: 5 	Loss: 1.532786 Acc@1: 0.538895 (ε = 4.02, δ = 1e-05) for α = 5.2
	Train Epoch: 5 	Loss: 1.469948 Acc@1: 0.555156 (ε = 4.13, δ = 1e-05) for α = 5.2
	Test set:Loss: 1.393711 Acc@1: 0.593130 
	Train Epoch: 6 	Loss: 1.311490 Acc@1: 0.620991 (ε = 4.19, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 1.403970 Acc@1: 0.587110 (ε = 4.30, δ = 1e-05) for α = 5.1
	Train Epoch: 6 	Loss: 1.448237 Acc@1: 0.581309 (ε = 4.41, δ = 1e-05) for α = 5.0
	Test set:Loss: 1.449169 Acc@1: 0.576729 
	Train Epoch: 7 	Loss: 1.547413 Acc@1: 0.571229 (ε = 4.46, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 1.401473 Acc@1: 0.596341 (ε = 4.56, δ = 1e-05) for α = 5.0
	Train Epoch: 7 	Loss: 1.416008 Acc@1: 0.598965 (ε = 4.66, δ = 1e-05) for α = 4.9
	Test set:Loss: 1.519892 Acc@1: 0.594262 
	Train Epoch: 8 	Loss: 1.475358 Acc@1: 0.604651 (ε = 4.71, δ = 1e-05) for α = 4.9
	Train Epoch: 8 	Loss: 1.401302 Acc@1: 0.611514 (ε = 4.81, δ = 1e-05) for α = 4.8
	Train Epoch: 8 	Loss: 1.371371 Acc@1: 0.616499 (ε = 4.91, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.333195 Acc@1: 0.628035 
	Train Epoch: 9 	Loss: 1.455225 Acc@1: 0.582026 (ε = 4.96, δ = 1e-05) for α = 4.8
	Train Epoch: 9 	Loss: 1.391687 Acc@1: 0.613476 (ε = 5.05, δ = 1e-05) for α = 4.7
	Train Epoch: 9 	Loss: 1.366144 Acc@1: 0.618858 (ε = 5.14, δ = 1e-05) for α = 4.7
	Test set:Loss: 1.405456 Acc@1: 0.632232 
	Train Epoch: 10 	Loss: 1.378745 Acc@1: 0.631081 (ε = 5.19, δ = 1e-05) for α = 4.7
	Train Epoch: 10 	Loss: 1.421865 Acc@1: 0.619623 (ε = 5.28, δ = 1e-05) for α = 4.6
	Train Epoch: 10 	Loss: 1.421369 Acc@1: 0.622124 (ε = 5.37, δ = 1e-05) for α = 4.6
	Test set:Loss: 1.298767 Acc@1: 0.642346 
	Train Epoch: 11 	Loss: 1.177200 Acc@1: 0.664393 (ε = 5.41, δ = 1e-05) for α = 4.6
	Train Epoch: 11 	Loss: 1.316470 Acc@1: 0.640376 (ε = 5.50, δ = 1e-05) for α = 4.5
	Train Epoch: 11 	Loss: 1.333849 Acc@1: 0.638674 (ε = 5.58, δ = 1e-05) for α = 4.5
	Test set:Loss: 1.346774 Acc@1: 0.632899 
	Train Epoch: 12 	Loss: 1.344875 Acc@1: 0.603399 (ε = 5.62, δ = 1e-05) for α = 4.5
	Train Epoch: 12 	Loss: 1.333430 Acc@1: 0.636950 (ε = 5.71, δ = 1e-05) for α = 4.4
	Train Epoch: 12 	Loss: 1.351116 Acc@1: 0.637681 (ε = 5.79, δ = 1e-05) for α = 4.4
	Test set:Loss: 1.360803 Acc@1: 0.645599 
	Train Epoch: 13 	Loss: 1.459712 Acc@1: 0.625356 (ε = 5.83, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 1.346498 Acc@1: 0.639416 (ε = 5.91, δ = 1e-05) for α = 4.4
	Train Epoch: 13 	Loss: 1.335779 Acc@1: 0.642853 (ε = 5.99, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.394230 Acc@1: 0.643527 
	Train Epoch: 14 	Loss: 1.400836 Acc@1: 0.651578 (ε = 6.03, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 1.315209 Acc@1: 0.648881 (ε = 6.11, δ = 1e-05) for α = 4.3
	Train Epoch: 14 	Loss: 1.316949 Acc@1: 0.648214 (ε = 6.18, δ = 1e-05) for α = 4.3
	Test set:Loss: 1.250560 Acc@1: 0.659627 
	Train Epoch: 15 	Loss: 1.213760 Acc@1: 0.690160 (ε = 6.22, δ = 1e-05) for α = 4.3
	Train Epoch: 15 	Loss: 1.302916 Acc@1: 0.657261 (ε = 6.30, δ = 1e-05) for α = 4.2
	Train Epoch: 15 	Loss: 1.347179 Acc@1: 0.652668 (ε = 6.37, δ = 1e-05) for α = 4.2
	Test set:Loss: 1.429212 Acc@1: 0.638577 
	Train Epoch: 16 	Loss: 1.508678 Acc@1: 0.641026 (ε = 6.41, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.280831 Acc@1: 0.656984 (ε = 6.49, δ = 1e-05) for α = 4.2
	Train Epoch: 16 	Loss: 1.295876 Acc@1: 0.652701 (ε = 6.56, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.256182 Acc@1: 0.666859 
	Train Epoch: 17 	Loss: 1.060486 Acc@1: 0.685265 (ε = 6.60, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.250886 Acc@1: 0.671628 (ε = 6.67, δ = 1e-05) for α = 4.1
	Train Epoch: 17 	Loss: 1.277564 Acc@1: 0.668413 (ε = 6.74, δ = 1e-05) for α = 4.1
	Test set:Loss: 1.428187 Acc@1: 0.642899 
	Train Epoch: 18 	Loss: 1.382860 Acc@1: 0.659226 (ε = 6.77, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.405410 Acc@1: 0.645642 (ε = 6.85, δ = 1e-05) for α = 4.1
	Train Epoch: 18 	Loss: 1.366217 Acc@1: 0.654356 (ε = 6.92, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.413032 Acc@1: 0.652467 
	Train Epoch: 19 	Loss: 1.312878 Acc@1: 0.655222 (ε = 6.95, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.377669 Acc@1: 0.653597 (ε = 7.02, δ = 1e-05) for α = 4.0
	Train Epoch: 19 	Loss: 1.359978 Acc@1: 0.660357 (ε = 7.09, δ = 1e-05) for α = 4.0
	Test set:Loss: 1.309228 Acc@1: 0.669099 
	Train Epoch: 20 	Loss: 1.277244 Acc@1: 0.696011 (ε = 7.12, δ = 1e-05) for α = 4.0
	Train Epoch: 20 	Loss: 1.286998 Acc@1: 0.680965 (ε = 7.19, δ = 1e-05) for α = 3.9
	Train Epoch: 20 	Loss: 1.267871 Acc@1: 0.679616 (ε = 7.26, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.326400 Acc@1: 0.672138 
	Train Epoch: 21 	Loss: 1.391916 Acc@1: 0.644022 (ε = 7.29, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.344612 Acc@1: 0.659833 (ε = 7.36, δ = 1e-05) for α = 3.9
	Train Epoch: 21 	Loss: 1.300602 Acc@1: 0.664002 (ε = 7.42, δ = 1e-05) for α = 3.9
	Test set:Loss: 1.368053 Acc@1: 0.652511 
	Train Epoch: 22 	Loss: 1.242443 Acc@1: 0.666667 (ε = 7.46, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.200933 Acc@1: 0.683869 (ε = 7.52, δ = 1e-05) for α = 3.9
	Train Epoch: 22 	Loss: 1.220701 Acc@1: 0.684398 (ε = 7.59, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.253930 Acc@1: 0.678528 
	Train Epoch: 23 	Loss: 1.145960 Acc@1: 0.695067 (ε = 7.62, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.244017 Acc@1: 0.681189 (ε = 7.68, δ = 1e-05) for α = 3.8
	Train Epoch: 23 	Loss: 1.274999 Acc@1: 0.681364 (ε = 7.75, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.328177 Acc@1: 0.675917 
	Train Epoch: 24 	Loss: 1.237077 Acc@1: 0.696093 (ε = 7.78, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.267384 Acc@1: 0.679301 (ε = 7.84, δ = 1e-05) for α = 3.8
	Train Epoch: 24 	Loss: 1.275282 Acc@1: 0.676483 (ε = 7.91, δ = 1e-05) for α = 3.8
	Test set:Loss: 1.272315 Acc@1: 0.681118 
	Train Epoch: 25 	Loss: 1.202073 Acc@1: 0.693260 (ε = 7.94, δ = 1e-05) for α = 3.8
	Train Epoch: 25 	Loss: 1.220414 Acc@1: 0.686068 (ε = 8.00, δ = 1e-05) for α = 3.7
	Train Epoch: 25 	Loss: 1.214627 Acc@1: 0.687518 (ε = 8.06, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.262381 Acc@1: 0.687963 
	Train Epoch: 26 	Loss: 1.248964 Acc@1: 0.694118 (ε = 8.09, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.202629 Acc@1: 0.689801 (ε = 8.15, δ = 1e-05) for α = 3.7
	Train Epoch: 26 	Loss: 1.203076 Acc@1: 0.690324 (ε = 8.21, δ = 1e-05) for α = 3.7
	Test set:Loss: 1.289583 Acc@1: 0.682900 
	Train Epoch: 27 	Loss: 1.212004 Acc@1: 0.687879 (ε = 8.24, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.174348 Acc@1: 0.699633 (ε = 8.31, δ = 1e-05) for α = 3.7
	Train Epoch: 27 	Loss: 1.200317 Acc@1: 0.698458 (ε = 8.37, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.323119 Acc@1: 0.690601 
	Train Epoch: 28 	Loss: 1.264466 Acc@1: 0.697211 (ε = 8.40, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.247093 Acc@1: 0.699972 (ε = 8.45, δ = 1e-05) for α = 3.6
	Train Epoch: 28 	Loss: 1.245442 Acc@1: 0.695552 (ε = 8.51, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.255631 Acc@1: 0.685063 
	Train Epoch: 29 	Loss: 1.175081 Acc@1: 0.678211 (ε = 8.54, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.244780 Acc@1: 0.686478 (ε = 8.60, δ = 1e-05) for α = 3.6
	Train Epoch: 29 	Loss: 1.213112 Acc@1: 0.693365 (ε = 8.66, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.351037 Acc@1: 0.684650 
	Train Epoch: 30 	Loss: 1.044942 Acc@1: 0.747191 (ε = 8.69, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.225026 Acc@1: 0.702975 (ε = 8.75, δ = 1e-05) for α = 3.6
	Train Epoch: 30 	Loss: 1.231144 Acc@1: 0.699567 (ε = 8.81, δ = 1e-05) for α = 3.6
	Test set:Loss: 1.319948 Acc@1: 0.682329 
	Train Epoch: 31 	Loss: 1.441598 Acc@1: 0.674731 (ε = 8.84, δ = 1e-05) for α = 3.5
	Train Epoch: 31 	Loss: 1.211473 Acc@1: 0.699249 (ε = 8.89, δ = 1e-05) for α = 3.5
	Train Epoch: 31 	Loss: 1.176995 Acc@1: 0.705531 (ε = 8.95, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.257932 Acc@1: 0.692561 
	Train Epoch: 32 	Loss: 1.097905 Acc@1: 0.713869 (ε = 8.98, δ = 1e-05) for α = 3.5
	Train Epoch: 32 	Loss: 1.200526 Acc@1: 0.705424 (ε = 9.03, δ = 1e-05) for α = 3.5
	Train Epoch: 32 	Loss: 1.202364 Acc@1: 0.702513 (ε = 9.09, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.303438 Acc@1: 0.691953 
	Train Epoch: 33 	Loss: 1.256338 Acc@1: 0.691877 (ε = 9.12, δ = 1e-05) for α = 3.5
	Train Epoch: 33 	Loss: 1.148495 Acc@1: 0.715849 (ε = 9.17, δ = 1e-05) for α = 3.5
	Train Epoch: 33 	Loss: 1.167856 Acc@1: 0.712309 (ε = 9.23, δ = 1e-05) for α = 3.5
	Test set:Loss: 1.292067 Acc@1: 0.693361 
	Train Epoch: 34 	Loss: 1.210920 Acc@1: 0.730015 (ε = 9.26, δ = 1e-05) for α = 3.5
	Train Epoch: 34 	Loss: 1.176432 Acc@1: 0.719733 (ε = 9.31, δ = 1e-05) for α = 3.4
	Train Epoch: 34 	Loss: 1.169769 Acc@1: 0.719684 (ε = 9.37, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.282809 Acc@1: 0.693882 
	Train Epoch: 35 	Loss: 1.188357 Acc@1: 0.706215 (ε = 9.40, δ = 1e-05) for α = 3.4
	Train Epoch: 35 	Loss: 1.149400 Acc@1: 0.714432 (ε = 9.45, δ = 1e-05) for α = 3.4
	Train Epoch: 35 	Loss: 1.164979 Acc@1: 0.714307 (ε = 9.50, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.267687 Acc@1: 0.698766 
	Train Epoch: 36 	Loss: 1.191639 Acc@1: 0.707214 (ε = 9.53, δ = 1e-05) for α = 3.4
	Train Epoch: 36 	Loss: 1.139605 Acc@1: 0.718028 (ε = 9.58, δ = 1e-05) for α = 3.4
	Train Epoch: 36 	Loss: 1.165250 Acc@1: 0.712151 (ε = 9.64, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.240137 Acc@1: 0.701646 
	Train Epoch: 37 	Loss: 1.133533 Acc@1: 0.708451 (ε = 9.67, δ = 1e-05) for α = 3.4
	Train Epoch: 37 	Loss: 1.109685 Acc@1: 0.713038 (ε = 9.72, δ = 1e-05) for α = 3.4
	Train Epoch: 37 	Loss: 1.137727 Acc@1: 0.710852 (ε = 9.77, δ = 1e-05) for α = 3.4
	Test set:Loss: 1.215247 Acc@1: 0.704262 
	Train Epoch: 38 	Loss: 1.135068 Acc@1: 0.734694 (ε = 9.80, δ = 1e-05) for α = 3.4
	Train Epoch: 38 	Loss: 1.114337 Acc@1: 0.726346 (ε = 9.85, δ = 1e-05) for α = 3.4
	Train Epoch: 38 	Loss: 1.111771 Acc@1: 0.724285 (ε = 9.91, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.253670 Acc@1: 0.700282 
	Train Epoch: 39 	Loss: 1.288776 Acc@1: 0.697504 (ε = 9.93, δ = 1e-05) for α = 3.3
	Train Epoch: 39 	Loss: 1.126964 Acc@1: 0.724922 (ε = 9.98, δ = 1e-05) for α = 3.3
	Train Epoch: 39 	Loss: 1.120018 Acc@1: 0.727640 (ε = 10.04, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.223652 Acc@1: 0.707620 
	Train Epoch: 40 	Loss: 1.029740 Acc@1: 0.742466 (ε = 10.06, δ = 1e-05) for α = 3.3
	Train Epoch: 40 	Loss: 1.120793 Acc@1: 0.717271 (ε = 10.11, δ = 1e-05) for α = 3.3
	Train Epoch: 40 	Loss: 1.089311 Acc@1: 0.726395 (ε = 10.17, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.187786 Acc@1: 0.708213 
	Train Epoch: 41 	Loss: 1.042268 Acc@1: 0.745763 (ε = 10.19, δ = 1e-05) for α = 3.3
	Train Epoch: 41 	Loss: 1.145190 Acc@1: 0.719814 (ε = 10.24, δ = 1e-05) for α = 3.3
	Train Epoch: 41 	Loss: 1.115187 Acc@1: 0.725903 (ε = 10.30, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.212578 Acc@1: 0.705527 
	Train Epoch: 42 	Loss: 1.165560 Acc@1: 0.725904 (ε = 10.32, δ = 1e-05) for α = 3.3
	Train Epoch: 42 	Loss: 1.069562 Acc@1: 0.731138 (ε = 10.37, δ = 1e-05) for α = 3.3
	Train Epoch: 42 	Loss: 1.091041 Acc@1: 0.728287 (ε = 10.42, δ = 1e-05) for α = 3.3
	Test set:Loss: 1.201650 Acc@1: 0.709653 
	Train Epoch: 43 	Loss: 1.076355 Acc@1: 0.736919 (ε = 10.45, δ = 1e-05) for α = 3.3
	Train Epoch: 43 	Loss: 1.069839 Acc@1: 0.730904 (ε = 10.50, δ = 1e-05) for α = 3.2
	Train Epoch: 43 	Loss: 1.076289 Acc@1: 0.730043 (ε = 10.55, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.223549 Acc@1: 0.705488 
	Train Epoch: 44 	Loss: 1.043441 Acc@1: 0.725490 (ε = 10.57, δ = 1e-05) for α = 3.2
	Train Epoch: 44 	Loss: 1.084954 Acc@1: 0.725661 (ε = 10.62, δ = 1e-05) for α = 3.2
	Train Epoch: 44 	Loss: 1.088011 Acc@1: 0.725387 (ε = 10.67, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.194324 Acc@1: 0.712968 
	Train Epoch: 45 	Loss: 1.035700 Acc@1: 0.730435 (ε = 10.70, δ = 1e-05) for α = 3.2
	Train Epoch: 45 	Loss: 1.109965 Acc@1: 0.723269 (ε = 10.75, δ = 1e-05) for α = 3.2
	Train Epoch: 45 	Loss: 1.092133 Acc@1: 0.731804 (ε = 10.80, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.196686 Acc@1: 0.713044 
	Train Epoch: 46 	Loss: 1.006782 Acc@1: 0.741144 (ε = 10.82, δ = 1e-05) for α = 3.2
	Train Epoch: 46 	Loss: 1.036938 Acc@1: 0.746004 (ε = 10.87, δ = 1e-05) for α = 3.2
	Train Epoch: 46 	Loss: 1.066593 Acc@1: 0.738841 (ε = 10.92, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.218898 Acc@1: 0.710979 
	Train Epoch: 47 	Loss: 0.986153 Acc@1: 0.765020 (ε = 10.95, δ = 1e-05) for α = 3.2
	Train Epoch: 47 	Loss: 1.074742 Acc@1: 0.734182 (ε = 11.00, δ = 1e-05) for α = 3.2
	Train Epoch: 47 	Loss: 1.083783 Acc@1: 0.735314 (ε = 11.05, δ = 1e-05) for α = 3.2
	Test set:Loss: 1.209402 Acc@1: 0.712390 
	Train Epoch: 48 	Loss: 0.933855 Acc@1: 0.746725 (ε = 11.07, δ = 1e-05) for α = 3.2
	Train Epoch: 48 	Loss: 1.086655 Acc@1: 0.732905 (ε = 11.12, δ = 1e-05) for α = 3.1
	Train Epoch: 48 	Loss: 1.079600 Acc@1: 0.733633 (ε = 11.17, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.205473 Acc@1: 0.715341 
	Train Epoch: 49 	Loss: 1.035993 Acc@1: 0.752994 (ε = 11.19, δ = 1e-05) for α = 3.1
	Train Epoch: 49 	Loss: 1.075071 Acc@1: 0.736887 (ε = 11.24, δ = 1e-05) for α = 3.1
	Train Epoch: 49 	Loss: 1.031803 Acc@1: 0.742951 (ε = 11.29, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.193911 Acc@1: 0.716033 
	Train Epoch: 50 	Loss: 1.023196 Acc@1: 0.757532 (ε = 11.31, δ = 1e-05) for α = 3.1
	Train Epoch: 50 	Loss: 1.094399 Acc@1: 0.741606 (ε = 11.36, δ = 1e-05) for α = 3.1
	Train Epoch: 50 	Loss: 1.061875 Acc@1: 0.743248 (ε = 11.41, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.175290 Acc@1: 0.715769 
	Train Epoch: 51 	Loss: 1.116497 Acc@1: 0.736695 (ε = 11.43, δ = 1e-05) for α = 3.1
	Train Epoch: 51 	Loss: 1.019838 Acc@1: 0.747570 (ε = 11.48, δ = 1e-05) for α = 3.1
	Train Epoch: 51 	Loss: 1.006762 Acc@1: 0.744006 (ε = 11.52, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.184699 Acc@1: 0.715661 
	Train Epoch: 52 	Loss: 1.131526 Acc@1: 0.748918 (ε = 11.55, δ = 1e-05) for α = 3.1
	Train Epoch: 52 	Loss: 1.060477 Acc@1: 0.743048 (ε = 11.60, δ = 1e-05) for α = 3.1
	Train Epoch: 52 	Loss: 1.050981 Acc@1: 0.743170 (ε = 11.64, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.168011 Acc@1: 0.718312 
	Train Epoch: 53 	Loss: 0.961283 Acc@1: 0.747059 (ε = 11.67, δ = 1e-05) for α = 3.1
	Train Epoch: 53 	Loss: 1.052683 Acc@1: 0.739322 (ε = 11.71, δ = 1e-05) for α = 3.1
	Train Epoch: 53 	Loss: 1.044928 Acc@1: 0.740400 (ε = 11.76, δ = 1e-05) for α = 3.1
	Test set:Loss: 1.173457 Acc@1: 0.717234 
	Train Epoch: 54 	Loss: 0.997149 Acc@1: 0.750696 (ε = 11.79, δ = 1e-05) for α = 3.1
	Train Epoch: 54 	Loss: 1.023905 Acc@1: 0.748710 (ε = 11.83, δ = 1e-05) for α = 3.1
	Train Epoch: 54 	Loss: 1.033093 Acc@1: 0.744782 (ε = 11.88, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.175889 Acc@1: 0.717938 
	Train Epoch: 55 	Loss: 0.945478 Acc@1: 0.761644 (ε = 11.90, δ = 1e-05) for α = 3.0
	Train Epoch: 55 	Loss: 1.059323 Acc@1: 0.738053 (ε = 11.95, δ = 1e-05) for α = 3.0
	Train Epoch: 55 	Loss: 1.043158 Acc@1: 0.738868 (ε = 11.99, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.167769 Acc@1: 0.719461 
	Train Epoch: 56 	Loss: 1.141494 Acc@1: 0.725304 (ε = 12.02, δ = 1e-05) for α = 3.0
	Train Epoch: 56 	Loss: 1.044750 Acc@1: 0.734485 (ε = 12.06, δ = 1e-05) for α = 3.0
	Train Epoch: 56 	Loss: 1.048688 Acc@1: 0.737336 (ε = 12.11, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.158762 Acc@1: 0.717938 
	Train Epoch: 57 	Loss: 1.175642 Acc@1: 0.707831 (ε = 12.13, δ = 1e-05) for α = 3.0
	Train Epoch: 57 	Loss: 1.020864 Acc@1: 0.740204 (ε = 12.17, δ = 1e-05) for α = 3.0
	Train Epoch: 57 	Loss: 1.013357 Acc@1: 0.742049 (ε = 12.22, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.163098 Acc@1: 0.718258 
	Train Epoch: 58 	Loss: 1.047434 Acc@1: 0.730088 (ε = 12.24, δ = 1e-05) for α = 3.0
	Train Epoch: 58 	Loss: 1.015781 Acc@1: 0.737037 (ε = 12.29, δ = 1e-05) for α = 3.0
	Train Epoch: 58 	Loss: 1.028931 Acc@1: 0.738518 (ε = 12.33, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.165784 Acc@1: 0.718238 
	Train Epoch: 59 	Loss: 1.085996 Acc@1: 0.729462 (ε = 12.36, δ = 1e-05) for α = 3.0
	Train Epoch: 59 	Loss: 1.063027 Acc@1: 0.739344 (ε = 12.40, δ = 1e-05) for α = 3.0
	Train Epoch: 59 	Loss: 1.047837 Acc@1: 0.739984 (ε = 12.45, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.163021 Acc@1: 0.719139 
	Train Epoch: 60 	Loss: 1.006156 Acc@1: 0.748201 (ε = 12.47, δ = 1e-05) for α = 3.0
	Train Epoch: 60 	Loss: 1.014287 Acc@1: 0.747843 (ε = 12.52, δ = 1e-05) for α = 3.0
	Train Epoch: 60 	Loss: 1.050474 Acc@1: 0.741460 (ε = 12.56, δ = 1e-05) for α = 3.0
	Test set:Loss: 1.163306 Acc@1: 0.718880 
test results
Base private model accuracy:  0.7192
              precision    recall  f1-score   support

         0.0       0.51      0.28      0.36       502
         1.0       0.43      0.22      0.29       502
         2.0       0.29      0.10      0.15       508
         3.0       0.17      0.03      0.05       492
         4.0       0.36      0.14      0.21       499
         5.0       0.64      0.75      0.69      2992
         6.0       0.79      0.84      0.82      3082
         7.0       0.73      0.76      0.74      2973
         8.0       0.79      0.86      0.82      3007
         9.0       0.76      0.85      0.80      2943

    accuracy                           0.72     17500
   macro avg       0.55      0.48      0.49     17500
weighted avg       0.68      0.72      0.69     17500

train results
Base private model accuracy:  0.7395748635149263
              precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       499
         1.0       0.58      0.25      0.35       500
         2.0       0.45      0.20      0.28       485
         3.0       0.20      0.03      0.06       479
         4.0       0.44      0.18      0.26       499
         5.0       0.66      0.79      0.72      2912
         6.0       0.79      0.85      0.82      2920
         7.0       0.76      0.78      0.77      3001
         8.0       0.80      0.88      0.84      2934
         9.0       0.78      0.86      0.82      2989

    accuracy                           0.74     17218
   macro avg       0.60      0.51      0.53     17218
weighted avg       0.71      0.74      0.72     17218

NN model attack results: 
train acc: 0.5664924506387921
test acc: 0.6377142857142857
total acc: 0.6023905529953917
precision, recall: (0.6060888474681578, 0.5664924506387921)
epsilon, acc, train acc, mia, report, train report
[12.579817382090297, 0.7192, 0.7395748635149263, 0.6023905529953917, '              precision    recall  f1-score   support\n\n         0.0       0.51      0.28      0.36       502\n         1.0       0.43      0.22      0.29       502\n         2.0       0.29      0.10      0.15       508\n         3.0       0.17      0.03      0.05       492\n         4.0       0.36      0.14      0.21       499\n         5.0       0.64      0.75      0.69      2992\n         6.0       0.79      0.84      0.82      3082\n         7.0       0.73      0.76      0.74      2973\n         8.0       0.79      0.86      0.82      3007\n         9.0       0.76      0.85      0.80      2943\n\n    accuracy                           0.72     17500\n   macro avg       0.55      0.48      0.49     17500\nweighted avg       0.68      0.72      0.69     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.52      0.30      0.38       499\n         1.0       0.58      0.25      0.35       500\n         2.0       0.45      0.20      0.28       485\n         3.0       0.20      0.03      0.06       479\n         4.0       0.44      0.18      0.26       499\n         5.0       0.66      0.79      0.72      2912\n         6.0       0.79      0.85      0.82      2920\n         7.0       0.76      0.78      0.77      3001\n         8.0       0.80      0.88      0.84      2934\n         9.0       0.78      0.86      0.82      2989\n\n    accuracy                           0.74     17218\n   macro avg       0.60      0.51      0.53     17218\nweighted avg       0.71      0.74      0.72     17218\n']
experiment_number: 120
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-120.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 1.5, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[5. 7. 8. ... 8. 0. 2.]
[5. 6. 4. ... 9. 2. 6.]
(17533, 3, 32, 32)
(17500, 3, 32, 32)
(17533, 3, 32, 32)
(17533,)
	Train Epoch: 1 	Loss: 2.316411 Acc@1: 0.027182 (ε = 0.86, δ = 1e-05) for α = 15.0
	Train Epoch: 1 	Loss: 2.227527 Acc@1: 0.157761 (ε = 1.03, δ = 1e-05) for α = 14.0
	Train Epoch: 1 	Loss: 2.120549 Acc@1: 0.198299 (ε = 1.15, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.827710 Acc@1: 0.392067 
	Train Epoch: 2 	Loss: 1.813798 Acc@1: 0.383639 (ε = 1.20, δ = 1e-05) for α = 13.0
	Train Epoch: 2 	Loss: 1.927154 Acc@1: 0.379041 (ε = 1.29, δ = 1e-05) for α = 13.0
	Train Epoch: 2 	Loss: 1.855992 Acc@1: 0.393927 (ε = 1.39, δ = 1e-05) for α = 13.0
	Test set:Loss: 1.646219 Acc@1: 0.477493 
	Train Epoch: 3 	Loss: 1.764874 Acc@1: 0.452830 (ε = 1.43, δ = 1e-05) for α = 13.0
	Train Epoch: 3 	Loss: 1.669112 Acc@1: 0.473920 (ε = 1.52, δ = 1e-05) for α = 12.0
	Train Epoch: 3 	Loss: 1.633379 Acc@1: 0.498991 (ε = 1.60, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.678436 Acc@1: 0.528675 
	Train Epoch: 4 	Loss: 1.587486 Acc@1: 0.543785 (ε = 1.64, δ = 1e-05) for α = 12.0
	Train Epoch: 4 	Loss: 1.730823 Acc@1: 0.524004 (ε = 1.71, δ = 1e-05) for α = 12.0
	Train Epoch: 4 	Loss: 1.725894 Acc@1: 0.521887 (ε = 1.79, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.714684 Acc@1: 0.521269 
	Train Epoch: 5 	Loss: 1.820034 Acc@1: 0.492435 (ε = 1.83, δ = 1e-05) for α = 10.9
	Train Epoch: 5 	Loss: 1.716513 Acc@1: 0.531341 (ε = 1.89, δ = 1e-05) for α = 10.9
	Train Epoch: 5 	Loss: 1.710901 Acc@1: 0.536003 (ε = 1.96, δ = 1e-05) for α = 10.9
	Test set:Loss: 1.679044 Acc@1: 0.574108 
	Train Epoch: 6 	Loss: 1.657967 Acc@1: 0.557864 (ε = 1.99, δ = 1e-05) for α = 10.8
	Train Epoch: 6 	Loss: 1.642521 Acc@1: 0.564919 (ε = 2.06, δ = 1e-05) for α = 10.6
	Train Epoch: 6 	Loss: 1.642619 Acc@1: 0.569887 (ε = 2.12, δ = 1e-05) for α = 10.4
	Test set:Loss: 1.815164 Acc@1: 0.547707 
	Train Epoch: 7 	Loss: 1.900126 Acc@1: 0.541005 (ε = 2.15, δ = 1e-05) for α = 10.3
	Train Epoch: 7 	Loss: 1.741416 Acc@1: 0.568125 (ε = 2.21, δ = 1e-05) for α = 10.1
	Train Epoch: 7 	Loss: 1.716957 Acc@1: 0.575618 (ε = 2.27, δ = 1e-05) for α = 10.0
	Test set:Loss: 1.660127 Acc@1: 0.594843 
	Train Epoch: 8 	Loss: 1.641020 Acc@1: 0.582026 (ε = 2.30, δ = 1e-05) for α = 9.9
	Train Epoch: 8 	Loss: 1.610174 Acc@1: 0.579707 (ε = 2.35, δ = 1e-05) for α = 9.7
	Train Epoch: 8 	Loss: 1.603771 Acc@1: 0.582449 (ε = 2.41, δ = 1e-05) for α = 9.6
	Test set:Loss: 1.506154 Acc@1: 0.599598 
	Train Epoch: 9 	Loss: 1.563344 Acc@1: 0.595273 (ε = 2.44, δ = 1e-05) for α = 9.5
	Train Epoch: 9 	Loss: 1.680559 Acc@1: 0.577235 (ε = 2.49, δ = 1e-05) for α = 9.4
	Train Epoch: 9 	Loss: 1.631657 Acc@1: 0.593629 (ε = 2.54, δ = 1e-05) for α = 9.2
	Test set:Loss: 1.754692 Acc@1: 0.599158 
	Train Epoch: 10 	Loss: 1.847842 Acc@1: 0.594816 (ε = 2.57, δ = 1e-05) for α = 9.2
	Train Epoch: 10 	Loss: 1.699399 Acc@1: 0.610973 (ε = 2.62, δ = 1e-05) for α = 9.0
	Train Epoch: 10 	Loss: 1.699151 Acc@1: 0.605960 (ε = 2.67, δ = 1e-05) for α = 8.9
	Test set:Loss: 1.730710 Acc@1: 0.594407 
	Train Epoch: 11 	Loss: 1.784382 Acc@1: 0.583807 (ε = 2.69, δ = 1e-05) for α = 8.9
	Train Epoch: 11 	Loss: 1.798601 Acc@1: 0.593716 (ε = 2.74, δ = 1e-05) for α = 8.7
	Train Epoch: 11 	Loss: 1.828239 Acc@1: 0.590899 (ε = 2.79, δ = 1e-05) for α = 8.6
	Test set:Loss: 1.741110 Acc@1: 0.570763 
	Train Epoch: 12 	Loss: 1.752648 Acc@1: 0.559775 (ε = 2.81, δ = 1e-05) for α = 8.6
	Train Epoch: 12 	Loss: 1.813086 Acc@1: 0.578977 (ε = 2.86, δ = 1e-05) for α = 8.5
	Train Epoch: 12 	Loss: 1.765140 Acc@1: 0.586993 (ε = 2.90, δ = 1e-05) for α = 8.4
	Test set:Loss: 1.781726 Acc@1: 0.602124 
	Train Epoch: 13 	Loss: 1.731476 Acc@1: 0.614060 (ε = 2.93, δ = 1e-05) for α = 8.3
	Train Epoch: 13 	Loss: 1.831238 Acc@1: 0.588710 (ε = 2.97, δ = 1e-05) for α = 8.3
	Train Epoch: 13 	Loss: 1.825820 Acc@1: 0.583998 (ε = 3.01, δ = 1e-05) for α = 8.2
	Test set:Loss: 1.851389 Acc@1: 0.564132 
	Train Epoch: 14 	Loss: 1.883772 Acc@1: 0.571644 (ε = 3.04, δ = 1e-05) for α = 8.1
	Train Epoch: 14 	Loss: 1.839584 Acc@1: 0.591971 (ε = 3.08, δ = 1e-05) for α = 8.0
	Train Epoch: 14 	Loss: 1.808161 Acc@1: 0.600669 (ε = 3.12, δ = 1e-05) for α = 8.0
	Test set:Loss: 1.730380 Acc@1: 0.598060 
	Train Epoch: 15 	Loss: 1.585483 Acc@1: 0.621583 (ε = 3.14, δ = 1e-05) for α = 7.9
	Train Epoch: 15 	Loss: 1.833140 Acc@1: 0.602731 (ε = 3.19, δ = 1e-05) for α = 7.8
	Train Epoch: 15 	Loss: 1.880510 Acc@1: 0.597311 (ε = 3.23, δ = 1e-05) for α = 7.8
	Test set:Loss: 1.862080 Acc@1: 0.586260 
	Train Epoch: 16 	Loss: 1.852930 Acc@1: 0.598093 (ε = 3.25, δ = 1e-05) for α = 7.7
	Train Epoch: 16 	Loss: 1.880805 Acc@1: 0.593139 (ε = 3.29, δ = 1e-05) for α = 7.7
	Train Epoch: 16 	Loss: 1.851079 Acc@1: 0.596672 (ε = 3.33, δ = 1e-05) for α = 7.6
	Test set:Loss: 1.861757 Acc@1: 0.606980 
	Train Epoch: 17 	Loss: 1.818885 Acc@1: 0.593705 (ε = 3.35, δ = 1e-05) for α = 7.6
	Train Epoch: 17 	Loss: 1.892408 Acc@1: 0.600497 (ε = 3.39, δ = 1e-05) for α = 7.5
	Train Epoch: 17 	Loss: 1.855371 Acc@1: 0.606696 (ε = 3.43, δ = 1e-05) for α = 7.4
	Test set:Loss: 1.954763 Acc@1: 0.591338 
	Train Epoch: 18 	Loss: 1.869145 Acc@1: 0.619970 (ε = 3.45, δ = 1e-05) for α = 7.4
	Train Epoch: 18 	Loss: 1.834461 Acc@1: 0.598863 (ε = 3.49, δ = 1e-05) for α = 7.4
	Train Epoch: 18 	Loss: 1.848137 Acc@1: 0.596228 (ε = 3.52, δ = 1e-05) for α = 7.3
	Test set:Loss: 1.886786 Acc@1: 0.602919 
	Train Epoch: 19 	Loss: 1.933240 Acc@1: 0.586486 (ε = 3.54, δ = 1e-05) for α = 7.3
	Train Epoch: 19 	Loss: 1.780878 Acc@1: 0.609203 (ε = 3.58, δ = 1e-05) for α = 7.2
	Train Epoch: 19 	Loss: 1.802467 Acc@1: 0.604723 (ε = 3.62, δ = 1e-05) for α = 7.2
	Test set:Loss: 1.826274 Acc@1: 0.606330 
	Train Epoch: 20 	Loss: 1.892009 Acc@1: 0.603022 (ε = 3.64, δ = 1e-05) for α = 7.1
	Train Epoch: 20 	Loss: 1.843104 Acc@1: 0.618242 (ε = 3.67, δ = 1e-05) for α = 7.1
	Train Epoch: 20 	Loss: 1.863556 Acc@1: 0.616815 (ε = 3.71, δ = 1e-05) for α = 7.0
	Test set:Loss: 1.886277 Acc@1: 0.608194 
	Train Epoch: 21 	Loss: 1.977482 Acc@1: 0.592068 (ε = 3.73, δ = 1e-05) for α = 7.0
	Train Epoch: 21 	Loss: 1.913542 Acc@1: 0.592026 (ε = 3.76, δ = 1e-05) for α = 7.0
	Train Epoch: 21 	Loss: 1.871025 Acc@1: 0.596350 (ε = 3.80, δ = 1e-05) for α = 6.9
	Test set:Loss: 1.924732 Acc@1: 0.589098 
	Train Epoch: 22 	Loss: 1.872743 Acc@1: 0.594030 (ε = 3.82, δ = 1e-05) for α = 6.9
	Train Epoch: 22 	Loss: 1.893666 Acc@1: 0.589741 (ε = 3.85, δ = 1e-05) for α = 6.8
	Train Epoch: 22 	Loss: 1.835792 Acc@1: 0.604339 (ε = 3.89, δ = 1e-05) for α = 6.8
	Test set:Loss: 1.818175 Acc@1: 0.615179 
	Train Epoch: 23 	Loss: 1.763039 Acc@1: 0.646043 (ε = 3.90, δ = 1e-05) for α = 6.8
	Train Epoch: 23 	Loss: 1.726958 Acc@1: 0.631248 (ε = 3.94, δ = 1e-05) for α = 6.7
	Train Epoch: 23 	Loss: 1.708391 Acc@1: 0.625227 (ε = 3.97, δ = 1e-05) for α = 6.7
	Test set:Loss: 1.721694 Acc@1: 0.616858 
	Train Epoch: 24 	Loss: 1.693188 Acc@1: 0.623188 (ε = 3.99, δ = 1e-05) for α = 6.7
	Train Epoch: 24 	Loss: 1.707229 Acc@1: 0.623068 (ε = 4.02, δ = 1e-05) for α = 6.6
	Train Epoch: 24 	Loss: 1.719304 Acc@1: 0.620064 (ε = 4.06, δ = 1e-05) for α = 6.6
	Test set:Loss: 1.706241 Acc@1: 0.609850 
	Train Epoch: 25 	Loss: 1.544399 Acc@1: 0.618421 (ε = 4.08, δ = 1e-05) for α = 6.6
	Train Epoch: 25 	Loss: 1.695739 Acc@1: 0.626741 (ε = 4.11, δ = 1e-05) for α = 6.5
	Train Epoch: 25 	Loss: 1.714104 Acc@1: 0.620858 (ε = 4.14, δ = 1e-05) for α = 6.5
	Test set:Loss: 1.738842 Acc@1: 0.618015 
	Train Epoch: 26 	Loss: 1.850376 Acc@1: 0.599144 (ε = 4.16, δ = 1e-05) for α = 6.5
	Train Epoch: 26 	Loss: 1.732951 Acc@1: 0.618813 (ε = 4.19, δ = 1e-05) for α = 6.4
	Train Epoch: 26 	Loss: 1.684856 Acc@1: 0.624293 (ε = 4.22, δ = 1e-05) for α = 6.4
	Test set:Loss: 1.717204 Acc@1: 0.615196 
	Train Epoch: 27 	Loss: 1.649583 Acc@1: 0.606789 (ε = 4.24, δ = 1e-05) for α = 6.4
	Train Epoch: 27 	Loss: 1.614494 Acc@1: 0.618454 (ε = 4.27, δ = 1e-05) for α = 6.4
	Train Epoch: 27 	Loss: 1.649787 Acc@1: 0.622128 (ε = 4.30, δ = 1e-05) for α = 6.3
	Test set:Loss: 1.801214 Acc@1: 0.621505 
	Train Epoch: 28 	Loss: 1.630229 Acc@1: 0.647230 (ε = 4.32, δ = 1e-05) for α = 6.3
	Train Epoch: 28 	Loss: 1.721209 Acc@1: 0.622420 (ε = 4.35, δ = 1e-05) for α = 6.3
	Train Epoch: 28 	Loss: 1.679670 Acc@1: 0.624606 (ε = 4.38, δ = 1e-05) for α = 6.2
	Test set:Loss: 1.771253 Acc@1: 0.619939 
	Train Epoch: 29 	Loss: 1.810099 Acc@1: 0.607578 (ε = 4.40, δ = 1e-05) for α = 6.2
	Train Epoch: 29 	Loss: 1.716153 Acc@1: 0.613998 (ε = 4.43, δ = 1e-05) for α = 6.2
	Train Epoch: 29 	Loss: 1.685666 Acc@1: 0.624047 (ε = 4.46, δ = 1e-05) for α = 6.2
	Test set:Loss: 1.649856 Acc@1: 0.631597 
	Train Epoch: 30 	Loss: 1.783920 Acc@1: 0.631503 (ε = 4.48, δ = 1e-05) for α = 6.1
	Train Epoch: 30 	Loss: 1.654892 Acc@1: 0.635967 (ε = 4.51, δ = 1e-05) for α = 6.1
	Train Epoch: 30 	Loss: 1.616933 Acc@1: 0.641994 (ε = 4.54, δ = 1e-05) for α = 6.1
	Test set:Loss: 1.575329 Acc@1: 0.629211 
	Train Epoch: 31 	Loss: 1.599777 Acc@1: 0.623512 (ε = 4.55, δ = 1e-05) for α = 6.1
	Train Epoch: 31 	Loss: 1.532697 Acc@1: 0.651169 (ε = 4.58, δ = 1e-05) for α = 6.0
	Train Epoch: 31 	Loss: 1.543455 Acc@1: 0.650158 (ε = 4.61, δ = 1e-05) for α = 6.0
	Test set:Loss: 1.625292 Acc@1: 0.639761 
	Train Epoch: 32 	Loss: 1.653972 Acc@1: 0.644886 (ε = 4.63, δ = 1e-05) for α = 6.0
	Train Epoch: 32 	Loss: 1.608773 Acc@1: 0.642906 (ε = 4.66, δ = 1e-05) for α = 6.0
	Train Epoch: 32 	Loss: 1.629214 Acc@1: 0.640171 (ε = 4.69, δ = 1e-05) for α = 6.0
	Test set:Loss: 1.615880 Acc@1: 0.628153 
	Train Epoch: 33 	Loss: 1.602172 Acc@1: 0.624501 (ε = 4.70, δ = 1e-05) for α = 5.9
	Train Epoch: 33 	Loss: 1.629073 Acc@1: 0.629451 (ε = 4.73, δ = 1e-05) for α = 5.9
	Train Epoch: 33 	Loss: 1.598224 Acc@1: 0.635178 (ε = 4.76, δ = 1e-05) for α = 5.9
	Test set:Loss: 1.630981 Acc@1: 0.639547 
	Train Epoch: 34 	Loss: 1.552431 Acc@1: 0.651297 (ε = 4.78, δ = 1e-05) for α = 5.9
	Train Epoch: 34 	Loss: 1.456709 Acc@1: 0.653192 (ε = 4.81, δ = 1e-05) for α = 5.8
	Train Epoch: 34 	Loss: 1.506343 Acc@1: 0.647745 (ε = 4.83, δ = 1e-05) for α = 5.8
	Test set:Loss: 1.663099 Acc@1: 0.635306 
	Train Epoch: 35 	Loss: 1.503576 Acc@1: 0.642651 (ε = 4.85, δ = 1e-05) for α = 5.8
	Train Epoch: 35 	Loss: 1.501260 Acc@1: 0.650008 (ε = 4.88, δ = 1e-05) for α = 5.8
	Train Epoch: 35 	Loss: 1.517682 Acc@1: 0.651276 (ε = 4.91, δ = 1e-05) for α = 5.8
	Test set:Loss: 1.612084 Acc@1: 0.637671 
	Train Epoch: 36 	Loss: 1.577323 Acc@1: 0.667626 (ε = 4.92, δ = 1e-05) for α = 5.8
	Train Epoch: 36 	Loss: 1.525160 Acc@1: 0.648052 (ε = 4.95, δ = 1e-05) for α = 5.7
	Train Epoch: 36 	Loss: 1.526786 Acc@1: 0.646352 (ε = 4.98, δ = 1e-05) for α = 5.7
	Test set:Loss: 1.631726 Acc@1: 0.634533 
	Train Epoch: 37 	Loss: 1.598281 Acc@1: 0.620944 (ε = 4.99, δ = 1e-05) for α = 5.7
	Train Epoch: 37 	Loss: 1.503036 Acc@1: 0.652857 (ε = 5.02, δ = 1e-05) for α = 5.7
	Train Epoch: 37 	Loss: 1.493957 Acc@1: 0.649718 (ε = 5.05, δ = 1e-05) for α = 5.6
	Test set:Loss: 1.578749 Acc@1: 0.637620 
	Train Epoch: 38 	Loss: 1.538037 Acc@1: 0.640845 (ε = 5.06, δ = 1e-05) for α = 5.6
	Train Epoch: 38 	Loss: 1.534788 Acc@1: 0.649495 (ε = 5.09, δ = 1e-05) for α = 5.6
	Train Epoch: 38 	Loss: 1.493670 Acc@1: 0.656721 (ε = 5.12, δ = 1e-05) for α = 5.6
	Test set:Loss: 1.605342 Acc@1: 0.644962 
	Train Epoch: 39 	Loss: 1.492995 Acc@1: 0.680328 (ε = 5.13, δ = 1e-05) for α = 5.6
	Train Epoch: 39 	Loss: 1.490213 Acc@1: 0.667369 (ε = 5.16, δ = 1e-05) for α = 5.6
	Train Epoch: 39 	Loss: 1.486698 Acc@1: 0.662908 (ε = 5.19, δ = 1e-05) for α = 5.5
	Test set:Loss: 1.545439 Acc@1: 0.647103 
	Train Epoch: 40 	Loss: 1.395880 Acc@1: 0.649783 (ε = 5.20, δ = 1e-05) for α = 5.5
	Train Epoch: 40 	Loss: 1.512967 Acc@1: 0.664643 (ε = 5.23, δ = 1e-05) for α = 5.5
	Train Epoch: 40 	Loss: 1.480109 Acc@1: 0.662910 (ε = 5.25, δ = 1e-05) for α = 5.5
	Test set:Loss: 1.588151 Acc@1: 0.646692 
	Train Epoch: 41 	Loss: 1.663520 Acc@1: 0.664223 (ε = 5.27, δ = 1e-05) for α = 5.5
	Train Epoch: 41 	Loss: 1.481810 Acc@1: 0.663454 (ε = 5.29, δ = 1e-05) for α = 5.5
	Train Epoch: 41 	Loss: 1.487572 Acc@1: 0.663131 (ε = 5.32, δ = 1e-05) for α = 5.4
	Test set:Loss: 1.536593 Acc@1: 0.649380 
	Train Epoch: 42 	Loss: 1.466233 Acc@1: 0.673729 (ε = 5.33, δ = 1e-05) for α = 5.4
	Train Epoch: 42 	Loss: 1.453939 Acc@1: 0.657601 (ε = 5.36, δ = 1e-05) for α = 5.4
	Train Epoch: 42 	Loss: 1.433981 Acc@1: 0.658495 (ε = 5.39, δ = 1e-05) for α = 5.4
	Test set:Loss: 1.534013 Acc@1: 0.646980 
	Train Epoch: 43 	Loss: 1.499517 Acc@1: 0.669096 (ε = 5.40, δ = 1e-05) for α = 5.4
	Train Epoch: 43 	Loss: 1.420416 Acc@1: 0.661435 (ε = 5.43, δ = 1e-05) for α = 5.4
	Train Epoch: 43 	Loss: 1.450614 Acc@1: 0.658320 (ε = 5.45, δ = 1e-05) for α = 5.4
	Test set:Loss: 1.512391 Acc@1: 0.652071 
	Train Epoch: 44 	Loss: 1.396781 Acc@1: 0.653392 (ε = 5.47, δ = 1e-05) for α = 5.3
	Train Epoch: 44 	Loss: 1.433287 Acc@1: 0.664376 (ε = 5.49, δ = 1e-05) for α = 5.3
	Train Epoch: 44 	Loss: 1.415786 Acc@1: 0.665278 (ε = 5.52, δ = 1e-05) for α = 5.3
	Test set:Loss: 1.522018 Acc@1: 0.654510 
	Train Epoch: 45 	Loss: 1.583986 Acc@1: 0.654443 (ε = 5.53, δ = 1e-05) for α = 5.3
	Train Epoch: 45 	Loss: 1.428479 Acc@1: 0.667160 (ε = 5.56, δ = 1e-05) for α = 5.3
	Train Epoch: 45 	Loss: 1.426270 Acc@1: 0.663892 (ε = 5.58, δ = 1e-05) for α = 5.3
	Test set:Loss: 1.525574 Acc@1: 0.651450 
	Train Epoch: 46 	Loss: 1.492214 Acc@1: 0.642757 (ε = 5.60, δ = 1e-05) for α = 5.3
	Train Epoch: 46 	Loss: 1.411230 Acc@1: 0.667476 (ε = 5.62, δ = 1e-05) for α = 5.2
	Train Epoch: 46 	Loss: 1.439113 Acc@1: 0.667542 (ε = 5.65, δ = 1e-05) for α = 5.2
	Test set:Loss: 1.492745 Acc@1: 0.653230 
	Train Epoch: 47 	Loss: 1.405941 Acc@1: 0.668122 (ε = 5.66, δ = 1e-05) for α = 5.2
	Train Epoch: 47 	Loss: 1.430319 Acc@1: 0.664426 (ε = 5.69, δ = 1e-05) for α = 5.2
	Train Epoch: 47 	Loss: 1.410875 Acc@1: 0.666259 (ε = 5.71, δ = 1e-05) for α = 5.2
	Test set:Loss: 1.508632 Acc@1: 0.657926 
	Train Epoch: 48 	Loss: 1.531782 Acc@1: 0.645802 (ε = 5.72, δ = 1e-05) for α = 5.2
	Train Epoch: 48 	Loss: 1.407742 Acc@1: 0.670693 (ε = 5.75, δ = 1e-05) for α = 5.2
	Train Epoch: 48 	Loss: 1.389850 Acc@1: 0.673817 (ε = 5.77, δ = 1e-05) for α = 5.1
	Test set:Loss: 1.497476 Acc@1: 0.656607 
	Train Epoch: 49 	Loss: 1.439813 Acc@1: 0.663900 (ε = 5.79, δ = 1e-05) for α = 5.1
	Train Epoch: 49 	Loss: 1.403082 Acc@1: 0.672861 (ε = 5.81, δ = 1e-05) for α = 5.1
	Train Epoch: 49 	Loss: 1.384826 Acc@1: 0.674207 (ε = 5.84, δ = 1e-05) for α = 5.1
	Test set:Loss: 1.490087 Acc@1: 0.659029 
	Train Epoch: 50 	Loss: 1.345015 Acc@1: 0.696839 (ε = 5.85, δ = 1e-05) for α = 5.1
	Train Epoch: 50 	Loss: 1.355657 Acc@1: 0.673213 (ε = 5.87, δ = 1e-05) for α = 5.1
	Train Epoch: 50 	Loss: 1.334712 Acc@1: 0.679111 (ε = 5.90, δ = 1e-05) for α = 5.1
	Test set:Loss: 1.492309 Acc@1: 0.658224 
	Train Epoch: 51 	Loss: 1.415679 Acc@1: 0.673295 (ε = 5.91, δ = 1e-05) for α = 5.1
	Train Epoch: 51 	Loss: 1.382634 Acc@1: 0.672284 (ε = 5.93, δ = 1e-05) for α = 5.0
	Train Epoch: 51 	Loss: 1.362388 Acc@1: 0.679176 (ε = 5.96, δ = 1e-05) for α = 5.0
	Test set:Loss: 1.499258 Acc@1: 0.658035 
	Train Epoch: 52 	Loss: 1.407254 Acc@1: 0.682759 (ε = 5.97, δ = 1e-05) for α = 5.0
	Train Epoch: 52 	Loss: 1.398246 Acc@1: 0.674606 (ε = 6.00, δ = 1e-05) for α = 5.0
	Train Epoch: 52 	Loss: 1.370770 Acc@1: 0.678911 (ε = 6.02, δ = 1e-05) for α = 5.0
	Test set:Loss: 1.474111 Acc@1: 0.658802 
	Train Epoch: 53 	Loss: 1.271378 Acc@1: 0.685265 (ε = 6.03, δ = 1e-05) for α = 5.0
	Train Epoch: 53 	Loss: 1.317629 Acc@1: 0.684244 (ε = 6.06, δ = 1e-05) for α = 5.0
	Train Epoch: 53 	Loss: 1.307567 Acc@1: 0.686314 (ε = 6.08, δ = 1e-05) for α = 5.0
	Test set:Loss: 1.494727 Acc@1: 0.656415 
	Train Epoch: 54 	Loss: 1.469861 Acc@1: 0.677143 (ε = 6.09, δ = 1e-05) for α = 5.0
	Train Epoch: 54 	Loss: 1.319847 Acc@1: 0.681201 (ε = 6.12, δ = 1e-05) for α = 4.9
	Train Epoch: 54 	Loss: 1.329889 Acc@1: 0.683320 (ε = 6.14, δ = 1e-05) for α = 4.9
	Test set:Loss: 1.469086 Acc@1: 0.661404 
	Train Epoch: 55 	Loss: 1.386626 Acc@1: 0.670940 (ε = 6.15, δ = 1e-05) for α = 4.9
	Train Epoch: 55 	Loss: 1.366310 Acc@1: 0.674949 (ε = 6.18, δ = 1e-05) for α = 4.9
	Train Epoch: 55 	Loss: 1.379670 Acc@1: 0.673465 (ε = 6.20, δ = 1e-05) for α = 4.9
	Test set:Loss: 1.454550 Acc@1: 0.660917 
	Train Epoch: 56 	Loss: 1.253480 Acc@1: 0.697234 (ε = 6.21, δ = 1e-05) for α = 4.9
	Train Epoch: 56 	Loss: 1.304968 Acc@1: 0.687289 (ε = 6.23, δ = 1e-05) for α = 4.9
	Train Epoch: 56 	Loss: 1.344224 Acc@1: 0.679200 (ε = 6.26, δ = 1e-05) for α = 4.9
	Test set:Loss: 1.457635 Acc@1: 0.660713 
	Train Epoch: 57 	Loss: 1.378797 Acc@1: 0.664653 (ε = 6.27, δ = 1e-05) for α = 4.9
	Train Epoch: 57 	Loss: 1.361198 Acc@1: 0.676434 (ε = 6.29, δ = 1e-05) for α = 4.9
	Train Epoch: 57 	Loss: 1.345675 Acc@1: 0.678843 (ε = 6.32, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.454739 Acc@1: 0.661569 
	Train Epoch: 58 	Loss: 1.320091 Acc@1: 0.692420 (ε = 6.33, δ = 1e-05) for α = 4.8
	Train Epoch: 58 	Loss: 1.343341 Acc@1: 0.682014 (ε = 6.35, δ = 1e-05) for α = 4.8
	Train Epoch: 58 	Loss: 1.350706 Acc@1: 0.680887 (ε = 6.38, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.452994 Acc@1: 0.661441 
	Train Epoch: 59 	Loss: 1.282404 Acc@1: 0.689956 (ε = 6.39, δ = 1e-05) for α = 4.8
	Train Epoch: 59 	Loss: 1.354677 Acc@1: 0.679280 (ε = 6.41, δ = 1e-05) for α = 4.8
	Train Epoch: 59 	Loss: 1.350691 Acc@1: 0.678792 (ε = 6.43, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.448240 Acc@1: 0.662167 
	Train Epoch: 60 	Loss: 1.206897 Acc@1: 0.705307 (ε = 6.44, δ = 1e-05) for α = 4.8
	Train Epoch: 60 	Loss: 1.257293 Acc@1: 0.693968 (ε = 6.47, δ = 1e-05) for α = 4.8
	Train Epoch: 60 	Loss: 1.294369 Acc@1: 0.687054 (ε = 6.49, δ = 1e-05) for α = 4.8
	Test set:Loss: 1.449020 Acc@1: 0.661751 
test results
Base private model accuracy:  0.6619428571428572
              precision    recall  f1-score   support

         0.0       0.31      0.10      0.15       502
         1.0       0.30      0.13      0.19       502
         2.0       0.24      0.09      0.14       508
         3.0       0.05      0.01      0.02       492
         4.0       0.26      0.11      0.16       499
         5.0       0.59      0.69      0.64      2992
         6.0       0.76      0.79      0.77      3082
         7.0       0.66      0.69      0.67      2973
         8.0       0.72      0.82      0.76      3007
         9.0       0.71      0.79      0.75      2943

    accuracy                           0.66     17500
   macro avg       0.46      0.42      0.42     17500
weighted avg       0.62      0.66      0.63     17500

train results
Base private model accuracy:  0.6755831859921291
              precision    recall  f1-score   support

         0.0       0.29      0.09      0.14       475
         1.0       0.44      0.19      0.26       521
         2.0       0.34      0.13      0.19       502
         3.0       0.07      0.01      0.02       496
         4.0       0.40      0.13      0.20       520
         5.0       0.60      0.70      0.65      2989
         6.0       0.74      0.80      0.77      2954
         7.0       0.67      0.71      0.69      2968
         8.0       0.72      0.83      0.77      3055
         9.0       0.73      0.81      0.77      3053

    accuracy                           0.68     17533
   macro avg       0.50      0.44      0.45     17533
weighted avg       0.64      0.68      0.65     17533

NN model attack results: 
train acc: 0.7045908183632734
test acc: 0.49542857142857144
total acc: 0.6001141715427429
precision, recall: (0.5831956573046967, 0.7045908183632734)
epsilon, acc, train acc, mia, report, train report
[6.5000187075137905, 0.6619428571428572, 0.6755831859921291, 0.6001141715427429, '              precision    recall  f1-score   support\n\n         0.0       0.31      0.10      0.15       502\n         1.0       0.30      0.13      0.19       502\n         2.0       0.24      0.09      0.14       508\n         3.0       0.05      0.01      0.02       492\n         4.0       0.26      0.11      0.16       499\n         5.0       0.59      0.69      0.64      2992\n         6.0       0.76      0.79      0.77      3082\n         7.0       0.66      0.69      0.67      2973\n         8.0       0.72      0.82      0.76      3007\n         9.0       0.71      0.79      0.75      2943\n\n    accuracy                           0.66     17500\n   macro avg       0.46      0.42      0.42     17500\nweighted avg       0.62      0.66      0.63     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.29      0.09      0.14       475\n         1.0       0.44      0.19      0.26       521\n         2.0       0.34      0.13      0.19       502\n         3.0       0.07      0.01      0.02       496\n         4.0       0.40      0.13      0.20       520\n         5.0       0.60      0.70      0.65      2989\n         6.0       0.74      0.80      0.77      2954\n         7.0       0.67      0.71      0.69      2968\n         8.0       0.72      0.83      0.77      3055\n         9.0       0.73      0.81      0.77      3053\n\n    accuracy                           0.68     17533\n   macro avg       0.50      0.44      0.45     17533\nweighted avg       0.64      0.68      0.65     17533\n']
experiment_number: 121
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-121.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 2.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[9. 7. 5. ... 8. 9. 7.]
[5. 8. 9. ... 9. 9. 0.]
(17563, 3, 32, 32)
(17500, 3, 32, 32)
(17563, 3, 32, 32)
(17563,)
	Train Epoch: 1 	Loss: 2.315751 Acc@1: 0.022989 (ε = 0.48, δ = 1e-05) for α = 26.0
	Train Epoch: 1 	Loss: 2.188247 Acc@1: 0.150381 (ε = 0.58, δ = 1e-05) for α = 25.0
	Train Epoch: 1 	Loss: 2.079412 Acc@1: 0.216691 (ε = 0.67, δ = 1e-05) for α = 24.0
	Test set:Loss: 1.889740 Acc@1: 0.334059 
	Train Epoch: 2 	Loss: 1.888656 Acc@1: 0.324812 (ε = 0.71, δ = 1e-05) for α = 24.0
	Train Epoch: 2 	Loss: 1.925660 Acc@1: 0.403715 (ε = 0.79, δ = 1e-05) for α = 23.0
	Train Epoch: 2 	Loss: 1.900839 Acc@1: 0.417323 (ε = 0.86, δ = 1e-05) for α = 23.0
	Test set:Loss: 1.702661 Acc@1: 0.509789 
	Train Epoch: 3 	Loss: 1.587745 Acc@1: 0.513140 (ε = 0.90, δ = 1e-05) for α = 22.0
	Train Epoch: 3 	Loss: 1.973151 Acc@1: 0.478784 (ε = 0.97, δ = 1e-05) for α = 21.0
	Train Epoch: 3 	Loss: 1.913989 Acc@1: 0.492952 (ε = 1.03, δ = 1e-05) for α = 20.0
	Test set:Loss: 1.697194 Acc@1: 0.543013 
	Train Epoch: 4 	Loss: 1.601264 Acc@1: 0.537293 (ε = 1.06, δ = 1e-05) for α = 20.0
	Train Epoch: 4 	Loss: 1.849814 Acc@1: 0.530492 (ε = 1.12, δ = 1e-05) for α = 19.0
	Train Epoch: 4 	Loss: 2.023781 Acc@1: 0.523781 (ε = 1.17, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.043330 Acc@1: 0.504989 
	Train Epoch: 5 	Loss: 2.064686 Acc@1: 0.494721 (ε = 1.20, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.066963 Acc@1: 0.499599 (ε = 1.25, δ = 1e-05) for α = 18.0
	Train Epoch: 5 	Loss: 2.009258 Acc@1: 0.505592 (ε = 1.30, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.172240 Acc@1: 0.530578 
	Train Epoch: 6 	Loss: 2.232671 Acc@1: 0.516031 (ε = 1.32, δ = 1e-05) for α = 17.0
	Train Epoch: 6 	Loss: 2.116829 Acc@1: 0.524689 (ε = 1.37, δ = 1e-05) for α = 16.0
	Train Epoch: 6 	Loss: 2.120566 Acc@1: 0.536126 (ε = 1.41, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.326619 Acc@1: 0.527765 
	Train Epoch: 7 	Loss: 2.284928 Acc@1: 0.509943 (ε = 1.44, δ = 1e-05) for α = 16.0
	Train Epoch: 7 	Loss: 2.458181 Acc@1: 0.502947 (ε = 1.48, δ = 1e-05) for α = 15.0
	Train Epoch: 7 	Loss: 2.346864 Acc@1: 0.512889 (ε = 1.52, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.559497 Acc@1: 0.521436 
	Train Epoch: 8 	Loss: 2.500083 Acc@1: 0.533775 (ε = 1.54, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.475203 Acc@1: 0.513276 (ε = 1.58, δ = 1e-05) for α = 15.0
	Train Epoch: 8 	Loss: 2.550708 Acc@1: 0.508868 (ε = 1.62, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.585319 Acc@1: 0.507468 
	Train Epoch: 9 	Loss: 2.741855 Acc@1: 0.506024 (ε = 1.64, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.513585 Acc@1: 0.516637 (ε = 1.68, δ = 1e-05) for α = 14.0
	Train Epoch: 9 	Loss: 2.481881 Acc@1: 0.516296 (ε = 1.71, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.318523 Acc@1: 0.514392 
	Train Epoch: 10 	Loss: 2.205811 Acc@1: 0.528591 (ε = 1.73, δ = 1e-05) for α = 14.0
	Train Epoch: 10 	Loss: 2.359694 Acc@1: 0.522735 (ε = 1.77, δ = 1e-05) for α = 13.0
	Train Epoch: 10 	Loss: 2.322201 Acc@1: 0.520620 (ε = 1.80, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.195526 Acc@1: 0.516765 
	Train Epoch: 11 	Loss: 2.206181 Acc@1: 0.522111 (ε = 1.82, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.201101 Acc@1: 0.516787 (ε = 1.85, δ = 1e-05) for α = 13.0
	Train Epoch: 11 	Loss: 2.176792 Acc@1: 0.525237 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.124094 Acc@1: 0.537674 
	Train Epoch: 12 	Loss: 1.962322 Acc@1: 0.563107 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 12 	Loss: 2.136806 Acc@1: 0.532720 (ε = 1.94, δ = 1e-05) for α = 12.0
	Train Epoch: 12 	Loss: 2.160587 Acc@1: 0.525419 (ε = 1.97, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.058885 Acc@1: 0.529276 
	Train Epoch: 13 	Loss: 2.042410 Acc@1: 0.540382 (ε = 1.98, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 2.049575 Acc@1: 0.535447 (ε = 2.01, δ = 1e-05) for α = 12.0
	Train Epoch: 13 	Loss: 2.031874 Acc@1: 0.539377 (ε = 2.05, δ = 1e-05) for α = 12.0
	Test set:Loss: 1.947397 Acc@1: 0.544643 
	Train Epoch: 14 	Loss: 2.145562 Acc@1: 0.517832 (ε = 2.06, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 1.974481 Acc@1: 0.530390 (ε = 2.09, δ = 1e-05) for α = 12.0
	Train Epoch: 14 	Loss: 1.966773 Acc@1: 0.530289 (ε = 2.12, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.258185 Acc@1: 0.519487 
	Train Epoch: 15 	Loss: 2.300900 Acc@1: 0.520167 (ε = 2.14, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 2.031789 Acc@1: 0.539690 (ε = 2.17, δ = 1e-05) for α = 10.9
	Train Epoch: 15 	Loss: 2.048351 Acc@1: 0.528954 (ε = 2.20, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.050027 Acc@1: 0.543247 
	Train Epoch: 16 	Loss: 2.021090 Acc@1: 0.529840 (ε = 2.21, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 2.010133 Acc@1: 0.545752 (ε = 2.24, δ = 1e-05) for α = 10.9
	Train Epoch: 16 	Loss: 2.027034 Acc@1: 0.544775 (ε = 2.26, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.189943 Acc@1: 0.539259 
	Train Epoch: 17 	Loss: 2.152036 Acc@1: 0.515604 (ε = 2.28, δ = 1e-05) for α = 10.9
	Train Epoch: 17 	Loss: 1.906766 Acc@1: 0.553833 (ε = 2.31, δ = 1e-05) for α = 10.7
	Train Epoch: 17 	Loss: 1.941262 Acc@1: 0.542482 (ε = 2.33, δ = 1e-05) for α = 10.6
	Test set:Loss: 1.951254 Acc@1: 0.533596 
	Train Epoch: 18 	Loss: 1.938442 Acc@1: 0.530612 (ε = 2.35, δ = 1e-05) for α = 10.6
	Train Epoch: 18 	Loss: 1.979629 Acc@1: 0.538123 (ε = 2.37, δ = 1e-05) for α = 10.5
	Train Epoch: 18 	Loss: 1.962219 Acc@1: 0.544882 (ε = 2.40, δ = 1e-05) for α = 10.4
	Test set:Loss: 1.955102 Acc@1: 0.547170 
	Train Epoch: 19 	Loss: 2.036279 Acc@1: 0.543704 (ε = 2.41, δ = 1e-05) for α = 10.4
	Train Epoch: 19 	Loss: 1.923740 Acc@1: 0.537139 (ε = 2.44, δ = 1e-05) for α = 10.3
	Train Epoch: 19 	Loss: 1.930108 Acc@1: 0.542959 (ε = 2.47, δ = 1e-05) for α = 10.2
	Test set:Loss: 2.123052 Acc@1: 0.543065 
	Train Epoch: 20 	Loss: 2.052993 Acc@1: 0.546628 (ε = 2.48, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 2.052594 Acc@1: 0.531676 (ε = 2.50, δ = 1e-05) for α = 10.1
	Train Epoch: 20 	Loss: 2.004392 Acc@1: 0.536752 (ε = 2.53, δ = 1e-05) for α = 10.0
	Test set:Loss: 1.889565 Acc@1: 0.546530 
	Train Epoch: 21 	Loss: 1.786017 Acc@1: 0.551724 (ε = 2.54, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.898751 Acc@1: 0.541184 (ε = 2.57, δ = 1e-05) for α = 9.9
	Train Epoch: 21 	Loss: 1.927547 Acc@1: 0.547869 (ε = 2.59, δ = 1e-05) for α = 9.8
	Test set:Loss: 2.010342 Acc@1: 0.553134 
	Train Epoch: 22 	Loss: 2.049329 Acc@1: 0.555066 (ε = 2.60, δ = 1e-05) for α = 9.8
	Train Epoch: 22 	Loss: 2.018143 Acc@1: 0.536675 (ε = 2.63, δ = 1e-05) for α = 9.7
	Train Epoch: 22 	Loss: 2.039127 Acc@1: 0.545446 (ε = 2.65, δ = 1e-05) for α = 9.6
	Test set:Loss: 2.002457 Acc@1: 0.533790 
	Train Epoch: 23 	Loss: 1.810577 Acc@1: 0.558140 (ε = 2.66, δ = 1e-05) for α = 9.6
	Train Epoch: 23 	Loss: 2.000676 Acc@1: 0.549911 (ε = 2.69, δ = 1e-05) for α = 9.5
	Train Epoch: 23 	Loss: 2.017743 Acc@1: 0.544232 (ε = 2.71, δ = 1e-05) for α = 9.4
	Test set:Loss: 1.857547 Acc@1: 0.539510 
	Train Epoch: 24 	Loss: 1.650801 Acc@1: 0.583697 (ε = 2.72, δ = 1e-05) for α = 9.4
	Train Epoch: 24 	Loss: 1.861349 Acc@1: 0.547914 (ε = 2.75, δ = 1e-05) for α = 9.3
	Train Epoch: 24 	Loss: 1.891749 Acc@1: 0.548992 (ε = 2.77, δ = 1e-05) for α = 9.3
	Test set:Loss: 2.181528 Acc@1: 0.531536 
	Train Epoch: 25 	Loss: 2.273117 Acc@1: 0.542424 (ε = 2.78, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.966058 Acc@1: 0.535139 (ε = 2.80, δ = 1e-05) for α = 9.2
	Train Epoch: 25 	Loss: 1.969089 Acc@1: 0.537267 (ε = 2.83, δ = 1e-05) for α = 9.1
	Test set:Loss: 2.098748 Acc@1: 0.549349 
	Train Epoch: 26 	Loss: 1.942134 Acc@1: 0.570845 (ε = 2.84, δ = 1e-05) for α = 9.1
	Train Epoch: 26 	Loss: 1.846364 Acc@1: 0.572352 (ε = 2.86, δ = 1e-05) for α = 9.0
	Train Epoch: 26 	Loss: 1.873996 Acc@1: 0.565932 (ε = 2.88, δ = 1e-05) for α = 9.0
	Test set:Loss: 1.954646 Acc@1: 0.547392 
	Train Epoch: 27 	Loss: 1.895071 Acc@1: 0.541551 (ε = 2.89, δ = 1e-05) for α = 9.0
	Train Epoch: 27 	Loss: 1.847459 Acc@1: 0.575011 (ε = 2.92, δ = 1e-05) for α = 8.9
	Train Epoch: 27 	Loss: 1.837913 Acc@1: 0.572130 (ε = 2.94, δ = 1e-05) for α = 8.9
	Test set:Loss: 1.892487 Acc@1: 0.553668 
	Train Epoch: 28 	Loss: 1.928649 Acc@1: 0.543885 (ε = 2.95, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.853412 Acc@1: 0.555765 (ε = 2.97, δ = 1e-05) for α = 8.8
	Train Epoch: 28 	Loss: 1.847179 Acc@1: 0.554670 (ε = 2.99, δ = 1e-05) for α = 8.7
	Test set:Loss: 1.923132 Acc@1: 0.551187 
	Train Epoch: 29 	Loss: 1.743480 Acc@1: 0.567847 (ε = 3.00, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.964854 Acc@1: 0.563593 (ε = 3.03, δ = 1e-05) for α = 8.7
	Train Epoch: 29 	Loss: 1.926449 Acc@1: 0.562390 (ε = 3.05, δ = 1e-05) for α = 8.6
	Test set:Loss: 1.888513 Acc@1: 0.560546 
	Train Epoch: 30 	Loss: 1.872956 Acc@1: 0.558824 (ε = 3.06, δ = 1e-05) for α = 8.6
	Train Epoch: 30 	Loss: 1.860656 Acc@1: 0.571169 (ε = 3.08, δ = 1e-05) for α = 8.5
	Train Epoch: 30 	Loss: 1.831061 Acc@1: 0.571363 (ε = 3.10, δ = 1e-05) for α = 8.5
	Test set:Loss: 1.817518 Acc@1: 0.573800 
	Train Epoch: 31 	Loss: 1.750782 Acc@1: 0.596317 (ε = 3.11, δ = 1e-05) for α = 8.5
	Train Epoch: 31 	Loss: 1.932755 Acc@1: 0.571147 (ε = 3.13, δ = 1e-05) for α = 8.4
	Train Epoch: 31 	Loss: 1.914195 Acc@1: 0.571895 (ε = 3.15, δ = 1e-05) for α = 8.4
	Test set:Loss: 1.807664 Acc@1: 0.577537 
	Train Epoch: 32 	Loss: 1.932039 Acc@1: 0.548991 (ε = 3.16, δ = 1e-05) for α = 8.4
	Train Epoch: 32 	Loss: 1.792857 Acc@1: 0.579138 (ε = 3.18, δ = 1e-05) for α = 8.3
	Train Epoch: 32 	Loss: 1.789838 Acc@1: 0.586599 (ε = 3.20, δ = 1e-05) for α = 8.3
	Test set:Loss: 1.811121 Acc@1: 0.581783 
	Train Epoch: 33 	Loss: 1.849600 Acc@1: 0.579832 (ε = 3.21, δ = 1e-05) for α = 8.2
	Train Epoch: 33 	Loss: 1.841034 Acc@1: 0.581275 (ε = 3.23, δ = 1e-05) for α = 8.2
	Train Epoch: 33 	Loss: 1.857876 Acc@1: 0.575143 (ε = 3.25, δ = 1e-05) for α = 8.2
	Test set:Loss: 1.796005 Acc@1: 0.572634 
	Train Epoch: 34 	Loss: 1.701075 Acc@1: 0.585816 (ε = 3.26, δ = 1e-05) for α = 8.1
	Train Epoch: 34 	Loss: 1.823680 Acc@1: 0.573586 (ε = 3.28, δ = 1e-05) for α = 8.1
	Train Epoch: 34 	Loss: 1.784735 Acc@1: 0.584419 (ε = 3.30, δ = 1e-05) for α = 8.1
	Test set:Loss: 1.791941 Acc@1: 0.590981 
	Train Epoch: 35 	Loss: 1.774870 Acc@1: 0.590846 (ε = 3.31, δ = 1e-05) for α = 8.1
	Train Epoch: 35 	Loss: 1.783033 Acc@1: 0.591086 (ε = 3.33, δ = 1e-05) for α = 8.0
	Train Epoch: 35 	Loss: 1.765972 Acc@1: 0.593783 (ε = 3.35, δ = 1e-05) for α = 8.0
	Test set:Loss: 1.779541 Acc@1: 0.590240 
	Train Epoch: 36 	Loss: 1.715466 Acc@1: 0.616314 (ε = 3.36, δ = 1e-05) for α = 8.0
	Train Epoch: 36 	Loss: 1.761614 Acc@1: 0.598625 (ε = 3.38, δ = 1e-05) for α = 7.9
	Train Epoch: 36 	Loss: 1.779600 Acc@1: 0.595850 (ε = 3.40, δ = 1e-05) for α = 7.9
	Test set:Loss: 1.934050 Acc@1: 0.587358 
	Train Epoch: 37 	Loss: 1.898247 Acc@1: 0.592806 (ε = 3.41, δ = 1e-05) for α = 7.9
	Train Epoch: 37 	Loss: 1.771624 Acc@1: 0.586270 (ε = 3.43, δ = 1e-05) for α = 7.8
	Train Epoch: 37 	Loss: 1.757886 Acc@1: 0.583549 (ε = 3.45, δ = 1e-05) for α = 7.8
	Test set:Loss: 1.792908 Acc@1: 0.581290 
	Train Epoch: 38 	Loss: 1.900225 Acc@1: 0.589958 (ε = 3.46, δ = 1e-05) for α = 7.8
	Train Epoch: 38 	Loss: 1.771179 Acc@1: 0.585419 (ε = 3.48, δ = 1e-05) for α = 7.8
	Train Epoch: 38 	Loss: 1.762240 Acc@1: 0.594014 (ε = 3.50, δ = 1e-05) for α = 7.7
	Test set:Loss: 1.723915 Acc@1: 0.586745 
	Train Epoch: 39 	Loss: 1.514069 Acc@1: 0.584733 (ε = 3.51, δ = 1e-05) for α = 7.7
	Train Epoch: 39 	Loss: 1.683071 Acc@1: 0.593626 (ε = 3.52, δ = 1e-05) for α = 7.7
	Train Epoch: 39 	Loss: 1.682487 Acc@1: 0.598037 (ε = 3.54, δ = 1e-05) for α = 7.6
	Test set:Loss: 1.837630 Acc@1: 0.595515 
	Train Epoch: 40 	Loss: 1.882020 Acc@1: 0.587324 (ε = 3.55, δ = 1e-05) for α = 7.6
	Train Epoch: 40 	Loss: 1.758776 Acc@1: 0.598501 (ε = 3.57, δ = 1e-05) for α = 7.6
	Train Epoch: 40 	Loss: 1.744044 Acc@1: 0.595573 (ε = 3.59, δ = 1e-05) for α = 7.6
	Test set:Loss: 1.811460 Acc@1: 0.578283 
	Train Epoch: 41 	Loss: 1.741762 Acc@1: 0.579109 (ε = 3.60, δ = 1e-05) for α = 7.5
	Train Epoch: 41 	Loss: 1.719873 Acc@1: 0.599284 (ε = 3.62, δ = 1e-05) for α = 7.5
	Train Epoch: 41 	Loss: 1.690773 Acc@1: 0.604689 (ε = 3.63, δ = 1e-05) for α = 7.5
	Test set:Loss: 1.711029 Acc@1: 0.602205 
	Train Epoch: 42 	Loss: 1.875146 Acc@1: 0.589636 (ε = 3.64, δ = 1e-05) for α = 7.5
	Train Epoch: 42 	Loss: 1.719980 Acc@1: 0.611133 (ε = 3.66, δ = 1e-05) for α = 7.4
	Train Epoch: 42 	Loss: 1.695932 Acc@1: 0.613792 (ε = 3.68, δ = 1e-05) for α = 7.4
	Test set:Loss: 1.723025 Acc@1: 0.602375 
	Train Epoch: 43 	Loss: 1.714548 Acc@1: 0.603829 (ε = 3.69, δ = 1e-05) for α = 7.4
	Train Epoch: 43 	Loss: 1.710135 Acc@1: 0.606965 (ε = 3.71, δ = 1e-05) for α = 7.4
	Train Epoch: 43 	Loss: 1.664525 Acc@1: 0.611198 (ε = 3.73, δ = 1e-05) for α = 7.3
	Test set:Loss: 1.696985 Acc@1: 0.600162 
	Train Epoch: 44 	Loss: 1.848079 Acc@1: 0.611367 (ε = 3.73, δ = 1e-05) for α = 7.3
	Train Epoch: 44 	Loss: 1.632330 Acc@1: 0.614407 (ε = 3.75, δ = 1e-05) for α = 7.3
	Train Epoch: 44 	Loss: 1.646168 Acc@1: 0.611150 (ε = 3.77, δ = 1e-05) for α = 7.3
	Test set:Loss: 1.743380 Acc@1: 0.608366 
	Train Epoch: 45 	Loss: 1.701445 Acc@1: 0.619114 (ε = 3.78, δ = 1e-05) for α = 7.3
	Train Epoch: 45 	Loss: 1.609593 Acc@1: 0.629443 (ε = 3.80, δ = 1e-05) for α = 7.2
	Train Epoch: 45 	Loss: 1.633678 Acc@1: 0.627034 (ε = 3.81, δ = 1e-05) for α = 7.2
	Test set:Loss: 1.712758 Acc@1: 0.607780 
	Train Epoch: 46 	Loss: 1.517858 Acc@1: 0.633621 (ε = 3.82, δ = 1e-05) for α = 7.2
	Train Epoch: 46 	Loss: 1.590263 Acc@1: 0.626651 (ε = 3.84, δ = 1e-05) for α = 7.2
	Train Epoch: 46 	Loss: 1.576073 Acc@1: 0.624443 (ε = 3.86, δ = 1e-05) for α = 7.2
	Test set:Loss: 1.724333 Acc@1: 0.592509 
	Train Epoch: 47 	Loss: 1.627854 Acc@1: 0.602528 (ε = 3.87, δ = 1e-05) for α = 7.1
	Train Epoch: 47 	Loss: 1.682642 Acc@1: 0.620314 (ε = 3.88, δ = 1e-05) for α = 7.1
	Train Epoch: 47 	Loss: 1.626637 Acc@1: 0.622238 (ε = 3.90, δ = 1e-05) for α = 7.1
	Test set:Loss: 1.717457 Acc@1: 0.610283 
	Train Epoch: 48 	Loss: 1.591481 Acc@1: 0.619048 (ε = 3.91, δ = 1e-05) for α = 7.1
	Train Epoch: 48 	Loss: 1.597022 Acc@1: 0.612346 (ε = 3.93, δ = 1e-05) for α = 7.1
	Train Epoch: 48 	Loss: 1.598692 Acc@1: 0.612461 (ε = 3.94, δ = 1e-05) for α = 7.0
	Test set:Loss: 1.671480 Acc@1: 0.605331 
	Train Epoch: 49 	Loss: 1.574591 Acc@1: 0.635461 (ε = 3.95, δ = 1e-05) for α = 7.0
	Train Epoch: 49 	Loss: 1.597338 Acc@1: 0.616388 (ε = 3.97, δ = 1e-05) for α = 7.0
	Train Epoch: 49 	Loss: 1.593006 Acc@1: 0.618472 (ε = 3.99, δ = 1e-05) for α = 7.0
	Test set:Loss: 1.647812 Acc@1: 0.603815 
	Train Epoch: 50 	Loss: 1.553073 Acc@1: 0.620344 (ε = 3.99, δ = 1e-05) for α = 7.0
	Train Epoch: 50 	Loss: 1.549440 Acc@1: 0.615565 (ε = 4.01, δ = 1e-05) for α = 6.9
	Train Epoch: 50 	Loss: 1.598558 Acc@1: 0.611751 (ε = 4.03, δ = 1e-05) for α = 6.9
	Test set:Loss: 1.647107 Acc@1: 0.610837 
	Train Epoch: 51 	Loss: 1.507868 Acc@1: 0.624826 (ε = 4.04, δ = 1e-05) for α = 6.9
	Train Epoch: 51 	Loss: 1.588208 Acc@1: 0.615701 (ε = 4.05, δ = 1e-05) for α = 6.9
	Train Epoch: 51 	Loss: 1.581273 Acc@1: 0.616511 (ε = 4.07, δ = 1e-05) for α = 6.9
	Test set:Loss: 1.658343 Acc@1: 0.611455 
	Train Epoch: 52 	Loss: 1.580804 Acc@1: 0.616923 (ε = 4.08, δ = 1e-05) for α = 6.9
	Train Epoch: 52 	Loss: 1.544188 Acc@1: 0.626108 (ε = 4.09, δ = 1e-05) for α = 6.8
	Train Epoch: 52 	Loss: 1.577384 Acc@1: 0.623941 (ε = 4.11, δ = 1e-05) for α = 6.8
	Test set:Loss: 1.629228 Acc@1: 0.607837 
	Train Epoch: 53 	Loss: 1.683345 Acc@1: 0.608371 (ε = 4.12, δ = 1e-05) for α = 6.8
	Train Epoch: 53 	Loss: 1.523903 Acc@1: 0.625981 (ε = 4.13, δ = 1e-05) for α = 6.8
	Train Epoch: 53 	Loss: 1.535527 Acc@1: 0.626720 (ε = 4.15, δ = 1e-05) for α = 6.8
	Test set:Loss: 1.647177 Acc@1: 0.610748 
	Train Epoch: 54 	Loss: 1.549922 Acc@1: 0.629428 (ε = 4.16, δ = 1e-05) for α = 6.8
	Train Epoch: 54 	Loss: 1.546133 Acc@1: 0.631440 (ε = 4.18, δ = 1e-05) for α = 6.7
	Train Epoch: 54 	Loss: 1.571734 Acc@1: 0.622832 (ε = 4.19, δ = 1e-05) for α = 6.7
	Test set:Loss: 1.623339 Acc@1: 0.611977 
	Train Epoch: 55 	Loss: 1.485376 Acc@1: 0.629944 (ε = 4.20, δ = 1e-05) for α = 6.7
	Train Epoch: 55 	Loss: 1.529420 Acc@1: 0.627074 (ε = 4.22, δ = 1e-05) for α = 6.7
	Train Epoch: 55 	Loss: 1.549217 Acc@1: 0.623641 (ε = 4.23, δ = 1e-05) for α = 6.7
	Test set:Loss: 1.630354 Acc@1: 0.612759 
	Train Epoch: 56 	Loss: 1.529036 Acc@1: 0.622695 (ε = 4.24, δ = 1e-05) for α = 6.7
	Train Epoch: 56 	Loss: 1.529726 Acc@1: 0.624282 (ε = 4.26, δ = 1e-05) for α = 6.6
	Train Epoch: 56 	Loss: 1.564565 Acc@1: 0.622008 (ε = 4.27, δ = 1e-05) for α = 6.6
	Test set:Loss: 1.625086 Acc@1: 0.611384 
	Train Epoch: 57 	Loss: 1.575161 Acc@1: 0.611765 (ε = 4.28, δ = 1e-05) for α = 6.6
	Train Epoch: 57 	Loss: 1.523955 Acc@1: 0.627168 (ε = 4.30, δ = 1e-05) for α = 6.6
	Train Epoch: 57 	Loss: 1.551553 Acc@1: 0.624496 (ε = 4.31, δ = 1e-05) for α = 6.6
	Test set:Loss: 1.633518 Acc@1: 0.613355 
	Train Epoch: 58 	Loss: 1.498187 Acc@1: 0.626087 (ε = 4.32, δ = 1e-05) for α = 6.6
	Train Epoch: 58 	Loss: 1.455974 Acc@1: 0.635891 (ε = 4.34, δ = 1e-05) for α = 6.5
	Train Epoch: 58 	Loss: 1.507540 Acc@1: 0.628091 (ε = 4.35, δ = 1e-05) for α = 6.5
	Test set:Loss: 1.634189 Acc@1: 0.612378 
	Train Epoch: 59 	Loss: 1.550743 Acc@1: 0.610193 (ε = 4.36, δ = 1e-05) for α = 6.5
	Train Epoch: 59 	Loss: 1.547839 Acc@1: 0.627800 (ε = 4.37, δ = 1e-05) for α = 6.5
	Train Epoch: 59 	Loss: 1.562599 Acc@1: 0.622680 (ε = 4.39, δ = 1e-05) for α = 6.5
	Test set:Loss: 1.634738 Acc@1: 0.612245 
	Train Epoch: 60 	Loss: 1.533873 Acc@1: 0.633053 (ε = 4.40, δ = 1e-05) for α = 6.5
	Train Epoch: 60 	Loss: 1.570383 Acc@1: 0.625685 (ε = 4.41, δ = 1e-05) for α = 6.5
	Train Epoch: 60 	Loss: 1.519211 Acc@1: 0.634803 (ε = 4.43, δ = 1e-05) for α = 6.4
	Test set:Loss: 1.631649 Acc@1: 0.613158 
test results
Base private model accuracy:  0.6132
              precision    recall  f1-score   support

         0.0       0.23      0.03      0.05       502
         1.0       0.06      0.00      0.01       502
         2.0       0.05      0.01      0.01       508
         3.0       0.03      0.00      0.00       492
         4.0       0.24      0.04      0.06       499
         5.0       0.51      0.70      0.59      2992
         6.0       0.75      0.74      0.75      3082
         7.0       0.61      0.62      0.62      2973
         8.0       0.66      0.77      0.71      3007
         9.0       0.61      0.73      0.66      2943

    accuracy                           0.61     17500
   macro avg       0.38      0.36      0.35     17500
weighted avg       0.56      0.61      0.57     17500

train results
Base private model accuracy:  0.6284803279621932
              precision    recall  f1-score   support

         0.0       0.27      0.03      0.06       422
         1.0       0.14      0.01      0.03       505
         2.0       0.14      0.02      0.04       496
         3.0       0.09      0.00      0.01       535
         4.0       0.21      0.04      0.07       521
         5.0       0.51      0.72      0.60      3054
         6.0       0.76      0.74      0.75      2967
         7.0       0.62      0.64      0.63      3021
         8.0       0.70      0.80      0.75      3028
         9.0       0.65      0.74      0.69      3014

    accuracy                           0.63     17563
   macro avg       0.41      0.38      0.36     17563
weighted avg       0.58      0.63      0.59     17563

NN model attack results: 
train acc: 0.6387702818104184
test acc: 0.5245714285714286
total acc: 0.5817767004135177
precision, recall: (0.5742067553735927, 0.6387702818104184)
epsilon, acc, train acc, mia, report, train report
[4.43477052649474, 0.6132, 0.6284803279621932, 0.5817767004135177, '              precision    recall  f1-score   support\n\n         0.0       0.23      0.03      0.05       502\n         1.0       0.06      0.00      0.01       502\n         2.0       0.05      0.01      0.01       508\n         3.0       0.03      0.00      0.00       492\n         4.0       0.24      0.04      0.06       499\n         5.0       0.51      0.70      0.59      2992\n         6.0       0.75      0.74      0.75      3082\n         7.0       0.61      0.62      0.62      2973\n         8.0       0.66      0.77      0.71      3007\n         9.0       0.61      0.73      0.66      2943\n\n    accuracy                           0.61     17500\n   macro avg       0.38      0.36      0.35     17500\nweighted avg       0.56      0.61      0.57     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.27      0.03      0.06       422\n         1.0       0.14      0.01      0.03       505\n         2.0       0.14      0.02      0.04       496\n         3.0       0.09      0.00      0.01       535\n         4.0       0.21      0.04      0.07       521\n         5.0       0.51      0.72      0.60      3054\n         6.0       0.76      0.74      0.75      2967\n         7.0       0.62      0.64      0.63      3021\n         8.0       0.70      0.80      0.75      3028\n         9.0       0.65      0.74      0.69      3014\n\n    accuracy                           0.63     17563\n   macro avg       0.41      0.38      0.36     17563\nweighted avg       0.58      0.63      0.59     17563\n']
experiment_number: 122
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-122.json
{'dataset': 'cifar', 'batch_size': 128, 'epochs': 60, 'noise_multiplier': 3.0, 'max_grad_norm': 10.0, 'lr': 0.1, 'delta': 1e-05, 'disable_dp': False, 'load_model': False, 'perform_aug': False, 'sampling_type': 'none', 'attack_model': 'nn', 'sampling_ratio': 0.5}
Files already downloaded and verified
Files already downloaded and verified
25000
[9. 5. 6. ... 5. 2. 0.]
[6. 8. 8. ... 8. 8. 9.]
(17699, 3, 32, 32)
(17500, 3, 32, 32)
(17699, 3, 32, 32)
(17699,)
	Train Epoch: 1 	Loss: 2.315204 Acc@1: 0.036984 (ε = 0.21, δ = 1e-05) for α = 57.0
	Train Epoch: 1 	Loss: 2.183509 Acc@1: 0.164996 (ε = 0.29, δ = 1e-05) for α = 56.0
	Train Epoch: 1 	Loss: 2.084855 Acc@1: 0.239539 (ε = 0.36, δ = 1e-05) for α = 54.0
	Test set:Loss: 2.449433 Acc@1: 0.391706 
	Train Epoch: 2 	Loss: 2.401173 Acc@1: 0.396501 (ε = 0.40, δ = 1e-05) for α = 51.0
	Train Epoch: 2 	Loss: 2.260658 Acc@1: 0.381697 (ε = 0.46, δ = 1e-05) for α = 45.0
	Train Epoch: 2 	Loss: 2.248775 Acc@1: 0.404735 (ε = 0.51, δ = 1e-05) for α = 42.0
	Test set:Loss: 2.150067 Acc@1: 0.428400 
	Train Epoch: 3 	Loss: 2.079822 Acc@1: 0.441926 (ε = 0.53, δ = 1e-05) for α = 40.0
	Train Epoch: 3 	Loss: 2.515081 Acc@1: 0.432419 (ε = 0.58, δ = 1e-05) for α = 37.0
	Train Epoch: 3 	Loss: 2.768548 Acc@1: 0.429687 (ε = 0.62, δ = 1e-05) for α = 35.0
	Test set:Loss: 2.588728 Acc@1: 0.483479 
	Train Epoch: 4 	Loss: 2.661417 Acc@1: 0.486376 (ε = 0.64, δ = 1e-05) for α = 34.0
	Train Epoch: 4 	Loss: 3.004938 Acc@1: 0.439531 (ε = 0.68, δ = 1e-05) for α = 33.0
	Train Epoch: 4 	Loss: 3.090508 Acc@1: 0.436148 (ε = 0.71, δ = 1e-05) for α = 31.0
	Test set:Loss: 2.969067 Acc@1: 0.382904 
	Train Epoch: 5 	Loss: 3.024354 Acc@1: 0.370851 (ε = 0.73, δ = 1e-05) for α = 31.0
	Train Epoch: 5 	Loss: 2.948575 Acc@1: 0.392032 (ε = 0.76, δ = 1e-05) for α = 29.0
	Train Epoch: 5 	Loss: 2.867889 Acc@1: 0.390210 (ε = 0.79, δ = 1e-05) for α = 28.0
	Test set:Loss: 2.635929 Acc@1: 0.375406 
	Train Epoch: 6 	Loss: 2.501075 Acc@1: 0.403790 (ε = 0.81, δ = 1e-05) for α = 28.0
	Train Epoch: 6 	Loss: 2.566680 Acc@1: 0.381086 (ε = 0.84, δ = 1e-05) for α = 27.0
	Train Epoch: 6 	Loss: 2.524007 Acc@1: 0.396478 (ε = 0.86, δ = 1e-05) for α = 26.0
	Test set:Loss: 2.269239 Acc@1: 0.400025 
	Train Epoch: 7 	Loss: 2.279918 Acc@1: 0.390208 (ε = 0.88, δ = 1e-05) for α = 26.0
	Train Epoch: 7 	Loss: 2.463152 Acc@1: 0.407233 (ε = 0.91, δ = 1e-05) for α = 25.0
	Train Epoch: 7 	Loss: 2.545387 Acc@1: 0.403953 (ε = 0.93, δ = 1e-05) for α = 25.0
	Test set:Loss: 2.240030 Acc@1: 0.391848 
	Train Epoch: 8 	Loss: 2.103390 Acc@1: 0.379452 (ε = 0.95, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.371183 Acc@1: 0.424901 (ε = 0.97, δ = 1e-05) for α = 24.0
	Train Epoch: 8 	Loss: 2.457053 Acc@1: 0.427929 (ε = 1.00, δ = 1e-05) for α = 23.0
	Test set:Loss: 2.456879 Acc@1: 0.429272 
	Train Epoch: 9 	Loss: 2.630807 Acc@1: 0.398582 (ε = 1.01, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.505910 Acc@1: 0.411986 (ε = 1.03, δ = 1e-05) for α = 23.0
	Train Epoch: 9 	Loss: 2.423139 Acc@1: 0.406423 (ε = 1.05, δ = 1e-05) for α = 22.0
	Test set:Loss: 2.297185 Acc@1: 0.379317 
	Train Epoch: 10 	Loss: 2.268193 Acc@1: 0.381093 (ε = 1.07, δ = 1e-05) for α = 22.0
	Train Epoch: 10 	Loss: 2.340240 Acc@1: 0.403207 (ε = 1.09, δ = 1e-05) for α = 21.0
	Train Epoch: 10 	Loss: 2.309007 Acc@1: 0.398807 (ε = 1.11, δ = 1e-05) for α = 21.0
	Test set:Loss: 2.286446 Acc@1: 0.395339 
	Train Epoch: 11 	Loss: 2.128783 Acc@1: 0.383838 (ε = 1.12, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.303287 Acc@1: 0.413253 (ε = 1.14, δ = 1e-05) for α = 21.0
	Train Epoch: 11 	Loss: 2.228974 Acc@1: 0.388722 (ε = 1.16, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.209192 Acc@1: 0.366732 
	Train Epoch: 12 	Loss: 2.274715 Acc@1: 0.341642 (ε = 1.17, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.233231 Acc@1: 0.352838 (ε = 1.19, δ = 1e-05) for α = 20.0
	Train Epoch: 12 	Loss: 2.231722 Acc@1: 0.351165 (ε = 1.22, δ = 1e-05) for α = 20.0
	Test set:Loss: 2.203300 Acc@1: 0.371020 
	Train Epoch: 13 	Loss: 2.176994 Acc@1: 0.384292 (ε = 1.23, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.277743 Acc@1: 0.386047 (ε = 1.24, δ = 1e-05) for α = 19.0
	Train Epoch: 13 	Loss: 2.295833 Acc@1: 0.369262 (ε = 1.26, δ = 1e-05) for α = 19.0
	Test set:Loss: 2.277999 Acc@1: 0.327982 
	Train Epoch: 14 	Loss: 2.344038 Acc@1: 0.331015 (ε = 1.27, δ = 1e-05) for α = 19.0
	Train Epoch: 14 	Loss: 2.233036 Acc@1: 0.337088 (ε = 1.29, δ = 1e-05) for α = 18.0
	Train Epoch: 14 	Loss: 2.282891 Acc@1: 0.342675 (ε = 1.31, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.267192 Acc@1: 0.350755 
	Train Epoch: 15 	Loss: 2.361031 Acc@1: 0.379209 (ε = 1.32, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.223831 Acc@1: 0.337320 (ε = 1.34, δ = 1e-05) for α = 18.0
	Train Epoch: 15 	Loss: 2.274998 Acc@1: 0.351842 (ε = 1.36, δ = 1e-05) for α = 18.0
	Test set:Loss: 2.204561 Acc@1: 0.340395 
	Train Epoch: 16 	Loss: 2.278231 Acc@1: 0.333333 (ε = 1.37, δ = 1e-05) for α = 18.0
	Train Epoch: 16 	Loss: 2.298763 Acc@1: 0.352864 (ε = 1.38, δ = 1e-05) for α = 17.0
	Train Epoch: 16 	Loss: 2.335686 Acc@1: 0.347872 (ε = 1.40, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.172381 Acc@1: 0.336984 
	Train Epoch: 17 	Loss: 2.191055 Acc@1: 0.349630 (ε = 1.41, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.205053 Acc@1: 0.309364 (ε = 1.43, δ = 1e-05) for α = 17.0
	Train Epoch: 17 	Loss: 2.227607 Acc@1: 0.317995 (ε = 1.44, δ = 1e-05) for α = 17.0
	Test set:Loss: 2.134013 Acc@1: 0.293559 
	Train Epoch: 18 	Loss: 1.991790 Acc@1: 0.264574 (ε = 1.45, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.078566 Acc@1: 0.323596 (ε = 1.47, δ = 1e-05) for α = 17.0
	Train Epoch: 18 	Loss: 2.140193 Acc@1: 0.322843 (ε = 1.49, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.232859 Acc@1: 0.322835 
	Train Epoch: 19 	Loss: 2.128654 Acc@1: 0.309556 (ε = 1.49, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.215261 Acc@1: 0.321415 (ε = 1.51, δ = 1e-05) for α = 16.0
	Train Epoch: 19 	Loss: 2.178994 Acc@1: 0.316556 (ε = 1.53, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.349475 Acc@1: 0.324723 
	Train Epoch: 20 	Loss: 2.306883 Acc@1: 0.312583 (ε = 1.53, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.156833 Acc@1: 0.301929 (ε = 1.55, δ = 1e-05) for α = 16.0
	Train Epoch: 20 	Loss: 2.114528 Acc@1: 0.308077 (ε = 1.57, δ = 1e-05) for α = 16.0
	Test set:Loss: 2.112447 Acc@1: 0.314275 
	Train Epoch: 21 	Loss: 2.052755 Acc@1: 0.326949 (ε = 1.58, δ = 1e-05) for α = 16.0
	Train Epoch: 21 	Loss: 2.155507 Acc@1: 0.294404 (ε = 1.59, δ = 1e-05) for α = 15.0
	Train Epoch: 21 	Loss: 2.154929 Acc@1: 0.305608 (ε = 1.61, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.266278 Acc@1: 0.318545 
	Train Epoch: 22 	Loss: 2.168633 Acc@1: 0.315353 (ε = 1.61, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.172049 Acc@1: 0.320775 (ε = 1.63, δ = 1e-05) for α = 15.0
	Train Epoch: 22 	Loss: 2.195484 Acc@1: 0.327568 (ε = 1.64, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.288509 Acc@1: 0.302519 
	Train Epoch: 23 	Loss: 2.221624 Acc@1: 0.324201 (ε = 1.65, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.164975 Acc@1: 0.295062 (ε = 1.67, δ = 1e-05) for α = 15.0
	Train Epoch: 23 	Loss: 2.240903 Acc@1: 0.315609 (ε = 1.68, δ = 1e-05) for α = 15.0
	Test set:Loss: 2.312689 Acc@1: 0.335322 
	Train Epoch: 24 	Loss: 2.360780 Acc@1: 0.330357 (ε = 1.69, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.230280 Acc@1: 0.317674 (ε = 1.70, δ = 1e-05) for α = 15.0
	Train Epoch: 24 	Loss: 2.265595 Acc@1: 0.330077 (ε = 1.72, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.355945 Acc@1: 0.344356 
	Train Epoch: 25 	Loss: 2.671505 Acc@1: 0.356436 (ε = 1.72, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.299569 Acc@1: 0.335116 (ε = 1.74, δ = 1e-05) for α = 14.0
	Train Epoch: 25 	Loss: 2.231824 Acc@1: 0.334797 (ε = 1.75, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.264246 Acc@1: 0.330084 
	Train Epoch: 26 	Loss: 2.867196 Acc@1: 0.348348 (ε = 1.76, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.343452 Acc@1: 0.315797 (ε = 1.77, δ = 1e-05) for α = 14.0
	Train Epoch: 26 	Loss: 2.214701 Acc@1: 0.314490 (ε = 1.79, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.148925 Acc@1: 0.320856 
	Train Epoch: 27 	Loss: 2.058243 Acc@1: 0.343348 (ε = 1.79, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.111081 Acc@1: 0.303427 (ε = 1.81, δ = 1e-05) for α = 14.0
	Train Epoch: 27 	Loss: 2.107955 Acc@1: 0.299233 (ε = 1.82, δ = 1e-05) for α = 14.0
	Test set:Loss: 2.306274 Acc@1: 0.270016 
	Train Epoch: 28 	Loss: 2.020322 Acc@1: 0.278409 (ε = 1.83, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.223082 Acc@1: 0.274294 (ε = 1.84, δ = 1e-05) for α = 14.0
	Train Epoch: 28 	Loss: 2.224200 Acc@1: 0.280069 (ε = 1.86, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.251293 Acc@1: 0.277501 
	Train Epoch: 29 	Loss: 2.288732 Acc@1: 0.315638 (ε = 1.86, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.153350 Acc@1: 0.310746 (ε = 1.88, δ = 1e-05) for α = 13.0
	Train Epoch: 29 	Loss: 2.192588 Acc@1: 0.298018 (ε = 1.89, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.178438 Acc@1: 0.292604 
	Train Epoch: 30 	Loss: 2.268415 Acc@1: 0.304348 (ε = 1.90, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.226931 Acc@1: 0.293475 (ε = 1.91, δ = 1e-05) for α = 13.0
	Train Epoch: 30 	Loss: 2.140410 Acc@1: 0.291892 (ε = 1.92, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.068196 Acc@1: 0.279532 
	Train Epoch: 31 	Loss: 1.934071 Acc@1: 0.291317 (ε = 1.93, δ = 1e-05) for α = 13.0
	Train Epoch: 31 	Loss: 2.219161 Acc@1: 0.300562 (ε = 1.94, δ = 1e-05) for α = 13.0
	Train Epoch: 31 	Loss: 2.181673 Acc@1: 0.293826 (ε = 1.95, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.148844 Acc@1: 0.308904 
	Train Epoch: 32 	Loss: 2.142617 Acc@1: 0.326501 (ε = 1.96, δ = 1e-05) for α = 13.0
	Train Epoch: 32 	Loss: 2.283649 Acc@1: 0.319871 (ε = 1.97, δ = 1e-05) for α = 13.0
	Train Epoch: 32 	Loss: 2.211017 Acc@1: 0.303266 (ε = 1.99, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.241711 Acc@1: 0.287027 
	Train Epoch: 33 	Loss: 2.394469 Acc@1: 0.301221 (ε = 1.99, δ = 1e-05) for α = 13.0
	Train Epoch: 33 	Loss: 2.242247 Acc@1: 0.298152 (ε = 2.01, δ = 1e-05) for α = 13.0
	Train Epoch: 33 	Loss: 2.219457 Acc@1: 0.305083 (ε = 2.02, δ = 1e-05) for α = 13.0
	Test set:Loss: 2.201283 Acc@1: 0.271702 
	Train Epoch: 34 	Loss: 2.032652 Acc@1: 0.300985 (ε = 2.02, δ = 1e-05) for α = 13.0
	Train Epoch: 34 	Loss: 2.243350 Acc@1: 0.309355 (ε = 2.04, δ = 1e-05) for α = 12.0
	Train Epoch: 34 	Loss: 2.298358 Acc@1: 0.310483 (ε = 2.05, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.203153 Acc@1: 0.278282 
	Train Epoch: 35 	Loss: 2.158214 Acc@1: 0.278008 (ε = 2.05, δ = 1e-05) for α = 12.0
	Train Epoch: 35 	Loss: 2.258162 Acc@1: 0.285208 (ε = 2.07, δ = 1e-05) for α = 12.0
	Train Epoch: 35 	Loss: 2.281616 Acc@1: 0.292159 (ε = 2.08, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.184264 Acc@1: 0.306054 
	Train Epoch: 36 	Loss: 2.033099 Acc@1: 0.326360 (ε = 2.08, δ = 1e-05) for α = 12.0
	Train Epoch: 36 	Loss: 2.158063 Acc@1: 0.316453 (ε = 2.10, δ = 1e-05) for α = 12.0
	Train Epoch: 36 	Loss: 2.167486 Acc@1: 0.315394 (ε = 2.11, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.325186 Acc@1: 0.290384 
	Train Epoch: 37 	Loss: 2.446378 Acc@1: 0.287129 (ε = 2.11, δ = 1e-05) for α = 12.0
	Train Epoch: 37 	Loss: 2.269196 Acc@1: 0.314951 (ε = 2.13, δ = 1e-05) for α = 12.0
	Train Epoch: 37 	Loss: 2.230557 Acc@1: 0.317615 (ε = 2.14, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.422794 Acc@1: 0.330545 
	Train Epoch: 38 	Loss: 2.184694 Acc@1: 0.339105 (ε = 2.14, δ = 1e-05) for α = 12.0
	Train Epoch: 38 	Loss: 2.256514 Acc@1: 0.317123 (ε = 2.16, δ = 1e-05) for α = 12.0
	Train Epoch: 38 	Loss: 2.180520 Acc@1: 0.307924 (ε = 2.17, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.179795 Acc@1: 0.325442 
	Train Epoch: 39 	Loss: 1.999541 Acc@1: 0.299401 (ε = 2.17, δ = 1e-05) for α = 12.0
	Train Epoch: 39 	Loss: 2.170577 Acc@1: 0.317535 (ε = 2.18, δ = 1e-05) for α = 12.0
	Train Epoch: 39 	Loss: 2.156143 Acc@1: 0.321151 (ε = 2.20, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.183446 Acc@1: 0.336122 
	Train Epoch: 40 	Loss: 2.031616 Acc@1: 0.332859 (ε = 2.20, δ = 1e-05) for α = 12.0
	Train Epoch: 40 	Loss: 2.141151 Acc@1: 0.326640 (ε = 2.21, δ = 1e-05) for α = 12.0
	Train Epoch: 40 	Loss: 2.122238 Acc@1: 0.329822 (ε = 2.23, δ = 1e-05) for α = 12.0
	Test set:Loss: 2.266836 Acc@1: 0.316995 
	Train Epoch: 41 	Loss: 2.021920 Acc@1: 0.351275 (ε = 2.23, δ = 1e-05) for α = 12.0
	Train Epoch: 41 	Loss: 2.143912 Acc@1: 0.318074 (ε = 2.24, δ = 1e-05) for α = 12.0
	Train Epoch: 41 	Loss: 2.098277 Acc@1: 0.329041 (ε = 2.26, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.165056 Acc@1: 0.331982 
	Train Epoch: 42 	Loss: 2.334564 Acc@1: 0.334274 (ε = 2.26, δ = 1e-05) for α = 10.9
	Train Epoch: 42 	Loss: 2.113311 Acc@1: 0.333002 (ε = 2.27, δ = 1e-05) for α = 10.9
	Train Epoch: 42 	Loss: 2.080990 Acc@1: 0.330219 (ε = 2.28, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.184317 Acc@1: 0.310533 
	Train Epoch: 43 	Loss: 2.093506 Acc@1: 0.316298 (ε = 2.29, δ = 1e-05) for α = 10.9
	Train Epoch: 43 	Loss: 2.142079 Acc@1: 0.323820 (ε = 2.30, δ = 1e-05) for α = 10.9
	Train Epoch: 43 	Loss: 2.128485 Acc@1: 0.327790 (ε = 2.31, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.164041 Acc@1: 0.326542 
	Train Epoch: 44 	Loss: 2.284973 Acc@1: 0.369327 (ε = 2.31, δ = 1e-05) for α = 10.9
	Train Epoch: 44 	Loss: 2.097053 Acc@1: 0.332548 (ε = 2.32, δ = 1e-05) for α = 10.9
	Train Epoch: 44 	Loss: 2.065165 Acc@1: 0.326495 (ε = 2.34, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.136979 Acc@1: 0.298982 
	Train Epoch: 45 	Loss: 2.027189 Acc@1: 0.314165 (ε = 2.34, δ = 1e-05) for α = 10.9
	Train Epoch: 45 	Loss: 2.094434 Acc@1: 0.314480 (ε = 2.35, δ = 1e-05) for α = 10.9
	Train Epoch: 45 	Loss: 2.077051 Acc@1: 0.319399 (ε = 2.36, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.108768 Acc@1: 0.324581 
	Train Epoch: 46 	Loss: 2.154415 Acc@1: 0.320117 (ε = 2.37, δ = 1e-05) for α = 10.9
	Train Epoch: 46 	Loss: 1.997335 Acc@1: 0.329391 (ε = 2.38, δ = 1e-05) for α = 10.9
	Train Epoch: 46 	Loss: 2.019514 Acc@1: 0.328883 (ε = 2.39, δ = 1e-05) for α = 10.9
	Test set:Loss: 2.057855 Acc@1: 0.304759 
	Train Epoch: 47 	Loss: 2.143026 Acc@1: 0.333333 (ε = 2.39, δ = 1e-05) for α = 10.8
	Train Epoch: 47 	Loss: 2.062475 Acc@1: 0.319284 (ε = 2.40, δ = 1e-05) for α = 10.8
	Train Epoch: 47 	Loss: 2.042306 Acc@1: 0.328290 (ε = 2.42, δ = 1e-05) for α = 10.8
	Test set:Loss: 2.039420 Acc@1: 0.334882 
	Train Epoch: 48 	Loss: 2.147779 Acc@1: 0.314483 (ε = 2.42, δ = 1e-05) for α = 10.7
	Train Epoch: 48 	Loss: 2.046822 Acc@1: 0.333046 (ε = 2.43, δ = 1e-05) for α = 10.7
	Train Epoch: 48 	Loss: 2.013461 Acc@1: 0.331901 (ε = 2.44, δ = 1e-05) for α = 10.7
	Test set:Loss: 2.036686 Acc@1: 0.331298 
	Train Epoch: 49 	Loss: 1.951911 Acc@1: 0.337094 (ε = 2.45, δ = 1e-05) for α = 10.6
	Train Epoch: 49 	Loss: 1.953387 Acc@1: 0.332071 (ε = 2.46, δ = 1e-05) for α = 10.6
	Train Epoch: 49 	Loss: 1.994528 Acc@1: 0.327012 (ε = 2.47, δ = 1e-05) for α = 10.6
	Test set:Loss: 2.092579 Acc@1: 0.335834 
	Train Epoch: 50 	Loss: 1.873257 Acc@1: 0.374294 (ε = 2.47, δ = 1e-05) for α = 10.5
	Train Epoch: 50 	Loss: 1.990647 Acc@1: 0.343763 (ε = 2.48, δ = 1e-05) for α = 10.5
	Train Epoch: 50 	Loss: 2.003363 Acc@1: 0.334503 (ε = 2.49, δ = 1e-05) for α = 10.5
	Test set:Loss: 2.049215 Acc@1: 0.315208 
	Train Epoch: 51 	Loss: 1.952576 Acc@1: 0.316891 (ε = 2.50, δ = 1e-05) for α = 10.5
	Train Epoch: 51 	Loss: 1.998625 Acc@1: 0.324309 (ε = 2.51, δ = 1e-05) for α = 10.4
	Train Epoch: 51 	Loss: 2.009391 Acc@1: 0.323516 (ε = 2.52, δ = 1e-05) for α = 10.4
	Test set:Loss: 2.037547 Acc@1: 0.334682 
	Train Epoch: 52 	Loss: 1.993577 Acc@1: 0.315278 (ε = 2.52, δ = 1e-05) for α = 10.4
	Train Epoch: 52 	Loss: 1.976131 Acc@1: 0.340948 (ε = 2.53, δ = 1e-05) for α = 10.3
	Train Epoch: 52 	Loss: 1.973075 Acc@1: 0.340490 (ε = 2.54, δ = 1e-05) for α = 10.3
	Test set:Loss: 2.030390 Acc@1: 0.341426 
	Train Epoch: 53 	Loss: 2.106449 Acc@1: 0.347120 (ε = 2.55, δ = 1e-05) for α = 10.3
	Train Epoch: 53 	Loss: 1.974394 Acc@1: 0.343532 (ε = 2.56, δ = 1e-05) for α = 10.2
	Train Epoch: 53 	Loss: 1.983766 Acc@1: 0.340666 (ε = 2.57, δ = 1e-05) for α = 10.2
	Test set:Loss: 2.024918 Acc@1: 0.341727 
	Train Epoch: 54 	Loss: 2.163665 Acc@1: 0.332865 (ε = 2.57, δ = 1e-05) for α = 10.2
	Train Epoch: 54 	Loss: 1.966780 Acc@1: 0.334601 (ε = 2.58, δ = 1e-05) for α = 10.2
	Train Epoch: 54 	Loss: 1.980177 Acc@1: 0.330745 (ε = 2.59, δ = 1e-05) for α = 10.1
	Test set:Loss: 2.035537 Acc@1: 0.341414 
	Train Epoch: 55 	Loss: 1.989298 Acc@1: 0.339463 (ε = 2.60, δ = 1e-05) for α = 10.1
	Train Epoch: 55 	Loss: 1.983554 Acc@1: 0.344009 (ε = 2.61, δ = 1e-05) for α = 10.1
	Train Epoch: 55 	Loss: 1.987086 Acc@1: 0.346020 (ε = 2.62, δ = 1e-05) for α = 10.0
	Test set:Loss: 2.055800 Acc@1: 0.341436 
	Train Epoch: 56 	Loss: 2.045836 Acc@1: 0.354978 (ε = 2.62, δ = 1e-05) for α = 10.0
	Train Epoch: 56 	Loss: 1.994385 Acc@1: 0.336268 (ε = 2.63, δ = 1e-05) for α = 10.0
	Train Epoch: 56 	Loss: 1.986837 Acc@1: 0.337956 (ε = 2.64, δ = 1e-05) for α = 10.0
	Test set:Loss: 2.031311 Acc@1: 0.340405 
	Train Epoch: 57 	Loss: 2.006176 Acc@1: 0.340116 (ε = 2.65, δ = 1e-05) for α = 10.0
	Train Epoch: 57 	Loss: 1.973470 Acc@1: 0.340819 (ε = 2.66, δ = 1e-05) for α = 9.9
	Train Epoch: 57 	Loss: 1.995515 Acc@1: 0.339074 (ε = 2.67, δ = 1e-05) for α = 9.9
	Test set:Loss: 2.025453 Acc@1: 0.344264 
	Train Epoch: 58 	Loss: 1.994875 Acc@1: 0.354793 (ε = 2.67, δ = 1e-05) for α = 9.9
	Train Epoch: 58 	Loss: 2.026899 Acc@1: 0.337560 (ε = 2.68, δ = 1e-05) for α = 9.8
	Train Epoch: 58 	Loss: 1.985309 Acc@1: 0.346561 (ε = 2.69, δ = 1e-05) for α = 9.8
	Test set:Loss: 2.035991 Acc@1: 0.343280 
	Train Epoch: 59 	Loss: 2.011786 Acc@1: 0.319838 (ε = 2.70, δ = 1e-05) for α = 9.8
	Train Epoch: 59 	Loss: 2.003918 Acc@1: 0.342104 (ε = 2.71, δ = 1e-05) for α = 9.8
	Train Epoch: 59 	Loss: 2.005175 Acc@1: 0.346231 (ε = 2.72, δ = 1e-05) for α = 9.7
	Test set:Loss: 2.034695 Acc@1: 0.344508 
	Train Epoch: 60 	Loss: 2.003750 Acc@1: 0.327586 (ε = 2.72, δ = 1e-05) for α = 9.7
	Train Epoch: 60 	Loss: 1.984843 Acc@1: 0.344105 (ε = 2.73, δ = 1e-05) for α = 9.7
	Train Epoch: 60 	Loss: 2.021250 Acc@1: 0.343957 (ε = 2.74, δ = 1e-05) for α = 9.7
	Test set:Loss: 2.034318 Acc@1: 0.344375 
test results
Base private model accuracy:  0.3443428571428571
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       502
         1.0       0.00      0.00      0.00       502
         2.0       0.00      0.00      0.00       508
         3.0       0.00      0.00      0.00       492
         4.0       0.00      0.00      0.00       499
         5.0       0.30      0.18      0.23      2992
         6.0       0.27      0.77      0.40      3082
         7.0       0.18      0.01      0.01      2973
         8.0       0.57      0.54      0.55      3007
         9.0       0.37      0.50      0.42      2943

    accuracy                           0.34     17500
   macro avg       0.17      0.20      0.16     17500
weighted avg       0.29      0.34      0.28     17500

train results
Base private model accuracy:  0.3523927905531386
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       493
         1.0       0.00      0.00      0.00       450
         2.0       0.00      0.00      0.00       483
         3.0       0.27      0.01      0.01       509
         4.0       0.00      0.00      0.00       482
         5.0       0.30      0.19      0.24      3012
         6.0       0.27      0.77      0.40      2985
         7.0       0.20      0.01      0.02      3093
         8.0       0.59      0.55      0.57      3004
         9.0       0.40      0.52      0.45      3188

    accuracy                           0.35     17699
   macro avg       0.20      0.21      0.17     17699
weighted avg       0.31      0.35      0.29     17699

NN model attack results: 
train acc: 0.7228813559322034
test acc: 0.27
total acc: 0.49772727272727274
precision, recall: (0.5003910833007431, 0.7228813559322034)
epsilon, acc, train acc, mia, report, train report
[2.742785014811625, 0.3443428571428571, 0.3523927905531386, 0.49772727272727274, '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       502\n         1.0       0.00      0.00      0.00       502\n         2.0       0.00      0.00      0.00       508\n         3.0       0.00      0.00      0.00       492\n         4.0       0.00      0.00      0.00       499\n         5.0       0.30      0.18      0.23      2992\n         6.0       0.27      0.77      0.40      3082\n         7.0       0.18      0.01      0.01      2973\n         8.0       0.57      0.54      0.55      3007\n         9.0       0.37      0.50      0.42      2943\n\n    accuracy                           0.34     17500\n   macro avg       0.17      0.20      0.16     17500\nweighted avg       0.29      0.34      0.28     17500\n', '              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00       493\n         1.0       0.00      0.00      0.00       450\n         2.0       0.00      0.00      0.00       483\n         3.0       0.27      0.01      0.01       509\n         4.0       0.00      0.00      0.00       482\n         5.0       0.30      0.19      0.24      3012\n         6.0       0.27      0.77      0.40      2985\n         7.0       0.20      0.01      0.02      3093\n         8.0       0.59      0.55      0.57      3004\n         9.0       0.40      0.52      0.45      3188\n\n    accuracy                           0.35     17699\n   macro avg       0.20      0.21      0.17     17699\nweighted avg       0.31      0.35      0.29     17699\n']
experiment_number: 123
dumped results to /homes/al5217/adversarial-robustness-toolbox/examples/cifar/none/test_results-123.json
Tue Jun  8 16:30:14 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |
| N/A   47C    P0    31W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 16:30:14 up 33 days, 10:06,  2 users,  load average: 2.43, 2.52, 2.51
